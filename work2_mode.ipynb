{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "90ad95fc",
    "language": "markdown"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/work2_basemode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "ae9dfa31",
    "language": "markdown"
   },
   "source": [
    "# 翼状胬肉区域分割模型\n",
    "\n",
    "这是项目的第二个任务：实现对眼部裂隙灯检查图片中翼状胬肉区域的精准分割。我们将使用U-Net模型解决这一问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "c8b6c127",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn.functional\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        !wget -O simhei.ttf \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "patch_size = 512  # 定义 patch 大小\n",
    "patch_stride = patch_size // 2 # 定义训练时的步长（产生50%重叠）\n",
    "predict_stride = patch_size // 2 # 定义预测时的步长（产生50%重叠）\n",
    "target_input_size = (patch_size, patch_size) # U-Net的输入尺寸应为 patch_size\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# ================== 掩码输出路径 ================\n",
    "output_mask_dir = r\"f:/mask\"\n",
    "# colab路径\n",
    "output_maskfiles_colab = \"/content/mask\"\n",
    "# Kaggle路径\n",
    "output_maskfiles_kaggle = \"/kaggle/working/mask\"\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "7f00c3ad",
    "language": "markdown"
   },
   "source": [
    "# 读取和准备数据\n",
    "我们需要读取原始图像和对应的分割标签（mask）。标签中像素值为128的区域表示翼状胬肉，像素值为0的区域表示背景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "64589f50",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "        BASE_PATCH_DIR = \"/content/train_patches_gpu\"\n",
    "\n",
    "        output_mask_dir = output_maskfiles_colab\n",
    "        print(f\"Colab 环境：验证结果将验证压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "        BASE_PATCH_DIR = \"/kaggle/working/train_patches_gpu\"\n",
    "        \n",
    "        output_mask_dir = output_maskfiles_kaggle\n",
    "        print(f\"Kaggle 环境：验证结果将压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "    BASE_PATCH_DIR = \"data/train_patches_gpu\"\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和分割掩码\n",
    "class PterygiumSegmentationDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None, mask_transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        :param mask_transform: 掩码变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        # 只保留翼状胬肉样本（标签1和2）\n",
    "        self.labels_df = self.labels_df[self.labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和分割掩码\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应掩码张量\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        \n",
    "        # 加载图像\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 加载分割掩码\n",
    "        mask_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}_label.png\")\n",
    "        mask = Image.open(mask_path).convert(\"RGB\")  # 转换为灰度图\n",
    "        \n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 应用掩码变换\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        else:\n",
    "            # 将掩码转换为张量，并二值化（翼状胬肉区域为1，背景为0）\n",
    "            mask = torch.from_numpy(np.array(mask))\n",
    "            mask = mask.float() / 255.0\n",
    "            mask = (mask > 0.2).float()  # 二值化，阈值设为0.2以捕获可能的淡色区域\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# 离线Patching函数 (利用GPU加速)\n",
    "用于将原始的大尺寸图像和对应的分割掩码离线切割成指定大小的Patches，并保存到磁盘。\n",
    "该函数会尝试将大图加载到GPU进行裁剪和过滤，以加速处理过程（需要注意GPU显存）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 配置参数 ---\n",
    "MIN_FOREGROUND_RATIO = 0 #0.01 # (可选) 保留的Mask Patch中前景像素(128)最小比例，设为0则不过滤\n",
    "\n",
    "# --- 离线 Patching 函数 ---\n",
    "def create_offline_patches_gpu(\n",
    "    input_image_dir,\n",
    "    label_file_path,\n",
    "    output_image_patch_dir,\n",
    "    output_mask_patch_dir,\n",
    "    patch_size,\n",
    "    stride,\n",
    "    device,\n",
    "    min_foreground_ratio=0\n",
    "    ):\n",
    "    \"\"\"\n",
    "    离线创建图像和掩码的Patches，尝试使用GPU加速，并根据标签文件筛选图像。\n",
    "\n",
    "    Args:\n",
    "        input_image_dir (str): 包含原始图像子文件夹 (如 0001, 0002...) 的目录。\n",
    "        label_file_path (str): 包含图像标签的Excel文件路径。\n",
    "        output_image_patch_dir (str): 保存图像Patch的目录。\n",
    "        output_mask_patch_dir (str or None): 保存掩码Patch的目录。如果为 None，则不处理或保存掩码。\n",
    "        patch_size (int): Patch的边长。\n",
    "        stride (int): 切割Patch时的步长。\n",
    "        device (torch.device): 用于计算的设备 (cuda or cpu)。\n",
    "        min_foreground_ratio (float): 保留的Mask Patch中前景像素(值>0)的最小比例。设为0则不过滤。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (成功处理的大图数量, 创建的Patch对数量)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if not output_mask_patch_dir:\n",
    "        raise ValueError(\"output_mask_patch_dir 必须提供，因为需要为健康样本生成零掩码。\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_image_patch_dir, exist_ok=True)\n",
    "        os.makedirs(output_mask_patch_dir, exist_ok=True) # 掩码目录也必须创建\n",
    "    except Exception as e:\n",
    "        print(f\"创建输出目录时出错: {e}\")\n",
    "        return 0, 0 # 无法创建目录则退出\n",
    "\n",
    "    # 读取标签文件\n",
    "    try:\n",
    "        labels_df = pd.read_excel(label_file_path)\n",
    "        # 包含所有样本 (Pterygium >= 0)\n",
    "        all_samples_df = labels_df.reset_index(drop=True)\n",
    "        # 获取需要处理的图像文件夹名称和对应的标签\n",
    "        image_folders_info = all_samples_df[['Image', 'Pterygium']].apply(\n",
    "            lambda row: (f\"{int(row['Image']):04d}\", int(row['Pterygium'])), axis=1\n",
    "        ).tolist()\n",
    "        print(f\"从 {os.path.basename(label_file_path)} 读取标签，找到 {len(image_folders_info)} 个样本（包括健康和有病）进行Patching。\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 标签文件未找到 {label_file_path}。无法进行Patching。\")\n",
    "        return 0, 0\n",
    "    except Exception as e:\n",
    "        print(f\"读取或处理标签文件 {label_file_path} 时出错: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "    processed_files = 0\n",
    "    created_patches = 0\n",
    "\n",
    "    # 修改 TQDM 描述\n",
    "    for folder_name, pterygium_label in tqdm(image_folders_info, desc=\"处理所有样本 (健康+有病)\"):\n",
    "        image_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}.png\")\n",
    "        mask_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}_label.png\")\n",
    "\n",
    "        # --- 检查图像文件 ---\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"警告: 图像文件未找到 {image_path}，跳过文件夹 {folder_name}。\")\n",
    "            continue\n",
    "\n",
    "        # --- 处理掩码路径和加载 ---\n",
    "        is_healthy = (pterygium_label == 0)\n",
    "        mask_pil = None\n",
    "        mask_tensor_gpu = None\n",
    "\n",
    "        if not is_healthy: # 如果是有病样本\n",
    "            if not os.path.exists(mask_path):\n",
    "                # 对于有病样本，掩码必须存在\n",
    "                print(f\"警告: 有病样本 {folder_name} (Pterygium={pterygium_label}) 的掩码文件未找到 {mask_path}，跳过。\")\n",
    "                continue\n",
    "            try:\n",
    "                mask_pil = Image.open(mask_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"加载有病样本 {folder_name} 的掩码时出错: {e}，跳过。\")\n",
    "                continue\n",
    "        # else: # 如果是健康样本，mask_pil 保持为 None，后面会创建零掩码\n",
    "\n",
    "        # --- 加载图像 ---\n",
    "        try:\n",
    "            img_pil = Image.open(image_path).convert('RGB')\n",
    "            img_w, img_h = img_pil.size\n",
    "\n",
    "            # 如果加载了掩码 (即有病样本)，检查尺寸是否匹配\n",
    "            if mask_pil:\n",
    "                mask_w, mask_h = mask_pil.size\n",
    "                if img_w != mask_w or img_h != mask_h:\n",
    "                    print(f\"警告: 图像和掩码尺寸不匹配 {folder_name}，跳过。 ({img_w}x{img_h} vs {mask_w}x{mask_h})\")\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"加载图像 {image_path} 时出错: {e}，跳过文件夹 {folder_name}。\")\n",
    "            continue\n",
    "\n",
    "        # --- 移至 GPU ---\n",
    "        try:\n",
    "            img_tensor_gpu = F.to_tensor(img_pil).to(device) # (3, H, W)\n",
    "\n",
    "            if mask_pil: # 如果是有病样本，处理真实掩码\n",
    "                mask_np_rgb = np.array(mask_pil)\n",
    "                mask_binary = (mask_np_rgb[:, :, 0] == 128).astype(np.float32) # 前景 = 1 if R == 128\n",
    "                mask_tensor_gpu = torch.from_numpy(mask_binary).unsqueeze(0).to(device) # (1, H, W)\n",
    "            # else: # 如果是健康样本，mask_tensor_gpu 保持为 None，将在 Patch 循环中创建零掩码\n",
    "\n",
    "        except RuntimeError as e: # 显存不足处理\n",
    "            print(f\"\\n错误: 将图像/掩码 {folder_name} 移至GPU时出错 (可能显存不足): {e}\")\n",
    "            print(\"尝试在CPU上处理此图像...\")\n",
    "            device_fallback = torch.device(\"cpu\")\n",
    "            img_tensor_gpu = F.to_tensor(img_pil).to(device_fallback)\n",
    "            if mask_pil:\n",
    "                mask_np_rgb = np.array(mask_pil)\n",
    "                mask_binary = (mask_np_rgb[:, :, 0] == 128).astype(np.float32)\n",
    "                mask_tensor_gpu = torch.from_numpy(mask_binary).unsqueeze(0).to(device_fallback)\n",
    "            # 对于健康样本，无需特殊处理 CPU fallback\n",
    "\n",
    "        # --- Patch 裁剪与保存 ---\n",
    "        patch_count_for_image = 0\n",
    "        for y in range(0, img_h - patch_size + 1, stride):\n",
    "            for x in range(0, img_w - patch_size + 1, stride):\n",
    "                # --- 裁剪图像 Patch ---\n",
    "                img_patch_gpu = img_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "                img_patch_cpu = img_patch_gpu.cpu()\n",
    "                img_patch_pil = F.to_pil_image(img_patch_cpu)\n",
    "\n",
    "                # --- 处理掩码 Patch ---\n",
    "                mask_patch_cpu = None\n",
    "                if mask_tensor_gpu is not None: # 如果是有病样本，裁剪真实掩码\n",
    "                    mask_patch_gpu = mask_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "                    # !!! 注意：如果 min_foreground_ratio > 0，健康样本永远无法通过过滤 !!!\n",
    "                    # 因此，如果决定加入健康样本，min_foreground_ratio 必须为 0\n",
    "                    # if min_foreground_ratio > 0: # 理论上这里应为 0\n",
    "                    #     foreground_ratio = torch.mean(mask_patch_gpu)\n",
    "                    #     if foreground_ratio < min_foreground_ratio:\n",
    "                    #         continue\n",
    "\n",
    "                    mask_patch_cpu = mask_patch_gpu.cpu() # (1, P, P), 值 0 或 1\n",
    "\n",
    "                else: # 如果是健康样本，创建全零掩码 Patch\n",
    "                    # 创建一个全零的 CPU 张量\n",
    "                    mask_patch_cpu = torch.zeros((1, patch_size, patch_size), dtype=torch.float32)\n",
    "\n",
    "                # --- 保存图像 Patch ---\n",
    "                patch_filename = f\"{folder_name}_y{y}_x{x}.png\"\n",
    "                img_save_path = os.path.join(output_image_patch_dir, patch_filename)\n",
    "                img_patch_pil.save(img_save_path)\n",
    "\n",
    "                # --- 保存掩码 Patch (现在健康样本也有零掩码了) ---\n",
    "                # 将 0/1 的 mask tensor 转换回 (128,0,0) 或 (0,0,0) 的 PIL RGB 图\n",
    "                mask_patch_np = (mask_patch_cpu.squeeze().numpy() * 128).astype(np.uint8)\n",
    "                zeros_channel = np.zeros_like(mask_patch_np)\n",
    "                mask_rgb_array = np.stack((mask_patch_np, zeros_channel, zeros_channel), axis=-1)\n",
    "                mask_patch_pil = Image.fromarray(mask_rgb_array, mode='RGB')\n",
    "\n",
    "                mask_save_path = os.path.join(output_mask_patch_dir, patch_filename)\n",
    "                mask_patch_pil.save(mask_save_path)\n",
    "\n",
    "                created_patches += 1\n",
    "                patch_count_for_image += 1\n",
    "\n",
    "        # --- 清理 GPU 内存 ---\n",
    "        del img_tensor_gpu\n",
    "        if mask_tensor_gpu is not None: del mask_tensor_gpu\n",
    "        # 清理循环变量以防万一\n",
    "        if 'img_patch_gpu' in locals(): del img_patch_gpu\n",
    "        if 'mask_patch_gpu' in locals() and mask_patch_gpu is not None: del mask_patch_gpu\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        processed_files += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"离线Patching完成！\")\n",
    "    # 修改打印信息\n",
    "    print(f\"成功处理的大图数量: {processed_files} / {len(image_folders_info)}\")\n",
    "    print(f\"总共创建 Patch 对数量: {created_patches}\")\n",
    "    print(f\"总耗时: {end_time - start_time:.2f} 秒\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    return processed_files, created_patches\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"计算文件夹的总大小（字节）\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "\n",
    "# 执行离线Patching\n",
    "调用函数开始处理\n",
    "如果输出目录已存在且包含文件，你可能想先清空或跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 路径设置 ---\n",
    "if os.path.exists(\"/kaggle/input/pterygium/train/\"):\n",
    "    INPUT_IMAGE_DIR = \"/kaggle/input/pterygium/train/train\" # 包含0001, 0002等子文件夹\n",
    "    OUTPUT_PATCH_DIR = \"/kaggle/working/train_patches\"\n",
    "elif 'google.colab' in sys.modules:\n",
    "    INPUT_IMAGE_DIR = \"/content/trains/train\" # 解压后的路径\n",
    "    OUTPUT_PATCH_DIR = \"/content/train_patches\"\n",
    "elif os.name == 'nt':\n",
    "    INPUT_IMAGE_DIR = \"f:/train\" # 包含0001, 0002等子文件夹\n",
    "    OUTPUT_PATCH_DIR = \"f:/train_patches\"\n",
    "else:\n",
    "    assert False, \"根据你的环境修改输入和输出路径\"\n",
    "    INPUT_IMAGE_DIR = \"data/train/train\"\n",
    "    OUTPUT_PATCH_DIR = \"data/train_patches\"\n",
    "\n",
    "OUTPUT_IMAGE_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"images\")\n",
    "OUTPUT_MASK_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"masks\")\n",
    "\n",
    "print(f\"使用设备: {device}\")\n",
    "print(f\"输入图像目录: {INPUT_IMAGE_DIR}\")\n",
    "print(f\"输出 Patch 目录: {OUTPUT_PATCH_DIR}\")\n",
    "print(f\"Patch 大小: {patch_size}x{patch_size}\")\n",
    "print(f\"步长: {patch_stride}\")\n",
    "print(f\"最小前景比例阈值: {MIN_FOREGROUND_RATIO}\")\n",
    "\n",
    "run_patching = True\n",
    "patch_count = 0\n",
    "# 检查输出目录是否存在\n",
    "if os.path.exists(OUTPUT_PATCH_DIR):\n",
    "    print(f\"警告：输出 Patch 目录 {OUTPUT_PATCH_DIR} 已存在。\")\n",
    "    try:\n",
    "        # 计算文件夹大小 (GB)\n",
    "        folder_size_gb = get_folder_size(OUTPUT_PATCH_DIR) / (1024**3)\n",
    "        print(f\"目录大小约为 {folder_size_gb:.2f} GB。\")\n",
    "\n",
    "        # 检查大小是否超过阈值\n",
    "        if folder_size_gb > 3.0:\n",
    "            print(\"目录大小超过 3GB，认为缓存有效，将跳过 Patching 步骤。\")\n",
    "            run_patching = False # 不需要执行 Patching\n",
    "            # 尝试统计现有 patches 数量，以备后续使用\n",
    "            try:\n",
    "                existing_patches = glob.glob(os.path.join(OUTPUT_IMAGE_PATCH_DIR, \"*.png\"))\n",
    "                patch_count = len(existing_patches)\n",
    "                print(f\"使用缓存目录中的 {patch_count} 个现有 patches。\")\n",
    "            except Exception as e:\n",
    "                print(f\"无法统计缓存目录中的文件，将 patch_count 设为 0。错误: {e}\")\n",
    "                patch_count = 0\n",
    "        else:\n",
    "            print(\"目录大小未达 3GB，缓存文件不完整或过小。将删除旧缓存并重新生成。\")\n",
    "            shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "    except Exception as e:\n",
    "        print(f\"检查目录大小或删除目录时出错: {e}。将尝试重新生成 Patch。\")\n",
    "        try:\n",
    "            if os.path.exists(OUTPUT_PATCH_DIR):\n",
    "                shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "        except Exception as del_e:\n",
    "            print(f\"删除目录 {OUTPUT_PATCH_DIR} 时再次出错: {del_e}\")\n",
    "else:\n",
    "    print(f\"输出 Patch 目录 {OUTPUT_PATCH_DIR} 不存在，将创建并执行 Patching。\")\n",
    "\n",
    "if run_patching:\n",
    "    print(f\"\\n准备执行离线 Patching，确保输出目录 {OUTPUT_PATCH_DIR} 及其子目录存在...\")\n",
    "    # 确保目标目录存在 (create_offline_patches_gpu 内部也会创建子目录)\n",
    "    # 但在这里创建父目录是个好习惯\n",
    "    os.makedirs(OUTPUT_PATCH_DIR, exist_ok=True)\n",
    "    # 如果之前删除了，子目录 image/mask 需要在函数内创建\n",
    "\n",
    "    print(\"\\n开始执行离线 Patching...\")\n",
    "    processed_count, patch_count = create_offline_patches_gpu(\n",
    "        input_image_dir=INPUT_IMAGE_DIR,\n",
    "        label_file_path=label_file,             # 传入标签文件\n",
    "        output_image_patch_dir=OUTPUT_IMAGE_PATCH_DIR, # 函数内部会创建 images 子目录\n",
    "        output_mask_patch_dir=OUTPUT_MASK_PATCH_DIR,   # 函数内部会创建 masks 子目录\n",
    "        patch_size=patch_size,\n",
    "        stride=patch_stride,                    # 使用训练步长\n",
    "        device=device,\n",
    "        min_foreground_ratio=MIN_FOREGROUND_RATIO\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nPatching 步骤已跳过（使用有效缓存）。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 验证生成的Patches\n",
    "随机抽查几个生成的图像和掩码Patch，确保它们是对应的并且格式正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_patches(image_patch_dir, mask_patch_dir, num_samples=5):\n",
    "    image_patches = glob.glob(os.path.join(image_patch_dir, \"*.png\"))\n",
    "    if not image_patches:\n",
    "        print(\"错误: 找不到生成的图像Patches。\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n随机抽查 {num_samples} 个生成的Patch对...\")\n",
    "    random_samples = random.sample(image_patches, min(num_samples, len(image_patches)))\n",
    "\n",
    "    fig, axes = plt.subplots(len(random_samples), 2, figsize=(8, 4 * len(random_samples)))\n",
    "    if len(random_samples) == 1: # 处理只有一个样本的情况\n",
    "        axes = axes.reshape(1, 2)\n",
    "\n",
    "    for i, img_path in enumerate(random_samples):\n",
    "        base_name = os.path.basename(img_path)\n",
    "        mask_path = os.path.join(mask_patch_dir, base_name)\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"错误: 找不到对应的掩码Patch {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        img_patch = Image.open(img_path)\n",
    "        mask_patch = Image.open(mask_path)\n",
    "\n",
    "        axes[i, 0].imshow(img_patch)\n",
    "        axes[i, 0].set_title(f\"图像 Patch:\\n{base_name}\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(mask_patch, cmap='gray')\n",
    "        axes[i, 1].set_title(f\"掩码 Patch (0/128):\\n{base_name}\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 执行验证\n",
    "try:\n",
    "    verify_patches(OUTPUT_IMAGE_PATCH_DIR, OUTPUT_MASK_PATCH_DIR, num_samples=5)\n",
    "except:\n",
    "    print(\"未生成任何Patch，跳过验证。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "9d732b67",
    "language": "markdown"
   },
   "source": [
    "# 创建数据加载器\n",
    "设置训练和验证数据加载器，包括数据增强策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "2ba9d65a",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class PterygiumSegDataset(Dataset):\n",
    "    def __init__(self, image_patch_dir, mask_patch_dir, file_list=None, augment=True):\n",
    "            \"\"\"\n",
    "            初始化数据集 (加载离线 Patches)\n",
    "            :param image_patch_dir: 包含图像 patch 文件的目录\n",
    "            :param mask_patch_dir: 包含对应掩码 patch 文件的目录\n",
    "            :param file_list: (可选) 一个文件名列表，只加载这些文件。如果为 None，加载目录下所有文件。\n",
    "            :param augment: 是否应用在线数据增强\n",
    "            \"\"\"\n",
    "            self.image_patch_dir = image_patch_dir\n",
    "            self.mask_patch_dir = mask_patch_dir\n",
    "            self.augment = augment\n",
    "    \n",
    "            # 获取 patch 的文件名列表\n",
    "            if file_list is None:\n",
    "                self.image_filenames = sorted([\n",
    "                    f for f in os.listdir(image_patch_dir)\n",
    "                    if os.path.isfile(os.path.join(image_patch_dir, f)) and f.endswith('.png')\n",
    "                ])\n",
    "            else:\n",
    "                self.image_filenames = sorted([f for f in file_list if f.endswith('.png')]) # 使用提供的列表\n",
    "\n",
    "            if not self.image_filenames:\n",
    "                # 检查是否是因为目录不存在或为空\n",
    "                if not os.path.isdir(image_patch_dir):\n",
    "                    raise FileNotFoundError(f\"图像 patch 目录不存在: {image_patch_dir}\")\n",
    "                elif not os.listdir(image_patch_dir) and file_list is None:\n",
    "                    print(f\"警告: 目录 {image_patch_dir} 为空。\")\n",
    "                    # Dataset 将为空，len() == 0\n",
    "                elif file_list is not None and not self.image_filenames:\n",
    "                    print(f\"警告: 提供的 file_list 为空或不包含 .png 文件。\")\n",
    "                else:\n",
    "                    # 目录存在但 filtered list 为空\n",
    "                    print(f\"警告: 在目录 {image_patch_dir} 中未找到匹配的 .png 文件 (可能检查 file_list)。\")\n",
    "    \n",
    "            # 定义图像标准化 (这个总是在最后应用)\n",
    "            self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            print(f\"数据集初始化: 找到 {len(self.image_filenames)} 个 patches in {image_patch_dir}\" + (f\" (来自 file_list)\" if file_list is not None else \"\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本的数量 (即 patch 的数量)\"\"\"\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像 patch 和 掩码 patch\n",
    "        :param idx: 索引\n",
    "        :return: 图像 patch 张量和对应掩码 patch 张量\n",
    "        \"\"\"\n",
    "        # 获取文件名\n",
    "        patch_filename = self.image_filenames[idx]\n",
    "        \n",
    "        # 构建完整路径\n",
    "        img_path = os.path.join(self.image_patch_dir, patch_filename)\n",
    "        mask_path = os.path.join(self.mask_patch_dir, patch_filename)\n",
    "\n",
    "        # 加载图像和掩码 patch (PIL Images)\n",
    "        try:\n",
    "            image_patch = Image.open(img_path).convert(\"RGB\")\n",
    "            mask_patch = Image.open(mask_path).convert(\"RGB\") # 掩码是 (128,0,0)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 文件未找到 {img_path} 或 {mask_path}\")\n",
    "            # 返回一个虚拟数据或引发错误\n",
    "            dummy_size = (3, 256, 256) # 假设 patch size 是 256x256，如果不同需要修改\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "        except Exception as e:\n",
    "            print(f\"加载 patch 时出错 {patch_filename}: {e}\")\n",
    "            # 返回虚拟数据\n",
    "            dummy_size = (3, 256, 256)\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "\n",
    "\n",
    "        # --- 在线数据增强 (如果启用) ---\n",
    "        if self.augment:\n",
    "            # 随机水平翻转 (同时应用到图像和掩码)\n",
    "            if random.random() < 0.5:\n",
    "                image_patch = F.hflip(image_patch)\n",
    "                mask_patch = F.hflip(mask_patch)\n",
    "            \n",
    "            # 随机旋转 (轻微, 同时应用) - 可选\n",
    "            # if random.random() < 0.3: # 以一定概率旋转\n",
    "            #    angle = random.uniform(-10, 10)\n",
    "            #    image_patch = F.rotate(image_patch, angle, interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "            #    mask_patch = F.rotate(mask_patch, angle, interpolation=transforms.InterpolationMode.NEAREST) # 掩码用最近邻\n",
    "\n",
    "            # 颜色抖动 (只应用到图像) - 可选\n",
    "            # if random.random() < 0.5:\n",
    "            #    image_patch = transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05)(image_patch)\n",
    "            \n",
    "            # 其他增强... (如随机仿射变换等, 注意同时应用到图像和掩码)\n",
    "\n",
    "        # --- 转换为 Tensor ---\n",
    "        image_tensor = F.to_tensor(image_patch)\n",
    "        \n",
    "        # --- 掩码处理：转换为单通道二值Tensor ---\n",
    "        # 将 PIL Mask 转换为 NumPy array (H, W, C)\n",
    "        mask_np = np.array(mask_patch)\n",
    "        # 检查红色通道是否为 128 来确定翼状胬肉区域\n",
    "        # mask_binary 的形状将是 (H, W)，值为 True/False\n",
    "        mask_binary = (mask_np[:, :, 0] == 128)\n",
    "        # 转换为 float32 类型的 0.0 或 1.0\n",
    "        mask_np_float = mask_binary.astype(np.float32)\n",
    "        # 转换为 PyTorch Tensor，并增加一个通道维度 (H, W) -> (1, H, W)\n",
    "        mask_tensor = torch.from_numpy(mask_np_float).unsqueeze(0)\n",
    "\n",
    "        # --- 标准化图像 ---\n",
    "        image_tensor = self.normalize(image_tensor)\n",
    "\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# 确保 Patch 目录存在且包含文件\n",
    "if not os.path.exists(OUTPUT_IMAGE_PATCH_DIR) or not os.listdir(OUTPUT_IMAGE_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的图像 Patches 于 {OUTPUT_IMAGE_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "if not os.path.exists(OUTPUT_MASK_PATCH_DIR) or not os.listdir(OUTPUT_MASK_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的掩码 Patches 于 {OUTPUT_MASK_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "\n",
    "# 创建完整的数据集实例 (包含所有生成的 Patches)\n",
    "full_dataset_offline = PterygiumSegDataset(\n",
    "    image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "    mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "    augment=True  # 初始设为 True，后面会为 val_subset 关闭\n",
    ")\n",
    "\n",
    "# 检查数据集是否为空\n",
    "if len(full_dataset_offline) == 0:\n",
    "    raise ValueError(\"错误：创建的数据集为空，无法进行划分和训练。请检查 Patching 过程和输出目录。\")\n",
    "\n",
    "# 定义训练集和验证集的大小\n",
    "total_size = len(full_dataset_offline)\n",
    "val_size = int(total_size * 0.2) # 20% 用于验证\n",
    "train_size = total_size - val_size\n",
    "\n",
    "print(f\"总共找到 {total_size} 个 Patch 对。\")\n",
    "print(f\"划分比例: 训练集 {train_size} Patches ({100*(train_size/total_size):.1f}%), \"\n",
    "    f\"验证集 {val_size} Patches ({100*(val_size/total_size):.1f}%)\")\n",
    "\n",
    "# 使用 random_split 划分数据集\n",
    "# 设置随机种子以保证可复现性\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset, val_subset = random_split(full_dataset_offline, [train_size, val_size], generator=generator)\n",
    "\n",
    "# !!! 重要: 禁用验证子集的数据增强 !!!\n",
    "# random_split 返回的是 Subset 对象，其 dataset 属性指向原始的 full_dataset_offline\n",
    "# 我们需要修改这个指向的原始数据集的 augment 属性，但这会影响两个子集\n",
    "# 更安全的做法是：创建两个独立的 Dataset 实例，或者在 DataLoader 中处理增强\n",
    "\n",
    "# 推荐做法：创建两个 Dataset 实例，虽然稍微冗余但更清晰\n",
    "# 1. 获取划分后的索引\n",
    "train_indices = train_subset.indices\n",
    "val_indices = val_subset.indices\n",
    "# 2. 获取所有文件名\n",
    "all_filenames = full_dataset_offline.image_filenames\n",
    "# 3. 根据索引获取训练和验证的文件名列表\n",
    "train_filenames = [all_filenames[i] for i in train_indices]\n",
    "val_filenames = [all_filenames[i] for i in val_indices]\n",
    "\n",
    "# 4. 创建独立的训练和验证 Dataset\n",
    "train_dataset_offline = PterygiumSegDataset(\n",
    "    image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "    mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "    file_list=train_filenames, # 传入训练文件名列表\n",
    "    augment=True  # 训练时启用增强\n",
    ")\n",
    "val_dataset_offline = PterygiumSegDataset(\n",
    "    image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "    mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "    file_list=val_filenames, # 传入验证文件名列表\n",
    "    augment=False # 验证时不进行增强\n",
    ")\n",
    "\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_offline,\n",
    "    batch_size=6 if platform.system() == \"Windows\" else 40,\n",
    "    shuffle=True, # 训练时打乱顺序\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 5,\n",
    "    pin_memory=False if platform.system() == \"Windows\" else True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset_offline,\n",
    "    batch_size=6 if platform.system() == \"Windows\" else 40,\n",
    "    shuffle=False, # 验证时不需要打乱\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 5,\n",
    "    pin_memory=False if platform.system() == \"Windows\" else True\n",
    ")\n",
    "\n",
    "print(f\"\\n训练集大小 (Patches): {len(train_dataset_offline)}\")\n",
    "print(f\"验证集大小 (Patches): {len(val_dataset_offline)}\")\n",
    "print(f\"训练 DataLoader 批次数: {len(train_loader)}\")\n",
    "print(f\"验证 DataLoader 批次数: {len(val_loader)}\")\n",
    "\n",
    "# 清理不再需要的完整数据集对象 (可选)\n",
    "del full_dataset_offline, train_subset, val_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# 测试数据加载器\n",
    "取一个批次的数据出来看看形状和内容是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    images_batch, masks_batch = next(iter(train_loader))\n",
    "    print(\"\\n从训练加载器获取一个批次的数据:\")\n",
    "    print(f\"图像批次形状: {images_batch.shape}\") # 应该类似 [BATCH_SIZE, 3, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"掩码批次形状: {masks_batch.shape}\")   # 应该类似 [BATCH_SIZE, 1, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"图像数据类型: {images_batch.dtype}\")\n",
    "    print(f\"掩码数据类型: {masks_batch.dtype}\")\n",
    "    print(f\"掩码最小值: {masks_batch.min()}\") # 应该是 0.0\n",
    "    print(f\"掩码最大值: {masks_batch.max()}\") # 应该是 1.0\n",
    "    \n",
    "    # 可视化一个样本\n",
    "    sample_idx = 0\n",
    "    img_sample = images_batch[sample_idx].permute(1, 2, 0).numpy() # CHW -> HWC\n",
    "    mask_sample = masks_batch[sample_idx].squeeze().numpy()       # 1HW -> HW\n",
    "    \n",
    "    # 反归一化以便显示\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_sample = std * img_sample + mean\n",
    "    img_sample = np.clip(img_sample, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(img_sample)\n",
    "    axes[0].set_title(\"示例图像 Patch (反归一化)\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(mask_sample, cmap='gray')\n",
    "    axes[1].set_title(\"示例掩码 Patch (0/1)\")\n",
    "    axes[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"错误：无法从 DataLoader 获取数据，请检查数据集是否为空或配置是否正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"测试 DataLoader 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "7700c359",
    "language": "markdown"
   },
   "source": [
    "# 构建U-Net分割模型\n",
    "U-Net是一种经典的图像分割模型，其结构包括下采样路径（编码器）和上采样路径（解码器），以及跳跃连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "b1637cba",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"双卷积块：(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下采样层：MaxPool + DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样层：UpConv + DoubleConv（带跳跃连接）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        # 使用双线性插值或转置卷积进行上采样\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # 输入可能不是整数倍的2，需要进行尺寸调整\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # 连接特征图\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"输出卷积层\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"完整的UNet模型\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True, dropout_p=0.5):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # 加载预训练的ResNet-18\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # 编码器部分 (使用ResNet-18的层)\n",
    "        self.inc = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        ) # 输出通道: 64\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.down1 = resnet.layer1 # 输出通道: 64\n",
    "        self.down2 = resnet.layer2 # 输出通道: 128\n",
    "        self.down3 = resnet.layer3 # 输出通道: 256\n",
    "        self.down4 = resnet.layer4 # 输出通道: 512\n",
    "\n",
    "        # --- 瓶颈层后 Dropout 层 ---\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        # 解码器部分 (调整通道数以匹配ResNet)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.up1 = Up(512 + 256, 512 // factor, bilinear) # down4(512) + down3(256) -> 256\n",
    "        self.up2 = Up(256 + 128, 256 // factor, bilinear) # up1(256) + down2(128) -> 128\n",
    "        self.up3 = Up(128 + 64, 128 // factor, bilinear)  # up2(128) + down1(64) -> 64\n",
    "        self.up4 = Up(64 + 64, 64, bilinear)             # up3(64) + inc(64) -> 64\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码路径 (ResNet)\n",
    "        x1 = self.inc(x)       # (N, 64, H/2, W/2) after initial conv+bn+relu (stride=2)\n",
    "        x_pool = self.maxpool(x1) # (N, 64, H/4, W/4)\n",
    "        x2 = self.down1(x_pool) # (N, 64, H/4, W/4)\n",
    "        x3 = self.down2(x2)     # (N, 128, H/8, W/8)\n",
    "        x4 = self.down3(x3)     # (N, 256, H/16, W/16)\n",
    "        x5 = self.down4(x4)     # (N, 512, H/32, W/32)\n",
    "\n",
    "        # --- Dropout 层 ---\n",
    "        x5_dropout = self.dropout(x5)\n",
    "\n",
    "        # 解码路径 (带跳跃连接)\n",
    "        x = self.up1(x5_dropout, x4) # 输入: x5(512), x4(256) -> 输出: 256\n",
    "        x = self.up2(x, x3)  # 输入: x(256), x3(128) -> 输出: 128\n",
    "        x = self.up3(x, x2)  # 输入: x(128), x2(64) -> 输出: 64\n",
    "        x = self.up4(x, x1)  # 输入: x(64), x1(64) -> 输出: 64\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# 初始化模型\n",
    "model = UNet(n_classes=1, bilinear=True, dropout_p=0.4).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"检测到 {torch.cuda.device_count()} 块GPU, 由于多卡存在问题，只使用GPU0\")\n",
    "    #model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "cefa71b2",
    "language": "markdown"
   },
   "source": [
    "# 定义损失函数和评估指标\n",
    "我们使用组合损失函数：二元交叉熵损失和Dice损失的组合，以更好地处理类别不平衡问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "ff097418",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Dice损失函数\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # 使用sigmoid将logits转换为概率\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # 将维度展平\n",
    "        batch_size = targets.size(0)\n",
    "        probs = probs.view(batch_size, -1)\n",
    "        targets = targets.view(batch_size, -1)\n",
    "        \n",
    "        # 计算交集\n",
    "        intersection = (probs * targets).sum(dim=1)\n",
    "        \n",
    "        # 计算Dice系数\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            probs.sum(dim=1) + targets.sum(dim=1) + self.smooth)\n",
    "        \n",
    "        # 返回Dice损失\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# 组合损失\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        # BCEWithLogitsLoss 实例本身不存储 pos_weight, 在 forward 中传入\n",
    "        self.bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss_fn = DiceLoss()\n",
    "\n",
    "    def forward(self, logits, targets, pos_weight=None):\n",
    "        \"\"\"\n",
    "        计算组合损失。\n",
    "        :param logits: 模型输出 (N, 1, H, W)\n",
    "        :param targets: 真实掩码 (N, 1, H, W)\n",
    "        :param pos_weight: 正样本权重 (scalar) for BCE loss.\n",
    "        \"\"\"\n",
    "        # 更新BCE损失的pos_weight参数\n",
    "        self.bce_loss_fn.pos_weight = pos_weight\n",
    "        bce = self.bce_loss_fn(logits, targets)\n",
    "\n",
    "        dice = self.dice_loss_fn(logits, targets)\n",
    "        return self.bce_weight * bce + self.dice_weight * dice\n",
    "\n",
    "# 评估指标：Dice系数\n",
    "def dice_coefficient(y_pred, y_true, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"计算预测掩码和真实掩码之间的Dice系数\"\"\"\n",
    "    assert y_pred.shape == y_true.shape, f\"预测形状 {y_pred.shape} 与目标形状 {y_true.shape} 不匹配\"\n",
    "    # 应用阈值将概率转换为二值掩码\n",
    "    y_pred = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    \n",
    "    # 压平张量\n",
    "    y_pred = y_pred.contiguous().view(-1)\n",
    "    y_true = y_true.contiguous().view(-1)\n",
    "    \n",
    "    # 计算交集\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    \n",
    "    # 计算Dice系数\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = CombinedLoss(bce_weight=0.6, dice_weight=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "9ee6f7d9",
    "language": "markdown"
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam优化器和学习率调度器，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "9cfd0144",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "num_epochs = 30\n",
    "log_interval = 5\n",
    "\n",
    "# 配置优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# 学习率调度器\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6) # 使用基线超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "d6ea8258",
    "language": "markdown"
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播、参数更新，并记录训练过程中的指标。同时实现早停机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "67252228",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 定义早停类\n",
    "from copy import deepcopy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "        # 根据模式确定比较操作\n",
    "        if self.mode == 'min':\n",
    "            self.delta_sign = -1  # 对于最小值模式，分数需要减少delta\n",
    "        else:  # mode == 'max'\n",
    "            self.delta_sign = 1  # 对于最大值模式，分数需要增加delta\n",
    "    \n",
    "    def __call__(self, val_score, model):\n",
    "        score = val_score\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            tqdm.write(f\"EarlyStopping: 初始化最佳分数为 {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            # 有足够的提升\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            tqdm.write(f\"EarlyStopping: 发现改进。最佳分数更新为 {self.best_score:.4f}。计数器重置。\")\n",
    "        else:\n",
    "            # 没有足够的提升\n",
    "            self.counter += 1\n",
    "            tqdm.write(f'EarlyStopping计数器: {self.counter} (共 {self.patience})。最佳分数仍为 {self.best_score:.4f}。')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                tqdm.write(\"EarlyStopping: 已达到耐心值。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "8226a404",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持早停和加权损失。\n",
    "    返回：最佳验证Dice系数, 训练Dice历史, 验证Dice历史, 最佳模型state_dict\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"\\n--- 开始训练 (使用 Patching 和 加权损失) ---\")\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max', min_delta=0.001) # 可能需要调整patience和delta\n",
    "    scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    train_dice_history = []\n",
    "    val_dice_history = []\n",
    "    best_model_state_dict = None\n",
    "    best_val_dice = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_samples = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "        for images, masks in train_loader_tqdm:\n",
    "            images, masks = images.to(device), masks.to(device) # images: (N, 3, P, P), masks: (N, 1, P, P)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # --- 计算 pos_weight ---\n",
    "            num_pixels = masks.numel() # 总像素数 N*1*P*P\n",
    "            num_pos = torch.sum(masks) # 正样本像素数\n",
    "            num_neg = num_pixels - num_pos\n",
    "            # 计算正样本权重 (避免除以0)\n",
    "            pos_weight_value = num_neg / (num_pos + 1e-6)\n",
    "            pos_weight_tensor = torch.tensor([pos_weight_value], device=device)\n",
    "\n",
    "            # 使用混合精度训练\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(images) # outputs: (N, 1, P, P)\n",
    "                \n",
    "                # 使用 'nearest' 插值以保持掩码的二值性\n",
    "                masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                # masks_downsampled 的形状现在是 (N, 1, 256, 256)\n",
    "                loss = criterion(outputs, masks_downsampled, pos_weight=pos_weight_tensor) # 使用下采样后的掩码\n",
    "\n",
    "            # 反向传播和优化\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            train_dice += dice_coefficient(outputs, masks_downsampled) * batch_size\n",
    "            train_samples += batch_size\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{dice_coefficient(outputs, masks_downsampled):.4f}',\n",
    "                'lr': f'{current_lr:.1e}',\n",
    "                'pw': f'{pos_weight_value:.2f}' # 显示pos_weight\n",
    "            })\n",
    "\n",
    "        train_loss /= train_samples\n",
    "        train_dice /= train_samples\n",
    "        train_dice_history.append(train_dice)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                # 验证时通常不计算加权损失，但如果计算，pos_weight也需计算\n",
    "                # 这里我们仍然使用原始criterion计算损失值，但不传递pos_weight\n",
    "                masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                loss = criterion(outputs, masks_downsampled, pos_weight=None) # 或者传递计算出的pos_weight\n",
    "\n",
    "                batch_size = images.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                current_val_dice = dice_coefficient(outputs, masks_downsampled) # 计算当前批次的Dice\n",
    "                val_dice += current_val_dice * batch_size\n",
    "                val_samples += batch_size\n",
    "\n",
    "        val_loss /= val_samples\n",
    "        val_dice /= val_samples # 平均Dice\n",
    "        val_dice_history.append(val_dice)\n",
    "\n",
    "        # 更新学习率 (基于验证Dice)\n",
    "        #scheduler.step(val_dice) # CosineAnnealingLR不需要参数，ReduceLROnPlateau需要\n",
    "        scheduler.step()\n",
    "\n",
    "        tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Train Dice: {train_dice:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val Dice: {val_dice:.4f}\")\n",
    "\n",
    "        # 早停检查\n",
    "        if val_dice > best_val_dice + early_stopping.min_delta:\n",
    "             best_val_dice = val_dice\n",
    "             early_stopping.best_score = val_dice # 更新 early stopping 的 best_score\n",
    "             early_stopping.best_model_weights = deepcopy(model.state_dict())\n",
    "             early_stopping.counter = 0\n",
    "             tqdm.write(f\"EarlyStopping: 发现改进。最佳分数更新为 {best_val_dice:.4f}。计数器重置。\")\n",
    "        else:\n",
    "            early_stopping.counter += 1\n",
    "            tqdm.write(f'EarlyStopping计数器: {early_stopping.counter} (共 {early_stopping.patience})。最佳分数仍为 {best_val_dice:.4f}。')\n",
    "            if early_stopping.counter >= early_stopping.patience:\n",
    "                early_stopping.early_stop = True\n",
    "\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            tqdm.write(f\"早停触发于第 {epoch + 1} 轮。\")\n",
    "            best_model_state_dict = early_stopping.best_model_weights\n",
    "            break\n",
    "\n",
    "    # 如果训练正常完成，获取最佳权重\n",
    "    if not early_stopping.early_stop and early_stopping.best_model_weights is not None:\n",
    "        tqdm.write(f\"训练在 {num_epochs} 轮后完成。\")\n",
    "        best_model_state_dict = early_stopping.best_model_weights\n",
    "    elif early_stopping.best_model_weights is None and not early_stopping.early_stop:\n",
    "        # Handle case where training finishes without improvement in the first epoch\n",
    "        best_model_state_dict = deepcopy(model.state_dict())\n",
    "        tqdm.write(\"训练完成，但未在验证集上观察到改进，保存最终模型。\")\n",
    "\n",
    "\n",
    "    # 使用最佳模型进行最终评估 (如果存在)\n",
    "    final_val_dice = 0.0\n",
    "    if best_model_state_dict:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "        model.eval()\n",
    "        val_samples_final = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                batch_size = images.size(0)\n",
    "                final_val_dice += dice_coefficient(outputs, masks_downsampled) * batch_size\n",
    "                val_samples_final += batch_size\n",
    "        if val_samples_final > 0:\n",
    "            final_val_dice /= val_samples_final\n",
    "        else:\n",
    "            final_val_dice = 0.0 # Avoid division by zero\n",
    "    else:\n",
    "        tqdm.write(\"警告：无法获取最佳模型权重。最终Dice系数为0。\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"--- 训练完成 ---\")\n",
    "    print(f\"最终(最佳)验证Dice系数: {final_val_dice:.4f}\")\n",
    "    print(f\"训练耗时: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "    return final_val_dice, train_dice_history, val_dice_history, best_model_state_dict\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "best_dice, train_dice_history, val_dice_history, best_model_weights = train_validate_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler, # 如果是ReduceLROnPlateau, scheduler.step(val_dice)\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "0c161af4",
    "language": "markdown"
   },
   "source": [
    "# 评估模型性能\n",
    "可视化学习曲线和分割结果，计算Dice系数和95% Hausdorff距离等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "958069be",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 可视化学习曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_dice_history) + 1), train_dice_history, label='训练Dice系数')\n",
    "plt.plot(range(1, len(val_dice_history) + 1), val_dice_history, label='验证Dice系数')\n",
    "plt.title('训练和验证Dice系数')\n",
    "plt.xlabel('轮次')\n",
    "plt.ylabel('Dice系数')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 可视化分割结果\n",
    "def visualize_segmentation(model, dataloader, num_samples=5):\n",
    "    \"\"\"可视化分割结果\"\"\"\n",
    "    model.eval()\n",
    "    dataiter = iter(dataloader)\n",
    "    \n",
    "    # 获取一批数据\n",
    "    try:\n",
    "        images, masks = next(dataiter)\n",
    "    except StopIteration:\n",
    "        print(\"数据集太小，无法获取足够的样本。\")\n",
    "        return\n",
    "    \n",
    "    # 限制样本数\n",
    "    num_samples = min(num_samples, images.size(0))\n",
    "    \n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        outputs = model(images)\n",
    "        pred_masks = (torch.sigmoid(outputs) > 0.5).float()\n",
    "    \n",
    "    # 反标准化图像以便可视化\n",
    "    images_np = []\n",
    "    for img in images[:num_samples]:\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)  # 转为HWC格式\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        images_np.append(img)\n",
    "    \n",
    "    # 准备掩码和预测\n",
    "    masks_np = masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    pred_masks_np = pred_masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 原始图像\n",
    "        axes[i, 0].imshow(images_np[i])\n",
    "        axes[i, 0].set_title('原始图像')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 真实掩码\n",
    "        axes[i, 1].imshow(masks_np[i], cmap='gray')\n",
    "        axes[i, 1].set_title('真实掩码')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 预测掩码\n",
    "        axes[i, 2].imshow(pred_masks_np[i], cmap='gray')\n",
    "        masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "        dice = dice_coefficient(outputs[i:i+1], masks_downsampled[i:i+1])\n",
    "        axes[i, 2].set_title(f'预测掩码 (Dice: {dice:.4f})')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_segmentation(model, val_loader, num_samples=5) # 可视化验证集(resize后)的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "430f63ad",
    "language": "markdown"
   },
   "source": [
    "# 模型保存和加载\n",
    "保存训练好的模型，以便将来加载并用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "1c3ddb6d",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "\n",
    "def save_model(model, path):\n",
    "    \"\"\"保存模型参数到指定路径\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "save_model_path=f'/kaggle/working/work2model_dice-{best_dice}_{time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime())}.pth'\n",
    "save_model(model,save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# 模型预测与应用\n",
    "\n",
    "遍历测试图像，加载它们，进行预处理，然后使用加载的模型进行预测，最后将预测的掩码保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0.级联-分类模型加载 ---\n",
    "if platform.system() == \"Windows\":\n",
    "    classification_model_path = 'w1.pth'\n",
    "    model_save_path = 'w2.pth'\n",
    "else:\n",
    "    # 在 Kaggle 中使用的路径\n",
    "    classification_model_path = '/kaggle/input/pterygium_classifier/pytorch/default/2/resnet18_pterygium_classifier.pth'\n",
    "\n",
    "# 定义验证集/测试集的变换 (无需数据增强)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "classification_model = ResNet18Classifier(num_classes=3)\n",
    "classification_model.load_state_dict(torch.load(classification_model_path, map_location=device, weights_only=True))\n",
    "classification_model = classification_model.to(device)\n",
    "classification_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 加载训练好的模型 ---\n",
    "\n",
    "try:\n",
    "    model_save_path = save_model_path\n",
    "except:\n",
    "    print(\"model_save_path 未定义。请确保在训练后保存模型。\")\n",
    "\n",
    "loaded_model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "# 加载最佳权重 (假设 best_model_weights 变量包含 state_dict)\n",
    "if 'best_model_weights' in locals() and best_model_weights is not None:\n",
    "    loaded_model.load_state_dict(best_model_weights)\n",
    "    print(\"成功加载训练好的模型权重。\")\n",
    "else:\n",
    "    # 如果没有 best_model_weights，尝试从文件加载（需要先保存）\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))\n",
    "        print(f\"从 {model_save_path} 加载模型权重。\")\n",
    "    else:\n",
    "        print(\"警告: 未找到训练好的模型权重 (best_model_weights 或文件)。模型将使用随机初始化的权重。\")\n",
    "\n",
    "loaded_model.eval(); # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义 Tiling 预测函数 ---\n",
    "def predict_with_tiling(model, image_path, patch_size, stride, device, batch_size=4, threshold=0.5):\n",
    "    \"\"\"\n",
    "    使用 Tiling 和重叠平均策略预测大图的掩码。\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 原始大图路径\n",
    "    :param patch_size: patch 大小 (int)\n",
    "    :param stride: 切割 patch 时的步长 (int)\n",
    "    :param device: 设备\n",
    "    :param batch_size: 推理时的批次大小\n",
    "    :param threshold: 二值化阈值\n",
    "    :return: 预测的二值掩码 (numpy array, H x W) 或 None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_w, img_h = img.size\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 图像文件未找到 {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 加载图像时出错 {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    model.eval() # 确保模型在评估模式\n",
    "\n",
    "    # 定义预处理 (仅 ToTensor 和 Normalize)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 计算所需的 padding\n",
    "    pad_h = max(patch_size - img_h, 0)\n",
    "    pad_w = max(patch_size - img_w, 0)\n",
    "    # 在右侧和底部进行 padding，使其尺寸至少为 patch_size\n",
    "    # 进一步 padding 使尺寸能被 stride 整除，以便覆盖所有边缘\n",
    "    target_h = img_h + pad_h\n",
    "    target_w = img_w + pad_w\n",
    "    pad_h_stride = (stride - (target_h - patch_size) % stride) % stride\n",
    "    pad_w_stride = (stride - (target_w - patch_size) % stride) % stride\n",
    "\n",
    "    padding = (0, 0, pad_w + pad_w_stride, pad_h + pad_h_stride) # (left, top, right, bottom)\n",
    "    img_padded = F.pad(img, padding, padding_mode='reflect') # 使用反射填充\n",
    "    padded_h, padded_w = img_padded.size[1], img_padded.size[0] # PIL size is W, H\n",
    "\n",
    "    # 创建空的概率图和计数图\n",
    "    pred_prob_map = torch.zeros((1, padded_h, padded_w), dtype=torch.float32, device=device)\n",
    "    count_map = torch.zeros((1, padded_h, padded_w), dtype=torch.float32, device=device)\n",
    "\n",
    "    # 收集所有 patch 的坐标\n",
    "    patch_coords = []\n",
    "    for y in range(0, padded_h - patch_size + 1, stride):\n",
    "        for x in range(0, padded_w - patch_size + 1, stride):\n",
    "            patch_coords.append((x, y))\n",
    "\n",
    "    # 分批处理 patches\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(patch_coords), batch_size), desc=\"Tiling Prediction\",leave=False):\n",
    "            batch_coords = patch_coords[i:i+batch_size]\n",
    "            batch_patches_pil = [img_padded.crop((x, y, x + patch_size, y + patch_size)) for x, y in batch_coords]\n",
    "            batch_patches_tensor = torch.stack([preprocess(p) for p in batch_patches_pil]).to(device)\n",
    "\n",
    "            # 模型预测 (输出 logits)\n",
    "            batch_outputs_logits = model(batch_patches_tensor)\n",
    "            batch_outputs_probs = torch.sigmoid(batch_outputs_logits) # (B, 1, P, P)\n",
    "\n",
    "            # 将预测结果累加回概率图\n",
    "            for j, (x, y) in enumerate(batch_coords):\n",
    "                # 修复：将模型输出上采样到patch_size大小\n",
    "                output_height, output_width = batch_outputs_probs[j].shape[1:] # 获取当前输出尺寸\n",
    "                if output_height != patch_size or output_width != patch_size:\n",
    "                    # 上采样到与patch相同大小\n",
    "                    upsampled_output = torch.nn.functional.interpolate(\n",
    "                        batch_outputs_probs[j].unsqueeze(0), # 增加批次维度\n",
    "                        size=(patch_size, patch_size),\n",
    "                        mode='bilinear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze(0) # 移除批次维度\n",
    "                    pred_prob_map[:, y:y+patch_size, x:x+patch_size] += upsampled_output\n",
    "                else:\n",
    "                    pred_prob_map[:, y:y+patch_size, x:x+patch_size] += batch_outputs_probs[j]\n",
    "                count_map[:, y:y+patch_size, x:x+patch_size] += 1\n",
    "\n",
    "    # 处理计数为0的区域（如果padding策略完美，不应出现，但以防万一）\n",
    "    count_map[count_map == 0] = 1\n",
    "    # 计算平均概率\n",
    "    avg_prob_map = pred_prob_map / count_map\n",
    "\n",
    "    # 裁剪回原始图像尺寸 (去掉 padding)\n",
    "    original_h, original_w = img_h, img_w\n",
    "    avg_prob_map_cropped = avg_prob_map[:, :original_h, :original_w]\n",
    "\n",
    "    # 应用阈值得到最终二值掩码\n",
    "    final_mask = (avg_prob_map_cropped > threshold).squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # --- 后处理：保留最大连通区域 ---\n",
    "    if np.sum(final_mask) > 0: # 检查是否有任何前景像素\n",
    "        # 标记连通区域 (背景为0)\n",
    "        labeled_mask = label(final_mask)\n",
    "        \n",
    "        # 计算每个区域的面积 (忽略背景区域0)\n",
    "        region_props = np.unique(labeled_mask[labeled_mask > 0], return_counts=True)\n",
    "        \n",
    "        if len(region_props[0]) > 0: # 确保至少有一个前景区域\n",
    "            # 找到最大区域的标签\n",
    "            largest_component_label = region_props[0][np.argmax(region_props[1])]\n",
    "            \n",
    "            # 创建只包含最大区域的新掩码\n",
    "            final_mask_processed = np.zeros_like(final_mask)\n",
    "            final_mask_processed[labeled_mask == largest_component_label] = 1\n",
    "            final_mask = final_mask_processed # 用处理后的掩码替换原掩码\n",
    "        else:\n",
    "            # 如果 labeled_mask > 0 为空（理论上不应在 np.sum > 0 后发生，但做个健壮性检查）\n",
    "            final_mask = np.zeros_like(final_mask) # 无前景区域，返回空掩码\n",
    "    else:\n",
    "        # 如果原始掩码全为0，则保持全零\n",
    "        pass \n",
    "    # --- 后处理结束 ---\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 对测试图像进行预测 ---\n",
    "\n",
    "# 输出预测掩码的目录\n",
    "if os.path.exists(output_mask_dir):\n",
    "    print(f\"输出目录 {output_mask_dir} 已存在，删除旧目录。\")\n",
    "    import shutil\n",
    "    shutil.rmtree(output_mask_dir)\n",
    "os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "# 查找所有测试图像\n",
    "test_image_paths = glob.glob(os.path.join(val_image_dir, \"*.png\"))\n",
    "\n",
    "print(f\"找到 {len(test_image_paths)} 张待预测图像于 {val_image_dir}\")\n",
    "\n",
    "# 遍历测试图像并进行预测\n",
    "for img_path in tqdm(test_image_paths, desc=\"处理预测图像\"):\n",
    "    #if predict_image(classification_model, img_path, val_transform, device) == 0:\n",
    "    #    continue 评估中，暂时注释掉\n",
    "    # 使用 Tiling 进行预测\n",
    "    predicted_mask_np = predict_with_tiling(\n",
    "        model=loaded_model,\n",
    "        image_path=img_path,\n",
    "        patch_size=patch_size,\n",
    "        stride=predict_stride, # 使用之前定义的 stride\n",
    "        device=device,\n",
    "        batch_size=32 # 可以根据GPU内存调整\n",
    "    )\n",
    "\n",
    "    if predicted_mask_np is not None:\n",
    "        # predicted_mask_np 是 (H, W) 的 numpy 数组，值为 0 或 1\n",
    "        # 创建RGB掩码图像，前景(1)为(128,0,0)，背景(0)为(0,0,0)\n",
    "        h, w = predicted_mask_np.shape\n",
    "        rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        # 设置前景区域(值为1的位置)为(128,0,0)\n",
    "        rgb_mask[predicted_mask_np == 1, 0] = 128  # R通道设为128\n",
    "        # 背景区域(值为0的位置)默认已经是(0,0,0)\n",
    "        mask_image = Image.fromarray(rgb_mask, mode='RGB')\n",
    "\n",
    "        base_name = os.path.basename(img_path)\n",
    "        save_name = f\"{os.path.splitext(base_name)[0]}.png\" # 统一保存为png\n",
    "        save_path = os.path.join(output_mask_dir, save_name)\n",
    "\n",
    "        try:\n",
    "            mask_image.save(save_path)\n",
    "            # print(f\"预测掩码已保存到: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存掩码时出错 {save_path}: {e}\")\n",
    "\n",
    "# 可视化结果\n",
    "# 要可视化的样本数量\n",
    "num_visualize = 10\n",
    "if not test_image_paths:\n",
    "    print(\"错误：找不到测试图像路径，无法进行可视化。\")\n",
    "else:\n",
    "    # 确保样本数量不超过实际图像数量\n",
    "    num_visualize = min(num_visualize, len(test_image_paths))\n",
    "    if num_visualize > 0:\n",
    "        # 随机选择图像路径进行可视化\n",
    "        sample_paths = random.sample(test_image_paths, num_visualize)\n",
    "        print(f\"\\n可视化 {num_visualize} 个预测结果...\")\n",
    "\n",
    "        for img_path in sample_paths:\n",
    "            try:\n",
    "                # 加载原始图像\n",
    "                original_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                # 构建对应的预测掩码文件的路径\n",
    "                base_name = os.path.basename(img_path)\n",
    "                file_stem = os.path.splitext(base_name)[0]\n",
    "                mask_filename = f\"{file_stem}.png\" # 假设保存的掩码文件名与原图名相同\n",
    "                predicted_mask_path = os.path.join(output_mask_dir, mask_filename)\n",
    "\n",
    "                # 检查预测掩码文件是否存在并加载\n",
    "                if os.path.exists(predicted_mask_path):\n",
    "                    predicted_mask_image = Image.open(predicted_mask_path) # 加载之前保存的RGB掩码\n",
    "\n",
    "                    # 创建绘图\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                    # 显示原始图像\n",
    "                    axes[0].imshow(original_image)\n",
    "                    axes[0].set_title(f\"原始图像: {base_name}\")\n",
    "                    axes[0].axis('off')\n",
    "\n",
    "                    # 显示对应的预测掩码\n",
    "                    axes[1].imshow(predicted_mask_image) # 显示加载的对应掩码\n",
    "                    axes[1].set_title(\"预测掩码 (RGB 128,0,0)\")\n",
    "                    axes[1].axis('off')\n",
    "\n",
    "                    plt.tight_layout() # 调整布局防止重叠\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(f\"警告：找不到预测掩码文件 {predicted_mask_path}，无法可视化此样本。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"可视化图像 {img_path} 时出错: {e}\")\n",
    "    else:\n",
    "        print(\"没有测试图像可供可视化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 压缩结果 ---\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    zip_file_path = f\"{output_mask_dir}.zip\"\n",
    "\n",
    "    if output_mask_dir and os.path.exists(output_mask_dir) and os.listdir(output_mask_dir):\n",
    "        print(f\"开始压缩目录: {output_mask_dir}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                files_to_zip = glob.glob(os.path.join(output_mask_dir, '*.*'))\n",
    "                if not files_to_zip:\n",
    "                    print(f\"警告: 目录 {output_mask_dir} 为空，无需压缩。\")\n",
    "                else:\n",
    "                    for file in tqdm(files_to_zip, desc=\"压缩文件\"):\n",
    "                        zipf.write(file, arcname=os.path.basename(file))\n",
    "                    print(f\"预测结果已成功压缩到: {zip_file_path}\")\n",
    "\n",
    "                    # 删除原始文件和目录 (可选)\n",
    "                    print(f\"删除原始掩码文件于: {output_mask_dir}\")\n",
    "                    import shutil\n",
    "                    shutil.rmtree(output_mask_dir)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"压缩或删除文件时发生错误: {e}\")\n",
    "    elif output_mask_dir:\n",
    "        print(f\"目录 {output_mask_dir} 不存在或为空，跳过压缩和删除步骤。\")\n",
    "\n",
    "\n",
    "print(\"\\n预测处理完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
