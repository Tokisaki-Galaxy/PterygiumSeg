{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "90ad95fc",
    "language": "markdown",
    "papermill": {
     "duration": 0.006235,
     "end_time": "2025-04-13T12:19:53.521073",
     "exception": false,
     "start_time": "2025-04-13T12:19:53.514838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/work2_basemode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "ae9dfa31",
    "language": "markdown",
    "papermill": {
     "duration": 0.00474,
     "end_time": "2025-04-13T12:19:53.531452",
     "exception": false,
     "start_time": "2025-04-13T12:19:53.526712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 翼状胬肉区域分割模型\n",
    "\n",
    "这是项目的第二个任务：实现对眼部裂隙灯检查图片中翼状胬肉区域的精准分割。我们将使用U-Net模型解决这一问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "c8b6c127",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import functional as F\n",
    "from skimage.morphology import binary_opening, binary_closing, disk, square\n",
    "import albumentations as A # type: ignore\n",
    "from albumentations.pytorch import ToTensorV2 # type: ignore\n",
    "import torch.nn.functional\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "import matplotlib.font_manager\n",
    "\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    _xla_available = True\n",
    "    print(\"torch_xla 导入成功。\")\n",
    "except ImportError:\n",
    "    _xla_available = False\n",
    "    print(\"torch_xla 未安装或导入失败。将使用 CUDA 或 CPU。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "c8b6c127",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        !wget -O simhei.ttf \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "if _xla_available:\n",
    "    num_workers = 0\n",
    "\n",
    "patch_size = 512  # 定义 patch 大小\n",
    "patch_stride = patch_size // 2 # 定义训练时的步长（产生50%重叠）\n",
    "predict_stride = patch_size // 2 # 定义预测时的步长（产生50%重叠）\n",
    "target_input_size = (patch_size, patch_size) # U-Net的输入尺寸应为 patch_size\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val_img\"\n",
    "# colab路径\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# ================== 掩码输出路径 ================\n",
    "output_mask_dir = r\"f:/mask\"\n",
    "# colab路径\n",
    "output_maskfiles_colab = \"/content/mask\"\n",
    "# Kaggle路径\n",
    "output_maskfiles_kaggle = \"/kaggle/working/mask\"\n",
    "\n",
    "# ================== 训练参数 ==================\n",
    "MIN_FOREGROUND_RATIO = 0.01 # 离线patching，保留的Mask Patch中前景像素(128)最小比例，设为0则不过滤\n",
    "tpu_batch_size = 32 # 单核TPU的批处理大小，可以调整\n",
    "cuda_batch_size = 40 # CUDA批处理大小\n",
    "windows_batch_size = 6 # Windows批处理大小\n",
    "\n",
    "# 配置GPU/TPU/CPU\n",
    "if _xla_available:\n",
    "    # 获取 XLA 设备 (TPU)\n",
    "    # xm.xla_device() 会自动获取当前进程可用的 TPU核心\n",
    "    device = xm.xla_device()\n",
    "    print(f\"检测到 TPU，使用的设备: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        cudnn.benchmark = True\n",
    "        print(\"cuDNN benchmark 模式已启用\")\n",
    "    print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "    print(f\"使用的设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "7f00c3ad",
    "language": "markdown",
    "papermill": {
     "duration": 0.005221,
     "end_time": "2025-04-13T12:20:05.099591",
     "exception": false,
     "start_time": "2025-04-13T12:20:05.094370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 读取和准备数据\n",
    "我们需要读取原始图像和对应的分割标签（mask）。标签中像素值为128的区域表示翼状胬肉，像素值为0的区域表示背景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "64589f50",
    "language": "python",
    "papermill": {
     "duration": 0.033099,
     "end_time": "2025-04-13T12:20:05.137816",
     "exception": false,
     "start_time": "2025-04-13T12:20:05.104717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 多环境变量设置 ==========\n",
    "R2_ACCOUNT_ID = os.environ.get('R2_ACCOUNT_ID', 'YOUR_R2_ACCOUNT_ID')\n",
    "R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID', 'YOUR_R2_ACCESS_KEY_ID')\n",
    "R2_SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', 'YOUR_R2_SECRET_ACCESS_KEY')\n",
    "R2_BUCKET_NAME = os.environ.get('R2_BUCKET_NAME', 'YOUR_R2_BUCKET_NAME')\n",
    "R2_ENDPOINT_URL = f'https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com'\n",
    "\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "        BASE_PATCH_DIR = \"/content/train_patches_gpu\"\n",
    "\n",
    "        output_mask_dir = output_maskfiles_colab\n",
    "        print(f\"Colab 环境：验证结果将验证压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive # type: ignore\n",
    "        from google.colab import userdata # type: ignore\n",
    "        drive.mount('/content/drive')\n",
    "        R2_ACCESS_KEY_ID = userdata.get(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = userdata.get(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = userdata.get(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = userdata.get(\"R2_ENDPOINT_URL\")\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "        BASE_PATCH_DIR = \"/kaggle/working/train_patches_gpu\"\n",
    "        \n",
    "        output_mask_dir = output_maskfiles_kaggle\n",
    "        print(f\"Kaggle 环境：验证结果将压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "        from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "        user_secrets = UserSecretsClient()\n",
    "        R2_ACCESS_KEY_ID = user_secrets.get_secret(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = user_secrets.get_secret(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = user_secrets.get_secret(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = user_secrets.get_secret(\"R2_ENDPOINT_URL\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "    BASE_PATCH_DIR = \"data/train_patches_gpu\"\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# 离线Patching函数 (利用GPU加速)\n",
    "用于将原始的大尺寸图像和对应的分割掩码离线切割成指定大小的Patches，并保存到磁盘。\n",
    "该函数会尝试将大图加载到GPU进行裁剪和过滤，以加速处理过程（需要注意GPU显存）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_offline_patches_gpu(\n",
    "    input_image_dir,\n",
    "    label_file_path,\n",
    "    output_image_patch_dir,\n",
    "    output_mask_patch_dir, # 如果为 None，则只处理图像 Patch\n",
    "    patch_size,\n",
    "    stride,\n",
    "    device,\n",
    "    min_foreground_ratio=0.01\n",
    "    ):\n",
    "    \"\"\"\n",
    "    离线创建图像和掩码的Patches，尝试使用GPU加速，并根据标签文件筛选图像。\n",
    "\n",
    "    Args:\n",
    "        input_image_dir (str): 包含原始图像子文件夹 (如 0001, 0002...) 的目录。\n",
    "        label_file_path (str): 包含图像标签的Excel文件路径。\n",
    "        output_image_patch_dir (str): 保存图像Patch的目录。\n",
    "        output_mask_patch_dir (str or None): 保存掩码Patch的目录。如果为 None，则不处理或保存掩码。\n",
    "        patch_size (int): Patch的边长。\n",
    "        stride (int): 切割Patch时的步长。\n",
    "        device (torch.device): 用于计算的设备 (cuda or cpu)。\n",
    "        min_foreground_ratio (float): 保留的Mask Patch中前景像素(值>0)的最小比例。设为0则不过滤。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (成功处理的大图数量, 创建的Patch对数量)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        os.makedirs(output_image_patch_dir, exist_ok=True)\n",
    "        if output_mask_patch_dir:\n",
    "            os.makedirs(output_mask_patch_dir, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"创建输出目录时出错: {e}\")\n",
    "        # 允许在 output_mask_patch_dir 为 None 时继续\n",
    "\n",
    "    # 读取并筛选标签文件\n",
    "    try:\n",
    "        labels_df = pd.read_excel(label_file_path)\n",
    "        # 只保留翼状胬肉样本（标签1和2）\n",
    "        pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        # 获取需要处理的图像文件夹名称列表 (格式化为 0001, 0002 ...)\n",
    "        image_folders_to_process = pterygium_df['Image'].astype(int).apply(lambda x: f\"{x:04d}\").tolist()\n",
    "        print(f\"从 {os.path.basename(label_file_path)} 读取标签，找到 {len(image_folders_to_process)} 个翼状胬肉样本进行Patching。\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 标签文件未找到 {label_file_path}。无法进行Patching。\")\n",
    "        return 0, 0\n",
    "    except Exception as e:\n",
    "        print(f\"读取或处理标签文件 {label_file_path} 时出错: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "    processed_files = 0\n",
    "    created_patches = 0\n",
    "\n",
    "    for folder_name in tqdm(image_folders_to_process, desc=\"处理带标签的大图\"):\n",
    "        image_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}.png\")\n",
    "        mask_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}_label.png\")\n",
    "\n",
    "        # 检查图像文件是否存在\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"警告: 图像文件未找到 {image_path}，跳过文件夹 {folder_name}。\")\n",
    "            continue\n",
    "\n",
    "        # 仅在需要处理掩码时检查掩码文件\n",
    "        if output_mask_patch_dir and not os.path.exists(mask_path):\n",
    "            print(f\"警告: 掩码文件未找到 {mask_path} (但需要处理掩码)，跳过文件夹 {folder_name}。\")\n",
    "            continue\n",
    "        elif not output_mask_patch_dir:\n",
    "            # 如果不需要处理掩码，即使掩码不存在也继续（只生成图像patch）\n",
    "            mask_path = None # 明确设置为 None\n",
    "\n",
    "        try:\n",
    "            # 1. 加载大图 (CPU)\n",
    "            img_pil = Image.open(image_path).convert('RGB')\n",
    "            img_w, img_h = img_pil.size\n",
    "            mask_pil = None\n",
    "            mask_tensor_gpu = None # 初始化\n",
    "\n",
    "            # 仅在需要时加载和处理掩码\n",
    "            if mask_path:\n",
    "                mask_pil = Image.open(mask_path).convert('RGB')\n",
    "                mask_w, mask_h = mask_pil.size\n",
    "                if img_w != mask_w or img_h != mask_h:\n",
    "                    print(f\"警告: 图像和掩码尺寸不匹配 {folder_name}，跳过。 ({img_w}x{img_h} vs {mask_w}x{mask_h})\")\n",
    "                    continue\n",
    "\n",
    "            # 2. 转换为Tensor并移至GPU (如果显存允许)\n",
    "            try:\n",
    "                img_tensor_gpu = F.to_tensor(img_pil).to(device) # (3, H, W)\n",
    "                if mask_pil:\n",
    "                    # 将Mask转换为0/1 Tensor，再移到GPU\n",
    "                    mask_np_rgb = np.array(mask_pil)\n",
    "                    mask_binary = (mask_np_rgb[:, :, 0] == 128).astype(np.float32) # 前景 = 1 if R == 128\n",
    "                    mask_tensor_gpu = torch.from_numpy(mask_binary).unsqueeze(0).to(device) # (1, H, W)\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"\\n错误: 将图像/掩码 {folder_name} 移至GPU时出错 (可能显存不足): {e}\")\n",
    "                print(\"尝试在CPU上处理此图像...\")\n",
    "                device_fallback = torch.device(\"cpu\")\n",
    "                img_tensor_gpu = F.to_tensor(img_pil).to(device_fallback)\n",
    "                if mask_pil:\n",
    "                    mask_np_rgb = np.array(mask_pil)\n",
    "                    mask_binary = (mask_np_rgb[:, :, 0] == 128).astype(np.float32)\n",
    "                    mask_tensor_gpu = torch.from_numpy(mask_binary).unsqueeze(0).to(device_fallback)\n",
    "\n",
    "            # 3. 在GPU上进行Patch裁剪和过滤\n",
    "            patch_count_for_image = 0\n",
    "            for y in range(0, img_h - patch_size + 1, stride):\n",
    "                for x in range(0, img_w - patch_size + 1, stride):\n",
    "                    # 在GPU上裁剪图像\n",
    "                    img_patch_gpu = img_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "                    mask_patch_gpu = None # 初始化\n",
    "\n",
    "                    # 仅在需要时裁剪掩码\n",
    "                    if mask_tensor_gpu is not None:\n",
    "                        mask_patch_gpu = mask_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "                        # 在GPU上过滤 (基于前景比例) - 仅在有掩码时进行\n",
    "                        if min_foreground_ratio > 0:\n",
    "                            foreground_ratio = torch.mean(mask_patch_gpu) # mask是0/1，均值即比例\n",
    "                            if foreground_ratio < min_foreground_ratio:\n",
    "                                continue # 跳过前景过少的Patch\n",
    "\n",
    "                    # 4. 将需要保存的Patch移回CPU\n",
    "                    img_patch_cpu = img_patch_gpu.cpu()\n",
    "                    mask_patch_cpu = None\n",
    "                    if mask_patch_gpu is not None:\n",
    "                        mask_patch_cpu = mask_patch_gpu.cpu() # 仍然是 0/1\n",
    "\n",
    "                    # 5. 转换回PIL Image并保存 (CPU)\n",
    "                    img_patch_pil = F.to_pil_image(img_patch_cpu)\n",
    "\n",
    "                    # 生成保存文件名\n",
    "                    patch_filename = f\"{folder_name}_y{y}_x{x}.png\"\n",
    "                    img_save_path = os.path.join(output_image_patch_dir, patch_filename)\n",
    "                    img_patch_pil.save(img_save_path)\n",
    "\n",
    "                    # 仅在需要时保存掩码 Patch\n",
    "                    if output_mask_patch_dir and mask_patch_cpu is not None:\n",
    "                        # 将 0/1 的 mask tensor 转换回 0/128 的 PIL 灰度图\n",
    "                        mask_patch_np = (mask_patch_cpu.squeeze().numpy() * 128).astype(np.uint8)\n",
    "                        # 保存为 RGB 格式 (128,0,0) 以匹配原始格式\n",
    "                        mask_patch_pil_rgb = Image.new(\"RGB\", (patch_size, patch_size))\n",
    "                        # 创建一个与mask_patch_np形状相同，但值为0的数组\n",
    "                        zeros_channel = np.zeros_like(mask_patch_np)\n",
    "                        # 堆叠通道 R=mask, G=0, B=0\n",
    "                        mask_rgb_array = np.stack((mask_patch_np, zeros_channel, zeros_channel), axis=-1)\n",
    "                        mask_patch_pil = Image.fromarray(mask_rgb_array, mode='RGB')\n",
    "\n",
    "                        mask_save_path = os.path.join(output_mask_patch_dir, patch_filename)\n",
    "                        mask_patch_pil.save(mask_save_path)\n",
    "\n",
    "                    created_patches += 1\n",
    "                    patch_count_for_image += 1\n",
    "\n",
    "            # 6. 清理GPU内存中的大Tensor (重要!)\n",
    "            del img_tensor_gpu\n",
    "            if mask_tensor_gpu is not None: del mask_tensor_gpu\n",
    "            if 'img_patch_gpu' in locals(): del img_patch_gpu\n",
    "            if 'mask_patch_gpu' in locals() and mask_patch_gpu is not None: del mask_patch_gpu\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                torch.cuda.empty_cache() # 释放缓存\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n处理文件 {folder_name} 时发生未预料错误: {e}\")\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"离线Patching完成！\")\n",
    "    print(f\"成功处理（基于标签过滤后）大图数量: {processed_files} / {len(image_folders_to_process)}\")\n",
    "    print(f\"总共创建Patch数量: {created_patches}\") # 注意：如果是图像+掩码对，这是一个对数\n",
    "    print(f\"总耗时: {end_time - start_time:.2f} 秒\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    return processed_files, created_patches\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    \"\"\"计算文件夹的总大小（字节）\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Cloudflare R2 缓存patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "def create_r2_client():\n",
    "    \"\"\"尝试创建并返回一个配置好的 boto3 R2 客户端。\"\"\"\n",
    "    # 确认环境变量已加载 (这些变量应在之前的单元格中设置)\n",
    "    required_vars = ['R2_ENDPOINT_URL', 'R2_ACCESS_KEY_ID', 'R2_SECRET_ACCESS_KEY', 'R2_BUCKET_NAME']\n",
    "    if not all(var in globals() and globals()[var] for var in required_vars):\n",
    "        print(\"R2 配置不完整（缺少 Endpoint URL, Access Key, Secret Key 或 Bucket Name）。跳过 R2 缓存。\")\n",
    "        return None, False # 返回 None 和 R2 未配置标志\n",
    "\n",
    "    global r2_configured # 声明我们要修改全局变量\n",
    "    r2_configured = True # 标记 R2 已配置\n",
    "\n",
    "    try:\n",
    "        print(\"正在创建 R2 (boto3 S3) 客户端...\")\n",
    "        s3_client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=R2_ENDPOINT_URL,\n",
    "            aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "            region_name='auto', # R2 通常使用 'auto'\n",
    "            config=botocore.config.Config(signature_version='s3v4') # 明确签名版本\n",
    "        )\n",
    "        # 尝试列出 buckets (可选，作为连接测试)\n",
    "        # s3_client.list_buckets()\n",
    "        print(\"R2 客户端创建成功。\")\n",
    "        return s3_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"创建 R2 客户端时出错: {e}\")\n",
    "        r2_configured = False # 出错则标记为未配置\n",
    "        return None, False\n",
    "\n",
    "def check_r2_cache(s3_client, bucket_name, cache_key):\n",
    "    \"\"\"检查指定的缓存键是否存在于 R2 存储桶中。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False # 文件未找到\n",
    "        else:\n",
    "            # 其他错误 (如权限问题)\n",
    "            print(f\"检查 R2 缓存时出错 (Key: {cache_key}): {e}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"检查 R2 缓存时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_from_r2(s3_client, bucket_name, cache_key, local_path):\n",
    "    \"\"\"从 R2 下载文件到本地路径，带进度条。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        # 获取文件大小以显示进度\n",
    "        response = s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        total_size = int(response.get('ContentLength', 0))\n",
    "\n",
    "        print(f\"正在从 R2 下载 {cache_key} 到 {local_path} ({total_size / (1024*1024):.2f} MB)...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Filename=local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 下载完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"从 R2 下载文件时出错 (Key: {cache_key}): {e}\")\n",
    "        # 如果文件下载失败，尝试删除本地可能不完整的文件\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"下载 R2 文件时发生未知错误: {e}\")\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def upload_to_r2(s3_client, bucket_name, local_path, cache_key):\n",
    "    \"\"\"将本地文件上传到 R2，带进度条。\"\"\"\n",
    "    if not s3_client or not os.path.exists(local_path):\n",
    "        print(f\"上传 R2 失败：客户端未初始化或本地文件不存在 ({local_path})。\")\n",
    "        return False\n",
    "    try:\n",
    "        total_size = os.path.getsize(local_path)\n",
    "        print(f\"正在上传 {local_path} ({total_size / (1024*1024):.2f} MB) 到 R2 作为 {cache_key}...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 上传完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"上传文件到 R2 时出错 (Key: {cache_key}): {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"上传 R2 文件时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"压缩指定文件夹的内容到 zip 文件。\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"错误：要压缩的文件夹不存在 {folder_path}\")\n",
    "        return False\n",
    "    print(f\"正在压缩目录 {folder_path} 到 {zip_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # 获取文件夹内的所有文件和子文件夹\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for filename in files:\n",
    "                    file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "            # 使用 tqdm 显示压缩进度 (按文件数)\n",
    "            with tqdm(total=len(file_paths), desc=\"压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                for file in file_paths:\n",
    "                    # 计算文件在 zip 中的相对路径\n",
    "                    arcname = os.path.relpath(file, folder_path)\n",
    "                    zipf.write(file, arcname)\n",
    "                    pbar.update(1)\n",
    "        print(\"目录压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"压缩目录时出错: {e}\")\n",
    "        # 如果压缩失败，删除可能不完整的 zip 文件\n",
    "        if os.path.exists(zip_path):\n",
    "            try: os.remove(zip_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def unzip_directory(zip_path, extract_to_folder):\n",
    "    \"\"\"解压缩 zip 文件到指定文件夹。\"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"错误：要解压的 zip 文件不存在 {zip_path}\")\n",
    "        return False\n",
    "    print(f\"正在解压缩文件 {zip_path} 到 {extract_to_folder}...\")\n",
    "    try:\n",
    "        os.makedirs(extract_to_folder, exist_ok=True) # 确保目标文件夹存在\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # 获取 zip 文件中的成员数量以显示进度\n",
    "            total_files = len(zip_ref.namelist())\n",
    "            with tqdm(total=total_files, desc=\"解压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                # 使用 extractall 并更新进度条可能不直接，改为逐个提取\n",
    "                for member in zip_ref.infolist():\n",
    "                    zip_ref.extract(member, extract_to_folder)\n",
    "                    pbar.update(1)\n",
    "                    # 或者直接用 extractall，进度条可能不准确但更快\n",
    "                    # zip_ref.extractall(extract_to_folder)\n",
    "        print(\"文件解压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"解压缩文件时出错: {e}\")\n",
    "        # 如果解压失败，可以选择是否删除不完整的解压目录\n",
    "        # if os.path.exists(extract_to_folder):\n",
    "        #     shutil.rmtree(extract_to_folder)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "\n",
    "# 执行离线Patching\n",
    "调用函数开始处理\n",
    "如果输出目录已存在且包含文件，你可能想先清空或跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/pterygium/train/\"):\n",
    "    INPUT_IMAGE_DIR = \"/kaggle/input/pterygium/train/train\"\n",
    "    OUTPUT_PATCH_DIR = \"/kaggle/working/train_patches\"\n",
    "elif 'google.colab' in sys.modules:\n",
    "    INPUT_IMAGE_DIR = \"/content/trains/train\"\n",
    "    OUTPUT_PATCH_DIR = \"/content/train_patches\"\n",
    "elif os.name == 'nt':\n",
    "    INPUT_IMAGE_DIR = \"f:/train\"\n",
    "    OUTPUT_PATCH_DIR = \"f:/train_patches\"\n",
    "else:\n",
    "    INPUT_IMAGE_DIR = \"data/train/train\"\n",
    "    OUTPUT_PATCH_DIR = \"data/train_patches\"\n",
    "\n",
    "OUTPUT_IMAGE_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"images\")\n",
    "OUTPUT_MASK_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"masks\")\n",
    "LOCAL_TEMP_ZIP_PATH = os.path.join(os.path.dirname(OUTPUT_PATCH_DIR), \"patch_cache_temp.zip\") # 临时zip文件路径\n",
    "\n",
    "print(f\"使用设备: {device}\") # 确保 device 已定义\n",
    "print(f\"输入图像目录: {INPUT_IMAGE_DIR}\")\n",
    "print(f\"输出 Patch 目录: {OUTPUT_PATCH_DIR}\")\n",
    "print(f\"Patch 大小: {patch_size}x{patch_size}\")\n",
    "print(f\"步长: {patch_stride}\")\n",
    "print(f\"最小前景比例阈值: {MIN_FOREGROUND_RATIO}\")\n",
    "\n",
    "# --- 生成缓存键 ---\n",
    "# 注意：如果输入数据或标签文件内容变化，这个 key 不会变，需要更复杂的策略\n",
    "# 但对于固定数据集和参数，这个 key 是有效的\n",
    "try:\n",
    "    cache_key = f\"v1-{os.path.basename(INPUT_IMAGE_DIR)}-{os.path.basename(label_file)}-{patch_size}-{patch_stride}-{MIN_FOREGROUND_RATIO}\"\n",
    "    R2_CACHE_KEY = f\"patch_cache_{cache_key}.zip\"\n",
    "    print(f\"生成的 R2 缓存键: {R2_CACHE_KEY}\")\n",
    "except Exception as e:\n",
    "    print(f\"生成缓存键时出错: {e}。无法使用 R2 缓存。\")\n",
    "\n",
    "# --- R2 缓存检查与处理 ---\n",
    "r2_client, r2_configured = create_r2_client()\n",
    "run_patching = True # 默认需要执行 patching\n",
    "patch_count = 0   # 初始化 patch 数量\n",
    "\n",
    "if r2_client and r2_configured:\n",
    "    print(\"\\n--- 正在检查 R2 缓存 ---\")\n",
    "    if check_r2_cache(r2_client, R2_BUCKET_NAME, R2_CACHE_KEY):\n",
    "        print(f\"在 R2 上找到缓存文件: {R2_CACHE_KEY}\")\n",
    "        # 检查本地目录是否需要更新\n",
    "        should_download = True\n",
    "        if os.path.exists(OUTPUT_PATCH_DIR):\n",
    "            print(f\"本地目录 {OUTPUT_PATCH_DIR} 已存在。将删除旧目录以下载最新缓存。\")\n",
    "            try:\n",
    "                shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "            except Exception as e:\n",
    "                print(f\"删除本地旧目录 {OUTPUT_PATCH_DIR} 时出错: {e}。继续尝试下载...\")\n",
    "        else:\n",
    "            print(f\"本地目录 {OUTPUT_PATCH_DIR} 不存在。准备下载缓存。\")\n",
    "\n",
    "\n",
    "        if should_download:\n",
    "            if download_from_r2(r2_client, R2_BUCKET_NAME, R2_CACHE_KEY, LOCAL_TEMP_ZIP_PATH):\n",
    "                if unzip_directory(LOCAL_TEMP_ZIP_PATH, OUTPUT_PATCH_DIR):\n",
    "                    print(\"成功从 R2 下载并解压缓存。\")\n",
    "                    run_patching = False # 不需要本地 patching\n",
    "                    # 清理下载的 zip 文件\n",
    "                    try:\n",
    "                        os.remove(LOCAL_TEMP_ZIP_PATH)\n",
    "                        print(f\"已删除临时文件: {LOCAL_TEMP_ZIP_PATH}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"删除临时文件 {LOCAL_TEMP_ZIP_PATH} 时出错: {e}\")\n",
    "                    # 统计下载的 patches 数量\n",
    "                    try:\n",
    "                        existing_patches = glob.glob(os.path.join(OUTPUT_IMAGE_PATCH_DIR, \"*.png\"))\n",
    "                        patch_count = len(existing_patches)\n",
    "                        print(f\"使用 R2 缓存中的 {patch_count} 个 patches。\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"无法统计下载的 patches 数量: {e}\")\n",
    "                        patch_count = 0\n",
    "                else:\n",
    "                    print(\"解压 R2 缓存失败。将尝试本地 Patching。\")\n",
    "                    # 清理可能不完整的解压目录\n",
    "                    if os.path.exists(OUTPUT_PATCH_DIR): shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "            else:\n",
    "                print(\"从 R2 下载缓存失败。将尝试本地 Patching。\")\n",
    "    else:\n",
    "        print(f\"在 R2 上未找到对应的缓存文件 ({R2_CACHE_KEY})。\")\n",
    "else:\n",
    "    print(\"\\nR2 客户端未配置或创建失败，将跳过 R2 缓存检查。\")\n",
    "\n",
    "# --- 本地 Patching (如果需要) ---\n",
    "if run_patching:\n",
    "    print(\"\\n--- 执行本地 Patching ---\")\n",
    "    os.makedirs(OUTPUT_PATCH_DIR, exist_ok=True)\n",
    "\n",
    "    # 调用你的 patching 函数\n",
    "    processed_count, patch_count = create_offline_patches_gpu(\n",
    "        input_image_dir=INPUT_IMAGE_DIR,\n",
    "        label_file_path=label_file,\n",
    "        output_image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "        output_mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "        patch_size=patch_size,\n",
    "        stride=patch_stride,\n",
    "        device=device, # 确保 device 已定义\n",
    "        min_foreground_ratio=MIN_FOREGROUND_RATIO\n",
    "    )\n",
    "\n",
    "    # --- 上传到 R2 (如果 Patching 成功且 R2 已配置) ---\n",
    "    if patch_count > 0 and r2_client and r2_configured:\n",
    "        print(\"\\n--- 准备上传 Patching 结果到 R2 ---\")\n",
    "        if zip_directory(OUTPUT_PATCH_DIR, LOCAL_TEMP_ZIP_PATH):\n",
    "            if upload_to_r2(r2_client, R2_BUCKET_NAME, LOCAL_TEMP_ZIP_PATH, R2_CACHE_KEY):\n",
    "                print(f\"成功上传缓存 {R2_CACHE_KEY} 到 R2。\")\n",
    "            else:\n",
    "                print(f\"上传缓存 {R2_CACHE_KEY} 到 R2 失败。\")\n",
    "            # 清理本地 zip 文件\n",
    "            try:\n",
    "                os.remove(LOCAL_TEMP_ZIP_PATH)\n",
    "                print(f\"已删除本地临时 zip 文件: {LOCAL_TEMP_ZIP_PATH}\")\n",
    "            except Exception as e:\n",
    "                print(f\"删除本地临时 zip 文件 {LOCAL_TEMP_ZIP_PATH} 时出错: {e}\")\n",
    "        else:\n",
    "            print(\"压缩 Patching 结果失败，无法上传到 R2。\")\n",
    "    elif patch_count == 0:\n",
    "        print(\"本地 Patching 未生成任何文件，跳过上传。\")\n",
    "    else: # R2 未配置\n",
    "        print(\"R2 未配置，跳过上传缓存步骤。\")\n",
    "\n",
    "elif not run_patching:\n",
    "    print(\"\\nPatching 步骤已跳过（使用 R2 缓存）。\")\n",
    "else:\n",
    "    raise Exception(\"出现未知状态，未执行 Patching 也未使用缓存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# 验证生成的Patches\n",
    "随机抽查几个生成的图像和掩码Patch，确保它们是对应的并且格式正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_patches(image_patch_dir, mask_patch_dir, num_samples=5):\n",
    "    image_patches = glob.glob(os.path.join(image_patch_dir, \"*.png\"))\n",
    "    if not image_patches:\n",
    "        print(\"错误: 找不到生成的图像Patches。\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n随机抽查 {num_samples} 个生成的Patch对...\")\n",
    "    random_samples = random.sample(image_patches, min(num_samples, len(image_patches)))\n",
    "\n",
    "    fig, axes = plt.subplots(len(random_samples), 2, figsize=(8, 4 * len(random_samples)))\n",
    "    if len(random_samples) == 1: # 处理只有一个样本的情况\n",
    "        axes = axes.reshape(1, 2)\n",
    "\n",
    "    for i, img_path in enumerate(random_samples):\n",
    "        base_name = os.path.basename(img_path)\n",
    "        mask_path = os.path.join(mask_patch_dir, base_name)\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"错误: 找不到对应的掩码Patch {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        img_patch = Image.open(img_path)\n",
    "        mask_patch = Image.open(mask_path)\n",
    "\n",
    "        axes[i, 0].imshow(img_patch)\n",
    "        axes[i, 0].set_title(f\"图像 Patch:\\n{base_name}\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(mask_patch, cmap='gray')\n",
    "        axes[i, 1].set_title(f\"掩码 Patch (0/128):\\n{base_name}\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 执行验证\n",
    "try:\n",
    "    verify_patches(OUTPUT_IMAGE_PATCH_DIR, OUTPUT_MASK_PATCH_DIR, num_samples=5)\n",
    "except:\n",
    "    print(\"未生成任何Patch，跳过验证。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练时的增强\n",
    "train_transform = A.Compose([\n",
    "    # --- 空间变换 ---\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.0625, # 平移范围 (图像尺寸的百分比)\n",
    "        scale_limit=0.1,    # 缩放范围 (+/- 10%)\n",
    "        rotate_limit=15,    # 旋转范围 (+/- 15度)\n",
    "        interpolation=1,    # cv2.INTER_LINEAR for image\n",
    "        border_mode=0,      # cv2.BORDER_CONSTANT (padding mode)\n",
    "        value=0,            # padding value (for image)\n",
    "        mask_value=0,       # padding value (for mask)\n",
    "        p=0.7 # 应用这个组合变换的概率\n",
    "    ),\n",
    "    # 弹性变形\n",
    "    A.ElasticTransform(\n",
    "        alpha=1,        # 强度参数\n",
    "        sigma=50,       # 高斯核标准差\n",
    "        alpha_affine=50,# 仿射部分强度\n",
    "        interpolation=1,\n",
    "        border_mode=0,\n",
    "        value=0,\n",
    "        mask_value=0,\n",
    "        p=0.5\n",
    "    ),\n",
    "\n",
    "    # --- 强度/颜色变换 (只作用于图像) ---\n",
    "    # OneOf: 从列表中随机选一个应用\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "    ], p=0.3), # 应用其中一种噪声/模糊的概率\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.4), # gamma 在 0.8 到 1.2 之间\n",
    "\n",
    "    # --- 遮挡 ---\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, # 随机挖洞\n",
    "                    min_holes=1, min_height=8, min_width=8,\n",
    "                    fill_value=0, mask_fill_value=0, p=0.3), # 只对图像生效(mask_fill_value=0)\n",
    "\n",
    "    # --- 标准化 & 转 Tensor ---\n",
    "    # 注意：Normalize 必须在 ToTensorV2 之前或之后都可以，但通常放在最后\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2() # 将 NumPy [H,W,C] 转为 PyTorch [C,H,W]\n",
    "])\n",
    "\n",
    "# 验证/测试时的变换 (通常只有 Resize, Normalize, ToTensor)\n",
    "# 模型输入是 Patch，这里不需要 Resize\n",
    "val_transform_alb = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "9d732b67",
    "language": "markdown",
    "papermill": {
     "duration": 0.016085,
     "end_time": "2025-04-13T12:54:26.726871",
     "exception": false,
     "start_time": "2025-04-13T12:54:26.710786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 创建数据加载器\n",
    "设置训练和验证数据加载器，包括数据增强策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "2ba9d65a",
    "language": "python",
    "papermill": {
     "duration": 0.029269,
     "end_time": "2025-04-13T12:54:26.772737",
     "exception": false,
     "start_time": "2025-04-13T12:54:26.743468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PterygiumSegDataset(Dataset):\n",
    "    def __init__(self, image_patch_dir, mask_patch_dir, file_list=None, transform=None):\n",
    "            \"\"\"\n",
    "            初始化数据集 (加载离线 Patches)\n",
    "            :param image_patch_dir: 包含图像 patch 文件的目录\n",
    "            :param mask_patch_dir: 包含对应掩码 patch 文件的目录\n",
    "            :param file_list: (可选) 一个文件名列表，只加载这些文件。如果为 None，加载目录下所有文件。\n",
    "            :param transform: (可选) 预处理和数据增强的转换函数\n",
    "            \"\"\"\n",
    "            self.image_patch_dir = image_patch_dir\n",
    "            self.mask_patch_dir = mask_patch_dir\n",
    "            self.transform = transform\n",
    "    \n",
    "            # 获取 patch 的文件名列表\n",
    "            if file_list is None:\n",
    "                self.image_filenames = sorted([\n",
    "                    f for f in os.listdir(image_patch_dir)\n",
    "                    if os.path.isfile(os.path.join(image_patch_dir, f)) and f.endswith('.png')\n",
    "                ])\n",
    "            else:\n",
    "                self.image_filenames = sorted([f for f in file_list if f.endswith('.png')]) # 使用提供的列表\n",
    "\n",
    "            if not self.image_filenames:\n",
    "                # 检查是否是因为目录不存在或为空\n",
    "                if not os.path.isdir(image_patch_dir):\n",
    "                    raise FileNotFoundError(f\"图像 patch 目录不存在: {image_patch_dir}\")\n",
    "                elif not os.listdir(image_patch_dir) and file_list is None:\n",
    "                    print(f\"警告: 目录 {image_patch_dir} 为空。\")\n",
    "                    # Dataset 将为空，len() == 0\n",
    "                elif file_list is not None and not self.image_filenames:\n",
    "                    print(f\"警告: 提供的 file_list 为空或不包含 .png 文件。\")\n",
    "                else:\n",
    "                    # 目录存在但 filtered list 为空\n",
    "                    print(f\"警告: 在目录 {image_patch_dir} 中未找到匹配的 .png 文件 (可能检查 file_list)。\")\n",
    "    \n",
    "            # 定义图像标准化 (这个总是在最后应用)\n",
    "            self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            print(f\"数据集初始化: 找到 {len(self.image_filenames)} 个 patches in {image_patch_dir}\" + (f\" (来自 file_list)\" if file_list is not None else \"\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本的数量 (即 patch 的数量)\"\"\"\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像 patch 和 掩码 patch\n",
    "        :param idx: 索引\n",
    "        :return: 图像 patch 张量和对应掩码 patch 张量\n",
    "        \"\"\"\n",
    "        # 获取文件名\n",
    "        patch_filename = self.image_filenames[idx]\n",
    "        \n",
    "        # 构建完整路径\n",
    "        img_path = os.path.join(self.image_patch_dir, patch_filename)\n",
    "        mask_path = os.path.join(self.mask_patch_dir, patch_filename)\n",
    "\n",
    "        # 加载图像和掩码 patch (PIL Images)\n",
    "        try:\n",
    "            image_patch = Image.open(img_path).convert(\"RGB\")\n",
    "            mask_patch = Image.open(mask_path).convert(\"RGB\") # 掩码是 (128,0,0)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 文件未找到 {img_path} 或 {mask_path}\")\n",
    "            # 返回一个虚拟数据或引发错误\n",
    "            dummy_size = (3, 256, 256) # 假设 patch size 是 256x256，如果不同需要修改\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "        except Exception as e:\n",
    "            print(f\"加载 patch 时出错 {patch_filename}: {e}\")\n",
    "            # 返回虚拟数据\n",
    "            dummy_size = (3, 256, 256)\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "\n",
    "\n",
    "        # 应用 albumentations 变换\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_patch, mask=mask_binary)\n",
    "            image_tensor = augmented['image'] # 已经是 Tensor [C,H,W]\n",
    "            mask_tensor = augmented['mask'].unsqueeze(0) # 已经是 Tensor [H,W]，增加通道维度 -> [1,H,W]\n",
    "        else:\n",
    "            # 如果没有指定变换，直接标准化和转 Tensor\n",
    "            # --- 转换为 Tensor ---\n",
    "            image_tensor = F.to_tensor(image_patch)\n",
    "            # --- 掩码处理：转换为单通道二值Tensor ---\n",
    "            # 将 PIL Mask 转换为 NumPy array (H, W, C)\n",
    "            mask_np = np.array(mask_patch)\n",
    "            # 检查红色通道是否为 128 来确定翼状胬肉区域\n",
    "            # mask_binary 的形状将是 (H, W)，值为 True/False\n",
    "            mask_binary = (mask_np[:, :, 0] == 128)\n",
    "            # 转换为 float32 类型的 0.0 或 1.0\n",
    "            mask_np_float = mask_binary.astype(np.float32)\n",
    "            # 转换为 PyTorch Tensor，并增加一个通道维度 (H, W) -> (1, H, W)\n",
    "            mask_tensor = torch.from_numpy(mask_np_float).unsqueeze(0)\n",
    "            # --- 标准化图像 ---\n",
    "            image_tensor = self.normalize(image_tensor)\n",
    "\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保 Patch 目录存在且包含文件\n",
    "if not os.path.exists(OUTPUT_IMAGE_PATCH_DIR) or not os.listdir(OUTPUT_IMAGE_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的图像 Patches 于 {OUTPUT_IMAGE_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "if not os.path.exists(OUTPUT_MASK_PATCH_DIR) or not os.listdir(OUTPUT_MASK_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的掩码 Patches 于 {OUTPUT_MASK_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "\n",
    "# 1. 获取所有 Patch 文件名\n",
    "all_patch_files = sorted([\n",
    "    f for f in os.listdir(OUTPUT_IMAGE_PATCH_DIR)\n",
    "    if os.path.isfile(os.path.join(OUTPUT_IMAGE_PATCH_DIR, f)) and f.endswith('.png')\n",
    "])\n",
    "\n",
    "if not all_patch_files:\n",
    "    raise ValueError(f\"错误：在 {OUTPUT_IMAGE_PATCH_DIR} 中未找到任何 Patch 文件。\")\n",
    "\n",
    "# 2. 按原始图像 ID 分组 Patch 文件名\n",
    "#    假设文件名格式为 \"XXXX_yYYY_xZZZ.png\"，其中 XXXX 是原始图像 ID\n",
    "patches_by_original_image = collections.defaultdict(list)\n",
    "for filename in all_patch_files:\n",
    "    try:\n",
    "        # 提取前4位作为原始图像 ID\n",
    "        original_image_id = filename[:4]\n",
    "        # 检查是否是有效的数字ID (可选，增加健壮性)\n",
    "        if original_image_id.isdigit():\n",
    "            patches_by_original_image[original_image_id].append(filename)\n",
    "        else:\n",
    "            print(f\"警告：无法从文件名 {filename} 中提取有效的原始图像 ID，跳过此文件。\")\n",
    "    except IndexError:\n",
    "        print(f\"警告：文件名 {filename} 格式不符合预期，无法提取原始图像 ID，跳过此文件。\")\n",
    "\n",
    "if not patches_by_original_image:\n",
    "    raise ValueError(\"错误：无法根据文件名对任何 Patch 进行分组。请检查文件名格式。\")\n",
    "\n",
    "# 3. 获取所有唯一的原始图像 ID\n",
    "unique_original_ids = sorted(list(patches_by_original_image.keys()))\n",
    "print(f\"从 {len(all_patch_files)} 个 Patches 中识别出 {len(unique_original_ids)} 个唯一的原始图像来源。\")\n",
    "\n",
    "# 4. 在唯一的原始图像 ID 层面进行训练/验证划分\n",
    "#    这样可以保证同一原始图像的所有 Patches 都在同一个集合中\n",
    "val_split_ratio = 0.2 # 验证集占原始图像 ID 的比例\n",
    "try:\n",
    "    train_ids, val_ids = train_test_split(\n",
    "        unique_original_ids,\n",
    "        test_size=val_split_ratio,\n",
    "        random_state=42 # 保证划分可复现\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"错误：无法进行 train_test_split。可能是唯一 ID 数量过少。错误信息: {e}\")\n",
    "    # 可以根据情况处理，例如使用所有数据进行训练，或者调整比例\n",
    "    if len(unique_original_ids) < 2:\n",
    "        print(\"唯一原始图像 ID 少于 2 个，无法划分验证集。将使用所有数据进行训练。\")\n",
    "        train_ids = unique_original_ids\n",
    "        val_ids = []\n",
    "    else:\n",
    "        # 其他错误，重新抛出\n",
    "        raise e\n",
    "\n",
    "print(f\"划分结果：{len(train_ids)} 个原始图像用于训练，{len(val_ids)} 个原始图像用于验证。\")\n",
    "\n",
    "# 5. 根据划分的 ID 列表，构建训练和验证的 Patch 文件名列表\n",
    "train_filenames = []\n",
    "for img_id in train_ids:\n",
    "    train_filenames.extend(patches_by_original_image[img_id])\n",
    "\n",
    "val_filenames = []\n",
    "for img_id in val_ids:\n",
    "    val_filenames.extend(patches_by_original_image[img_id])\n",
    "\n",
    "print(f\"划分后的 Patch 数量：训练集 {len(train_filenames)} Patches，验证集 {len(val_filenames)} Patches。\")\n",
    "# 注意：这里的 Patch 数量比例不一定会严格等于原始图像 ID 的比例 (val_split_ratio)，\n",
    "# 因为不同原始图像产生的 Patch 数量可能不同。\n",
    "\n",
    "# 6. 创建独立的训练和验证 Dataset 实例\n",
    "train_dataset_offline = PterygiumSegDataset(\n",
    "    image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "    mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "    file_list=train_filenames, # 传入分组后的训练文件名列表\n",
    "    transform=train_transform\n",
    ")\n",
    "# 只有在 val_filenames 不为空时才创建验证集\n",
    "if val_filenames:\n",
    "    val_dataset_offline = PterygiumSegDataset(\n",
    "        image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "        mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "        file_list=val_filenames, # 传入分组后的验证文件名列表\n",
    "        augment=False # 验证时不进行增强\n",
    "        transform=val_transform_alb\n",
    "    )\n",
    "else:\n",
    "    val_dataset_offline = None # 如果没有验证 ID，则验证集为空\n",
    "    print(\"警告：验证集为空。\")\n",
    "\n",
    "\n",
    "# 7. 创建 DataLoader\n",
    "train_loader_batch_size = tpu_batch_size if _xla_available else (cuda_batch_size if torch.cuda.is_available() else windows_batch_size)\n",
    "val_loader_batch_size = train_loader_batch_size\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_offline,\n",
    "    batch_size=train_loader_batch_size,\n",
    "    shuffle=True, # 训练时打乱顺序\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=not _xla_available and torch.cuda.is_available(),\n",
    "    drop_last=True if _xla_available else False\n",
    ")\n",
    "\n",
    "# 只有在验证集存在时才创建 val_loader\n",
    "if val_dataset_offline:\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_offline,\n",
    "        batch_size=val_loader_batch_size,\n",
    "        shuffle=False, # 验证时不需要打乱\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=not _xla_available and torch.cuda.is_available(),\n",
    "        drop_last=True if _xla_available else False\n",
    "    )\n",
    "    print(f\"\\n训练集大小 (Patches): {len(train_dataset_offline)}\")\n",
    "    print(f\"验证集大小 (Patches): {len(val_dataset_offline)}\")\n",
    "    print(f\"训练 DataLoader 批次数: {len(train_loader)}\")\n",
    "    print(f\"验证 DataLoader 批次数: {len(val_loader)}\")\n",
    "else:\n",
    "    val_loader = None\n",
    "    print(f\"\\n训练集大小 (Patches): {len(train_dataset_offline)}\")\n",
    "    print(\"验证集为空，无法创建验证 DataLoader。\")\n",
    "    # 可能需要调整后续的训练/验证循环逻辑，跳过验证步骤\n",
    "\n",
    "# 清理不再需要的大列表\n",
    "del all_patch_files, patches_by_original_image, unique_original_ids\n",
    "del train_ids, val_ids #, train_filenames, val_filenames # 如果后续不再需要这些列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# 测试数据加载器\n",
    "取一个批次的数据出来看看形状和内容是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    images_batch, masks_batch = next(iter(train_loader))\n",
    "    print(\"\\n从训练加载器获取一个批次的数据:\")\n",
    "    print(f\"图像批次形状: {images_batch.shape}\") # 应该类似 [BATCH_SIZE, 3, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"掩码批次形状: {masks_batch.shape}\")   # 应该类似 [BATCH_SIZE, 1, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"图像数据类型: {images_batch.dtype}\")\n",
    "    print(f\"掩码数据类型: {masks_batch.dtype}\")\n",
    "    print(f\"掩码最小值: {masks_batch.min()}\") # 应该是 0.0\n",
    "    print(f\"掩码最大值: {masks_batch.max()}\") # 应该是 1.0\n",
    "    \n",
    "    # 可视化一个样本\n",
    "    sample_idx = 0\n",
    "    img_sample = images_batch[sample_idx].permute(1, 2, 0).numpy() # CHW -> HWC\n",
    "    mask_sample = masks_batch[sample_idx].squeeze().numpy()       # 1HW -> HW\n",
    "    \n",
    "    # 反归一化以便显示\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_sample = std * img_sample + mean\n",
    "    img_sample = np.clip(img_sample, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(img_sample)\n",
    "    axes[0].set_title(\"示例图像 Patch (反归一化)\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(mask_sample, cmap='gray')\n",
    "    axes[1].set_title(\"示例掩码 Patch (0/1)\")\n",
    "    axes[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"错误：无法从 DataLoader 获取数据，请检查数据集是否为空或配置是否正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"测试 DataLoader 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "7700c359",
    "language": "markdown",
    "papermill": {
     "duration": 0.016819,
     "end_time": "2025-04-13T12:54:30.151721",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.134902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建U-Net分割模型\n",
    "U-Net是一种经典的图像分割模型，其结构包括下采样路径（编码器）和上采样路径（解码器），以及跳跃连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "b1637cba",
    "language": "python",
    "papermill": {
     "duration": 0.641308,
     "end_time": "2025-04-13T12:54:30.809649",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.168341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"双卷积块：(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下采样层：MaxPool + DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样层：UpConv + DoubleConv（带跳跃连接）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        # 使用双线性插值或转置卷积进行上采样\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # 输入可能不是整数倍的2，需要进行尺寸调整\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # 连接特征图\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"输出卷积层\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"完整的UNet模型\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True, dropout_p=0.5):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # 加载预训练的ResNet-18\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # 编码器部分 (使用ResNet-18的层)\n",
    "        self.inc = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        ) # 输出通道: 64\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.down1 = resnet.layer1 # 输出通道: 64\n",
    "        self.down2 = resnet.layer2 # 输出通道: 128\n",
    "        self.down3 = resnet.layer3 # 输出通道: 256\n",
    "        self.down4 = resnet.layer4 # 输出通道: 512\n",
    "\n",
    "        # --- 瓶颈层后 Dropout 层 ---\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        # 解码器部分 (调整通道数以匹配ResNet)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.up1 = Up(512 + 256, 512 // factor, bilinear) # down4(512) + down3(256) -> 256\n",
    "        self.up2 = Up(256 + 128, 256 // factor, bilinear) # up1(256) + down2(128) -> 128\n",
    "        self.up3 = Up(128 + 64, 128 // factor, bilinear)  # up2(128) + down1(64) -> 64\n",
    "        self.up4 = Up(64 + 64, 64, bilinear)             # up3(64) + inc(64) -> 64\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码路径 (ResNet)\n",
    "        x1 = self.inc(x)       # (N, 64, H/2, W/2) after initial conv+bn+relu (stride=2)\n",
    "        x_pool = self.maxpool(x1) # (N, 64, H/4, W/4)\n",
    "        x2 = self.down1(x_pool) # (N, 64, H/4, W/4)\n",
    "        x3 = self.down2(x2)     # (N, 128, H/8, W/8)\n",
    "        x4 = self.down3(x3)     # (N, 256, H/16, W/16)\n",
    "        x5 = self.down4(x4)     # (N, 512, H/32, W/32)\n",
    "\n",
    "        # --- Dropout 层 ---\n",
    "        x5_dropout = self.dropout(x5)\n",
    "\n",
    "        # 解码路径 (带跳跃连接)\n",
    "        x = self.up1(x5_dropout, x4) # 输入: x5(512), x4(256) -> 输出: 256\n",
    "        x = self.up2(x, x3)  # 输入: x(256), x3(128) -> 输出: 128\n",
    "        x = self.up3(x, x2)  # 输入: x(128), x2(64) -> 输出: 64\n",
    "        x = self.up4(x, x1)  # 输入: x(64), x1(64) -> 输出: 64\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# 初始化模型\n",
    "model = UNet(n_classes=1, bilinear=True, dropout_p=0.5).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"检测到 {torch.cuda.device_count()} 块GPU, 由于多卡存在问题，只使用GPU0\")\n",
    "    #model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "cefa71b2",
    "language": "markdown",
    "papermill": {
     "duration": 0.018469,
     "end_time": "2025-04-13T12:54:30.847525",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.829056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 定义损失函数和评估指标\n",
    "我们使用组合损失函数：二元交叉熵损失和Dice损失的组合，以更好地处理类别不平衡问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "ff097418",
    "language": "python",
    "papermill": {
     "duration": 0.027326,
     "end_time": "2025-04-13T12:54:30.892288",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.864962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dice损失函数\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # 使用sigmoid将logits转换为概率\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # 将维度展平\n",
    "        batch_size = targets.size(0)\n",
    "        probs = probs.view(batch_size, -1)\n",
    "        targets = targets.view(batch_size, -1)\n",
    "        \n",
    "        # 计算交集\n",
    "        intersection = (probs * targets).sum(dim=1)\n",
    "        \n",
    "        # 计算Dice系数\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            probs.sum(dim=1) + targets.sum(dim=1) + self.smooth)\n",
    "        \n",
    "        # 返回Dice损失\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# 组合损失\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        # BCEWithLogitsLoss 实例本身不存储 pos_weight, 在 forward 中传入\n",
    "        self.bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss_fn = DiceLoss()\n",
    "\n",
    "    def forward(self, logits, targets, pos_weight=None):\n",
    "        \"\"\"\n",
    "        计算组合损失。\n",
    "        :param logits: 模型输出 (N, 1, H, W)\n",
    "        :param targets: 真实掩码 (N, 1, H, W)\n",
    "        :param pos_weight: 正样本权重 (scalar) for BCE loss.\n",
    "        \"\"\"\n",
    "        # 更新BCE损失的pos_weight参数\n",
    "        self.bce_loss_fn.pos_weight = pos_weight\n",
    "        bce = self.bce_loss_fn(logits, targets)\n",
    "\n",
    "        dice = self.dice_loss_fn(logits, targets)\n",
    "        return self.bce_weight * bce + self.dice_weight * dice\n",
    "\n",
    "# 评估指标：Dice系数\n",
    "def dice_coefficient(y_pred, y_true, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"计算预测掩码和真实掩码之间的Dice系数\"\"\"\n",
    "    assert y_pred.shape == y_true.shape, f\"预测形状 {y_pred.shape} 与目标形状 {y_true.shape} 不匹配\"\n",
    "    # 应用阈值将概率转换为二值掩码\n",
    "    y_pred = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    \n",
    "    # 压平张量\n",
    "    y_pred = y_pred.contiguous().view(-1)\n",
    "    y_true = y_true.contiguous().view(-1)\n",
    "    \n",
    "    # 计算交集\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    \n",
    "    # 计算Dice系数\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = CombinedLoss(bce_weight=0.6, dice_weight=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "9ee6f7d9",
    "language": "markdown",
    "papermill": {
     "duration": 0.016647,
     "end_time": "2025-04-13T12:54:30.925830",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.909183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam优化器和学习率调度器，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "9cfd0144",
    "language": "python",
    "papermill": {
     "duration": 0.022822,
     "end_time": "2025-04-13T12:54:30.965406",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.942584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "num_epochs = 30\n",
    "log_interval = 5\n",
    "\n",
    "# 配置优化器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=7e-5)\n",
    "\n",
    "# 学习率调度器\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6) # 使用基线超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "d6ea8258",
    "language": "markdown",
    "papermill": {
     "duration": 0.016547,
     "end_time": "2025-04-13T12:54:30.998872",
     "exception": false,
     "start_time": "2025-04-13T12:54:30.982325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播、参数更新，并记录训练过程中的指标。同时实现早停机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "67252228",
    "language": "python",
    "papermill": {
     "duration": 0.024384,
     "end_time": "2025-04-13T12:54:31.039851",
     "exception": false,
     "start_time": "2025-04-13T12:54:31.015467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max', verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 在性能没有提升多少轮后停止训练。\n",
    "            min_delta (float): 被认为是性能提升的最小变化量。\n",
    "            mode (str): 'min' 或 'max'。监控指标是越小越好还是越大越好。\n",
    "            verbose (bool): 是否打印早停信息。\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state_dict_cpu = None # 直接存储 CPU 上的 state_dict\n",
    "\n",
    "        if self.mode not in ['min', 'max']:\n",
    "            raise ValueError(\"mode 必须是 'min' 或 'max'\")\n",
    "\n",
    "        self.delta_sign = 1 if mode == 'max' else -1\n",
    "\n",
    "    def __call__(self, val_score, model_state_dict_cpu):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            val_score (float): 当前验证分数。\n",
    "            model_state_dict_cpu (dict): 模型当前的 state_dict (已移至 CPU)。\n",
    "        \"\"\"\n",
    "        score = val_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state_dict_cpu = deepcopy(model_state_dict_cpu) # 保存第一个状态\n",
    "            if self.verbose:\n",
    "                tqdm.write(f\"EarlyStopping: 初始化最佳分数为 {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升 (乘以 delta_sign 以统一处理 min/max)\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            self.best_score = score\n",
    "            self.best_model_state_dict_cpu = deepcopy(model_state_dict_cpu) # 保存更好的状态\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                tqdm.write(f\"EarlyStopping: 发现改进。最佳分数更新为 {self.best_score:.4f}。计数器重置。\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                tqdm.write(f'EarlyStopping计数器: {self.counter}/{self.patience}。最佳分数仍为 {self.best_score:.4f}。')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    tqdm.write(\"EarlyStopping: 已达到耐心值，触发早停。\")\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        \"\"\"将最佳权重加载回模型\"\"\"\n",
    "        if self.best_model_state_dict_cpu:\n",
    "            # 需要将 state_dict 移回模型所在的设备\n",
    "            device = next(model.parameters()).device\n",
    "            best_state_device = {k: v.to(device) for k, v in self.best_model_state_dict_cpu.items()}\n",
    "            model.load_state_dict(best_state_device)\n",
    "            if self.verbose:\n",
    "                print(\"已将最佳模型权重加载回模型。\")\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(\"警告：未找到可加载的最佳模型权重。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "8226a404",
    "language": "python",
    "papermill": {
     "duration": 9419.261074,
     "end_time": "2025-04-13T15:31:30.317789",
     "exception": false,
     "start_time": "2025-04-13T12:54:31.056715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持单核TPU、CUDA和CPU。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 要训练的模型 (应已移动到目标 device)。\n",
    "        train_loader (DataLoader): 训练数据加载器。\n",
    "        val_loader (DataLoader): 验证数据加载器。\n",
    "        criterion (nn.Module): 损失函数。\n",
    "        optimizer: 优化器。\n",
    "        scheduler: 学习率调度器。\n",
    "        num_epochs (int): 训练的总轮数。\n",
    "        device (torch.device or str): 目标设备 ('cpu', 'cuda', or xm.xla_device())。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (最终验证Dice系数, 训练Dice历史, 验证Dice历史, 最佳模型在CPU上的state_dict)\n",
    "            如果验证加载器为 None，则最终验证 Dice 为 0，验证历史为空。\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    is_tpu = 'xla' in str(device)\n",
    "    print(f\"\\n--- 开始训练 ---\")\n",
    "    print(f\"设备: {device}\")\n",
    "    print(f\"轮数: {num_epochs}\")\n",
    "    print(f\"优化器: {type(optimizer).__name__}\")\n",
    "    print(f\"学习率调度器: {type(scheduler).__name__}\")\n",
    "    print(f\"损失函数: {type(criterion).__name__}\")\n",
    "\n",
    "    # 初始化 EarlyStopping\n",
    "    # 注意：如果 val_loader 为 None，早停将基于不存在的验证分数，实际上不会起作用，\n",
    "    # 但我们仍然创建它以保持代码结构一致。训练将运行完所有 num_epochs。\n",
    "    # 在这种情况下，我们保存最后一轮的模型。\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max', min_delta=0.001, verbose=True)\n",
    "\n",
    "    # 配置混合精度 (仅用于 CUDA)\n",
    "    use_amp = not is_tpu and torch.cuda.is_available()\n",
    "    scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    print(f\"使用混合精度 (AMP): {use_amp}\")\n",
    "\n",
    "    train_dice_history = []\n",
    "    val_dice_history = []\n",
    "    best_model_state_dict_cpu = None # 存储在CPU上的最佳权重\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # --- 训练阶段 ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_samples = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
    "\n",
    "        for images, masks in train_loader_tqdm:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # --- 计算 pos_weight (移至设备) ---\n",
    "            num_pixels = masks.numel()\n",
    "            num_pos = torch.sum(masks)\n",
    "            num_neg = num_pixels - num_pos\n",
    "            # 避免除以零，并确保 pos_weight 合理\n",
    "            pos_weight_value = torch.clamp(num_neg / (num_pos + 1e-6), min=1.0) # 至少为1，防止过分抑制前景\n",
    "            pos_weight_tensor = torch.tensor([pos_weight_value], device=device)\n",
    "\n",
    "            # --- 前向传播 (根据需要使用 AMP) ---\n",
    "            with torch.amp.autocast(device_type=str(device).split(':')[0], enabled=use_amp):\n",
    "                outputs = model(images)\n",
    "                # 确保掩码尺寸与输出匹配\n",
    "                masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                loss = criterion(outputs, masks_downsampled, pos_weight=pos_weight_tensor)\n",
    "\n",
    "            # --- 反向传播和优化 ---\n",
    "            if is_tpu:\n",
    "                loss.backward()\n",
    "                # xm.optimizer_step 会处理梯度同步（如果需要）和权重更新\n",
    "                xm.optimizer_step(optimizer)\n",
    "                # 对于单核 TPU，通常不需要显式的 xm.mark_step() 在这里\n",
    "            else: # CPU 或 CUDA\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # --- 累积指标 ---\n",
    "            batch_size = images.size(0)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            # dice_coefficient 应能在各种设备上运行\n",
    "            current_dice = dice_coefficient(outputs.detach(), masks_downsampled.detach())\n",
    "            train_dice += current_dice * batch_size\n",
    "            train_samples += batch_size\n",
    "\n",
    "            # --- 更新进度条 ---\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{current_dice:.4f}',\n",
    "                'lr': f'{current_lr:.1e}',\n",
    "                'pw': f'{pos_weight_value.item():.2f}'\n",
    "            })\n",
    "\n",
    "        # --- 计算平均训练指标 ---\n",
    "        if train_samples > 0:\n",
    "            train_loss /= train_samples\n",
    "            train_dice /= train_samples\n",
    "        else:\n",
    "            train_loss, train_dice = 0.0, 0.0 # 处理空 loader 的情况\n",
    "        train_dice_history.append(train_dice)\n",
    "\n",
    "        # --- 验证阶段 (如果 val_loader 存在) ---\n",
    "        current_val_dice = 0.0 # 初始化本轮验证分数\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_dice = 0.0\n",
    "            val_samples = 0\n",
    "            val_loader_tqdm = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader_tqdm:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    # 前向传播 (验证时通常不使用 AMP autocast，但也可以用)\n",
    "                    outputs = model(images)\n",
    "                    masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                    # 验证时不使用 pos_weight\n",
    "                    loss = criterion(outputs, masks_downsampled, pos_weight=None)\n",
    "\n",
    "                    # --- 累积指标 ---\n",
    "                    batch_size = images.size(0)\n",
    "                    val_loss += loss.item() * batch_size\n",
    "                    current_dice_val = dice_coefficient(outputs, masks_downsampled)\n",
    "                    val_dice += current_dice_val * batch_size\n",
    "                    val_samples += batch_size\n",
    "\n",
    "                    val_loader_tqdm.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'dice': f'{current_dice_val:.4f}'\n",
    "                        })\n",
    "\n",
    "\n",
    "            # --- 计算平均验证指标 ---\n",
    "            if val_samples > 0:\n",
    "                val_loss /= val_samples\n",
    "                val_dice /= val_samples\n",
    "            else:\n",
    "                val_loss, val_dice = 0.0, 0.0 # 处理空 loader\n",
    "            val_dice_history.append(val_dice)\n",
    "            current_val_dice = val_dice # 更新本轮验证分数用于早停\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, \"\n",
    "                    f\"LR: {current_lr:.1e}, Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "            # --- 早停检查 (仅当有验证集时) ---\n",
    "            # 获取当前模型状态到 CPU\n",
    "            current_model_state_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            early_stopping(current_val_dice, current_model_state_cpu) # 使用修改后的 ES 类\n",
    "            if early_stopping.early_stop:\n",
    "                best_model_state_dict_cpu = early_stopping.best_model_state_dict_cpu # 获取最佳状态\n",
    "                break # 跳出 epoch 循环\n",
    "\n",
    "        else:\n",
    "            # 如果没有验证集，直接打印训练结果\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, \"\n",
    "                    f\"LR: {current_lr:.1e}, Duration: {epoch_duration:.2f}s\")\n",
    "            # 没有验证集，无法早停，将保存最后一轮的模型状态\n",
    "            if epoch == num_epochs - 1: # 如果是最后一轮\n",
    "                best_model_state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "\n",
    "        # --- 更新学习率 ---\n",
    "        # CosineAnnealingLR 在每个 epoch 后调用 step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # --- 训练结束处理 ---\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(\"\\n--- 训练完成 ---\")\n",
    "\n",
    "    # 如果没有提前停止，并且有最佳权重记录 (来自验证过程)\n",
    "    if not early_stopping.early_stop and early_stopping.best_model_state_dict_cpu is not None:\n",
    "        best_model_state_dict_cpu = early_stopping.best_model_state_dict_cpu\n",
    "        print(f\"训练完成 {num_epochs} 轮。使用验证集找到的最佳模型权重。\")\n",
    "    elif early_stopping.early_stop:\n",
    "        print(f\"训练因早停而在第 {epoch + 1} 轮结束。\")\n",
    "        # best_model_state_dict_cpu 已在 break 前被赋值\n",
    "    elif best_model_state_dict_cpu is None: # 训练完成但从未有过最佳状态(例如val_loader=None)\n",
    "        print(\"警告：训练完成，但没有记录最佳模型权重（可能因为没有验证集）。将使用最后一轮的模型权重。\")\n",
    "        # 此时 best_model_state_dict_cpu 应该已经被赋值为最后一轮的状态\n",
    "        if best_model_state_dict_cpu is None: # 双重检查，理论上不应发生\n",
    "            best_model_state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "\n",
    "    # --- 使用最佳模型进行最终评估 (如果 val_loader 存在) ---\n",
    "    final_val_dice = 0.0\n",
    "    if val_loader and best_model_state_dict_cpu:\n",
    "        print(\"\\n使用最佳权重在验证集上进行最终评估...\")\n",
    "        # 将最佳权重加载回模型 (确保移回正确的设备)\n",
    "        best_state_device = {k: v.to(device) for k, v in best_model_state_dict_cpu.items()}\n",
    "        model.load_state_dict(best_state_device)\n",
    "        model.eval()\n",
    "        val_samples_final = 0\n",
    "        val_dice_final = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=\"Final Validation\", leave=False):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                batch_size = images.size(0)\n",
    "                val_dice_final += dice_coefficient(outputs, masks_downsampled) * batch_size\n",
    "                val_samples_final += batch_size\n",
    "        if val_samples_final > 0:\n",
    "            final_val_dice = val_dice_final / val_samples_final\n",
    "        else:\n",
    "            final_val_dice = 0.0\n",
    "        print(f\"最终(最佳)验证 Dice 系数: {final_val_dice:.4f}\")\n",
    "    elif not val_loader:\n",
    "        print(\"没有提供验证集，跳过最终验证评估。\")\n",
    "    else: # 有 val_loader 但没有 best_model_state_dict_cpu\n",
    "        print(\"警告：无法获取最佳模型权重，无法进行最终验证评估。\")\n",
    "\n",
    "\n",
    "    print(f\"总训练耗时: {total_training_time:.2f} 秒\")\n",
    "\n",
    "    # 返回最终验证 Dice 和 CPU 上的最佳 state_dict\n",
    "    return final_val_dice, train_dice_history, val_dice_history, best_model_state_dict_cpu\n",
    "\n",
    "# 开始训练\n",
    "best_dice, train_dice_history, val_dice_history, best_model_weights = train_validate_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler, # 如果是ReduceLROnPlateau, scheduler.step(val_dice)\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "0c161af4",
    "language": "markdown",
    "papermill": {
     "duration": 0.020103,
     "end_time": "2025-04-13T15:31:30.358707",
     "exception": false,
     "start_time": "2025-04-13T15:31:30.338604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型性能\n",
    "可视化学习曲线和分割结果，计算Dice系数和95% Hausdorff距离等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "958069be",
    "language": "python",
    "papermill": {
     "duration": 8.053137,
     "end_time": "2025-04-13T15:31:38.432143",
     "exception": false,
     "start_time": "2025-04-13T15:31:30.379006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化学习曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_dice_history) + 1), train_dice_history, label='训练Dice系数')\n",
    "plt.plot(range(1, len(val_dice_history) + 1), val_dice_history, label='验证Dice系数')\n",
    "plt.title('训练和验证Dice系数')\n",
    "plt.xlabel('轮次')\n",
    "plt.ylabel('Dice系数')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 可视化分割结果\n",
    "def visualize_segmentation(model, dataloader, num_samples=5):\n",
    "    \"\"\"可视化分割结果\"\"\"\n",
    "    model.eval()\n",
    "    dataiter = iter(dataloader)\n",
    "    \n",
    "    # 获取一批数据\n",
    "    try:\n",
    "        images, masks = next(dataiter)\n",
    "    except StopIteration:\n",
    "        print(\"数据集太小，无法获取足够的样本。\")\n",
    "        return\n",
    "    \n",
    "    # 限制样本数\n",
    "    num_samples = min(num_samples, images.size(0))\n",
    "    \n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        outputs = model(images)\n",
    "        pred_masks = (torch.sigmoid(outputs) > 0.5).float()\n",
    "    \n",
    "    # 反标准化图像以便可视化\n",
    "    images_np = []\n",
    "    for img in images[:num_samples]:\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)  # 转为HWC格式\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        images_np.append(img)\n",
    "    \n",
    "    # 准备掩码和预测\n",
    "    masks_np = masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    pred_masks_np = pred_masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 原始图像\n",
    "        axes[i, 0].imshow(images_np[i])\n",
    "        axes[i, 0].set_title('原始图像')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 真实掩码\n",
    "        axes[i, 1].imshow(masks_np[i], cmap='gray')\n",
    "        axes[i, 1].set_title('真实掩码')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 预测掩码\n",
    "        axes[i, 2].imshow(pred_masks_np[i], cmap='gray')\n",
    "        masks_downsampled = torch.nn.functional.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "        dice = dice_coefficient(outputs[i:i+1], masks_downsampled[i:i+1])\n",
    "        axes[i, 2].set_title(f'预测掩码 (Dice: {dice:.4f})')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_segmentation(model, val_loader, num_samples=5) # 可视化验证集(resize后)的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "430f63ad",
    "language": "markdown",
    "papermill": {
     "duration": 0.034218,
     "end_time": "2025-04-13T15:31:38.502643",
     "exception": false,
     "start_time": "2025-04-13T15:31:38.468425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载\n",
    "保存训练好的模型，以便将来加载并用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "1c3ddb6d",
    "language": "python",
    "papermill": {
     "duration": 0.138946,
     "end_time": "2025-04-13T15:31:38.676981",
     "exception": false,
     "start_time": "2025-04-13T15:31:38.538035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    \"\"\"保存模型参数到指定路径\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "save_model_path=f'/kaggle/working/work2model_dice-{best_dice}_{time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime())}.pth'\n",
    "save_model(model,save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# 模型预测与应用\n",
    "\n",
    "遍历测试图像，加载它们，进行预处理，然后使用加载的模型进行预测，最后将预测的掩码保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0.级联-分类模型加载 ---\n",
    "if platform.system() == \"Windows\":\n",
    "    classification_model_path = 'w1.pth'\n",
    "    model_save_path = 'work2model_dice-0.8811619244894272_2025-04-13-15-31-38.pth'\n",
    "else:\n",
    "    # 在 Kaggle 中使用的路径\n",
    "    classification_model_path = '/kaggle/input/pterygium_classifier/pytorch/default/2/resnet18_pterygium_classifier.pth'\n",
    "\n",
    "# 定义验证集/测试集的变换 (无需数据增强)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "classification_model = ResNet18Classifier(num_classes=3)\n",
    "classification_model.load_state_dict(torch.load(classification_model_path, map_location=device, weights_only=True))\n",
    "classification_model = classification_model.to(device)\n",
    "classification_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 加载训练好的模型 ---\n",
    "\n",
    "try:\n",
    "    model_save_path = save_model_path\n",
    "except:\n",
    "    print(\"model_save_path 未定义。请确保在训练后保存模型。\")\n",
    "\n",
    "loaded_model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "# 加载最佳权重 (假设 best_model_weights 变量包含 state_dict)\n",
    "if 'best_model_weights' in locals() and best_model_weights is not None:\n",
    "    loaded_model.load_state_dict(best_model_weights)\n",
    "    print(\"成功加载训练好的模型权重。\")\n",
    "else:\n",
    "    # 如果没有 best_model_weights，尝试从文件加载（需要先保存）\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))\n",
    "        print(f\"从 {model_save_path} 加载模型权重。\")\n",
    "    else:\n",
    "        print(\"警告: 未找到训练好的模型权重 (best_model_weights 或文件)。模型将使用随机初始化的权重。\")\n",
    "\n",
    "loaded_model.eval(); # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义 Tiling 预测函数 ---\n",
    "def predict_with_tiling(model, image_path, patch_size, stride, device, batch_size=4, threshold=0.5):\n",
    "    \"\"\"\n",
    "    使用 Tiling 和重叠平均策略预测大图的掩码。\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 原始大图路径\n",
    "    :param patch_size: patch 大小 (int)\n",
    "    :param stride: 切割 patch 时的步长 (int)\n",
    "    :param device: 设备\n",
    "    :param batch_size: 推理时的批次大小\n",
    "    :param threshold: 二值化阈值\n",
    "    :return: 预测的二值掩码 (numpy array, H x W) 或 None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_w, img_h = img.size\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 图像文件未找到 {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 加载图像时出错 {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    model.eval() # 确保模型在评估模式\n",
    "\n",
    "    # 定义预处理 (仅 ToTensor 和 Normalize)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 计算所需的 padding\n",
    "    pad_h = max(patch_size - img_h, 0)\n",
    "    pad_w = max(patch_size - img_w, 0)\n",
    "    # 在右侧和底部进行 padding，使其尺寸至少为 patch_size\n",
    "    # 进一步 padding 使尺寸能被 stride 整除，以便覆盖所有边缘\n",
    "    target_h = img_h + pad_h\n",
    "    target_w = img_w + pad_w\n",
    "    pad_h_stride = (stride - (target_h - patch_size) % stride) % stride\n",
    "    pad_w_stride = (stride - (target_w - patch_size) % stride) % stride\n",
    "\n",
    "    padding = (0, 0, pad_w + pad_w_stride, pad_h + pad_h_stride) # (left, top, right, bottom)\n",
    "    img_padded = F.pad(img, padding, padding_mode='reflect') # 使用反射填充\n",
    "    padded_h, padded_w = img_padded.size[1], img_padded.size[0] # PIL size is W, H\n",
    "\n",
    "    # 创建空的概率图和计数图\n",
    "    pred_prob_map = torch.zeros((1, padded_h, padded_w), dtype=torch.float32, device=device)\n",
    "    count_map = torch.zeros((1, padded_h, padded_w), dtype=torch.float32, device=device)\n",
    "\n",
    "    # 收集所有 patch 的坐标\n",
    "    patch_coords = []\n",
    "    for y in range(0, padded_h - patch_size + 1, stride):\n",
    "        for x in range(0, padded_w - patch_size + 1, stride):\n",
    "            patch_coords.append((x, y))\n",
    "\n",
    "    # 分批处理 patches\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(patch_coords), batch_size), desc=\"Tiling Prediction\",leave=False):\n",
    "            batch_coords = patch_coords[i:i+batch_size]\n",
    "            batch_patches_pil = [img_padded.crop((x, y, x + patch_size, y + patch_size)) for x, y in batch_coords]\n",
    "            batch_patches_tensor = torch.stack([preprocess(p) for p in batch_patches_pil]).to(device)\n",
    "\n",
    "            # 模型预测 (输出 logits)\n",
    "            batch_outputs_logits = model(batch_patches_tensor)\n",
    "            batch_outputs_probs = torch.sigmoid(batch_outputs_logits) # (B, 1, P, P)\n",
    "\n",
    "            # 将预测结果累加回概率图\n",
    "            for j, (x, y) in enumerate(batch_coords):\n",
    "                # 修复：将模型输出上采样到patch_size大小\n",
    "                output_height, output_width = batch_outputs_probs[j].shape[1:] # 获取当前输出尺寸\n",
    "                if output_height != patch_size or output_width != patch_size:\n",
    "                    # 上采样到与patch相同大小\n",
    "                    upsampled_output = torch.nn.functional.interpolate(\n",
    "                        batch_outputs_probs[j].unsqueeze(0), # 增加批次维度\n",
    "                        size=(patch_size, patch_size),\n",
    "                        mode='bilinear',\n",
    "                        align_corners=False\n",
    "                    ).squeeze(0) # 移除批次维度\n",
    "                    pred_prob_map[:, y:y+patch_size, x:x+patch_size] += upsampled_output\n",
    "                else:\n",
    "                    pred_prob_map[:, y:y+patch_size, x:x+patch_size] += batch_outputs_probs[j]\n",
    "                count_map[:, y:y+patch_size, x:x+patch_size] += 1\n",
    "\n",
    "    # 处理计数为0的区域（如果padding策略完美，不应出现，但以防万一）\n",
    "    count_map[count_map == 0] = 1\n",
    "    # 计算平均概率\n",
    "    avg_prob_map = pred_prob_map / count_map\n",
    "\n",
    "    # 裁剪回原始图像尺寸 (去掉 padding)\n",
    "    original_h, original_w = img_h, img_w\n",
    "    avg_prob_map_cropped = avg_prob_map[:, :original_h, :original_w]\n",
    "\n",
    "    # 应用阈值得到最终二值掩码\n",
    "    final_mask = (avg_prob_map_cropped > threshold).squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # --- 后处理 ---\n",
    "    # --- 1.开运算断开细小连接 (在 MCC 之前) ---\n",
    "    if np.sum(final_mask) > 0: # 仅当存在前景时处理\n",
    "        # 定义结构元素 (Kernel) - 需要调整大小！\n",
    "        # disk(radius) 或 square(width)\n",
    "        # 半径/宽度需要略大于你想断开的细线的厚度\n",
    "        # !!! 这是一个关键的超参数，需要根据你的数据进行调整 !!!\n",
    "        # 初始可以尝试较小的值，例如 disk(1) 或 disk(2) (对应直径约3或5像素) 或者 square(3)\n",
    "        selem_opening = disk(6)\n",
    "\n",
    "        # 应用开运算\n",
    "        final_mask_opened = binary_opening(final_mask, selem_opening)\n",
    "\n",
    "        # 更新掩码，开运算可能会移除所有前景\n",
    "        final_mask = final_mask_opened.astype(np.uint8)\n",
    "\n",
    "    # --- 2.保留最大连通区域 (MCC) ---\n",
    "    if np.sum(final_mask) > 0: # 再次检查，因为开运算可能移除所有前景\n",
    "        labeled_mask = label(final_mask)\n",
    "        region_props = np.unique(labeled_mask[labeled_mask > 0], return_counts=True)\n",
    "\n",
    "        if len(region_props[0]) > 0:\n",
    "            largest_component_label = region_props[0][np.argmax(region_props[1])]\n",
    "            # 只保留最大区域\n",
    "            final_mask_mcc = np.zeros_like(final_mask)\n",
    "            final_mask_mcc[labeled_mask == largest_component_label] = 1\n",
    "            final_mask = final_mask_mcc\n",
    "        else:\n",
    "            final_mask = np.zeros_like(final_mask) # 如果开运算后没有有效区域了\n",
    "    else:\n",
    "        # 如果开运算后没有前景，或者原始就没有前景，保持全零\n",
    "        final_mask = np.zeros_like(final_mask)\n",
    "\n",
    "    # --- 3.填充小空洞 (在 MCC 之后) ---\n",
    "    if np.sum(final_mask) > 0: # 仅对选出的最大区域进行处理\n",
    "        # 定义结构元素 (Kernel) - 需要调整大小！\n",
    "        # 通常用于闭运算的核比开运算的核稍大或相同\n",
    "        # 目的是填充内部小孔，大小取决于孔洞的大小\n",
    "        # !!! 同样需要调整 !!!\n",
    "        selem_closing = disk(3) # 示例：半径为3的圆盘\n",
    "\n",
    "        # 应用闭运算\n",
    "        final_mask_closed = binary_closing(final_mask, selem_closing)\n",
    "\n",
    "        # 更新最终掩码\n",
    "        final_mask = final_mask_closed.astype(np.uint8)\n",
    "    # --- 后处理结束 ---\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 对测试图像进行预测 ---\n",
    "\n",
    "# 输出预测掩码的目录\n",
    "if os.path.exists(output_mask_dir):\n",
    "    print(f\"输出目录 {output_mask_dir} 已存在，删除旧目录。\")\n",
    "    shutil.rmtree(output_mask_dir)\n",
    "os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "# 查找所有测试图像\n",
    "test_image_paths = glob.glob(os.path.join(val_image_dir, \"*.png\"))\n",
    "\n",
    "print(f\"找到 {len(test_image_paths)} 张待预测图像于 {val_image_dir}\")\n",
    "\n",
    "# 统计跳过了多少健康图像\n",
    "skipped_healthy_count = 0\n",
    "processed_count = 0\n",
    "\n",
    "# 遍历测试图像并进行预测\n",
    "for img_path in tqdm(test_image_paths, desc=\"处理预测图像\"):\n",
    "    base_name = os.path.basename(img_path)\n",
    "    save_name = f\"{os.path.splitext(base_name)[0]}.png\" # 统一保存为png\n",
    "    save_path = os.path.join(output_mask_dir, save_name)\n",
    "\n",
    "    # --- 级联：使用分类模型判断 ---\n",
    "    predicted_class = predict_image(classification_model, img_path, val_transform, device)\n",
    "\n",
    "    if predicted_class == 0: # 预测为健康 (类别 0)\n",
    "        try:\n",
    "            # 获取原始图像尺寸用于创建空掩码\n",
    "            with Image.open(img_path) as img_pil:\n",
    "                img_w, img_h = img_pil.size\n",
    "            \n",
    "            empty_mask_np = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n",
    "            empty_mask_image = Image.fromarray(empty_mask_np, mode='RGB')\n",
    "            empty_mask_image.save(save_path)\n",
    "            skipped_healthy_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"为健康图像 {base_name} 创建或保存空掩码时出错: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- 如果不是健康，则执行分割 ---\n",
    "    # 使用 Tiling 进行预测\n",
    "    predicted_mask_np = predict_with_tiling(\n",
    "        model=loaded_model,\n",
    "        image_path=img_path,\n",
    "        patch_size=patch_size,\n",
    "        stride=predict_stride, # 使用之前定义的 stride\n",
    "        device=device,\n",
    "        batch_size=32 # 可以根据GPU内存调整\n",
    "    )\n",
    "\n",
    "    if predicted_mask_np is not None:\n",
    "        # predicted_mask_np 是经过后处理 (如最大连通域) 的 0/1 掩码\n",
    "        # 创建RGB掩码图像，前景(1)为(128,0,0)，背景(0)为(0,0,0)\n",
    "        h, w = predicted_mask_np.shape\n",
    "        rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        # 设置前景区域(值为1的位置)为(128,0,0)\n",
    "        rgb_mask[predicted_mask_np == 1, 0] = 128  # R通道设为128\n",
    "        # 背景区域(值为0的位置)默认已经是(0,0,0)\n",
    "        mask_image = Image.fromarray(rgb_mask, mode='RGB')\n",
    "\n",
    "        try:\n",
    "            mask_image.save(save_path)\n",
    "            processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"保存分割掩码时出错 {save_path}: {e}\")\n",
    "    else:\n",
    "        # 如果 predict_with_tiling 返回 None (例如文件未找到)，也创建一个空掩码\n",
    "        try:\n",
    "            print(f\"警告：predict_with_tiling未能处理图像 {base_name}，将保存空掩码。\")\n",
    "            # 获取原始图像尺寸用于创建空掩码\n",
    "            with Image.open(img_path) as img_pil:\n",
    "                img_w, img_h = img_pil.size\n",
    "            empty_mask_np = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n",
    "            empty_mask_image = Image.fromarray(empty_mask_np, mode='RGB')\n",
    "            empty_mask_image.save(save_path)\n",
    "        except Exception as e:\n",
    "            print(f\"为处理失败的图像 {base_name} 创建或保存空掩码时出错: {e}\")\n",
    "\n",
    "print(f\"\\n预测处理完成。\")\n",
    "print(f\"总共处理图像: {len(test_image_paths)}\")\n",
    "print(f\"其中 {skipped_healthy_count} 张被分类为健康并保存了空掩码。\")\n",
    "print(f\"对其余 {processed_count} 张图像进行了分割并保存了掩码。\")\n",
    "# 注意：processed_count + skipped_healthy_count 可能不等于总数，如果 predict_with_tiling 失败且保存空掩码也失败了。\n",
    "\n",
    "# 可视化结果\n",
    "# 要可视化的样本数量\n",
    "num_visualize = 10\n",
    "if not test_image_paths:\n",
    "    print(\"错误：找不到测试图像路径，无法进行可视化。\")\n",
    "else:\n",
    "    # 确保样本数量不超过实际图像数量\n",
    "    num_visualize = min(num_visualize, len(test_image_paths))\n",
    "    if num_visualize > 0:\n",
    "        # 随机选择图像路径进行可视化\n",
    "        sample_paths = random.sample(test_image_paths, num_visualize)\n",
    "        print(f\"\\n可视化 {num_visualize} 个预测结果...\")\n",
    "\n",
    "        for img_path in sample_paths:\n",
    "            try:\n",
    "                # 加载原始图像\n",
    "                original_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                # 构建对应的预测掩码文件的路径\n",
    "                base_name = os.path.basename(img_path)\n",
    "                file_stem = os.path.splitext(base_name)[0]\n",
    "                mask_filename = f\"{file_stem}.png\" # 假设保存的掩码文件名与原图名相同\n",
    "                predicted_mask_path = os.path.join(output_mask_dir, mask_filename)\n",
    "\n",
    "                # 检查预测掩码文件是否存在并加载\n",
    "                if os.path.exists(predicted_mask_path):\n",
    "                    predicted_mask_image = Image.open(predicted_mask_path) # 加载之前保存的RGB掩码\n",
    "\n",
    "                    # 创建绘图\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                    # 显示原始图像\n",
    "                    axes[0].imshow(original_image)\n",
    "                    axes[0].set_title(f\"原始图像: {base_name}\")\n",
    "                    axes[0].axis('off')\n",
    "\n",
    "                    # 显示对应的预测掩码\n",
    "                    axes[1].imshow(predicted_mask_image) # 显示加载的对应掩码\n",
    "                    axes[1].set_title(\"预测掩码 (RGB 128,0,0)\")\n",
    "                    axes[1].axis('off')\n",
    "\n",
    "                    plt.tight_layout() # 调整布局防止重叠\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(f\"警告：找不到预测掩码文件 {predicted_mask_path}，无法可视化此样本。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"可视化图像 {img_path} 时出错: {e}\")\n",
    "    else:\n",
    "        print(\"没有测试图像可供可视化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 压缩结果 ---\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    zip_file_path = f\"{output_mask_dir}.zip\"\n",
    "\n",
    "    if output_mask_dir and os.path.exists(output_mask_dir) and os.listdir(output_mask_dir):\n",
    "        print(f\"开始压缩目录: {output_mask_dir}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                files_to_zip = glob.glob(os.path.join(output_mask_dir, '*.*'))\n",
    "                if not files_to_zip:\n",
    "                    print(f\"警告: 目录 {output_mask_dir} 为空，无需压缩。\")\n",
    "                else:\n",
    "                    for file in tqdm(files_to_zip, desc=\"压缩文件\"):\n",
    "                        zipf.write(file, arcname=os.path.basename(file))\n",
    "                    print(f\"预测结果已成功压缩到: {zip_file_path}\")\n",
    "\n",
    "                    # 删除原始文件和目录 (可选)\n",
    "                    print(f\"删除原始掩码文件于: {output_mask_dir}\")\n",
    "                    shutil.rmtree(output_mask_dir)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"压缩或删除文件时发生错误: {e}\")\n",
    "    elif output_mask_dir:\n",
    "        print(f\"目录 {output_mask_dir} 不存在或为空，跳过压缩和删除步骤。\")\n",
    "\n",
    "\n",
    "print(\"\\n预测处理完成。\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 301250,
     "modelInstanceId": 280343,
     "sourceId": 334939,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
