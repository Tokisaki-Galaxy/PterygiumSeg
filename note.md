# 调试笔记

**所有提到的解决方案都在第二天的提交中实现。每天提交的结果都是前一天最后的结果。**

## 2025-04-13
提交时间 2025-04-13 07:06

### 任务一

加入dropout层

### 任务二

修改数据输入方式，从Resize方式变成切分/拼接方式，val dice上升50%，到0.94左右。

```
Epoch [26/30], Train Loss: 0.1078, Train Dice: 0.9587, Val Loss: 0.1889, Val Dice: 0.9412
EarlyStopping: 发现改进。最佳分数更新为 0.9412。计数器重置。

Epoch [27/30], Train Loss: 0.1028, Train Dice: 0.9609, Val Loss: 0.1858, Val Dice: 0.9430
EarlyStopping: 发现改进。最佳分数更新为 0.9430。计数器重置。

Epoch [28/30], Train Loss: 0.0980, Train Dice: 0.9631, Val Loss: 0.1917, Val Dice: 0.9418
EarlyStopping计数器: 1 (共 7)。最佳分数仍为 0.9430。

Epoch [29/30], Train Loss: 0.0962, Train Dice: 0.9637, Val Loss: 0.1848, Val Dice: 0.9441
EarlyStopping: 发现改进。最佳分数更新为 0.9441。计数器重置。

Epoch [30/30], Train Loss: 0.0955, Train Dice: 0.9641, Val Loss: 0.1894, Val Dice: 0.9421
EarlyStopping计数器: 1 (共 7)。最佳分数仍为 0.9441。
训练在 30 轮后完成。
--- 训练完成 ---
最终(最佳)验证Dice系数: 0.9441
训练耗时: 10892.47 秒
```

### 提交结果

score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
4.3726	0.8933	0.0044	    0.8931	0.4199	0.893	    27153.915

### 问题

val dice有0.94，但是在官方val上只有0.4，怎么会这样？。另外观察到预测的蒙版文件里面很多小区域噪点。

### 解决方案

HD95 高达 27153，这表明预测边界与真实边界偏差极大。这强烈暗示模型产生了大量远离真实病灶的、大片的假阳性区域，或者预测的边界非常不规则、破碎。这与观察到的“蒙版文件里面很多小区域噪点”以及“健康人也预测出问题”相符。高 Val Dice (0.94) 可能是因为模型对病灶主体的重叠区域预测得很好，掩盖了边界和假阳性问题的严重性。而官方评估可能更侧重边界精度（HD95）和整体假阳性控制。

 - 必须进行后处理： 鉴于高 HD95 和噪点观察，必须对预测结果应用后处理。最大连通域 (MCC) 是最应该尝试的。
 - 检查预测代码： 仔细审查 predict_with_tiling 和调用它的循环，确保没有 bug。

## 2025-04-14
提交时间 2025-04-14 08:04

### 任务一

修改了batchSize和学习率，val F1上升到89%，标准差为0.02。

### 任务二

对于预测中蒙版文件存在很多小区域噪点的问题，尝试使用最大连通域解决。只保留图中最大的连通域。
另外还观察到对于任何数据输入，即使是健康的，模型也会预测出问题。
尝试通过增大了数据输入方式，但是效果很差。所以采用备用方案。把任务一的模型结果输入到任务二，做成级联方法。
任务一中有约5%的误诊断，但是对于未调整的任务二（有33%的健康人被检测出）预计中33%的错误率已经降低非常大。

在上面提到的增大数据输入方式的尝试。之前模型采用的是只切分与病灶相关的区域，增大数据输入方式是把整个图像都输入到模型中。

#### 输入健康数据进行训练

```
20.2s	207	开始执行离线 Patching...
20.6s	208	从 train_classification_label.xlsx 读取标签，找到 450 个样本（包括健康和有病）进行Patching。
10259.8s	209	------------------------------
10259.8s	210	离线Patching完成！
10259.8s	211	成功处理的大图数量: 450 / 450
10259.8s	212	总共创建 Patch 对数量: 102600
10259.8s	213	总耗时: 10239.71 秒
10259.8s	214	------------------------------
...
27541.5s	255	Epoch [10/30], Train Loss: 0.4902, Train Dice: 0.6253, Val Loss: 0.3515, Val Dice: 0.6461
27541.5s	256	EarlyStopping计数器: 2 (共 7)。最佳分数仍为 0.6535。
```
运行7个小时之后，达到Epoch 9/30，但val dice为0.65，并且上升缓慢。由于占用大量GPU时间，提升较小，决定停止。

#### 和之前一致，只输入病灶相关数据进行训练

```
21.5s	38	开始执行离线 Patching...
22.0s	39	从 train_classification_label.xlsx 读取标签，找到 300 个翼状胬肉样本进行Patching。
2120.5s	40	------------------------------
2120.5s	41	离线Patching完成！
2120.5s	42	成功处理（基于标签过滤后）大图数量: 300 / 300
2120.5s	43	总共创建Patch数量: 21560
2120.5s	44	总耗时: 2099.09 秒
2120.5s	45	------------------------------
...
12997.6s	128	Epoch [30/30], Train Loss: 0.0619, Train Dice: 0.9772, Val Loss: 0.1504, Val Dice: 0.9574
12997.6s	129	EarlyStopping计数器: 2 (共 7)。最佳分数仍为 0.9567。
12997.6s	130	训练在 30 轮后完成。
13036.4s	131	--- 训练完成 ---
13036.4s	132	最终(最佳)验证Dice系数: 0.9567
13036.4s	133	训练耗时: 10910.10 秒
```

#### 修复数据泄露问题

nnd代码里面存在数据泄露，在划分训练/测试的时候。
```
generator = torch.Generator().manual_seed(42)
train_subset, val_subset = random_split(full_dataset_offline, [train_size, val_size], generator=generator)
```
来自同一张原始大图的多个 Patches（例如 0001_y0_x0.png, 0001_y0_x256.png, 0001_y256_x0.png ...）中的一部分被分到了 train_indices，而另一部分被分到了 val_indices。

#### 总结

把健康的数据也加入到训练集中，首先patching时间大幅增加，其次训练的时间也大幅度增加，并且长时间无法收敛到较高值。
猜测由于类别极端不平衡（patching数量差异巨大）这导致训练数据中，绝大多数 Patch 的目标是全零。模型花了大量时间和精力去学习“输出零”，不仅要学会在病灶眼上分割病灶，还要学会在健康眼上“什么都不做”。学习过程变得困难和缓慢。

还发现了代码中的数据泄露问题，解决了早上发现的`val dice有0.94，但是在官方val上只有0.4`的问题。但是基于健康数据过大，跑一次占用过多的GPU时间，并且还无法收敛。所以不再重新训练完全健康数据。

现在提交的是修复数据泄露+级联+最大连通域的结果。

### 提交结果

score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
6.9576	0.9133	0.3714	    0.9111	0.7742	0.9221	    4387.8467

### 问题

在合并val_img和mask时，发现有些时候有些细小的毛边。

另外在训练的时候，发现模型二有过拟合。
```
Epoch [23/30], Train Loss: 0.1607, Train Dice: 0.9312, Val Loss: 0.3716, Val Dice: 0.8583
EarlyStopping计数器: 4 (共 7)。最佳分数仍为 0.8812。
Epoch [24/30], Train Loss: 0.1494, Train Dice: 0.9375, Val Loss: 0.3953, Val Dice: 0.8508
EarlyStopping计数器: 5 (共 7)。最佳分数仍为 0.8812。
Epoch [25/30], Train Loss: 0.1410, Train Dice: 0.9417, Val Loss: 0.3621, Val Dice: 0.8685
EarlyStopping计数器: 6 (共 7)。最佳分数仍为 0.8812。
Epoch [26/30], Train Loss: 0.1335, Train Dice: 0.9453, Val Loss: 0.4100, Val Dice: 0.8517
EarlyStopping计数器: 7 (共 7)。最佳分数仍为 0.8812。
早停触发于第 26 轮。
--- 训练完成 ---
最终(最佳)验证Dice系数: 0.8812
训练耗时: 9419.20 秒
```
train dice上升到0.94，但是val dice只有0.85。最后在官方验证集上，val dice只有0.77。

### 解决方案

对于细小的毛边，在后处理的代码，加入其他步骤。
1.开运算
2.最大连通域
3.闭运算

对于过拟合问题，模型一上也观察到过拟合。所以尝试把模型一，模型二改成adamw优化器。
模型二的dropout概率增加到0.5，weight_decay=7e-5，学习率降低到5e-4（之前的50%）。

但是对于模型一，又尝试了几组参数，val dice都在0.9左右，而且排行榜也不错，先就这样把。后面再改就看看**错误分类图像**了。
因为是级联的方法，模型一直接影响模型二的效果。所以模型一的效果必须尽可能的好。目前的1-5%还可以接受。

## 2025-04-15
提交时间 2025-04-15 13:23

### 排行榜

```
排名	参赛团队	所属组织	score	ACC	HD_score	MACROF1	DICE	MACROPRE	HD	提交时间
123456
中南民族大学	7.9969	0.9533	0.4825	0.9531	0.9224	0.9531	724.5057	2025-04-15 11:06
itsmygo的团队
沈阳药科大学	7.5732	0.9267	0.4556	0.9263	0.8568	0.9261	2065.45	2025-04-15 13:23
Zymonody的团队
太原理工大学	7.554	0.8733	0.4702	0.8703	0.8779	0.888	3676.7383	2025-04-14 15:17
lsyyh75579的团队
南方医科大学	7.3882	0.9333	0.3718	0.9333	0.8681	0.9338	694.8503	2025-04-15 12:37
```

### 提交结果

score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
7.5732	0.9267	0.4556	    0.9263	0.8568	0.9261	    2065.45

### 任务一

原本今天结果相较于之前也不错，但是有人提交的结果咋acc有0.95+，然后去看了一下文献，居然文献里面有现成的，而且准确率非常高。
今天刚刚看了文献，发现文献里面使用`EfficientNet-B7`,准确度有94.47%，需要评估是否要把ResNet18换成这个。

### 任务二

同样的，任务二，在文献里面使用PsPnet+ResNet50.也需要评估一下。

## 2025-04-16

### 排行榜

和昨天的结果差不多，因为今天提交的结果比昨天差，所以分数也没上升。

### 提交结果

score   ACC     HD_score	MACROF1	DICE	MACROPRE	HD
7.0376	0.9133	0.4056	    0.9119	0.77	0.9154	    4258.3813

### 任务一

昨天发现了一个在val集上有Micro F1 0.98的模型，今天尝试了一下，发现在官方test集上只有0.91，也就之前的水平。白高兴了。
先这样吧，另外没必要上EfficientNet-B7，我怀疑那个论文有问题，这个问题用那种模型基本上肯定是过拟合的。而且论文中提到，使用EfficientNet-B7，Acc也就提高到0.95左右。

### 任务二

今天把UNET换成了UNET3+，但是dice和HD反而下降了。并且训练时间提升了30%-50%。
今天为了把UNET换成UNET3+，改了很多代码，但是效果反而变差了。

另外今天因为主模型变更，`predict_with_tiling_unfold`函数里的概率计算从`先对 Logits 的和应用 Sigmoid，再平均`改成`先平均 Logits，再 Sigmoid`。之前的方法`先对 Logits 的和应用 Sigmoid，再平均`，在UNET3+模型上，不知道为什么会映射到[0,0.5]之间。改成`先平均 Logits，再 Sigmoid`，就能映射到[0,1]之间了。

## 2025-04-17

### 排行榜

```
排名	参赛团队	所属组织	score	ACC	HD_score	MACROF1	DICE	MACROPRE	HD	提交时间
小周2006的团队
桂林电子科技大学	8.4214	0.94	0.61	0.9398	0.9429	0.94	114.45	2025-04-17 22:27
123456
中南民族大学	7.9969	0.9533	0.4825	0.9531	0.9224	0.9531	724.5057	2025-04-15 11:06
xxxz的团队
中南民族大学	7.811	0.9067	0.4886	0.9065	0.9059	0.9082	511.6337	2025-04-16 00:42
lsyyh75579的团队
南方医科大学	7.588	0.9333	0.4172	0.9333	0.884	0.9338	804.4363	2025-04-17 10:15
西游记的团队
中南民族大学	7.5749	0.8533	0.4589	0.8533	0.9095	0.8536	382.52	2025-04-17 22:34
itsmygo的团队
沈阳药科大学	7.5732	0.9267	0.4556	0.9263	0.8568	0.9261	2065.45	2025-04-15 13:23
```

### 提交结果
score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
7.0578	0.9267	0.3519	    0.9263	0.8057	0.9261	    2833.2467	

### 任务一

使用SHAP模型的时候，分析ResNet18模型，发现模型的注意力除了集中在病灶上面，还集中在眼睛的边缘以及**反光部分**。是否需要考虑抑制反光？

### 任务二

今天尝试了注意力模型，没有提交到官方test集上验证。因为训练的时候发现存在过拟合问题，触发了早停，而且训练时间比平时少了40%。
接着不使用注意力，改为用边界损失。但是训练完提交到官方test集上，发现dice hd95相较于之前最原始的反而还下降了。

## 2025-04-22

之前在任务一的SHAP分析卓有成效，今天试着推广到模型二。
今天重新看了一下排行榜，重新分析。发现很多人的任务一结果基本上也没我好，主要差距在于任务二，尤其是dice，不过也要注意hd95。
我考虑重新大改任务二模型。不过是否需要先用SHAP分析一下现有的任务二模型？

## 2025-04-23

### 任务一

因为之前发现的SHAP分析结果，模型的注意力除了集中在病灶上面，还集中在眼睛的边缘以及反光部分。今天考虑了几种方法来抑制反光。

1. 直接把反光部分的像素值认为255左右，加入损失函数中。（不可行，因为病灶也在眼白）
2. 在数据增强的时候使用模拟反光的方式，加入损失函数中。（采用这种办法）
3. 添加预处理，抑制高光函数。（有点麻烦，信息会损失，而且不好写）

应用方法二，本地val集上平均Macro F1:0.9225，标准差:0.0136。优于之前任意一个参数组合。

## 2025-04-24

### 任务一

今天改进了SHAP分析，发现ResNet18存在局限，采用ResNet34，效果很好。
另外根据改进后的SHAP分析，问题主要集中在严重程度的区分，建议观察和建议手术。
**如果有时间，把分类任务视为一个有序分类问题，设置现在三分类为线性回归。但是改的地方太多，等之后有时间吧。**

### 任务二

今天尝试换成deeplabv3+resnet50（预训练），但是训练时间大大增加。今天只尝试了4个epoch，val dice在0.85，test dice为0.73。
尝试降低patch的分辨率，从512x512改成256x256。

另外，今天在改进val dice和test dice差距的时候，发现可能是因为数据输入不平衡。还是要加一点完全健康的眼睛数据。但是不能像之前那样，patching数量差异巨大。大概改进为1:1.2的比例。

```
256x256
--- 处理病灶图像 ---
病灶图像 Patching 完成。共创建 75197 个病灶 Patches。

--- 处理健康图像 ---
目标健康 Patch 数量 (基于 1.2:1 比例): 90236
估计需要采样约 88 张健康图像。
已从 150 张中随机采样 88 张健康图像进行Patching。
健康图像 Patching 完成。共创建 89232 个健康 Patches。
------------------------------
离线Patching完成！
成功处理大图数量: 388
总共创建Patch数量: 164429
其中病灶 Patch 数量: 75197
其中健康 Patch 数量: 89232
健康 Patch / 病灶 Patch 实际比例: 1.19
总耗时: 4767.66 秒
------------------------------
```

## 2025-04-25
发现问题还在预测部分。在分割完patch，最后进行重叠的函数上。重新组装patch会导致概率云叠加，会导致阈值变动。现在加入自动阈值探测。

但是效果似乎还是很不好，分析表明现在的模型输入数据只有病灶相关的，虽然之前通过级联处理的方法来取巧的避免了这个问题，但是模型非常明显没有学会如何区分眼白和病灶。尝试加入健康部分，但是和之前不同，只尝试增加病灶的眼睛。（之前是用病灶patch进行训练）

## 2025-04-26

昨天的加入疾病眼睛的健康部分的尝试，不知道怎么样，似乎效果没有明显提升，今天试试在dataloader部分增加加权采样
