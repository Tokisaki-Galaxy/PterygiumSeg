# 调试笔记

## 2025-04-13 早晨
提交时间 2025-04-13 07:06

### 任务一

加入dropout层

### 任务二

修改数据输入方式，从Resize方式变成切分/拼接方式，val dice上升50%，到0.94左右。

```
Epoch [26/30], Train Loss: 0.1078, Train Dice: 0.9587, Val Loss: 0.1889, Val Dice: 0.9412
EarlyStopping: 发现改进。最佳分数更新为 0.9412。计数器重置。

Epoch [27/30], Train Loss: 0.1028, Train Dice: 0.9609, Val Loss: 0.1858, Val Dice: 0.9430
EarlyStopping: 发现改进。最佳分数更新为 0.9430。计数器重置。

Epoch [28/30], Train Loss: 0.0980, Train Dice: 0.9631, Val Loss: 0.1917, Val Dice: 0.9418
EarlyStopping计数器: 1 (共 7)。最佳分数仍为 0.9430。

Epoch [29/30], Train Loss: 0.0962, Train Dice: 0.9637, Val Loss: 0.1848, Val Dice: 0.9441
EarlyStopping: 发现改进。最佳分数更新为 0.9441。计数器重置。

Epoch [30/30], Train Loss: 0.0955, Train Dice: 0.9641, Val Loss: 0.1894, Val Dice: 0.9421
EarlyStopping计数器: 1 (共 7)。最佳分数仍为 0.9441。
训练在 30 轮后完成。
--- 训练完成 ---
最终(最佳)验证Dice系数: 0.9441
训练耗时: 10892.47 秒
```

### 提交结果

score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
4.3726	0.8933	0.0044	    0.8931	0.4199	0.893	    27153.915

### 问题

val dice有0.94，但是在官方val上只有0.4，怎么会这样？。另外观察到预测的蒙版文件里面很多小区域噪点。

### 可能的解决方案

HD95 高达 27153，这表明预测边界与真实边界偏差极大。这强烈暗示模型产生了大量远离真实病灶的、大片的假阳性区域，或者预测的边界非常不规则、破碎。这与观察到的“蒙版文件里面很多小区域噪点”以及“健康人也预测出问题”相符。高 Val Dice (0.94) 可能是因为模型对病灶主体的重叠区域预测得很好，掩盖了边界和假阳性问题的严重性。而官方评估可能更侧重边界精度（HD95）和整体假阳性控制。

 - 必须进行后处理： 鉴于高 HD95 和噪点观察，必须对预测结果应用后处理。最大连通域 (MCC) 是最应该尝试的。
 - 检查预测代码： 仔细审查 predict_with_tiling 和调用它的循环，确保没有 bug。

## 2025-04-13
提交时间 2025-04-14

### 任务一

修改了batchSize和学习率，val F1上升到89%，标准差为0.02。

### 任务二

对于预测中蒙版文件存在很多小区域噪点的问题，尝试使用最大连通域解决。只保留图中最大的连通域。
另外还观察到对于任何数据输入，即使是健康的，模型也会预测出问题。
尝试通过增大了数据输入方式，但是效果很差。所以采用备用方案。把任务一的模型结果输入到任务二，做成级联方法。
任务一中有约5%的误诊断，但是对于未调整的任务二（有33%的健康人被检测出）预计中33%的错误率已经降低非常大。

在上面提到的增大数据输入方式的尝试。之前模型采用的是只切分与病灶相关的区域，增大数据输入方式是把整个图像都输入到模型中。

#### 输入健康数据进行训练

```
20.2s	207	开始执行离线 Patching...
20.6s	208	从 train_classification_label.xlsx 读取标签，找到 450 个样本（包括健康和有病）进行Patching。
10259.8s	209	------------------------------
10259.8s	210	离线Patching完成！
10259.8s	211	成功处理的大图数量: 450 / 450
10259.8s	212	总共创建 Patch 对数量: 102600
10259.8s	213	总耗时: 10239.71 秒
10259.8s	214	------------------------------
...
27541.5s	255	Epoch [10/30], Train Loss: 0.4902, Train Dice: 0.6253, Val Loss: 0.3515, Val Dice: 0.6461
27541.5s	256	EarlyStopping计数器: 2 (共 7)。最佳分数仍为 0.6535。
```
运行7个小时之后，达到Epoch 9/30，但val dice为0.65，并且上升缓慢。由于占用大量GPU时间，提升较小，决定停止。

#### 和之前一致，只输入病灶相关数据进行训练

```
21.5s	38	开始执行离线 Patching...
22.0s	39	从 train_classification_label.xlsx 读取标签，找到 300 个翼状胬肉样本进行Patching。
2120.5s	40	------------------------------
2120.5s	41	离线Patching完成！
2120.5s	42	成功处理（基于标签过滤后）大图数量: 300 / 300
2120.5s	43	总共创建Patch数量: 21560
2120.5s	44	总耗时: 2099.09 秒
2120.5s	45	------------------------------
...
12997.6s	128	Epoch [30/30], Train Loss: 0.0619, Train Dice: 0.9772, Val Loss: 0.1504, Val Dice: 0.9574
12997.6s	129	EarlyStopping计数器: 2 (共 7)。最佳分数仍为 0.9567。
12997.6s	130	训练在 30 轮后完成。
13036.4s	131	--- 训练完成 ---
13036.4s	132	最终(最佳)验证Dice系数: 0.9567
13036.4s	133	训练耗时: 10910.10 秒
```

#### 修复数据泄露问题

nnd代码里面存在数据泄露，在划分训练/测试的时候。
```
generator = torch.Generator().manual_seed(42)
train_subset, val_subset = random_split(full_dataset_offline, [train_size, val_size], generator=generator)
```
来自同一张原始大图的多个 Patches（例如 0001_y0_x0.png, 0001_y0_x256.png, 0001_y256_x0.png ...）中的一部分被分到了 train_indices，而另一部分被分到了 val_indices。

#### 总结

把健康的数据也加入到训练集中，首先patching时间大幅增加，其次训练的时间也大幅度增加，并且长时间无法收敛到较高值。
猜测由于类别极端不平衡（patching数量差异巨大）这导致训练数据中，绝大多数 Patch 的目标是全零。模型花了大量时间和精力去学习“输出零”，不仅要学会在病灶眼上分割病灶，还要学会在健康眼上“什么都不做”。学习过程变得困难和缓慢。

还发现了代码中的数据泄露问题，解决了早上发现的`val dice有0.94，但是在官方val上只有0.4`的问题。但是基于健康数据过大，跑一次占用过多的GPU时间，并且还无法收敛。所以不再重新训练完全健康数据。

现在提交的是修复数据泄露+级联+最大连通域的结果。

### 提交结果

score	ACC	    HD_score	MACROF1	DICE	MACROPRE	HD
6.9576	0.9133	0.3714	    0.9111	0.7742	0.9221	    4387.8467

### 问题
