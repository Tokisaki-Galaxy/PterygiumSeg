{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 翼状胬肉诊断模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "I8rV7E66jSoG",
    "papermill": {
     "duration": 0.004352,
     "end_time": "2025-04-13T01:53:45.053747",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.049395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 交叉验证参数 ---\n",
    "K = 5  # 折数\n",
    "base_seed = 420 # 用于 KFold 分割的随机种子\n",
    "# --- 定义要使用的 CNN 特征提取器列表 ---\n",
    "#CNN_FEATURE_EXTRACTORS = ['ResNet18Classifier', 'ResNet34Classifier', 'ResNet50Classifier']\n",
    "CNN_FEATURE_EXTRACTORS = ['ResNet50Classifier']\n",
    "# --- LightGBM 超参数 (初步设置，需要调优) ---\n",
    "# 这些参数直接影响模型的复杂度和正则化能力\n",
    "lgbm_params = {\n",
    "    'objective': 'multiclass', # 多分类任务\n",
    "    'num_class': 3,            # 3 个类别\n",
    "    'metric': 'multi_logloss', # Log Loss 作为评估指标\n",
    "    'boosting_type': 'gbdt',   # 梯度提升决策树\n",
    "    'n_estimators': 1000,      # 树的数量 (配合早停使用，可以设置得大一些)\n",
    "    'learning_rate': 0.03,     # 学习率\n",
    "    'num_leaves': 20,          # 控制树的复杂度，防止过拟合\n",
    "    'max_depth': 7,            # 树的最大深度，-1表示不限制 (配合 num_leaves 控制)\n",
    "    'seed': base_seed,         # 随机种子\n",
    "    'n_jobs': -1,              # 使用所有可用核心\n",
    "    'verbose': -1,             # 不打印中间信息\n",
    "    'colsample_bytree': 0.7,   # 每棵树随机采样的特征比例\n",
    "    'subsample': 0.7,          # 每棵树随机采样的样本比例\n",
    "    'reg_alpha': 0.3,          # L1 正则化\n",
    "    'reg_lambda': 0.4,         # L2 正则化\n",
    "    'min_child_samples': 30    # 叶子节点的最小样本数\n",
    "}\n",
    "\n",
    "# --- CNN 微调参数 (在每折内部使用) ---\n",
    "cnn_micro_train_params = {\n",
    "    'num_epochs': 10, # 在每折中微调 CNN 的 epoch 数，不需要太多，只要让其适应当前折叠的数据即可\n",
    "    'lr': 5e-4,       # 微调的学习率\n",
    "    'weight_decay': 1e-4 # 微调的权重衰减\n",
    "}\n",
    "\n",
    "# ================== 缩放参数设置 =================\n",
    "TARGET_SIZE = (512, 512) # 目标尺寸\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "#colab_val_zip_path = \"/content/drive/My Drive/val.zip\"\n",
    "#colab_val_extract_path = \"/content/val/\"\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# =================== SHAP设置 =================\n",
    "shap_scaling_factor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():\n",
    "    \"\"\"\n",
    "    检查是否可能缺少 GUI 后端（例如，在无头服务器上运行）。\n",
    "    如果是这种情况，将 Matplotlib 后端设置为 'Agg' 以避免错误。\n",
    "\n",
    "    应该在首次导入 `matplotlib.pyplot` 之前调用此函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        # 尝试获取 IPython 实例\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "e-siDBWjjSo6",
    "papermill": {
     "duration": 11.426914,
     "end_time": "2025-04-13T01:53:56.485296",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.058382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "import shap\n",
    "import sys\n",
    "from PIL import Image\n",
    "import platform\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        subprocess.run(['wget','-q','-O', 'simhei.ttf', \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"], check=True)\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "FqZSY8dujSo8",
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-04-13T01:53:56.494490",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.490079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80",
    "papermill": {
     "duration": 0.023889,
     "end_time": "2025-04-13T01:53:56.522681",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.498792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('.env'):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('.env')\n",
    "\n",
    "R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID', '')\n",
    "R2_SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', '')\n",
    "R2_BUCKET_NAME = os.environ.get('R2_BUCKET_NAME', '')\n",
    "R2_ENDPOINT_URL = os.environ.get('R2_ENDPOINT_URL', '')\n",
    "\n",
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive # type: ignore\n",
    "        from google.colab import userdata # type: ignore\n",
    "        drive.mount('/content/drive')\n",
    "        R2_ACCESS_KEY_ID = userdata.get(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = userdata.get(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = userdata.get(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = userdata.get(\"R2_ENDPOINT_URL\")\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # Google Drive 有每日下载次数限制，可能会导致下载失败\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "\n",
    "        from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "        user_secrets = UserSecretsClient()\n",
    "        R2_ACCESS_KEY_ID = user_secrets.get_secret(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = user_secrets.get_secret(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = user_secrets.get_secret(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = user_secrets.get_secret(\"R2_ENDPOINT_URL\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.004176,
     "end_time": "2025-04-13T01:53:56.531483",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.527307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 数据 Resize\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 准备R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_r2_client():\n",
    "    \"\"\"尝试创建并返回一个配置好的 boto3 R2 客户端。\"\"\"\n",
    "    # 确认环境变量已加载 (这些变量应在之前的单元格中设置)\n",
    "    required_vars = ['R2_ENDPOINT_URL', 'R2_ACCESS_KEY_ID', 'R2_SECRET_ACCESS_KEY', 'R2_BUCKET_NAME']\n",
    "    if not all(var in globals() and globals()[var] for var in required_vars):\n",
    "        print(\"R2 配置不完整（缺少 Endpoint URL, Access Key, Secret Key 或 Bucket Name）。跳过 R2 缓存。\")\n",
    "        return None, False # 返回 None 和 R2 未配置标志\n",
    "\n",
    "    global r2_configured # 声明我们要修改全局变量\n",
    "    r2_configured = True # 标记 R2 已配置\n",
    "\n",
    "    try:\n",
    "        print(\"正在创建 R2 (boto3 S3) 客户端...\")\n",
    "        s3_client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=R2_ENDPOINT_URL,\n",
    "            aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "            region_name='auto', # R2 通常使用 'auto'\n",
    "            config=botocore.config.Config(signature_version='s3v4') # 明确签名版本\n",
    "        )\n",
    "        # 尝试列出 buckets (可选，作为连接测试)\n",
    "        # s3_client.list_buckets()\n",
    "        print(\"R2 客户端创建成功。\")\n",
    "        return s3_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"创建 R2 客户端时出错: {e}\")\n",
    "        r2_configured = False # 出错则标记为未配置\n",
    "        return None, False\n",
    "\n",
    "def check_r2_cache(s3_client, bucket_name, cache_key):\n",
    "    \"\"\"检查指定的缓存键是否存在于 R2 存储桶中。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False # 文件未找到\n",
    "        else:\n",
    "            # 其他错误 (如权限问题)\n",
    "            print(f\"检查 R2 缓存时出错 (Key: {cache_key}): {e}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"检查 R2 缓存时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_from_r2(s3_client, bucket_name, cache_key, local_path):\n",
    "    \"\"\"从 R2 下载文件到本地路径，带进度条。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        # 获取文件大小以显示进度\n",
    "        response = s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        total_size = int(response.get('ContentLength', 0))\n",
    "\n",
    "        print(f\"正在从 R2 下载 {cache_key} 到 {local_path} ({total_size / (1024*1024):.2f} MB)...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Filename=local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 下载完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"从 R2 下载文件时出错 (Key: {cache_key}): {e}\")\n",
    "        # 如果文件下载失败，尝试删除本地可能不完整的文件\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"下载 R2 文件时发生未知错误: {e}\")\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def upload_to_r2(s3_client, bucket_name, local_path, cache_key):\n",
    "    \"\"\"将本地文件上传到 R2，带进度条。\"\"\"\n",
    "    if not s3_client or not os.path.exists(local_path):\n",
    "        print(f\"上传 R2 失败：客户端未初始化或本地文件不存在 ({local_path})。\")\n",
    "        return False\n",
    "    try:\n",
    "        total_size = os.path.getsize(local_path)\n",
    "        print(f\"正在上传 {local_path} ({total_size / (1024*1024):.2f} MB) 到 R2 作为 {cache_key}...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 上传完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"上传文件到 R2 时出错 (Key: {cache_key}): {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"上传 R2 文件时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"压缩指定文件夹的内容到 zip 文件。\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"错误：要压缩的文件夹不存在 {folder_path}\")\n",
    "        return False\n",
    "    print(f\"正在压缩目录 {folder_path} 到 {zip_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # 获取文件夹内的所有文件和子文件夹\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for filename in files:\n",
    "                    file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "            # 使用 tqdm 显示压缩进度 (按文件数)\n",
    "            with tqdm(total=len(file_paths), desc=\"压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                for file in file_paths:\n",
    "                    # 计算文件在 zip 中的相对路径\n",
    "                    arcname = os.path.relpath(file, folder_path)\n",
    "                    zipf.write(file, arcname)\n",
    "                    pbar.update(1)\n",
    "        print(\"目录压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"压缩目录时出错: {e}\")\n",
    "        # 如果压缩失败，删除可能不完整的 zip 文件\n",
    "        if os.path.exists(zip_path):\n",
    "            try: os.remove(zip_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def unzip_directory(zip_path, extract_to_folder):\n",
    "    \"\"\"解压缩 zip 文件到指定文件夹。\"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"错误：要解压的 zip 文件不存在 {zip_path}\")\n",
    "        return False\n",
    "    print(f\"正在解压缩文件 {zip_path} 到 {extract_to_folder}...\")\n",
    "    try:\n",
    "        os.makedirs(extract_to_folder, exist_ok=True) # 确保目标文件夹存在\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # 获取 zip 文件中的成员数量以显示进度\n",
    "            total_files = len(zip_ref.namelist())\n",
    "            with tqdm(total=total_files, desc=\"解压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                # 使用 extractall 并更新进度条可能不直接，改为逐个提取\n",
    "                for member in zip_ref.infolist():\n",
    "                    zip_ref.extract(member, extract_to_folder)\n",
    "                    pbar.update(1)\n",
    "                    # 或者直接用 extractall，进度条可能不准确但更快\n",
    "                    # zip_ref.extractall(extract_to_folder)\n",
    "        print(\"文件解压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"解压缩文件时出错: {e}\")\n",
    "        # 如果解压失败，可以选择是否删除不完整的解压目录\n",
    "        # if os.path.exists(extract_to_folder):\n",
    "        #     shutil.rmtree(extract_to_folder)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Resize(TARGET_SIZE, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_name = f\"{int(image_name):04d}\"\n",
    "        if os.path.exists(os.path.join(base_input_dir, f\"{image_name}.png\")):\n",
    "            # 验证集图像路径\n",
    "            input_path = os.path.join(base_input_dir, f\"{image_name}.png\")\n",
    "            os.makedirs(base_output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(base_output_dir, f\"{image_name}.{output_format.lower()}\")\n",
    "        else:\n",
    "            # 训练集图像路径\n",
    "            input_path = os.path.join(base_input_dir, image_name, f\"{image_name}.png\")\n",
    "            # Create corresponding output subdirectory if it doesn't exist\n",
    "            output_folder_path = os.path.join(base_output_dir, image_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "            output_path = os.path.join(output_folder_path, f\"{image_name}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    print('在 Google Colab 环境中运行')\n",
    "    original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "    output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    temp_dir = colab_extract_path\n",
    "elif os.path.exists(\"/kaggle/working\"):\n",
    "    print('在 Kaggle 环境中运行')\n",
    "    original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "    output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    temp_dir = kaggle_temp_path\n",
    "else:\n",
    "    print(\"错误: 无法识别的非 Windows 环境（可能是Linux），需要手动处理\")\n",
    "    exit(1)\n",
    "\n",
    "if original_image_dir:\n",
    "    print(f\"原始输入目录: {original_image_dir}\")\n",
    "    print(f\"目标输出目录: {output_dir}\")\n",
    "    print(f\"临时文件目录: {temp_dir}\")\n",
    "    print(f\"目标尺寸: {TARGET_SIZE}\")\n",
    "\n",
    "    # 创建 R2 客户端并检查配置\n",
    "    s3_client, r2_configured = create_r2_client()\n",
    "    r2_cache_key = f\"work1_resized_{TARGET_SIZE[0]}x{TARGET_SIZE[1]}.zip\"\n",
    "    print(f\"生成的 R2 缓存键: {r2_cache_key}\")\n",
    "    r2_local_zip_path = os.path.join(temp_dir, r2_cache_key)\n",
    "    resize_done = False\n",
    "    if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据在本地，跳过resize步骤\")\n",
    "        resize_done = True\n",
    "\n",
    "    # --- If not found locally, try R2 cache ---\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if not resize_done and r2_configured:\n",
    "        print(f\"本地目录 {output_dir} 为空或不存在，尝试检查 R2 缓存...\")\n",
    "        if check_r2_cache(s3_client, R2_BUCKET_NAME, r2_cache_key):\n",
    "            print(f\"检测到 R2 缓存文件: {r2_cache_key}. 尝试下载...\")\n",
    "            # Download the cache\n",
    "            if download_from_r2(s3_client, R2_BUCKET_NAME, r2_cache_key, r2_local_zip_path):\n",
    "                print(f\"R2 缓存下载成功。正在解压到 {output_dir}...\")\n",
    "                # Unzip the cache\n",
    "                # Ensure output_dir is clean before extracting to avoid mixing old/new files\n",
    "                if os.path.exists(output_dir):\n",
    "                    try: shutil.rmtree(output_dir)\n",
    "                    except Exception as e: print(f\"警告: 清理旧的输出目录失败: {e}\")\n",
    "                os.makedirs(output_dir, exist_ok=True) # Recreate empty directory\n",
    "                if unzip_directory(r2_local_zip_path, output_dir):\n",
    "                    print(\"R2 缓存解压成功。跳过本地resize步骤。\")\n",
    "                    resize_done = True # Data loaded from R2 cache\n",
    "                    # Clean up the temporary zip file after extraction\n",
    "                    if os.path.exists(r2_local_zip_path):\n",
    "                        try: os.remove(r2_local_zip_path)\n",
    "                        except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存解压失败。将执行本地resize。\")\n",
    "                    resize_done = False # Reset flag to perform local resize\n",
    "                    # Clean up potentially incomplete extraction directory\n",
    "                    if os.path.exists(output_dir):\n",
    "                        try: shutil.rmtree(output_dir)\n",
    "                        except Exception as e: print(f\"警告: 清理不完整输出目录失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 从 R2 下载缓存失败。将执行本地resize。\")\n",
    "                resize_done = False # Reset flag to perform local resize\n",
    "        else:\n",
    "            print(\"未检测到 R2 缓存文件。将执行本地resize。\")\n",
    "            resize_done = False # Ensure flag is false\n",
    "    elif not resize_done and not r2_configured:\n",
    "        print(\"R2 未配置或初始化失败，将执行本地resize。\")\n",
    "        resize_done = False # Ensure flag is false\n",
    "    # --- Perform local resizing if not done by cache ---\n",
    "    if not resize_done:\n",
    "        print(\"执行本地图像resize...\")\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading label file {label_file}: {e}\")\n",
    "            sys.exit(1)\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        # Create the main output directory BEFORE starting the loop (done above, but ensure it exists)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # Iterate through images listed in the label file\n",
    "        # Use original_image_dir as input base for resizing\n",
    "        for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "            if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "        print(f\"\\n本地处理完成!\")\n",
    "        print(f\"成功处理图像数: {success_count}\")\n",
    "        print(f\"处理失败图像数: {error_count}\")\n",
    "        print(f\"处理后的图像保存在: {output_dir}\")\n",
    "        # --- Upload resized data to R2 cache if configured and resizing was successful ---\n",
    "        if r2_configured and success_count > 0: # Only upload if some files were processed successfully\n",
    "            print(f\"将本地resize后的数据上传到 R2 缓存 ({r2_cache_key})...\")\n",
    "            # Create a zip file of the output directory\n",
    "            if zip_directory(output_dir, r2_local_zip_path):\n",
    "                # Upload the zip file\n",
    "                if upload_to_r2(s3_client, R2_BUCKET_NAME, r2_local_zip_path, r2_cache_key):\n",
    "                    print(\"R2 缓存上传成功。\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存上传失败。\")\n",
    "                # Clean up the temporary local zip file after upload attempt\n",
    "                if os.path.exists(r2_local_zip_path):\n",
    "                    try: os.remove(r2_local_zip_path)\n",
    "                    except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 创建本地 zip 文件失败，跳过 R2 上传。\")\n",
    "        elif not r2_configured:\n",
    "            print(\"R2 未配置，跳过上传resize后的数据。\")\n",
    "        elif success_count == 0:\n",
    "            print(\"本地resize失败（成功处理图像数为0），跳过R2上传。\")\n",
    "    image_dir = output_dir\n",
    "else:\n",
    "    print(\"未识别的非 Windows 环境，跳过图片resize步骤。\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "okNIq-rfjSo-",
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-04-13T02:01:05.452384",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.448028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 模拟高光的数据增强策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class AddRandomHighlight:\n",
    "    \"\"\"\n",
    "    一个 torchvision transform，用于在 PIL 图像上随机添加圆形高光。\n",
    "\n",
    "    参数:\n",
    "        p (float): 应用此变换的概率 (0 到 1)。\n",
    "        max_highlights (int): 单张图像上添加的最大高光数量（实际数量将在1到max_highlights之间随机选择）。\n",
    "        radius_range (tuple): 一个包含两个整数的元组 (min_radius, max_radius)，指定高光圆形的半径范围。\n",
    "        color (tuple): 一个包含三个整数的元组 (R, G, B)，指定高光的颜色 (默认为白色)。\n",
    "    \"\"\"\n",
    "    def __init__(self, p=0.5, max_highlights=3, radius_range=(5, 15), color=(255, 255, 255)):\n",
    "        if not 0.0 <= p <= 1.0:\n",
    "            raise ValueError(f\"概率 p 必须在 [0, 1] 范围内, 但得到 {p}\")\n",
    "        if not (isinstance(max_highlights, int) and max_highlights >= 1):\n",
    "            raise ValueError(f\"最大高光数 max_highlights 必须是 >= 1 的整数, 但得到 {max_highlights}\")\n",
    "        if not (isinstance(radius_range, tuple) and len(radius_range) == 2 and\n",
    "                isinstance(radius_range[0], int) and isinstance(radius_range[1], int) and\n",
    "                0 < radius_range[0] <= radius_range[1]):\n",
    "            raise ValueError(f\"半径范围 radius_range 必须是 (min, max) 形式的正整数元组，且 min <= max, 但得到 {radius_range}\")\n",
    "        if not (isinstance(color, tuple) and len(color) == 3 and all(0 <= c <= 255 for c in color)):\n",
    "            raise ValueError(f\"颜色 color 必须是 (R, G, B) 形式的元组，且值在 [0, 255] 范围内, 但得到 {color}\")\n",
    "            \n",
    "        self.p = p\n",
    "        self.max_highlights = max_highlights\n",
    "        self.radius_range = radius_range\n",
    "        self.color = color\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        对输入的 PIL 图像应用变换。\n",
    "\n",
    "        参数:\n",
    "            img (PIL.Image.Image): 输入的 PIL 图像。\n",
    "\n",
    "        返回:\n",
    "            PIL.Image.Image: 可能添加了高光的 PIL 图像。\n",
    "        \"\"\"\n",
    "        # 以概率 p 应用此变换\n",
    "        if random.random() < self.p:\n",
    "            # 复制图像以避免修改原始图像（如果原始图像后续还需使用）\n",
    "            # 如果这是 Compose 链中的一步，通常不需要显式复制\n",
    "            # img = img.copy() # 如果需要确保不修改原始输入，取消注释此行\n",
    "\n",
    "            # 随机决定生成多少个高光 (至少1个)\n",
    "            # 根据用户要求“小于四个”，我们生成 1 到 max_highlights (这里是3) 个\n",
    "            num_highlights = random.randint(1, self.max_highlights)\n",
    "            \n",
    "            # 获取图像尺寸\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 创建 ImageDraw 对象以在图像上绘制\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            for _ in range(num_highlights):\n",
    "                # 随机选择半径\n",
    "                radius = random.randint(self.radius_range[0], self.radius_range[1])\n",
    "                \n",
    "                # 随机选择圆心位置\n",
    "                # 确保圆心位置加上半径不会超出图像边界太多（允许部分圆在边缘）\n",
    "                # 稍微限制圆心范围，避免完全生成在图像外的圆心\n",
    "                center_x = random.randint(0, width - 1) \n",
    "                center_y = random.randint(0, height - 1)\n",
    "\n",
    "                # 计算圆形的边界框 (left, top, right, bottom)\n",
    "                # ellipse 方法绘制的是指定边界框内的椭圆，如果边界框是正方形，则为圆形\n",
    "                left = center_x - radius\n",
    "                top = center_y - radius\n",
    "                right = center_x + radius\n",
    "                bottom = center_y + radius\n",
    "                \n",
    "                # 绘制实心圆形高光\n",
    "                draw.ellipse([left, top, right, bottom], fill=self.color)\n",
    "            \n",
    "        # 返回处理后的图像（可能是原始图像或添加了高光的图像）\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 提供一个清晰的表示形式，方便调试\n",
    "        return f\"{self.__class__.__name__}(p={self.p}, max_highlights={self.max_highlights}, radius_range={self.radius_range}, color={self.color})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 应用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "11JDwC__jSo-",
    "papermill": {
     "duration": 1.465971,
     "end_time": "2025-04-13T02:01:06.922765",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.456794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((int(TARGET_SIZE[0]*1.2), int(TARGET_SIZE[1]*1.2))), # 先放大一点\n",
    "    transforms.RandomCrop(TARGET_SIZE), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=20), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    AddRandomHighlight(p=0.3, max_highlights=3, radius_range=(5, 12)), # 试试添加高光抑制模型关注高光问题\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(TARGET_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=420, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=val_transform) # 使用验证变换\n",
    "\n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "eGn3VBzHjSo_",
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-04-13T02:01:06.932847",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.928379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建 ResNet 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b",
    "papermill": {
     "duration": 0.692259,
     "end_time": "2025-04-13T02:01:07.629659",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.937400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "class ResNet101Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet101 = models.resnet101(weights=ResNet101_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet101.fc.in_features\n",
    "        self.resnet101.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet101(x)\n",
    "\n",
    "class ResNet152Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet152 = models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet152.fc.in_features\n",
    "        self.resnet152.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet152(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extractor(model_name, device, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    加载一个 CNN 模型并移除最后的分类层，作为特征提取器。\n",
    "    \"\"\"\n",
    "    if model_name == 'ResNet18Classifier':\n",
    "        base_model = ResNet18Classifier(num_classes=3, dropout_rate=dropout_rate).resnet18\n",
    "        feature_extractor = nn.Sequential(*(list(base_model.children())[:-1]))\n",
    "    elif model_name == 'ResNet34Classifier':\n",
    "        base_model = ResNet34Classifier(num_classes=3, dropout_rate=dropout_rate).resnet34\n",
    "        feature_extractor = nn.Sequential(*(list(base_model.children())[:-1]))\n",
    "    elif model_name == 'ResNet50Classifier':\n",
    "        base_model = ResNet50Classifier(num_classes=3, dropout_rate=dropout_rate).resnet50\n",
    "        feature_extractor = nn.Sequential(*(list(base_model.children())[:-1]))\n",
    "    elif model_name == 'ResNet101Classifier':\n",
    "        base_model = ResNet101Classifier(num_classes=3, dropout_rate=dropout_rate).resnet101\n",
    "        feature_extractor = nn.Sequential(*(list(base_model.children())[:-1]))\n",
    "    elif model_name == 'ResNet152Classifier':\n",
    "        base_model = ResNet152Classifier(num_classes=3, dropout_rate=dropout_rate).resnet152\n",
    "        feature_extractor = nn.Sequential(*(list(base_model.children())[:-1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name for feature extraction: {model_name}\")\n",
    "    \n",
    "    # 确保模型在评估模式以获取一致的特征 (特别是对于包含 Batch Norm 或 Dropout 的层)\n",
    "    feature_extractor.eval() \n",
    "    return feature_extractor.to(device)\n",
    "\n",
    "def extract_features(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    使用指定的模型（特征提取器）从数据加载器中提取特征。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(data_loader, desc=\"Extracting Features\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # 注意：这里直接使用模型进行前向传播，模型应该是已经移除了fc层的特征提取器\n",
    "            # 对于 ResNet，最终输出是一个形状为 (N, C, 1, 1) 的张量，需要展平\n",
    "            with torch.amp.autocast('cuda'): # 在特征提取时也使用自动混合精度\n",
    "                outputs = model(inputs)\n",
    "                # 展平特征向量 (从 N, C, 1, 1 变成 N, C)\n",
    "                outputs = outputs.view(outputs.size(0), -1) \n",
    "            \n",
    "            features_list.append(outputs.cpu().numpy())\n",
    "            labels_list.append(targets.cpu().numpy())\n",
    "            \n",
    "    all_features = np.concatenate(features_list, axis=0)\n",
    "    all_labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2025-04-13T02:01:58.797761",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.790330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": 0.083802,
     "end_time": "2025-04-13T02:01:58.888785",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.804983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存 Boosting 模型\n",
    "def save_boosting_model(model, path):\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Boosting 模型已保存到 {path}\")\n",
    "\n",
    "# 加载 Boosting 模型\n",
    "def load_boosting_model(path):\n",
    "    model = joblib.load(path)\n",
    "    print(f\"Boosting 模型已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 保存 CNN 模型参数 (如果需要在预测时加载 CNN 特征提取器，例如在最终预测阶段)\n",
    "def save_cnn_state_dict(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"CNN 模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载 CNN 模型参数\n",
    "def load_cnn_state_dict(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    print(f\"CNN 模型参数已从 {path} 加载\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "papermill": {
     "duration": 0.007368,
     "end_time": "2025-04-13T02:04:20.035996",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.028628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Boosting 基线模型 K 折交叉验证\n",
    "K 折交叉验证 (K=5)，在每折中训练 CNN 特征提取器，提取特征，然后训练 LightGBM 模型，并评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "papermill": {
     "duration": 295.540911,
     "end_time": "2025-04-13T02:09:15.584272",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.043361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 存储结果 ---\n",
    "fold_val_accuracies = []\n",
    "fold_val_macro_f1_scores = []\n",
    "fold_val_macro_precision_scores = [] # 评估指标包含 precision\n",
    "\n",
    "# --- 准备完整数据集 (加载一次，用于 KFold 分割和创建 Subset) ---\n",
    "try:\n",
    "    full_labels_df = pd.read_excel(label_file)\n",
    "    all_original_labels = full_labels_df['Pterygium'].values\n",
    "    # 创建基础数据集实例，不应用变换 (变换在创建 Subset 时按需应用)\n",
    "    base_full_dataset_no_transform = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=None)\n",
    "\n",
    "    # 确保数据集大小和标签数量匹配\n",
    "    assert len(base_full_dataset_no_transform) == len(all_original_labels), \"Dataset size and label count mismatch!\"\n",
    "    print(f\"成功加载完整数据集，共 {len(base_full_dataset_no_transform)} 张图像。\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing full dataset for K-Fold: {e}\")\n",
    "    K = 0 # 设置 K 为 0 以跳过循环\n",
    "\n",
    "# --- 创建 KFold 分割器 ---\n",
    "if K > 0:\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=base_seed)\n",
    "    print(f\"开始进行 {K}-Fold Cross-Validation...\")\n",
    "else:\n",
    "    print(\"Skipping K-Fold Cross-Validation due to data preparation error or K=0.\")\n",
    "\n",
    "# --- K-Fold 循环 ---\n",
    "current_fold_num = 0\n",
    "\n",
    "# 注意：这里直接迭代 skf.split() 结果，它提供了索引\n",
    "for train_idx_fold, val_idx_fold in skf.split(np.arange(len(base_full_dataset_no_transform)), all_original_labels):\n",
    "    current_fold_num += 1\n",
    "    fold_id_str = f\"Fold {current_fold_num}/{K}\"\n",
    "    print(f\"\\n--- 开始 {fold_id_str} ---\")\n",
    "\n",
    "    # --- 1. 创建当前折的 Subset 数据集和 DataLoader ---\n",
    "    # 在 Subset 中应用变换\n",
    "    train_subset_fold = Subset(base_full_dataset_no_transform, train_idx_fold)\n",
    "    val_subset_fold = Subset(base_full_dataset_no_transform, val_idx_fold)\n",
    "\n",
    "    # 为 Subset 应用变换 (需要一个包装类或手动应用)\n",
    "    # 更简单的方法是创建数据集时直接使用变换，然后在 split 后 Subset\n",
    "    # 但这里我们是按需加载和变换的，所以需要确保 Subset 使用正确的变换\n",
    "    # 为了兼容性，我们假设 base_full_dataset_no_transform 只是提供了路径和标签\n",
    "    # 在 DataLoaer 中，getItem 会调用 transforms。所以 Subset 可以直接用于新的 Dataset 实例\n",
    "    # 更好的方法是：\n",
    "    # train_dataset_fold = PterygiumDataset(labels_df.iloc[train_idx_fold], image_dir, train_transform) # 需要修改 Dataset 初始化接受 df\n",
    "    # val_dataset_fold = PterygiumDataset(labels_df.iloc[val_idx_fold], image_dir, val_transform)\n",
    "    # 简化起见，我们直接用 Subset 索引原始的 Dataset 实例，并在 Dataset 中处理变换\n",
    "    # 原有的 PterygiumDataset 已经可以接受 label_file 和 image_dir\n",
    "    # 我们需要临时创建针对当前 fold 的 label 文件\n",
    "    \n",
    "    # 临时保存当前折的训练和验证标签文件\n",
    "    fold_train_df = full_labels_df.iloc[train_idx_fold].copy()\n",
    "    fold_val_df = full_labels_df.iloc[val_idx_fold].copy()\n",
    "    \n",
    "    # 确定临时文件路径 (例如，在 /kaggle/working 或 /tmp)\n",
    "    if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "        temp_dir_for_folds = os.path.join(kaggle_temp_path, \"fold_labels\")\n",
    "    else: # Local or other non-kaggle/colab env\n",
    "        temp_dir_for_folds = \"./temp_fold_labels\"\n",
    "\n",
    "    os.makedirs(temp_dir_for_folds, exist_ok=True)\n",
    "    \n",
    "    fold_train_label_file = os.path.join(temp_dir_for_folds, f\"fold_{current_fold_num}_train_labels.xlsx\")\n",
    "    fold_val_label_file = os.path.join(temp_dir_for_folds, f\"fold_{current_fold_num}_val_labels.xlsx\")\n",
    "\n",
    "    fold_train_df.to_excel(fold_train_label_file, index=False)\n",
    "    fold_val_df.to_excel(fold_val_label_file, index=False)\n",
    "\n",
    "    train_dataset_fold = PterygiumDataset(label_file=fold_train_label_file, image_dir=image_dir, transform=train_transform)\n",
    "    val_dataset_fold = PterygiumDataset(label_file=fold_val_label_file, image_dir=image_dir, transform=val_transform)\n",
    "\n",
    "    train_loader_fold = DataLoader(train_dataset_fold,\n",
    "                                batch_size=64,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "    val_loader_fold = DataLoader(val_dataset_fold,\n",
    "                                batch_size=64,\n",
    "                                shuffle=False,\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "    print(f\"Fold {current_fold_num}: Train size={len(train_dataset_fold)}, Val size={len(val_dataset_fold)}\")\n",
    "\n",
    "    # --- 2. 微调 CNN 特征提取器 (在当前折叠的训练集上) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 微调 CNN 特征提取器 ---\")\n",
    "    \n",
    "    fold_cnn_feature_extractors = {}\n",
    "    \n",
    "    for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "        print(f\"  微调 {cnn_name}...\")\n",
    "        # 创建一个新的 CNN 模型实例 (带分类头，因为我们需要训练它)\n",
    "        cnn_model_for_finetuning = globals()[cnn_name](num_classes=3).to(device)\n",
    "        \n",
    "        # 配置优化器和调度器（针对当前 CNN 的微调）\n",
    "        cnn_optimizer = optim.AdamW(cnn_model_for_finetuning.parameters(), \n",
    "                                    lr=cnn_micro_train_params['lr'], \n",
    "                                    weight_decay=cnn_micro_train_params['weight_decay'])\n",
    "        cnn_scheduler = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer, \n",
    "                                                            T_max=cnn_micro_train_params['num_epochs'], \n",
    "                                                            eta_min=1e-6)\n",
    "        cnn_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 执行微调（使用简化的训练循环，不需要早停，只需要固定的 epoch）\n",
    "        start_time_cnn_finetune = time.time()\n",
    "        scaler_cnn = torch.amp.GradScaler('cuda') # AMP scaler for CNN training\n",
    "        \n",
    "        for cnn_epoch in range(cnn_micro_train_params['num_epochs']):\n",
    "            cnn_model_for_finetuning.train()\n",
    "            train_loss_cnn = 0\n",
    "            train_correct_cnn = 0\n",
    "            train_total_cnn = 0\n",
    "            \n",
    "            cnn_train_loader_tqdm = tqdm(train_loader_fold, desc=f'  {cnn_name} Epoch {cnn_epoch+1}/{cnn_micro_train_params[\"num_epochs\"]}', leave=False)\n",
    "            \n",
    "            for batch_idx, (inputs, targets) in enumerate(cnn_train_loader_tqdm):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                cnn_optimizer.zero_grad()\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = cnn_model_for_finetuning(inputs)\n",
    "                    loss = cnn_criterion(outputs, targets)\n",
    "                scaler_cnn.scale(loss).backward()\n",
    "                scaler_cnn.step(cnn_optimizer)\n",
    "                scaler_cnn.update()\n",
    "                train_loss_cnn += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total_cnn += targets.size(0)\n",
    "                train_correct_cnn += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                cnn_train_loader_tqdm.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100. * train_correct_cnn / train_total_cnn:.2f}%',\n",
    "                    'lr': f'{cnn_optimizer.param_groups[0][\"lr\"]:.1e}'\n",
    "                })\n",
    "            if cnn_epoch%3==0: print(f\"    Fold {current_fold_num} {cnn_name} Epoch {cnn_epoch+1} Final Train Acc: {100. * train_correct_cnn / train_total_cnn:.2f}%, Avg Loss: {train_loss_cnn / len(train_loader_fold):.4f}\")\n",
    "            cnn_scheduler.step() # 更新 CNN 学习率\n",
    "    \n",
    "        end_time_cnn_finetune = time.time()\n",
    "        print(f\"  微调 {cnn_name} 完成，耗时: {end_time_cnn_finetune - start_time_cnn_finetune:.2f} 秒\")\n",
    "\n",
    "        # --- NEW: Evaluate the finetuned CNN classifier directly on the validation fold ---\n",
    "        print(f\"  评估微调后的 {cnn_name} 在验证集上...\")\n",
    "        cnn_model_for_finetuning.eval() # Set to evaluation mode\n",
    "        val_correct_cnn = 0\n",
    "        val_total_cnn = 0\n",
    "        all_val_labels_cnn = []\n",
    "        all_val_preds_cnn = []\n",
    "\n",
    "        with torch.no_grad(): # Disable gradient calculation for evaluation\n",
    "            cnn_val_loader_tqdm = tqdm(val_loader_fold, desc=f'  Evaluating {cnn_name}', leave=False)\n",
    "            for batch_idx, (inputs, targets) in enumerate(cnn_val_loader_tqdm):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                with torch.amp.autocast('cuda'): # Use AMP for consistent inference\n",
    "                    outputs = cnn_model_for_finetuning(inputs)\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total_cnn += targets.size(0)\n",
    "                val_correct_cnn += predicted.eq(targets).sum().item()\n",
    "\n",
    "                all_val_labels_cnn.extend(targets.cpu().numpy())\n",
    "                all_val_preds_cnn.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        cnn_val_accuracy = 100. * val_correct_cnn / val_total_cnn\n",
    "        # Added zero_division=0 to handle potential cases where a class is not present in the validation fold\n",
    "        cnn_val_macro_precision = precision_score(all_val_labels_cnn, all_val_preds_cnn, average='macro', zero_division=0)\n",
    "        cnn_val_macro_f1 = f1_score(all_val_labels_cnn, all_val_preds_cnn, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"    Fold {current_fold_num} {cnn_name} Validation Accuracy: {cnn_val_accuracy:.2f}%\")\n",
    "        print(f\"    Fold {current_fold_num} {cnn_name} Validation Macro Precision: {cnn_val_macro_precision:.4f}\")\n",
    "        print(f\"    Fold {current_fold_num} {cnn_name} Validation Macro F1: {cnn_val_macro_f1:.4f}\")\n",
    "        # --- END NEW ---\n",
    "\n",
    "        # 获取微调后的特征提取器版本（移除分类头）\n",
    "        feature_extractor = get_feature_extractor(cnn_name, device)\n",
    "        # 将微调后的模型权重加载到特征提取器中\n",
    "        # 需要注意的是，如果原始模型和特征提取器层的名字不完全一致，这里可能需要手动映射\n",
    "        # 幸运的是，ResNet 移除最后一层后，前面的层名字是保留的\n",
    "        feature_extractor.load_state_dict(cnn_model_for_finetuning.state_dict(), strict=False) # strict=False 忽略 fc 层的 key 缺失\n",
    "        \n",
    "        # 将特征提取器设置为评估模式\n",
    "        feature_extractor.eval()\n",
    "        \n",
    "        fold_cnn_feature_extractors[cnn_name] = feature_extractor\n",
    "\n",
    "    # --- 3. 提取特征 ---\n",
    "    print(f\"--- Fold {current_fold_num}: 提取特征 ---\")\n",
    "    \n",
    "    train_features_list_fold = []\n",
    "    val_features_list_fold = []\n",
    "    \n",
    "    # 对每个微调好的 CNN 提取特征\n",
    "    for cnn_name, feature_extractor in fold_cnn_feature_extractors.items():\n",
    "        print(f\"  使用 {cnn_name} 提取训练集特征...\")\n",
    "        train_features, train_labels = extract_features(feature_extractor, train_loader_fold, device)\n",
    "        train_features_list_fold.append(train_features)\n",
    "        \n",
    "        print(f\"  使用 {cnn_name} 提取验证集特征...\")\n",
    "        val_features, val_labels = extract_features(feature_extractor, val_loader_fold, device)\n",
    "        val_features_list_fold.append(val_features)\n",
    "    \n",
    "    # 拼接所有 CNN 的特征\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold = np.concatenate(train_features_list_fold, axis=1)\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    y_train_fold = train_labels # 所有 CNN 提取出的标签应该是相同的\n",
    "\n",
    "    X_val_fold = np.concatenate(val_features_list_fold, axis=1)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    y_val_fold = val_labels # 所有 CNN 提取出的标签应该是相同的\n",
    "\n",
    "    print(f\"拼接后训练特征形状: {X_train_fold.shape}\")\n",
    "    print(f\"拼接后验证特征形状: {X_val_fold.shape}\")\n",
    "\n",
    "    # --- 4. 训练 Boosting 模型 (LightGBM) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 训练 LightGBM 模型 ---\")\n",
    "    \n",
    "    # LightGBM 训练需要指定 eval_set 用于早停\n",
    "    lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "    \n",
    "    # 使用早停，监控验证集上的 Log Loss\n",
    "    eval_set = [(X_val_fold, y_val_fold)]\n",
    "    \n",
    "    start_time_lgbm_train = time.time()\n",
    "    lgbm_model.fit(X_train_fold, y_train_fold,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric='multi_logloss',\n",
    "                callbacks=[lgb.early_stopping(50, verbose=True)]) # 早停参数\n",
    "    end_time_lgbm_train = time.time()\n",
    "    print(f\"LightGBM 训练完成，耗时: {end_time_lgbm_train - start_time_lgbm_train:.2f} 秒\")\n",
    "    print(f\"LightGBM 在训练集上的最佳迭代次数: {lgbm_model.booster_.best_iteration}\")\n",
    "\n",
    "    # --- 5. 评估 Boosting 模型 (在当前折叠的验证集上) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 评估 LightGBM 模型 ---\")\n",
    "    \n",
    "    y_pred_fold = lgbm_model.predict(X_val_fold)\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    fold_macro_precision = precision_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    fold_macro_f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    \n",
    "    print(f\"Fold {current_fold_num} 验证准确率: {fold_accuracy:.4f}\")\n",
    "    print(f\"Fold {current_fold_num} 验证Macro Precision: {fold_macro_precision:.4f}\")\n",
    "    print(f\"Fold {current_fold_num} 验证Macro F1: {fold_macro_f1:.4f}\")\n",
    "    \n",
    "    # 存储结果\n",
    "    fold_val_accuracies.append(fold_accuracy)\n",
    "    fold_val_macro_precision_scores.append(fold_macro_precision)\n",
    "    fold_val_macro_f1_scores.append(fold_macro_f1)\n",
    "    \n",
    "    # 清理临时文件\n",
    "    if os.path.exists(fold_train_label_file): os.remove(fold_train_label_file)\n",
    "    if os.path.exists(fold_val_label_file): os.remove(fold_val_label_file)\n",
    "\n",
    "# --- 6. K-Fold 循环结束后，进行分析 ---\n",
    "if K > 0 and fold_val_accuracies: # 确保有结果可分析\n",
    "    print(\"\\n--- K-Fold Cross-Validation 结果分析 ---\")\n",
    "\n",
    "    # 计算平均值和标准差\n",
    "    mean_accuracy = np.mean(fold_val_accuracies)\n",
    "    std_accuracy = np.std(fold_val_accuracies)\n",
    "    mean_precision = np.mean(fold_val_macro_precision_scores)\n",
    "    std_precision = np.std(fold_val_macro_precision_scores)\n",
    "    mean_f1 = np.mean(fold_val_macro_f1_scores)\n",
    "    std_f1 = np.std(fold_val_macro_f1_scores)\n",
    "\n",
    "    print(f\"平均验证准确率 (across {K} folds): {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    print(f\"平均验证Macro Precision (across {K} folds): {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "    print(f\"平均验证Macro F1 (across {K} folds): {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n每折的验证准确率:\")\n",
    "    for i, acc in enumerate(fold_val_accuracies):\n",
    "        print(f\"  Fold {i+1}: {acc:.4f}\")\n",
    "    print(\"\\n每折的验证Macro F1:\")\n",
    "    for i, f1 in enumerate(fold_val_macro_f1_scores):\n",
    "        print(f\"  Fold {i+1}: {f1:.4f}\")\n",
    "        \n",
    "# --- 清理临时文件夹 ---\n",
    "if 'temp_dir_for_folds' in locals() and os.path.exists(temp_dir_for_folds):\n",
    "    print(f\"清理临时文件夹: {temp_dir_for_folds}\")\n",
    "    try:\n",
    "        shutil.rmtree(temp_dir_for_folds)\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 清理临时文件夹失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# 训练最终用于提交的模型\n",
    "使用整个训练集训练 CNN 特征提取器，提取特征，然后训练最终的 LightGBM 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 开始训练最终提交模型 ---\")\n",
    "\n",
    "# 使用整个训练集的数据加载器 (即原始的 train_loader)\n",
    "final_cnn_train_loader = train_loader # 这里 train_loader 应该包含所有训练数据\n",
    "# 使用验证集的变换来提取特征 (为了特征一致性，通常用 eval transform)\n",
    "# 创建一个包含所有训练数据的 DataLoader，但使用 val_transform\n",
    "full_train_dataset_eval_transform = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=val_transform)\n",
    "full_train_loader_eval_transform = DataLoader(full_train_dataset_eval_transform,\n",
    "                                            batch_size=64,\n",
    "                                            shuffle=False, # 提取特征不需要 shuffle\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=train_loader.prefetch_factor, # 使用相同的预取设置\n",
    "                                            pin_memory=train_loader.pin_memory)\n",
    "\n",
    "\n",
    "# --- 1. 训练或加载 CNN 特征提取器 (在整个训练集上) ---\n",
    "print(\"--- 训练或加载 CNN 特征提取器 (在整个训练集上) ---\")\n",
    "\n",
    "final_cnn_feature_extractors = {}\n",
    "\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "    print(f\"  训练 {cnn_name} 在完整数据集上...\")\n",
    "    # 创建一个新的 CNN 模型实例 (带分类头)\n",
    "    cnn_model_for_final_training = globals()[cnn_name](num_classes=3).to(device)\n",
    "\n",
    "    # 配置优化器和调度器\n",
    "    cnn_optimizer_final = optim.AdamW(cnn_model_for_final_training.parameters(), \n",
    "                                        lr=cnn_micro_train_params['lr'], # 可以使用与 fold 相同的 lr，或重新调优\n",
    "                                        weight_decay=cnn_micro_train_params['weight_decay'])\n",
    "    # T_max 应该基于完整的 num_epochs\n",
    "    cnn_scheduler_final = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer_final, \n",
    "                                                                T_max=cnn_micro_train_params['num_epochs'], \n",
    "                                                                eta_min=1e-6) # 这里可以考虑增加 T_max，因为数据量更大\n",
    "    cnn_criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 执行训练 (使用简化的训练循环)\n",
    "    start_time_cnn_final_train = time.time()\n",
    "    scaler_cnn_final = torch.amp.GradScaler('cuda') # AMP scaler for CNN training\n",
    "    \n",
    "    # 这里可以考虑加入一个简单的早停，监控训练集上的损失或一个小的保留验证集\n",
    "    # 为了简单和遵循“不考虑时间”原则，我们先运行固定的 epoch 数\n",
    "    for cnn_epoch in range(cnn_micro_train_params['num_epochs']): # 可以增加这个 epoch 数\n",
    "        cnn_model_for_final_training.train()\n",
    "        train_loss_cnn_final = 0\n",
    "        train_correct_cnn_final = 0\n",
    "        train_total_cnn_final = 0\n",
    "        \n",
    "        cnn_train_loader_final_tqdm = tqdm(final_cnn_train_loader, desc=f'  {cnn_name} Final Epoch {cnn_epoch+1}/{cnn_micro_train_params[\"num_epochs\"]}', leave=False)\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(cnn_train_loader_final_tqdm):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            cnn_optimizer_final.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = cnn_model_for_final_training(inputs)\n",
    "                loss = cnn_criterion_final(outputs, targets)\n",
    "            scaler_cnn_final.scale(loss).backward()\n",
    "            scaler_cnn_final.step(cnn_optimizer_final)\n",
    "            scaler_cnn_final.update()\n",
    "            train_loss_cnn_final += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total_cnn_final += targets.size(0)\n",
    "            train_correct_cnn_final += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            cnn_train_loader_final_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * train_correct_cnn_final / train_total_cnn_final:.2f}%',\n",
    "                'lr': f'{cnn_optimizer_final.param_groups[0][\"lr\"]:.1e}'\n",
    "            })\n",
    "        if cnn_epoch%3==0: print(f\"    Final Training {cnn_name} Epoch {cnn_epoch+1} Final Train Acc: {100. * train_correct_cnn_final / train_total_cnn_final:.2f}%, Avg Loss: {train_loss_cnn / len(train_loader_fold):.4f}\")\n",
    "        cnn_scheduler_final.step() # 更新 CNN 学习率\n",
    "    \n",
    "    end_time_cnn_final_train = time.time()\n",
    "    print(f\"  训练 {cnn_name} 在完整数据集上完成，耗时: {end_time_cnn_final_train - start_time_cnn_final_train:.2f} 秒\")\n",
    "\n",
    "    # 获取最终的特征提取器版本\n",
    "    feature_extractor = get_feature_extractor(cnn_name, device)\n",
    "    feature_extractor.load_state_dict(cnn_model_for_final_training.state_dict(), strict=False)\n",
    "    feature_extractor.eval()\n",
    "    final_cnn_feature_extractors[cnn_name] = feature_extractor\n",
    "    save_cnn_state_dict(feature_extractor, f'./final_{cnn_name}_feature_extractor.pth')\n",
    "\n",
    "# --- 2. 提取特征 (从整个训练集) ---\n",
    "print(\"--- 提取整个训练集的特征 ---\")\n",
    "\n",
    "final_train_features_list = []\n",
    "\n",
    "# 对每个训练好的 CNN 提取特征 (使用 eval transform 的 DataLoader)\n",
    "for cnn_name, feature_extractor in final_cnn_feature_extractors.items():\n",
    "    print(f\"  使用 {cnn_name} 提取完整训练集特征...\")\n",
    "    # 注意：这里提取的是完整训练集的特征，用于训练最终的 Boosting 模型\n",
    "    features, labels = extract_features(feature_extractor, full_train_loader_eval_transform, device)\n",
    "    final_train_features_list.append(features)\n",
    "\n",
    "X_final_train = np.concatenate(final_train_features_list, axis=1)\n",
    "final_scaler = StandardScaler()\n",
    "X_final_train = final_scaler.fit_transform(X_final_train)\n",
    "y_final_train = labels # 所有 CNN 提取出的标签应该是相同的\n",
    "\n",
    "print(f\"拼接后完整训练集特征形状: {X_final_train.shape}\")\n",
    "\n",
    "# --- 3. 训练最终的 Boosting 模型 ---\n",
    "print(\"--- 训练最终 LightGBM 模型 ---\")\n",
    "\n",
    "# 使用与 K-Fold 中相同的 LightGBM 参数，或者基于 K-Fold 结果进行微调\n",
    "final_lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "\n",
    "# 在整个训练集上训练最终模型，不再需要 eval_set 和早停（除非你再分一个小的最终验证集）\n",
    "# 为了最大化利用数据，通常直接在全量数据上训练\n",
    "start_time_final_lgbm_train = time.time()\n",
    "final_lgbm_model.fit(X_final_train, y_final_train)\n",
    "end_time_final_lgbm_train = time.time()\n",
    "print(f\"最终 LightGBM 模型训练完成，耗时: {end_time_final_lgbm_train - start_time_final_lgbm_train:.2f} 秒\")\n",
    "\n",
    "# --- 4. 保存最终模型 ---\n",
    "final_model_save_path = \"./final_boosted_classifier.joblib\"\n",
    "save_boosting_model(final_lgbm_model, final_model_save_path)\n",
    "\n",
    "# 保存 scaler 以便预测时使用\n",
    "final_scaler_save_path = \"./final_feature_scaler.joblib\"\n",
    "joblib.dump(final_scaler, final_scaler_save_path)\n",
    "print(f\"特征Scaler已保存到 {final_scaler_save_path}\")\n",
    "\n",
    "print(\"\\n--- 最终提交模型训练完成 ---\")\n",
    "# -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# 最终模型预测\n",
    "加载训练好的 Boosted 模型，并使用它对新图像进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最终的 Boosting 模型\n",
    "final_lgbm_model_loaded = load_boosting_model(\"./final_boosted_classifier.joblib\")\n",
    "# 加载最终的 Scaler\n",
    "final_scaler_loaded = joblib.load(\"./final_feature_scaler.joblib\")\n",
    "print(\"Scaler已从 ./final_feature_scaler.joblib 加载\")\n",
    "\n",
    "final_cnn_feature_extractors_loaded = {}\n",
    "print(\"加载微调后的 CNN 特征提取器...\")\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "    print(f\"  加载 {cnn_name} 特征提取器...\")\n",
    "    # 创建特征提取器模型实例 (不带分类头，使用 get_feature_extractor)\n",
    "    feature_extractor = get_feature_extractor(cnn_name, device)\n",
    "    final_cnn_state_dict_path = f'./final_{cnn_name}_feature_extractor.pth'\n",
    "    if os.path.exists(final_cnn_state_dict_path):\n",
    "        load_cnn_state_dict(feature_extractor, final_cnn_state_dict_path, device)\n",
    "        final_cnn_feature_extractors_loaded[cnn_name] = feature_extractor\n",
    "        print(f\"  {cnn_name} 权重加载成功。\")\n",
    "    else:\n",
    "        print(f\"警告: 未找到 {cnn_name} 的微调权重文件 {final_cnn_state_dict_path}。将使用预训练权重。\")\n",
    "        # 如果文件不存在，get_feature_extractor 默认会加载 ImageNet 预训练权重\n",
    "        final_cnn_feature_extractors_loaded[cnn_name] = feature_extractor\n",
    "\n",
    "\n",
    "def predict_image_boosted(cnn_feature_extractors, boosted_model, scaler, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用 Boosted Ensemble 模型对单张图像进行预测。\n",
    "    \"\"\"\n",
    "    # 1. 加载和预处理图像\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device) # 应用 eval transform\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 预测图像文件未找到 {image_path}\")\n",
    "        return None # Or raise error\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理预测图像 {image_path}: {e}\")\n",
    "        return None # Or raise error\n",
    "\n",
    "    # 2. 使用每个 CNN 提取特征\n",
    "    features_list = []\n",
    "    with torch.no_grad():\n",
    "        for cnn_name, feature_extractor in cnn_feature_extractors.items():\n",
    "            # 确保 CNN 处于评估模式\n",
    "            feature_extractor.eval() \n",
    "            with torch.amp.autocast('cuda'): # AMP 推理\n",
    "                outputs = feature_extractor(image_tensor)\n",
    "                features_list.append(outputs.view(outputs.size(0), -1).cpu().numpy())\n",
    "    image_features_unscaled = np.concatenate(features_list, axis=1)\n",
    "\n",
    "    # 3. 标准化特征\n",
    "    image_features_scaled = scaler.transform(image_features_unscaled)\n",
    "\n",
    "    # 4. 使用 Boosted 模型进行预测\n",
    "    predicted_class = boosted_model.predict(image_features_scaled)[0] # predict 返回数组\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# --- 预测示例 (使用你的 val_image_dir 结构) ---\n",
    "def test_final_model_on_val_dir(cnn_feature_extractors, boosted_model, scaler, input_dir, transform, device):\n",
    "    \"\"\"\n",
    "    在验证集目录上测试最终 Boosted 模型。\n",
    "    \"\"\"\n",
    "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\")) \n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Predicting images with Boosted Model\", leave=True):\n",
    "        try:\n",
    "            predicted_class = predict_image_boosted(cnn_feature_extractors, boosted_model, scaler, img_path, transform, device)\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            results.append({\"Image\": int(base_name), \"Pterygium\": predicted_class})\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"处理预测图像 {img_path} 时出错: {e}\")\n",
    "    \n",
    "    # 按图像名称排序\n",
    "    results.sort(key=lambda x: x[\"Image\"])\n",
    "    df = pd.DataFrame(results, columns=[\"Image\", \"Pterygium\"])\n",
    "    \n",
    "    # 保存结果到文件\n",
    "    output_result_path = \"./Classification_Results.xlsx\"\n",
    "    df.to_excel(output_result_path, index=False)\n",
    "    print(f\"\\n分类结果已保存到 {output_result_path}\")\n",
    "\n",
    "# 调用测试函数\n",
    "test_final_model_on_val_dir(final_cnn_feature_extractors_loaded,\n",
    "                            final_lgbm_model_loaded,\n",
    "                            final_scaler_loaded,\n",
    "                            val_image_dir,\n",
    "                            val_transform,\n",
    "                            device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231745112,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 937.871658,
   "end_time": "2025-04-13T02:09:18.610590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T01:53:40.738932",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
