{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "ae9dfa31",
    "language": "markdown",
    "papermill": {
     "duration": 0.01069,
     "end_time": "2025-04-30T04:44:46.131996",
     "exception": false,
     "start_time": "2025-04-30T04:44:46.121306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 翼状胬肉区域分割模型\n",
    "\n",
    "这是项目的第二个任务：实现对眼部裂隙灯检查图片中翼状胬肉区域的精准分割。我们将使用U-Net模型解决这一问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.010478,
     "end_time": "2025-04-30T04:44:46.153079",
     "exception": false,
     "start_time": "2025-04-30T04:44:46.142601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.021313,
     "end_time": "2025-04-30T04:44:46.185043",
     "exception": false,
     "start_time": "2025-04-30T04:44:46.163730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val_img\"\n",
    "# colab路径\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# ================== 掩码输出路径 ================\n",
    "output_mask_dir = r\"f:/mask\" # 后处理后的二值掩码 (RGB 128,0,0)\n",
    "output_mask_model_output_dir = r\"f:/mask_original\" # # 模型原始输出阈值化后的二值掩码 (RGB 128,0,0)\n",
    "output_mask_prob_dir = r\"f:/mask_probability\" # 模型原始输出概率图 (RGB 0-255)\n",
    "# colab路径\n",
    "output_maskfiles_colab = \"/content/mask\"\n",
    "output_maskmodeloutputfiles_colab = \"/content/mask_original\"\n",
    "output_maskprobfiles_colab = \"/content/mask_probability\"\n",
    "# Kaggle路径\n",
    "output_maskfiles_kaggle = \"/kaggle/working/mask\"\n",
    "output_maskmodeloutputfile_kaggle = \"/kaggle/working/mask_original\"\n",
    "output_maskprobfiles_kaggle = \"/kaggle/working/mask_probability\"\n",
    "\n",
    "# ================== 训练参数 ==================\n",
    "DEBUG_MODE = True # 设置为 True 以启用调试模式加速训练 (图像缩放 1/4)\n",
    "patch_size = 256\n",
    "patch_stride = patch_size // 2 # 定义训练时的步长（产生50%重叠）\n",
    "predict_stride = patch_size // 2 # 定义预测时的步长（产生50%重叠）\n",
    "target_input_size = (patch_size, patch_size)\n",
    "train_model_select = 'unet' # 'unet', 'deeplabv3', 'unet_attention'\n",
    "MIN_FOREGROUND_RATIO = 0 # 离线patching，保留的Mask Patch中前景像素(128)最小比例，设为0则不过滤\n",
    "HEALTHY_PTERYGIUM_PATCH_RATIO = 0.3 # 健康和翼状胬肉patch比例，设为0则不平衡采样\n",
    "tpu_batch_size = 16\n",
    "# 512分辨率下，unet为36，deeplabv3为20\n",
    "cuda_batch_size = 19 if train_model_select == 'deeplabv3' else 36\n",
    "windows_batch_size = 3\n",
    "num_epochs = 30\n",
    "log_interval = 5\n",
    "\n",
    "if patch_size == 256: cuda_batch_size *= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.017739,
     "end_time": "2025-04-30T04:44:46.213989",
     "exception": false,
     "start_time": "2025-04-30T04:44:46.196250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "c8b6c127",
    "language": "python",
    "papermill": {
     "duration": 19.478741,
     "end_time": "2025-04-30T04:45:05.703650",
     "exception": false,
     "start_time": "2025-04-30T04:44:46.224909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import shap\n",
    "import collections\n",
    "import subprocess\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "from torchvision.models import ResNet34_Weights \n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import functional as F\n",
    "from skimage.morphology import binary_opening, binary_closing, disk, square\n",
    "try:\n",
    "    subprocess.run(['pip', 'install','--upgrade','albumentations'], check=True)\n",
    "except:\n",
    "    print(\"pip install albumentations 失败\")\n",
    "    pass\n",
    "import albumentations as A # type: ignore\n",
    "from albumentations.pytorch import ToTensorV2 # type: ignore\n",
    "import cv2\n",
    "import torch.nn.functional as Fnn\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "import matplotlib.font_manager\n",
    "\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    _xla_available = True\n",
    "    print(\"torch_xla 导入成功。\")\n",
    "except ImportError:\n",
    "    _xla_available = False\n",
    "    print(\"torch_xla 未安装或导入失败。将使用 CUDA 或 CPU。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "c8b6c127",
    "language": "python",
    "papermill": {
     "duration": 3.021228,
     "end_time": "2025-04-30T04:45:08.736531",
     "exception": false,
     "start_time": "2025-04-30T04:45:05.715303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        try:\n",
    "            subprocess.run(['wget','-q','-O', 'simhei.ttf', \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"], check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"下载字体失败: {e}\")\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "if _xla_available:\n",
    "    num_workers = 0\n",
    "\n",
    "# 配置GPU/TPU/CPU\n",
    "if _xla_available:\n",
    "    # 获取 XLA 设备 (TPU)\n",
    "    # xm.xla_device() 会自动获取当前进程可用的 TPU核心\n",
    "    device = xm.xla_device()\n",
    "    print(f\"检测到 TPU，使用的设备: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        cudnn.benchmark = True\n",
    "        print(\"cuDNN benchmark 模式已启用\")\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "    print(f\"使用的设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "7f00c3ad",
    "language": "markdown",
    "papermill": {
     "duration": 0.011191,
     "end_time": "2025-04-30T04:45:08.759590",
     "exception": false,
     "start_time": "2025-04-30T04:45:08.748399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 读取和准备数据\n",
    "我们需要读取原始图像和对应的分割标签（mask）。标签中像素值为128的区域表示翼状胬肉，像素值为0的区域表示背景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "64589f50",
    "language": "python",
    "papermill": {
     "duration": 1.183386,
     "end_time": "2025-04-30T04:45:09.954567",
     "exception": false,
     "start_time": "2025-04-30T04:45:08.771181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 多环境变量设置 ==========\n",
    "if os.path.exists('.env'):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('.env')\n",
    "\n",
    "R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID', '')\n",
    "R2_SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', '')\n",
    "R2_BUCKET_NAME = os.environ.get('R2_BUCKET_NAME', '')\n",
    "R2_ENDPOINT_URL = os.environ.get('R2_ENDPOINT_URL', '')\n",
    "\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        output_mask_dir = output_maskfiles_colab\n",
    "        output_mask_model_output_dir = output_maskmodeloutputfiles_colab\n",
    "        output_mask_prob_dir = output_maskprobfiles_colab\n",
    "        print(f\"Colab 环境：验证结果将验证压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive # type: ignore\n",
    "        from google.colab import userdata # type: ignore\n",
    "        drive.mount('/content/drive')\n",
    "        R2_ACCESS_KEY_ID = userdata.get(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = userdata.get(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = userdata.get(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = userdata.get(\"R2_ENDPOINT_URL\")\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "        \n",
    "        output_mask_dir = output_maskfiles_kaggle\n",
    "        output_mask_model_output_dir= output_maskmodeloutputfile_kaggle\n",
    "        output_mask_prob_dir = output_maskprobfiles_kaggle\n",
    "        print(f\"Kaggle 环境：验证结果将压缩 {output_mask_dir} 到 {output_mask_dir}.zip\")\n",
    "\n",
    "        from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "        user_secrets = UserSecretsClient()\n",
    "        R2_ACCESS_KEY_ID = user_secrets.get_secret(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = user_secrets.get_secret(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = user_secrets.get_secret(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = user_secrets.get_secret(\"R2_ENDPOINT_URL\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.011063,
     "end_time": "2025-04-30T04:45:09.977665",
     "exception": false,
     "start_time": "2025-04-30T04:45:09.966602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 离线Patching函数 (利用GPU加速)\n",
    "用于将原始的大尺寸图像和对应的分割掩码离线切割成指定大小的Patches，并保存到磁盘。\n",
    "该函数会尝试将大图加载到GPU进行裁剪和过滤，以加速处理过程（需要注意GPU显存）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.038653,
     "end_time": "2025-04-30T04:45:10.027650",
     "exception": false,
     "start_time": "2025-04-30T04:45:09.988997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_offline_patches_gpu_mixed(\n",
    "    input_image_dir,\n",
    "    label_file_path,\n",
    "    output_image_patch_dir,\n",
    "    output_mask_patch_dir,\n",
    "    patch_size,\n",
    "    stride,\n",
    "    device,\n",
    "    min_foreground_ratio=0.01,\n",
    "    healthy_pterygium_patch_ratio=1.2, # 健康Patch数量与病灶Patch数量的比例目标\n",
    "    debug_mode=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    离线创建图像和掩码的Patches，尝试使用GPU加速，并根据标签文件筛选图像。\n",
    "    包含策略性采样的健康图像 Patch (Mask 全零)。\n",
    "    在调试模式下，原始大图会缩放到 1/4 大小后再进行 patching。\n",
    "\n",
    "    Args:\n",
    "        input_image_dir (str): 包含原始图像子文件夹 (如 0001, 0002...) 的目录。\n",
    "        label_file_path (str): 包含图像标签的Excel文件路径。\n",
    "        output_image_patch_dir (str): 保存图像Patch的目录。\n",
    "        output_mask_patch_dir (str or None): 保存掩码Patch的目录。如果为 None，则不处理或保存掩码。\n",
    "        patch_size (int): Patch的边长。\n",
    "        stride (int): 切割Patch时的步长。\n",
    "        device (torch.device): 用于计算的设备 (cuda or cpu)。\n",
    "        min_foreground_ratio (float): 保留的Mask Patch中前景像素(值>0)的最小比例 (仅用于病灶图像)。设为0则不过滤。\n",
    "        healthy_pterygium_patch_ratio (float): 目标健康 Patch 数量 / 病灶 Patch 数量 的比例。\n",
    "        debug_mode (bool): 是否启用调试模式，缩放图像。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (成功处理的大图数量, 创建的Patch对数量)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        os.makedirs(output_image_patch_dir, exist_ok=True)\n",
    "        if output_mask_patch_dir:\n",
    "            os.makedirs(output_mask_patch_dir, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"创建输出目录时出错: {e}\")\n",
    "        return 0, 0 # 如果目录创建失败，无法继续\n",
    "\n",
    "    # 读取并筛选标签文件\n",
    "    try:\n",
    "        labels_df = pd.read_excel(label_file_path)\n",
    "        # 将图像分为两组：病灶和健康\n",
    "        pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        healthy_df = labels_df[labels_df['Pterygium'] == 0].reset_index(drop=True)\n",
    "\n",
    "        pterygium_folders = pterygium_df['Image'].astype(int).apply(lambda x: f\"{x:04d}\").tolist()\n",
    "        healthy_folders = healthy_df['Image'].astype(int).apply(lambda x: f\"{x:04d}\").tolist()\n",
    "\n",
    "        print(f\"从 {os.path.basename(label_file_path)} 读取标签。\")\n",
    "        print(f\"找到 {len(pterygium_folders)} 个翼状胬肉样本进行Patching。\")\n",
    "        print(f\"找到 {len(healthy_folders)} 个健康样本。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 标签文件未找到 {label_file_path}。无法进行Patching。\")\n",
    "        return 0, 0\n",
    "    except Exception as e:\n",
    "        print(f\"读取或处理标签文件 {label_file_path} 时出错: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "    total_processed_folders = 0\n",
    "    total_created_patches = 0\n",
    "    pterygium_patch_count = 0\n",
    "    healthy_patch_count = 0\n",
    "\n",
    "    # --- 阶段 1: 处理病灶图像 ---\n",
    "    print(\"\\n--- 处理病灶图像 ---\")\n",
    "    if DEBUG_MODE: print(\"\\n调试模式已启用，图像缩放到 1/4 大小进行处理。\")\n",
    "    for folder_name in tqdm(pterygium_folders, desc=\"Patching 病灶图像\", leave=False):\n",
    "        image_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}.png\")\n",
    "        mask_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}_label.png\")\n",
    "\n",
    "        if not os.path.exists(image_path) or (output_mask_patch_dir and not os.path.exists(mask_path)):\n",
    "            print(f\"警告: 病灶图像或掩码文件未找到 {folder_name}，跳过。\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_pil = Image.open(image_path).convert('RGB')\n",
    "            mask_pil = Image.open(mask_path).convert('RGB') # 掩码是 (128,0,0)\n",
    "\n",
    "            # --- 调试模式下缩放 ---\n",
    "            if debug_mode:\n",
    "                original_w, original_h = img_pil.size\n",
    "                new_w, new_h = original_w // 4, original_h // 4\n",
    "                img_pil = img_pil.resize((new_w, new_h), Image.Resampling.BICUBIC if hasattr(Image, 'Resampling') else Image.BICUBIC) # Use BICUBIC for image\n",
    "                mask_pil = mask_pil.resize((new_w, new_h), Image.Resampling.NEAREST if hasattr(Image, 'Resampling') else Image.NEAREST) # Use NEAREST for mask\n",
    "            # --- 缩放结束 ---\n",
    "\n",
    "            img_w, img_h = img_pil.size\n",
    "            mask_w, mask_h = mask_pil.size\n",
    "\n",
    "            if img_w != mask_w or img_h != mask_h:\n",
    "                print(f\"警告: 病灶图像和掩码尺寸不匹配 {folder_name}，跳过。 ({img_w}x{img_h} vs {mask_w}x{mask_h})\")\n",
    "                continue\n",
    "\n",
    "            img_tensor_gpu = F.to_tensor(img_pil).to(device)\n",
    "            mask_np_rgb = np.array(mask_pil)\n",
    "            mask_binary = (mask_np_rgb[:, :, 0] == 128).astype(np.float32)\n",
    "            mask_tensor_gpu = torch.from_numpy(mask_binary).unsqueeze(0).to(device)\n",
    "\n",
    "            for y in range(0, img_h - patch_size + 1, stride):\n",
    "                for x in range(0, img_w - patch_size + 1, stride):\n",
    "                    img_patch_gpu = img_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "                    mask_patch_gpu = mask_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "                    # --- 应用前景过滤 (仅对病灶图像 Patch) ---\n",
    "                    if min_foreground_ratio > 0:\n",
    "                        foreground_ratio = torch.mean(mask_patch_gpu)\n",
    "                        if foreground_ratio < min_foreground_ratio:\n",
    "                            continue # 跳过前景过少的病灶 Patch\n",
    "\n",
    "                    # --- 保存 Patch ---\n",
    "                    img_patch_cpu = img_patch_gpu.cpu()\n",
    "                    mask_patch_cpu = mask_patch_gpu.cpu()\n",
    "\n",
    "                    patch_filename = f\"{folder_name}_y{y}_x{x}.png\"\n",
    "                    img_save_path = os.path.join(output_image_patch_dir, patch_filename)\n",
    "                    F.to_pil_image(img_patch_cpu).save(img_save_path)\n",
    "\n",
    "                    if output_mask_patch_dir:\n",
    "                        # 将 0/1 mask tensor 转换为 0/128 的 PIL 灰度图 (或 RGB 128,0,0)\n",
    "                        mask_patch_np_uint8 = (mask_patch_cpu.squeeze().numpy() * 128).astype(np.uint8)\n",
    "                        mask_rgb_array = np.stack((mask_patch_np_uint8, np.zeros_like(mask_patch_np_uint8), np.zeros_like(mask_patch_np_uint8)), axis=-1)\n",
    "                        Image.fromarray(mask_rgb_array, mode='RGB').save(os.path.join(output_mask_patch_dir, patch_filename))\n",
    "\n",
    "\n",
    "                    pterygium_patch_count += 1\n",
    "                    total_created_patches += 1\n",
    "\n",
    "            del img_tensor_gpu, mask_tensor_gpu\n",
    "            if 'img_patch_gpu' in locals(): del img_patch_gpu\n",
    "            if 'mask_patch_gpu' in locals() and mask_patch_gpu is not None: del mask_patch_gpu\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                torch.cuda.empty_cache()\n",
    "            total_processed_folders += 1 # 成功处理一个病灶文件夹\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n处理病灶文件 {folder_name} 时发生未预料错误: {e}\")\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    print(f\"病灶图像 Patching 完成。共创建 {pterygium_patch_count} 个病灶 Patches。\")\n",
    "\n",
    "\n",
    "    # --- 阶段 2: 策略性采样并处理健康图像 ---\n",
    "    if output_mask_patch_dir and healthy_folders: # 只有在需要 Mask 且有健康图像时才处理\n",
    "        print(\"\\n--- 处理健康图像 ---\")\n",
    "        target_healthy_patch_count = int(pterygium_patch_count * healthy_pterygium_patch_ratio)\n",
    "        print(f\"目标健康 Patch 数量 (基于 {healthy_pterygium_patch_ratio}:1 比例): {target_healthy_patch_count}\")\n",
    "\n",
    "        # 粗略估计每张健康大图能产生的 Patch 数量 (基于原始或缩放后的尺寸)\n",
    "        # 假设原始图像尺寸一致 5184x3456\n",
    "        original_h, original_w = 3456, 5184\n",
    "        img_h, img_w = (original_h // 4, original_w // 4) if debug_mode else (original_h, original_w)\n",
    "\n",
    "        est_patches_per_full_image_precise = ((img_h - patch_size + stride) // stride) * ((img_w - patch_size + stride) // stride)\n",
    "        if est_patches_per_full_image_precise <= 0: # 防止计算错误或尺寸太小\n",
    "            est_patches_per_full_image_precise = (img_h // stride) * (img_w // stride) # 回退到粗略估计\n",
    "            if est_patches_per_full_image_precise == 0: est_patches_per_full_image_precise = 1 # 至少1个\n",
    "\n",
    "        # 估计需要多少张健康大图来达到目标 Patch 数量\n",
    "        num_healthy_folders_to_sample = min(len(healthy_folders), max(1, int(target_healthy_patch_count / est_patches_per_full_image_precise)))\n",
    "        print(f\"估计需要采样约 {num_healthy_folders_to_sample} 张健康图像。\")\n",
    "\n",
    "        # 随机采样健康文件夹\n",
    "        if num_healthy_folders_to_sample < len(healthy_folders):\n",
    "            sampled_healthy_folders = random.sample(healthy_folders, num_healthy_folders_to_sample)\n",
    "            print(f\"已从 {len(healthy_folders)} 张中随机采样 {len(sampled_healthy_folders)} 张健康图像进行Patching。\")\n",
    "        else:\n",
    "            sampled_healthy_folders = healthy_folders\n",
    "            print(f\"将对所有 {len(healthy_folders)} 张健康图像进行Patching。\")\n",
    "\n",
    "\n",
    "        # 遍历采样的健康图像文件夹进行 Patching\n",
    "        for folder_name in tqdm(sampled_healthy_folders, desc=\"Patching 健康图像\", leave=False):\n",
    "            image_path = os.path.join(input_image_dir, folder_name, f\"{folder_name}.png\")\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"警告: 健康图像文件未找到 {image_path}，跳过文件夹 {folder_name}。\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img_pil = Image.open(image_path).convert('RGB')\n",
    "\n",
    "                # --- 调试模式下缩放 ---\n",
    "                if debug_mode:\n",
    "                    original_w, original_h = img_pil.size\n",
    "                    new_w, new_h = original_w // 4, original_h // 4\n",
    "                    img_pil = img_pil.resize((new_w, new_h), Image.Resampling.BICUBIC if hasattr(Image, 'Resampling') else Image.BICUBIC)\n",
    "                # --- 缩放结束 ---\n",
    "\n",
    "                img_w, img_h = img_pil.size\n",
    "\n",
    "                # 为健康图像创建全零 Mask (与缩放或未缩放后的图像尺寸相同)\n",
    "                mask_np_zero = np.zeros((img_h, img_w), dtype=np.float32) # 0/1 float32 格式\n",
    "                mask_tensor_gpu = torch.from_numpy(mask_np_zero).unsqueeze(0).to(device)\n",
    "\n",
    "                img_tensor_gpu = F.to_tensor(img_pil).to(device)\n",
    "\n",
    "                for y in range(0, img_h - patch_size + 1, stride):\n",
    "                    for x in range(0, img_w - patch_size + 1, stride):\n",
    "                        img_patch_gpu = img_tensor_gpu[:, y:y+patch_size, x:x+patch_size]\n",
    "                        mask_patch_gpu = mask_tensor_gpu[:, y:y+patch_size, x:x+patch_size] # 仍然是全零\n",
    "\n",
    "                        # --- 不对健康图像的 Patch 应用前景过滤 ---\n",
    "\n",
    "                        # --- 保存 Patch ---\n",
    "                        img_patch_cpu = img_patch_gpu.cpu()\n",
    "                        mask_patch_cpu = mask_patch_gpu.cpu() # 仍然是全零\n",
    "\n",
    "                        patch_filename = f\"{folder_name}_y{y}_x{x}.png\"\n",
    "                        img_save_path = os.path.join(output_image_patch_dir, patch_filename)\n",
    "                        F.to_pil_image(img_patch_cpu).save(img_save_path)\n",
    "\n",
    "                        if output_mask_patch_dir:\n",
    "                            # 将 0/1 的全零 mask tensor 转换为 0/128 的 PIL 灰度图 (仍然是全零图像)\n",
    "                            mask_patch_np_uint8 = (mask_patch_cpu.squeeze().numpy() * 128).astype(np.uint8)\n",
    "                            mask_rgb_array = np.stack((mask_patch_np_uint8, np.zeros_like(mask_patch_np_uint8), np.zeros_like(mask_patch_np_uint8)), axis=-1)\n",
    "                            Image.fromarray(mask_rgb_array, mode='RGB').save(os.path.join(output_mask_patch_dir, patch_filename))\n",
    "\n",
    "                        healthy_patch_count += 1\n",
    "                        total_created_patches += 1\n",
    "\n",
    "                del img_tensor_gpu, mask_tensor_gpu\n",
    "                if 'img_patch_gpu' in locals(): del img_patch_gpu\n",
    "                if 'mask_patch_gpu' in locals() and mask_patch_gpu is not None: del mask_patch_gpu\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    torch.cuda.empty_cache()\n",
    "                total_processed_folders += 1 # 成功处理一个健康文件夹\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n处理健康文件 {folder_name} 时发生未预料错误: {e}\")\n",
    "                if device == torch.device(\"cuda\"):\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"健康图像 Patching 完成。共创建 {healthy_patch_count} 个健康 Patches。\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"离线Patching完成！\")\n",
    "    print(f\"成功处理大图数量: {total_processed_folders}\") # 包括病灶和采样的健康图像文件夹\n",
    "    print(f\"总共创建Patch数量: {total_created_patches}\") # 病灶 Patch + 健康 Patch\n",
    "    print(f\"其中病灶 Patch 数量: {pterygium_patch_count}\")\n",
    "    print(f\"其中健康 Patch 数量: {healthy_patch_count}\")\n",
    "    if pterygium_patch_count > 0:\n",
    "        print(f\"健康 Patch / 病灶 Patch 实际比例: {healthy_patch_count / pterygium_patch_count:.2f}\")\n",
    "    print(f\"总耗时: {end_time - start_time:.2f} 秒\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    return total_processed_folders, total_created_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": 0.011481,
     "end_time": "2025-04-30T04:45:10.081944",
     "exception": false,
     "start_time": "2025-04-30T04:45:10.070463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cloudflare R2 缓存patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": 0.111679,
     "end_time": "2025-04-30T04:45:10.205363",
     "exception": false,
     "start_time": "2025-04-30T04:45:10.093684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "def create_r2_client():\n",
    "    \"\"\"尝试创建并返回一个配置好的 boto3 R2 客户端。\"\"\"\n",
    "    # 确认环境变量已加载 (这些变量应在之前的单元格中设置)\n",
    "    required_vars = ['R2_ENDPOINT_URL', 'R2_ACCESS_KEY_ID', 'R2_SECRET_ACCESS_KEY', 'R2_BUCKET_NAME']\n",
    "    if not all(var in globals() and globals()[var] for var in required_vars):\n",
    "        print(\"R2 配置不完整（缺少 Endpoint URL, Access Key, Secret Key 或 Bucket Name）。跳过 R2 缓存。\")\n",
    "        return None, False # 返回 None 和 R2 未配置标志\n",
    "\n",
    "    global r2_configured # 声明我们要修改全局变量\n",
    "    r2_configured = True # 标记 R2 已配置\n",
    "\n",
    "    try:\n",
    "        print(\"正在创建 R2 (boto3 S3) 客户端...\")\n",
    "        s3_client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=R2_ENDPOINT_URL,\n",
    "            aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "            region_name='auto', # R2 通常使用 'auto'\n",
    "            config=botocore.config.Config(signature_version='s3v4') # 明确签名版本\n",
    "        )\n",
    "        # 尝试列出 buckets (可选，作为连接测试)\n",
    "        # s3_client.list_buckets()\n",
    "        print(\"R2 客户端创建成功。\")\n",
    "        return s3_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"创建 R2 客户端时出错: {e}\")\n",
    "        r2_configured = False # 出错则标记为未配置\n",
    "        return None, False\n",
    "\n",
    "def check_r2_cache(s3_client, bucket_name, cache_key):\n",
    "    \"\"\"检查指定的缓存键是否存在于 R2 存储桶中。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False # 文件未找到\n",
    "        else:\n",
    "            # 其他错误 (如权限问题)\n",
    "            print(f\"检查 R2 缓存时出错 (Key: {cache_key}): {e}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"检查 R2 缓存时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_from_r2(s3_client, bucket_name, cache_key, local_path):\n",
    "    \"\"\"从 R2 下载文件到本地路径，带进度条。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        # 获取文件大小以显示进度\n",
    "        response = s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        total_size = int(response.get('ContentLength', 0))\n",
    "\n",
    "        print(f\"正在从 R2 下载 {cache_key} 到 {local_path} ({total_size / (1024*1024):.2f} MB)...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Filename=local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 下载完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"从 R2 下载文件时出错 (Key: {cache_key}): {e}\")\n",
    "        # 如果文件下载失败，尝试删除本地可能不完整的文件\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"下载 R2 文件时发生未知错误: {e}\")\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def upload_to_r2(s3_client, bucket_name, local_path, cache_key):\n",
    "    \"\"\"将本地文件上传到 R2，带进度条。\"\"\"\n",
    "    if not s3_client or not os.path.exists(local_path):\n",
    "        print(f\"上传 R2 失败：客户端未初始化或本地文件不存在 ({local_path})。\")\n",
    "        return False\n",
    "    try:\n",
    "        total_size = os.path.getsize(local_path)\n",
    "        print(f\"正在上传 {local_path} ({total_size / (1024*1024):.2f} MB) 到 R2 作为 {cache_key}...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 上传完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"上传文件到 R2 时出错 (Key: {cache_key}): {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"上传 R2 文件时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"压缩指定文件夹的内容到 zip 文件。\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"错误：要压缩的文件夹不存在 {folder_path}\")\n",
    "        return False\n",
    "    print(f\"正在压缩目录 {folder_path} 到 {zip_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # 获取文件夹内的所有文件和子文件夹\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for filename in files:\n",
    "                    file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "            # 使用 tqdm 显示压缩进度 (按文件数)\n",
    "            with tqdm(total=len(file_paths), desc=\"压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                for file in file_paths:\n",
    "                    # 计算文件在 zip 中的相对路径\n",
    "                    arcname = os.path.relpath(file, folder_path)\n",
    "                    zipf.write(file, arcname)\n",
    "                    pbar.update(1)\n",
    "        print(\"目录压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"压缩目录时出错: {e}\")\n",
    "        # 如果压缩失败，删除可能不完整的 zip 文件\n",
    "        if os.path.exists(zip_path):\n",
    "            try: os.remove(zip_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def unzip_directory(zip_path, extract_to_folder):\n",
    "    \"\"\"解压缩 zip 文件到指定文件夹。\"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"错误：要解压的 zip 文件不存在 {zip_path}\")\n",
    "        return False\n",
    "    print(f\"正在解压缩文件 {zip_path} 到 {extract_to_folder}...\")\n",
    "    try:\n",
    "        os.makedirs(extract_to_folder, exist_ok=True) # 确保目标文件夹存在\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # 获取 zip 文件中的成员数量以显示进度\n",
    "            total_files = len(zip_ref.namelist())\n",
    "            with tqdm(total=total_files, desc=\"解压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                # 使用 extractall 并更新进度条可能不直接，改为逐个提取\n",
    "                for member in zip_ref.infolist():\n",
    "                    zip_ref.extract(member, extract_to_folder)\n",
    "                    pbar.update(1)\n",
    "                    # 或者直接用 extractall，进度条可能不准确但更快\n",
    "                    # zip_ref.extractall(extract_to_folder)\n",
    "        print(\"文件解压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"解压缩文件时出错: {e}\")\n",
    "        # 如果解压失败，可以选择是否删除不完整的解压目录\n",
    "        # if os.path.exists(extract_to_folder):\n",
    "        #     shutil.rmtree(extract_to_folder)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": 0.019658,
     "end_time": "2025-04-30T04:45:10.236864",
     "exception": false,
     "start_time": "2025-04-30T04:45:10.217206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/pterygium/train/\"):\n",
    "    INPUT_IMAGE_DIR = \"/kaggle/input/pterygium/train/train\"\n",
    "    OUTPUT_PATCH_DIR = \"/kaggle/working/train_patches\"\n",
    "elif 'google.colab' in sys.modules:\n",
    "    INPUT_IMAGE_DIR = \"/content/trains/train\"\n",
    "    OUTPUT_PATCH_DIR = \"/content/train_patches\"\n",
    "elif os.name == 'nt':\n",
    "    INPUT_IMAGE_DIR = \"f:/train\"\n",
    "    OUTPUT_PATCH_DIR = \"f:/train_patches\"\n",
    "else:\n",
    "    INPUT_IMAGE_DIR = \"data/train/train\"\n",
    "    OUTPUT_PATCH_DIR = \"data/train_patches\"\n",
    "\n",
    "OUTPUT_IMAGE_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"images\")\n",
    "OUTPUT_MASK_PATCH_DIR = os.path.join(OUTPUT_PATCH_DIR, \"masks\")\n",
    "LOCAL_TEMP_ZIP_PATH = os.path.join(os.path.dirname(OUTPUT_PATCH_DIR), \"patch_cache_temp.zip\") # 临时zip文件路径\n",
    "\n",
    "print(f\"使用设备: {device}\") # 确保 device 已定义\n",
    "print(f\"输入图像目录: {INPUT_IMAGE_DIR}\")\n",
    "print(f\"输出 Patch 目录: {OUTPUT_PATCH_DIR}\")\n",
    "print(f\"Patch 大小: {patch_size}x{patch_size}\")\n",
    "print(f\"步长: {patch_stride}\")\n",
    "print(f\"最小前景比例阈值: {MIN_FOREGROUND_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": 0.012112,
     "end_time": "2025-04-30T04:45:10.260799",
     "exception": false,
     "start_time": "2025-04-30T04:45:10.248687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 执行离线Patching\n",
    "调用函数开始处理\n",
    "如果输出目录已存在且包含文件，你可能想先清空或跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": 28.418822,
     "end_time": "2025-04-30T04:45:38.743811",
     "exception": false,
     "start_time": "2025-04-30T04:45:10.324989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 生成缓存键 ---\n",
    "try:\n",
    "    cache_key = f\"v1-{os.path.basename(INPUT_IMAGE_DIR)}-{os.path.basename(label_file)}-{patch_size}-{patch_stride}-{MIN_FOREGROUND_RATIO}-{HEALTHY_PTERYGIUM_PATCH_RATIO}\"\n",
    "    if DEBUG_MODE: cache_key = f\"{cache_key}-DEBUG\"\n",
    "    R2_CACHE_KEY = f\"patch_cache_{cache_key}.zip\"\n",
    "    print(f\"生成的 R2 缓存键: {R2_CACHE_KEY}\")\n",
    "except Exception as e:\n",
    "    print(f\"生成缓存键时出错: {e}。无法使用 R2 缓存。\")\n",
    "\n",
    "# --- R2 缓存检查与处理 ---\n",
    "r2_client, r2_configured = create_r2_client()\n",
    "run_patching = True\n",
    "patch_count = 0\n",
    "\n",
    "# 调试\n",
    "#if os.path.exists(OUTPUT_PATCH_DIR):\n",
    "#    run_patching = False\n",
    "#    r2_configured = False # 强制跳过 R2 检查\n",
    "#    print(f\"输出目录 {OUTPUT_PATCH_DIR} 已存在，跳过本地 Patching。\")\n",
    "\n",
    "if r2_client and r2_configured:\n",
    "    print(\"\\n--- 正在检查 R2 缓存 ---\")\n",
    "    if check_r2_cache(r2_client, R2_BUCKET_NAME, R2_CACHE_KEY):\n",
    "        print(f\"在 R2 上找到缓存文件: {R2_CACHE_KEY}\")\n",
    "        # 检查本地目录是否需要更新\n",
    "        should_download = True\n",
    "        if os.path.exists(OUTPUT_PATCH_DIR):\n",
    "            print(f\"本地目录 {OUTPUT_PATCH_DIR} 已存在。将删除旧目录以下载最新缓存。\")\n",
    "            try:\n",
    "                shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "            except Exception as e:\n",
    "                print(f\"删除本地旧目录 {OUTPUT_PATCH_DIR} 时出错: {e}。继续尝试下载...\")\n",
    "        else:\n",
    "            print(f\"本地目录 {OUTPUT_PATCH_DIR} 不存在。准备下载缓存。\")\n",
    "\n",
    "\n",
    "        if should_download:\n",
    "            if download_from_r2(r2_client, R2_BUCKET_NAME, R2_CACHE_KEY, LOCAL_TEMP_ZIP_PATH):\n",
    "                if unzip_directory(LOCAL_TEMP_ZIP_PATH, OUTPUT_PATCH_DIR):\n",
    "                    print(\"成功从 R2 下载并解压缓存。\")\n",
    "                    run_patching = False # 不需要本地 patching\n",
    "                    # 清理下载的 zip 文件\n",
    "                    try:\n",
    "                        os.remove(LOCAL_TEMP_ZIP_PATH)\n",
    "                        print(f\"已删除临时文件: {LOCAL_TEMP_ZIP_PATH}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"删除临时文件 {LOCAL_TEMP_ZIP_PATH} 时出错: {e}\")\n",
    "                    # 统计下载的 patches 数量\n",
    "                    try:\n",
    "                        existing_patches = glob.glob(os.path.join(OUTPUT_IMAGE_PATCH_DIR, \"*.png\"))\n",
    "                        patch_count = len(existing_patches)\n",
    "                        print(f\"使用 R2 缓存中的 {patch_count} 个 patches。\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"无法统计下载的 patches 数量: {e}\")\n",
    "                        patch_count = 0\n",
    "                else:\n",
    "                    print(\"解压 R2 缓存失败。将尝试本地 Patching。\")\n",
    "                    # 清理可能不完整的解压目录\n",
    "                    if os.path.exists(OUTPUT_PATCH_DIR): shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "            else:\n",
    "                print(\"从 R2 下载缓存失败。将尝试本地 Patching。\")\n",
    "    else:\n",
    "        print(f\"在 R2 上未找到对应的缓存文件 ({R2_CACHE_KEY})。\")\n",
    "else:\n",
    "    print(\"\\nR2 客户端未配置或创建失败，将跳过 R2 缓存检查。\")\n",
    "\n",
    "# --- 本地 Patching (如果需要) ---\n",
    "if run_patching:\n",
    "    print(\"\\n--- 执行本地 Patching ---\")\n",
    "    shutil.rmtree(OUTPUT_PATCH_DIR, ignore_errors=True) # 清理旧目录\n",
    "    os.makedirs(OUTPUT_PATCH_DIR, exist_ok=True)\n",
    "\n",
    "    # 调用你的 patching 函数\n",
    "    processed_count, patch_count = create_offline_patches_gpu_mixed(\n",
    "        input_image_dir=INPUT_IMAGE_DIR,\n",
    "        label_file_path=label_file,\n",
    "        output_image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "        output_mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "        patch_size=patch_size,\n",
    "        stride=patch_stride,\n",
    "        device=device, # 确保 device 已定义\n",
    "        min_foreground_ratio=MIN_FOREGROUND_RATIO,\n",
    "        healthy_pterygium_patch_ratio=HEALTHY_PTERYGIUM_PATCH_RATIO,\n",
    "        debug_mode=DEBUG_MODE\n",
    "    )\n",
    "\n",
    "    # --- 上传到 R2 (如果 Patching 成功且 R2 已配置) ---\n",
    "    if patch_count > 0 and r2_client and r2_configured:\n",
    "        print(\"\\n--- 准备上传 Patching 结果到 R2 ---\")\n",
    "        if zip_directory(OUTPUT_PATCH_DIR, LOCAL_TEMP_ZIP_PATH):\n",
    "            if upload_to_r2(r2_client, R2_BUCKET_NAME, LOCAL_TEMP_ZIP_PATH, R2_CACHE_KEY):\n",
    "                print(f\"成功上传缓存 {R2_CACHE_KEY} 到 R2。\")\n",
    "            else:\n",
    "                print(f\"上传缓存 {R2_CACHE_KEY} 到 R2 失败。\")\n",
    "            # 清理本地 zip 文件\n",
    "            try:\n",
    "                os.remove(LOCAL_TEMP_ZIP_PATH)\n",
    "                print(f\"已删除本地临时 zip 文件: {LOCAL_TEMP_ZIP_PATH}\")\n",
    "            except Exception as e:\n",
    "                print(f\"删除本地临时 zip 文件 {LOCAL_TEMP_ZIP_PATH} 时出错: {e}\")\n",
    "        else:\n",
    "            print(\"压缩 Patching 结果失败，无法上传到 R2。\")\n",
    "    elif patch_count == 0:\n",
    "        print(\"本地 Patching 未生成任何文件，跳过上传。\")\n",
    "    else: # R2 未配置\n",
    "        print(\"R2 未配置，跳过上传缓存步骤。\")\n",
    "\n",
    "elif not run_patching:\n",
    "    print(\"\\nPatching 步骤已跳过（使用 R2 缓存）。\")\n",
    "else:\n",
    "    raise Exception(\"出现未知状态，未执行 Patching 也未使用缓存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.012408,
     "end_time": "2025-04-30T04:45:38.768825",
     "exception": false,
     "start_time": "2025-04-30T04:45:38.756417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": 0.0295,
     "end_time": "2025-04-30T04:45:38.810846",
     "exception": false,
     "start_time": "2025-04-30T04:45:38.781346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练时的增强\n",
    "train_transform = A.Compose([\n",
    "    # --- 空间变换 ---\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Affine(\n",
    "        scale=(0.9, 1.1),              # 缩放范围\n",
    "        translate_percent=(-0.0625, 0.0625), # 平移范围 (两轴相同比例)\n",
    "                                        # 或使用 dict: translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)}\n",
    "        rotate=(-15, 15),              # 旋转范围\n",
    "        interpolation=cv2.INTER_LINEAR, # 图像插值\n",
    "        mask_interpolation=cv2.INTER_NEAREST, # !!! 关键：必须为掩码设置最近邻插值 !!!\n",
    "        border_mode=cv2.BORDER_CONSTANT, # 边界模式 (使用正确的参数名)\n",
    "        fill=0,                        # 图像填充值\n",
    "        fill_mask=0,                   # 掩码填充值\n",
    "        keep_ratio=True,               # 保持长宽比\n",
    "        p=0.7                          # 应用概率\n",
    "    ),\n",
    "    # 弹性变形\n",
    "    A.ElasticTransform(\n",
    "        alpha=1,\n",
    "        sigma=50,\n",
    "        interpolation=cv2.INTER_LINEAR,   # 图像插值\n",
    "        mask_interpolation=cv2.INTER_NEAREST, # !!! 关键：掩码必须用最近邻插值 !!!\n",
    "        approximate=False,              # 使用精确计算 (默认)\n",
    "        p=0.5                           # 应用概率\n",
    "    ),\n",
    "\n",
    "    # --- 强度/颜色变换 (只作用于图像) ---\n",
    "    # OneOf: 从列表中随机选一个应用\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(std_range=(0.01, 0.05), mean_range=(0.0, 0.0), p=1.0),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "    ], p=0.3), # 应用其中一种噪声/模糊的概率\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.4), # gamma 在 0.8 到 1.2 之间\n",
    "\n",
    "    # --- 遮挡 ---\n",
    "    A.CoarseDropout(\n",
    "        num_holes_range=(1, 8),\n",
    "        hole_height_range=(8, 32),\n",
    "        hole_width_range=(8, 32),\n",
    "        fill=0,\n",
    "        fill_mask=0,\n",
    "        p=0.3\n",
    "    ),\n",
    "\n",
    "    # --- 标准化 & 转 Tensor ---\n",
    "    # 注意：Normalize 必须在 ToTensorV2 之前或之后都可以，但通常放在最后\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2() # 将 NumPy [H,W,C] 转为 PyTorch [C,H,W]\n",
    "])\n",
    "\n",
    "# 验证/测试时的变换 (通常只有 Resize, Normalize, ToTensor)\n",
    "# 模型输入是 Patch，这里不需要 Resize\n",
    "val_transform_alb = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "9d732b67",
    "language": "markdown",
    "papermill": {
     "duration": 0.012114,
     "end_time": "2025-04-30T04:45:38.835839",
     "exception": false,
     "start_time": "2025-04-30T04:45:38.823725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 创建数据加载器\n",
    "设置训练和验证数据加载器，包括数据增强策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "2ba9d65a",
    "language": "python",
    "papermill": {
     "duration": 0.025657,
     "end_time": "2025-04-30T04:45:38.873842",
     "exception": false,
     "start_time": "2025-04-30T04:45:38.848185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PterygiumSegDataset(Dataset):\n",
    "    def __init__(self, image_patch_dir, mask_patch_dir, file_list=None, transform=None):\n",
    "            \"\"\"\n",
    "            初始化数据集 (加载离线 Patches)\n",
    "            :param image_patch_dir: 包含图像 patch 文件的目录\n",
    "            :param mask_patch_dir: 包含对应掩码 patch 文件的目录\n",
    "            :param file_list: (可选) 一个文件名列表，只加载这些文件。如果为 None，加载目录下所有文件。\n",
    "            :param transform: (可选) 预处理和数据增强的转换函数\n",
    "            \"\"\"\n",
    "            self.image_patch_dir = image_patch_dir\n",
    "            self.mask_patch_dir = mask_patch_dir\n",
    "            self.transform = transform\n",
    "    \n",
    "            # 获取 patch 的文件名列表\n",
    "            if file_list is None:\n",
    "                self.image_filenames = sorted([\n",
    "                    f for f in os.listdir(image_patch_dir)\n",
    "                    if os.path.isfile(os.path.join(image_patch_dir, f)) and f.endswith('.png')\n",
    "                ])\n",
    "            else:\n",
    "                self.image_filenames = sorted([f for f in file_list if f.endswith('.png')]) # 使用提供的列表\n",
    "\n",
    "            if not self.image_filenames:\n",
    "                # 检查是否是因为目录不存在或为空\n",
    "                if not os.path.isdir(image_patch_dir):\n",
    "                    raise FileNotFoundError(f\"图像 patch 目录不存在: {image_patch_dir}\")\n",
    "                elif not os.listdir(image_patch_dir) and file_list is None:\n",
    "                    print(f\"警告: 目录 {image_patch_dir} 为空。\")\n",
    "                    # Dataset 将为空，len() == 0\n",
    "                elif file_list is not None and not self.image_filenames:\n",
    "                    print(f\"警告: 提供的 file_list 为空或不包含 .png 文件。\")\n",
    "                else:\n",
    "                    # 目录存在但 filtered list 为空\n",
    "                    print(f\"警告: 在目录 {image_patch_dir} 中未找到匹配的 .png 文件 (可能检查 file_list)。\")\n",
    "    \n",
    "            # 定义图像标准化 (这个总是在最后应用)\n",
    "            self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            print(f\"数据集初始化: 找到 {len(self.image_filenames)} 个 patches in {image_patch_dir}\" + (f\" (来自 file_list)\" if file_list is not None else \"\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本的数量 (即 patch 的数量)\"\"\"\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像 patch 和 掩码 patch\n",
    "        :param idx: 索引\n",
    "        :return: 图像 patch 张量和对应掩码 patch 张量\n",
    "        \"\"\"\n",
    "        # 获取文件名\n",
    "        patch_filename = self.image_filenames[idx]\n",
    "        \n",
    "        # 构建完整路径\n",
    "        img_path = os.path.join(self.image_patch_dir, patch_filename)\n",
    "        mask_path = os.path.join(self.mask_patch_dir, patch_filename)\n",
    "\n",
    "        # 加载图像和掩码 patch (PIL Images)\n",
    "        try:\n",
    "            image_patch = Image.open(img_path).convert(\"RGB\")\n",
    "            mask_patch = Image.open(mask_path).convert(\"RGB\") # 掩码是 (128,0,0)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 文件未找到 {img_path} 或 {mask_path}\")\n",
    "            # 返回一个虚拟数据或引发错误\n",
    "            dummy_size = (3, 256, 256) # 假设 patch size 是 256x256，如果不同需要修改\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "        except Exception as e:\n",
    "            print(f\"加载 patch 时出错 {patch_filename}: {e}\")\n",
    "            # 返回虚拟数据\n",
    "            dummy_size = (3, 256, 256)\n",
    "            if hasattr(self, 'patch_size'): dummy_size = (3, self.patch_size, self.patch_size)\n",
    "            return torch.zeros(dummy_size), torch.zeros((1, dummy_size[1], dummy_size[2]))\n",
    "\n",
    "        # --- 掩码处理：转换为单通道二值Tensor ---\n",
    "        # 将 PIL Mask 转换为 NumPy array (H, W, C)\n",
    "        mask_np = np.array(mask_patch)\n",
    "        # 将 Image PIL 转换为 NumPy array (H, W, C) 以便传递给 albumentations\n",
    "        image_patch_np = np.array(image_patch)\n",
    "        # 检查红色通道是否为 128 来确定翼状胬肉区域\n",
    "        mask_binary_np = (mask_np[:, :, 0] == 128).astype(np.uint8)\n",
    "        \n",
    "        # 应用 albumentations 变换\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_patch_np, mask=mask_binary_np)\n",
    "            image_tensor = augmented['image'] # 已经是 Tensor [C,H,W]\n",
    "            mask_tensor = augmented['mask'].unsqueeze(0).float() # 已经是 Tensor [H,W]，增加通道维度 -> [1,H,W]\n",
    "        else:\n",
    "            # 如果没有 transform，手动进行标准化和 Tensor 转换\n",
    "            # --- 图像处理 ---\n",
    "            image_tensor = F.to_tensor(image_patch) # (C, H, W)\n",
    "            image_tensor = self.normalize(image_tensor) # 应用标准化\n",
    "            # --- 掩码处理 ---\n",
    "            # 将 NumPy 二进制掩码转换为 PyTorch Tensor，并增加通道维度\n",
    "            mask_tensor = torch.from_numpy(mask_binary_np).unsqueeze(0).float() # [1, H, W], float32\n",
    "\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "papermill": {
     "duration": 13.490115,
     "end_time": "2025-04-30T04:45:52.376525",
     "exception": false,
     "start_time": "2025-04-30T04:45:38.886410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 确保 Patch 目录存在且包含文件\n",
    "if not os.path.exists(OUTPUT_IMAGE_PATCH_DIR) or not os.listdir(OUTPUT_IMAGE_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的图像 Patches 于 {OUTPUT_IMAGE_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "if not os.path.exists(OUTPUT_MASK_PATCH_DIR) or not os.listdir(OUTPUT_MASK_PATCH_DIR):\n",
    "    raise FileNotFoundError(f\"错误：无法找到生成的掩码 Patches 于 {OUTPUT_MASK_PATCH_DIR}。请先成功执行 Patching 步骤。\")\n",
    "\n",
    "# 1. 获取所有 Patch 文件名\n",
    "all_patch_files = sorted([\n",
    "    f for f in os.listdir(OUTPUT_IMAGE_PATCH_DIR)\n",
    "    if os.path.isfile(os.path.join(OUTPUT_IMAGE_PATCH_DIR, f)) and f.endswith('.png')\n",
    "])\n",
    "\n",
    "if not all_patch_files:\n",
    "    raise ValueError(f\"错误：在 {OUTPUT_IMAGE_PATCH_DIR} 中未找到任何 Patch 文件。\")\n",
    "\n",
    "# 2. 按原始图像 ID 分组 Patch 文件名\n",
    "#    假设文件名格式为 \"XXXX_yYYY_xZZZ.png\"，其中 XXXX 是原始图像 ID\n",
    "patches_by_original_image = collections.defaultdict(list)\n",
    "for filename in all_patch_files:\n",
    "    try:\n",
    "        # 提取前4位作为原始图像 ID\n",
    "        original_image_id = filename[:4]\n",
    "        # 检查是否是有效的数字ID (可选，增加健壮性)\n",
    "        if original_image_id.isdigit():\n",
    "            patches_by_original_image[original_image_id].append(filename)\n",
    "        else:\n",
    "            print(f\"警告：无法从文件名 {filename} 中提取有效的原始图像 ID，跳过此文件。\")\n",
    "    except IndexError:\n",
    "        print(f\"警告：文件名 {filename} 格式不符合预期，无法提取原始图像 ID，跳过此文件。\")\n",
    "\n",
    "if not patches_by_original_image:\n",
    "    raise ValueError(\"错误：无法根据文件名对任何 Patch 进行分组。请检查文件名格式。\")\n",
    "\n",
    "# 3. 获取所有唯一的原始图像 ID\n",
    "unique_original_ids = sorted(list(patches_by_original_image.keys()))\n",
    "print(f\"从 {len(all_patch_files)} 个 Patches 中识别出 {len(unique_original_ids)} 个唯一的原始图像来源。\")\n",
    "\n",
    "# 4. 在唯一的原始图像 ID 层面进行训练/验证划分\n",
    "#    这样可以保证同一原始图像的所有 Patches 都在同一个集合中\n",
    "val_split_ratio = 0.2 # 验证集占原始图像 ID 的比例\n",
    "try:\n",
    "    train_ids, val_ids = train_test_split(\n",
    "        unique_original_ids,\n",
    "        test_size=val_split_ratio,\n",
    "        random_state=42 # 保证划分可复现\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"错误：无法进行 train_test_split。可能是唯一 ID 数量过少。错误信息: {e}\")\n",
    "    # 可以根据情况处理，例如使用所有数据进行训练，或者调整比例\n",
    "    if len(unique_original_ids) < 2:\n",
    "        print(\"唯一原始图像 ID 少于 2 个，无法划分验证集。将使用所有数据进行训练。\")\n",
    "        train_ids = unique_original_ids\n",
    "        val_ids = []\n",
    "    else:\n",
    "        # 其他错误，重新抛出\n",
    "        raise e\n",
    "\n",
    "print(f\"划分结果：{len(train_ids)} 个原始图像用于训练，{len(val_ids)} 个原始图像用于验证。\")\n",
    "\n",
    "# 5. 根据划分的 ID 列表，构建训练和验证的 Patch 文件名列表\n",
    "train_filenames = []\n",
    "for img_id in train_ids:\n",
    "    train_filenames.extend(patches_by_original_image[img_id])\n",
    "\n",
    "val_filenames = []\n",
    "for img_id in val_ids:\n",
    "    val_filenames.extend(patches_by_original_image[img_id])\n",
    "\n",
    "print(f\"划分后的 Patch 数量：训练集 {len(train_filenames)} Patches，验证集 {len(val_filenames)} Patches。\")\n",
    "# 注意：这里的 Patch 数量比例不一定会严格等于原始图像 ID 的比例 (val_split_ratio)，\n",
    "# 因为不同原始图像产生的 Patch 数量可能不同。\n",
    "\n",
    "# --- 计算训练集 Patch 的权重用于 WeightedRandomSampler ---\n",
    "print(\"\\n正在计算训练集 Patches 的前景/背景分布并生成采样权重...\")\n",
    "foreground_patch_indices = [] # 存储包含前景像素的 Patch 索引\n",
    "background_patch_indices = [] # 存储纯背景 Patch 索引 (不包含前景像素)\n",
    "\n",
    "# 遍历训练集的文件名，检查对应的 Mask 文件\n",
    "for i, filename in enumerate(tqdm(train_filenames, desc=\"检查 Patch 前景\")):\n",
    "    mask_path = os.path.join(OUTPUT_MASK_PATCH_DIR, filename)\n",
    "    try:\n",
    "        mask_pil = Image.open(mask_path).convert(\"RGB\")\n",
    "        mask_np_rgb = np.array(mask_pil)\n",
    "        # 检查红色通道是否有值 128\n",
    "        if np.any(mask_np_rgb[:, :, 0] == 128):\n",
    "            foreground_patch_indices.append(i)\n",
    "        else:\n",
    "            background_patch_indices.append(i)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"警告: 计算权重时未找到 Mask 文件 {mask_path}，跳过此 Patch。\")\n",
    "        # 可以选择将这个 Patch 视为背景或完全忽略\n",
    "        background_patch_indices.append(i) # 暂时将未找到 Mask 的视为背景\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 计算权重时处理 Mask 文件 {mask_path} 时出错: {e}，跳过此 Patch。\")\n",
    "        background_patch_indices.append(i) # 暂时将处理出错的视为背景\n",
    "\n",
    "num_fg_patches = len(foreground_patch_indices)\n",
    "num_bg_patches = len(background_patch_indices)\n",
    "total_patches = num_fg_patches + num_bg_patches\n",
    "\n",
    "print(f\"训练集中包含前景的 Patches 数量: {num_fg_patches}\")\n",
    "print(f\"训练集中纯背景的 Patches 数量: {num_bg_patches}\")\n",
    "print(f\"训练集 Patch 总数 (用于采样器): {total_patches}\")\n",
    "\n",
    "if total_patches == 0:\n",
    "    raise ValueError(\"错误：训练集 Patch 总数为零，无法创建 DataLoader。\")\n",
    "\n",
    "# 计算权重\n",
    "# 目标是让前景 Patch 的采样概率高于背景 Patch\n",
    "# 一个简单的策略是让前景 Patch 的权重与背景 Patch 的总数成正比，\n",
    "# 背景 Patch 的权重与前景 Patch 的总数成正比。\n",
    "# 或者，更直接地，让纯背景 Patch 的权重等于 前景 Patch 数量 / 背景 Patch 数量，前景 Patch 的权重为 1。\n",
    "# 这样，总的前景权重 ~= 总的背景权重。\n",
    "weight_for_bg = num_fg_patches / (num_bg_patches + 1e-6) if num_bg_patches > 0 else 1.0 # 避免除以零\n",
    "weight_for_fg = 1.0 # 将前景权重设为基准 1\n",
    "\n",
    "# 创建权重列表，对应 train_filenames 的顺序\n",
    "patch_weights = torch.zeros(total_patches)\n",
    "patch_weights[foreground_patch_indices] = weight_for_fg\n",
    "patch_weights[background_patch_indices] = weight_for_bg\n",
    "\n",
    "print(f\"纯背景 Patch 权重: {weight_for_bg:.4f}\")\n",
    "print(f\"包含前景 Patch 权重: {weight_for_fg:.4f}\")\n",
    "\n",
    "\n",
    "# 6. 创建独立的训练和验证 Dataset 实例\n",
    "train_dataset_offline = PterygiumSegDataset(\n",
    "    image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "    mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "    file_list=train_filenames, # 传入分组后的训练文件名列表\n",
    "    transform=train_transform\n",
    ")\n",
    "# 只有在 val_filenames 不为空时才创建验证集\n",
    "if val_filenames:\n",
    "    val_dataset_offline = PterygiumSegDataset(\n",
    "        image_patch_dir=OUTPUT_IMAGE_PATCH_DIR,\n",
    "        mask_patch_dir=OUTPUT_MASK_PATCH_DIR,\n",
    "        file_list=val_filenames, # 传入分组后的验证文件名列表\n",
    "        transform=val_transform_alb\n",
    "    )\n",
    "else:\n",
    "    val_dataset_offline = None # 如果没有验证 ID，则验证集为空\n",
    "    print(\"警告：验证集为空。\")\n",
    "\n",
    "# 7. 创建 DataLoader\n",
    "train_loader_batch_size = tpu_batch_size if _xla_available else (cuda_batch_size if torch.cuda.is_available() else windows_batch_size)\n",
    "val_loader_batch_size = train_loader_batch_size\n",
    "\n",
    "# --- 创建 WeightedRandomSampler ---\n",
    "if total_patches > 0:\n",
    "    # replacement=True 允许重复采样，通常用于训练，防止一个 Epoch 只看到一次样本\n",
    "    # num_samples=len(patch_weights) 表示每个 Epoch 采样总共 len(patch_weights) 次\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(patch_weights, num_samples=len(patch_weights), replacement=True)\n",
    "    print(f\"创建 WeightedRandomSampler，每个 Epoch 采样 {len(patch_weights)} 个 Patches。\")\n",
    "else:\n",
    "    sampler = None # 没有 Patches，无法创建 Sampler\n",
    "    print(\"警告：没有训练 Patch，无法创建 WeightedRandomSampler。\")\n",
    "\n",
    "\n",
    "# 创建 DataLoader (使用 Sampler 并禁用 shuffle)\n",
    "if sampler:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset_offline,\n",
    "        batch_size=train_loader_batch_size,\n",
    "        sampler=sampler, # 使用加权采样器\n",
    "        shuffle=False, # 使用 sampler 时必须设置 shuffle=False\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=not _xla_available and torch.cuda.is_available(),\n",
    "        drop_last=True if _xla_available else False # 对于不规则采样，drop_last=True 确保批次大小一致\n",
    "    )\n",
    "    print(f\"\\n训练集大小 (Patches): {len(train_dataset_offline)}\")\n",
    "    print(f\"训练 DataLoader 批次数: {len(train_loader)}\")\n",
    "else:\n",
    "    train_loader = None # 没有 Patches，无法创建 DataLoader\n",
    "    print(\"\\n训练 DataLoader 为 None (因为没有训练 Patch)。\")\n",
    "\n",
    "\n",
    "# 只有在验证集存在时才创建 val_loader\n",
    "if val_dataset_offline:\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_offline,\n",
    "        batch_size=val_loader_batch_size,\n",
    "        shuffle=False, # 验证时不需要打乱\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=not _xla_available and torch.cuda.is_available(),\n",
    "        drop_last=True if _xla_available else False\n",
    "    )\n",
    "    if train_loader: # 如果 train_loader 也存在，一起打印\n",
    "        print(f\"验证集大小 (Patches): {len(val_dataset_offline)}\")\n",
    "        print(f\"验证 DataLoader 批次数: {len(val_loader)}\")\n",
    "    else: # 如果只有 val_loader 存在 (不应该发生，因为 train_filenames 应该有数据)\n",
    "        print(f\"验证集大小 (Patches): {len(val_dataset_offline)}\")\n",
    "        print(f\"验证 DataLoader 批次数: {len(val_loader)}\")\n",
    "else:\n",
    "    val_loader = None\n",
    "    print(\"验证集为空，无法创建验证 DataLoader。\")\n",
    "    # 可能需要调整后续的训练/验证循环逻辑，跳过验证步骤\n",
    "\n",
    "# 清理不再需要的大列表\n",
    "del all_patch_files, patches_by_original_image, unique_original_ids\n",
    "del train_filenames, val_filenames #, train_filenames, val_filenames # 如果后续不再需要这些列表\n",
    "del foreground_patch_indices, background_patch_indices, patch_weights\n",
    "print(\"数据加载器和采样器创建完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": 0.012174,
     "end_time": "2025-04-30T04:45:52.401678",
     "exception": false,
     "start_time": "2025-04-30T04:45:52.389504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 测试数据加载器\n",
    "取一个批次的数据出来看看形状和内容是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": 8.719775,
     "end_time": "2025-04-30T04:46:01.133667",
     "exception": false,
     "start_time": "2025-04-30T04:45:52.413892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    images_batch, masks_batch = next(iter(train_loader))\n",
    "    print(\"\\n从训练加载器获取一个批次的数据:\")\n",
    "    print(f\"图像批次形状: {images_batch.shape}\") # 应该类似 [BATCH_SIZE, 3, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"掩码批次形状: {masks_batch.shape}\")   # 应该类似 [BATCH_SIZE, 1, PATCH_SIZE, PATCH_SIZE]\n",
    "    print(f\"图像数据类型: {images_batch.dtype}\")\n",
    "    print(f\"掩码数据类型: {masks_batch.dtype}\")\n",
    "    print(f\"掩码最小值: {masks_batch.min()}\") # 应该是 0.0\n",
    "    print(f\"掩码最大值: {masks_batch.max()}\") # 应该是 1.0\n",
    "    \n",
    "    # 可视化一个样本\n",
    "    sample_idx = 0\n",
    "    img_sample = images_batch[sample_idx].permute(1, 2, 0).numpy() # CHW -> HWC\n",
    "    mask_sample = masks_batch[sample_idx].squeeze().numpy()       # 1HW -> HW\n",
    "    \n",
    "    # 反归一化以便显示\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_sample = std * img_sample + mean\n",
    "    img_sample = np.clip(img_sample, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(img_sample)\n",
    "    axes[0].set_title(\"示例图像 Patch (反归一化)\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(mask_sample, cmap='gray')\n",
    "    axes[1].set_title(\"示例掩码 Patch (0/1)\")\n",
    "    axes[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"错误：无法从 DataLoader 获取数据，请检查数据集是否为空或配置是否正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"测试 DataLoader 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": 0.023118,
     "end_time": "2025-04-30T04:46:01.173264",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.150146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建DeepLabV3分割模型\n",
    "使用 torchvision 的 DeepLabV3 实现，并可选择 ResNet34 或 ResNet50 作为骨干网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "papermill": {
     "duration": 0.026654,
     "end_time": "2025-04-30T04:46:01.215167",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.188513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deeplabv3(backbone_name='resnet50', num_classes=1, pretrained_backbone=True):\n",
    "    \"\"\"\n",
    "    创建 DeepLabV3 模型，可选择 ResNet50 或 ResNet34 骨干网络。\n",
    "\n",
    "    Args:\n",
    "        backbone_name (str): 骨干网络名称 ('resnet50' or 'resnet34').\n",
    "        num_classes (int): 输出类别的数量 (对于二元分割为 1).\n",
    "        pretrained_backbone (bool): 是否为骨干网络加载 ImageNet 预训练权重。\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: 配置好的 DeepLabV3 模型。\n",
    "    \"\"\"\n",
    "    print(f\"创建 DeepLabV3 模型，骨干网络: {backbone_name}, 类别数: {num_classes}, 预训练骨干: {pretrained_backbone}\")\n",
    "\n",
    "    weights_backbone = None\n",
    "    if pretrained_backbone:\n",
    "        if backbone_name == 'resnet50':\n",
    "            weights_backbone = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "        elif backbone_name == 'resnet34':\n",
    "            weights_backbone = models.ResNet34_Weights.IMAGENET1K_V1\n",
    "        else:\n",
    "            # 对于其他骨干网络，如果需要预训练，可以在这里添加\n",
    "            pass # 保持 weights_backbone = None\n",
    "\n",
    "    # --- 加载标准的 DeepLabV3 (默认用 ResNet50 或 ResNet101) ---\n",
    "    # 我们先加载一个标准的预训练模型，然后根据需要修改其骨干和分类头\n",
    "    # 使用 ResNet50 作为基础加载，因为它有官方的分割预训练权重\n",
    "    model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT, progress=True)\n",
    "    print(\"已加载基于 ResNet50 的预训练 DeepLabV3 (COCO weights)。\")\n",
    "\n",
    "    # --- 如果需要，用 ResNet34 替换骨干网络 ---\n",
    "    if backbone_name == 'resnet34':\n",
    "        print(\"将骨干网络替换为 ResNet34...\")\n",
    "        # 加载预训练的 ResNet34\n",
    "        resnet34_backbone = models.resnet34(weights=weights_backbone)\n",
    "        # 替换 DeepLabV3 模型中的 'backbone' 部分\n",
    "        # 注意：这需要 DeepLabV3 实现允许直接替换 backbone 模块，\n",
    "        # 或者我们需要手动匹配层结构。torchvision 的实现通常可以。\n",
    "        # 我们需要保留 ResNet34 的 stem 和 layer1 到 layer4\n",
    "        model.backbone.conv1 = resnet34_backbone.conv1\n",
    "        model.backbone.bn1 = resnet34_backbone.bn1\n",
    "        model.backbone.relu = resnet34_backbone.relu\n",
    "        model.backbone.maxpool = resnet34_backbone.maxpool\n",
    "        model.backbone.layer1 = resnet34_backbone.layer1 # 输出 64 channels (low-level features)\n",
    "        model.backbone.layer2 = resnet34_backbone.layer2\n",
    "        model.backbone.layer3 = resnet34_backbone.layer3\n",
    "        model.backbone.layer4 = resnet34_backbone.layer4 # 输出 512 channels\n",
    "        print(\"ResNet34 骨干网络替换完成。\")\n",
    "        # 重要提示：替换骨干后，模型不再完全使用原始的 COCO 分割权重，\n",
    "        # 只有骨干部分（如果 pretrained_backbone=True）具有 ImageNet 权重。\n",
    "        # ASPP 和分类头是从 ResNet50 的权重初始化的，需要微调。\n",
    "\n",
    "    # --- 修改分类头以匹配 num_classes ---\n",
    "    # DeepLabV3 有两个分类头：主分类头 (classifier) 和辅助分类头 (aux_classifier)\n",
    "    # 我们需要修改两者的最后一个卷积层\n",
    "\n",
    "    # 1. 修改主分类头 (model.classifier)\n",
    "    #    通常是 DeepLabHead -> ASPP -> Conv2d(aspp_channels, aspp_channels) -> ReLU -> Dropout -> Conv2d(aspp_channels, num_classes)\n",
    "    #    我们需要找到并替换最后一个 Conv2d\n",
    "    #    对于 ResNet50/101/34，ASPP 的输出通道数通常是 256\n",
    "    try:\n",
    "        # 获取主分类头最后一个卷积层的输入通道数\n",
    "        last_conv_in_channels = model.classifier[-1].in_channels\n",
    "        # 创建新的最后一个卷积层\n",
    "        model.classifier[-1] = nn.Conv2d(last_conv_in_channels, num_classes, kernel_size=1)\n",
    "        print(f\"主分类头已修改为输出 {num_classes} 类。\")\n",
    "    except Exception as e:\n",
    "        print(f\"自动修改主分类头失败: {e}\")\n",
    "        print(\"模型分类器结构:\", model.classifier)\n",
    "        # 如果失败，你可能需要手动检查 model.classifier 的结构并进行替换\n",
    "\n",
    "    # 2. 修改辅助分类头 (model.aux_classifier) (如果存在且需要训练)\n",
    "    #    通常是 FCNHead -> Conv2d -> ReLU -> Dropout -> Conv2d\n",
    "    #    它接收来自骨干网络中间层（如 layer3）的特征\n",
    "    if hasattr(model, 'aux_classifier') and model.aux_classifier is not None:\n",
    "        try:\n",
    "            # 获取辅助分类头最后一个卷积层的输入通道数\n",
    "            # ResNet layer3 输出通道: ResNet50/101=1024, ResNet34=256\n",
    "            # 这个值需要与 FCNHead 内部的通道数匹配\n",
    "            # 或者直接获取最后一个 Conv2d 的 in_channels\n",
    "            last_aux_conv_in_channels = model.aux_classifier[-1].in_channels\n",
    "            # 创建新的最后一个卷积层\n",
    "            model.aux_classifier[-1] = nn.Conv2d(last_aux_conv_in_channels, num_classes, kernel_size=1)\n",
    "            print(f\"辅助分类头已修改为输出 {num_classes} 类。\")\n",
    "        except Exception as e:\n",
    "            print(f\"自动修改辅助分类头失败: {e}\")\n",
    "            print(\"模型辅助分类器结构:\", model.aux_classifier)\n",
    "            # 你可以选择禁用辅助损失或手动修复\n",
    "            # model.aux_classifier = None # 禁用辅助损失\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "7700c359",
    "language": "markdown",
    "papermill": {
     "duration": 0.016038,
     "end_time": "2025-04-30T04:46:01.247795",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.231757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建U-Net分割模型\n",
    "U-Net是一种经典的图像分割模型，其结构包括下采样路径（编码器）和上采样路径（解码器），以及跳跃连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "papermill": {
     "duration": 0.015936,
     "end_time": "2025-04-30T04:46:01.280543",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.264607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 辅助层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "papermill": {
     "duration": 0.031209,
     "end_time": "2025-04-30T04:46:01.329433",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.298224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"双卷积块：(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下采样层：MaxPool + DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样层：UpConv + DoubleConv（带跳跃连接）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        # 使用双线性插值或转置卷积进行上采样\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, mid_channels=in_channels // 2)\n",
    "        else:\n",
    "            # 当使用转置卷积时，上采样会改变通道数\n",
    "            # 输入的 in_channels 是拼接后的通道数\n",
    "            # 转置卷积的输入应该是来自深层解码器的通道数，这里需要推断\n",
    "            # 假设深层解码器输出通道数 = 跳跃连接通道数 = in_channels / 2\n",
    "            deep_channels = in_channels // 2\n",
    "            skip_channels = in_channels // 2\n",
    "            self.up = nn.ConvTranspose2d(deep_channels, deep_channels, kernel_size=2, stride=2)\n",
    "            # DoubleConv 的输入通道数仍然是拼接后的 in_channels\n",
    "            self.conv = DoubleConv(in_channels, out_channels) # mid_channels 会默认为 out_channels\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # 输入可能不是整数倍的2，需要进行尺寸调整\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = Fnn.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # 连接特征图\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"输出卷积层\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "papermill": {
     "duration": 0.015258,
     "end_time": "2025-04-30T04:46:01.360609",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.345351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "papermill": {
     "duration": 0.024886,
     "end_time": "2025-04-30T04:46:01.400946",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.376060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention_block(nn.Module):\n",
    "    \"\"\"\n",
    "    注意力门 (Attention Gate - AG) 用于 UNet，旨在抑制无关区域，突出相关区域。\n",
    "    \"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        \"\"\"\n",
    "        初始化注意力门。\n",
    "        Args:\n",
    "            F_g (int): 来自下一层解码器（Gating Signal）的特征通道数。\n",
    "            F_l (int): 来自编码器跳跃连接（Input Feature）的特征通道数。\n",
    "            F_int (int): 中间层的特征通道数。\n",
    "        \"\"\"\n",
    "        super(Attention_block, self).__init__()\n",
    "\n",
    "        # 对 Gating Signal (g) 进行处理\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        # 对 Input Feature (x) 进行处理\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        # 计算注意力系数\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        前向传播。\n",
    "        Args:\n",
    "            g: Gating Signal，来自更深层解码器的输出。\n",
    "            x: Input Feature，来自编码器的跳跃连接。\n",
    "        Returns:\n",
    "            torch.Tensor: 经过注意力加权后的 Input Feature (x)。\n",
    "        \"\"\"\n",
    "        # g 通常需要上采样以匹配 x 的尺寸，但这通常在 Up 模块或调用前完成\n",
    "        # 这里假设 g 和 x 已经具有相同的空间尺寸\n",
    "\n",
    "        # 对 g 和 x 分别进行线性变换\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "\n",
    "        # 将变换后的 g 和 x 相加，并通过 ReLU\n",
    "        # 注意：这里 g1 和 x1 必须有相同的空间尺寸\n",
    "        psi = self.relu(g1 + x1)\n",
    "\n",
    "        # 计算注意力系数 alpha (通道数为 1)\n",
    "        psi = self.psi(psi) # (N, 1, H, W)\n",
    "\n",
    "        # 将注意力系数 alpha 应用到 x 上 (逐元素相乘)\n",
    "        # alpha 会自动广播到 x 的通道维度\n",
    "        return x * psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "papermill": {
     "duration": 0.017314,
     "end_time": "2025-04-30T04:46:01.434832",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.417518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "papermill": {
     "duration": 0.025564,
     "end_time": "2025-04-30T04:46:01.475781",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.450217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"完整的UNet模型\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # 加载预训练的ResNet\n",
    "        resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # 编码器部分 (使用ResNet的层)\n",
    "        self.inc = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        ) # 输出通道: 64\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.down1 = resnet.layer1 # 输出通道: 64\n",
    "        self.down2 = resnet.layer2 # 输出通道: 128\n",
    "        self.down3 = resnet.layer3 # 输出通道: 256\n",
    "        self.down4 = resnet.layer4 # 输出通道: 512\n",
    "\n",
    "        # --- 瓶颈层后 Dropout 层 ---\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        # 解码器部分 (调整通道数以匹配ResNet)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.up1 = Up(512 + 256, 512 // factor, bilinear) # down4(512) + down3(256) -> 256\n",
    "        self.up2 = Up(256 + 128, 256 // factor, bilinear) # up1(256) + down2(128) -> 128\n",
    "        self.up3 = Up(128 + 64, 128 // factor, bilinear)  # up2(128) + down1(64) -> 64\n",
    "        self.up4 = Up(64 + 64, 64, bilinear)             # up3(64) + inc(64) -> 64\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码路径 (ResNet)\n",
    "        x1 = self.inc(x)       # (N, 64, H/2, W/2) after initial conv+bn+relu (stride=2)\n",
    "        x_pool = self.maxpool(x1) # (N, 64, H/4, W/4)\n",
    "        x2 = self.down1(x_pool) # (N, 64, H/4, W/4)\n",
    "        x3 = self.down2(x2)     # (N, 128, H/8, W/8)\n",
    "        x4 = self.down3(x3)     # (N, 256, H/16, W/16)\n",
    "        x5 = self.down4(x4)     # (N, 512, H/32, W/32)\n",
    "\n",
    "        # --- Dropout 层 ---\n",
    "        x5_dropout = self.dropout(x5)\n",
    "\n",
    "        # 解码路径 (带跳跃连接)\n",
    "        x = self.up1(x5_dropout, x4) # 输入: x5(512), x4(256) -> 输出: 256\n",
    "        x = self.up2(x, x3)  # 输入: x(256), x3(128) -> 输出: 128\n",
    "        x = self.up3(x, x2)  # 输入: x(128), x2(64) -> 输出: 64\n",
    "        x = self.up4(x, x1)  # 输入: x(64), x1(64) -> 输出: 64\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "b1637cba",
    "language": "python",
    "papermill": {
     "duration": 0.028485,
     "end_time": "2025-04-30T04:46:01.521405",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.492920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNetAttention(nn.Module):\n",
    "    \"\"\"UNet模型+ResNet+Dropout+注意力\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # 加载预训练的ResNet\n",
    "        resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # 编码器部分 (使用ResNet的层)\n",
    "        self.inc = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        ) # 输出通道: 64\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.down1 = resnet.layer1 # 输出通道: 64\n",
    "        self.down2 = resnet.layer2 # 输出通道: 128\n",
    "        self.down3 = resnet.layer3 # 输出通道: 256\n",
    "        self.down4 = resnet.layer4 # 输出通道: 512\n",
    "\n",
    "        # --- 瓶颈层后 Dropout 层 ---\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        # 解码器部分 (调整通道数以匹配ResNet)\n",
    "        self.up1 = Up(in_channels=768, out_channels=256, bilinear=bilinear)\n",
    "        # up2: 输入拼接自 x3_att(128) 和 d1(256), 输出 128\n",
    "        self.up2 = Up(in_channels=384, out_channels=128, bilinear=bilinear)\n",
    "        # up3: 输入拼接自 x2_att(64) 和 d2(128), 输出 64\n",
    "        self.up3 = Up(in_channels=192, out_channels=64, bilinear=bilinear)\n",
    "        # up4: 输入拼接自 x1_att(64) 和 d3(64), 输出 64\n",
    "        self.up4 = Up(in_channels=128, out_channels=64, bilinear=bilinear)\n",
    "        \n",
    "        # --- 注意力门实例 ---\n",
    "        # F_g: 来自深层解码器的通道数, F_l: 来自编码器跳跃连接的通道数, F_int: 中间通道数 (通常设为 F_l // 2 或 F_g // 2)\n",
    "        self.att1 = Attention_block(F_g=512, F_l=256, F_int=128) # 处理 x4\n",
    "        self.att2 = Attention_block(F_g=256, F_l=128, F_int=64)  # 处理 x3\n",
    "        self.att3 = Attention_block(F_g=128, F_l=64, F_int=32)   # 处理 x2 (down1 的输出)\n",
    "        self.att4 = Attention_block(F_g=64, F_l=64, F_int=32)    # 处理 x1 (inc 的输出)\n",
    "\n",
    "        # --- 上采样层 (用于匹配 Attention Gate 输入尺寸) ---\n",
    "        # 这里我们选择在 Attention Gate 内部处理尺寸匹配，或者在上采样模块 Up 中处理\n",
    "        # 为了简化，我们在调用 Attention Gate 前确保 g 和 x 尺寸一致\n",
    "        self.up_bilinear_x2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # --- 输出卷积 ---\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码路径 (ResNet)\n",
    "        x1 = self.inc(x)       # (N, 64, H/2, W/2) after initial conv+bn+relu (stride=2)\n",
    "        x_pool = self.maxpool(x1) # (N, 64, H/4, W/4)\n",
    "        x2 = self.down1(x_pool) # (N, 64, H/4, W/4)\n",
    "        x3 = self.down2(x2)     # (N, 128, H/8, W/8)\n",
    "        x4 = self.down3(x3)     # (N, 256, H/16, W/16)\n",
    "        x5 = self.down4(x4)     # (N, 512, H/32, W/32)\n",
    "\n",
    "        # --- Dropout 层 ---\n",
    "        x5_dropout = self.dropout(x5)\n",
    "\n",
    "        # 解码路径 (带跳跃连接)\n",
    "        # --- 解码路径 ---\n",
    "        # Level 1: 处理 x4 (来自 down3)\n",
    "        g1 = self.up_bilinear_x2(x5_dropout) # 上采样 gating signal (来自瓶颈层)\n",
    "        x4_att = self.att1(g=g1, x=x4)       # 计算注意力加权的 x4\n",
    "        d1 = self.up1(g1, x4_att)            # 使用加权的 x4 进行上采样和合并\n",
    "\n",
    "        # Level 2: 处理 x3 (来自 down2)\n",
    "        g2 = self.up_bilinear_x2(d1)         # 上采样 gating signal (来自上一解码层)\n",
    "        x3_att = self.att2(g=g2, x=x3)       # 计算注意力加权的 x3\n",
    "        d2 = self.up2(g2, x3_att)            # 使用加权的 x3 进行上采样和合并\n",
    "\n",
    "        # Level 3: 处理 x2 (来自 down1)\n",
    "        g3 = self.up_bilinear_x2(d2)         # 上采样 gating signal\n",
    "        x2_att = self.att3(g=g3, x=x2)       # 计算注意力加权的 x2\n",
    "        d3 = self.up3(g3, x2_att)            # 使用加权的 x2 进行上采样和合并\n",
    "\n",
    "        # Level 4: 处理 x1 (来自 inc)\n",
    "        g4 = self.up_bilinear_x2(d3)         # 上采样 gating signal\n",
    "        x1_att = self.att4(g=g4, x=x1)       # 计算注意力加权的 x1\n",
    "        # 注意：这里的 Up 模块 (up4) 输入通道数需要匹配拼接后的通道数\n",
    "        # Up(in_channels=64+64, out_channels=64)\n",
    "        d4 = self.up4(g4, x1_att)            # 使用加权的 x1 进行上采样和合并\n",
    "\n",
    "        logits = self.outc(d4)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "papermill": {
     "duration": 0.015609,
     "end_time": "2025-04-30T04:46:01.552764",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.537155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "papermill": {
     "duration": 3.699833,
     "end_time": "2025-04-30T04:46:05.268264",
     "exception": false,
     "start_time": "2025-04-30T04:46:01.568431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_model_select == 'unet':\n",
    "    model = UNet(n_classes=1, bilinear=True, dropout_p=0.5).to(device)\n",
    "elif train_model_select == 'unet_attention':\n",
    "    model = UNetAttention(n_classes=1, bilinear=True, dropout_p=0.5).to(device)\n",
    "elif train_model_select == 'deeplabv3':\n",
    "    model = create_deeplabv3(backbone_name='resnet50', num_classes=1, pretrained_backbone=True).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"检测到 {torch.cuda.device_count()} 块GPU, 由于多卡存在问题，只使用GPU0\")\n",
    "    #model = nn.DataParallel(model)\n",
    "\n",
    "os.system('pip install torchinfo')\n",
    "from torchinfo import summary\n",
    "\n",
    "#print(\"\\n模型摘要:\")\n",
    "#summary(model, input_size=(cuda_batch_size if torch.cuda.is_available() else windows_batch_size, 3, patch_size, patch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "cefa71b2",
    "language": "markdown",
    "papermill": {
     "duration": 0.015885,
     "end_time": "2025-04-30T04:46:05.300244",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.284359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 定义损失函数和评估指标\n",
    "我们使用组合损失函数：二元交叉熵损失和Dice损失的组合，以更好地处理类别不平衡问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "papermill": {
     "duration": 0.015157,
     "end_time": "2025-04-30T04:46:05.330821",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.315664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dice损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "papermill": {
     "duration": 0.024107,
     "end_time": "2025-04-30T04:46:05.370417",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.346310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # 使用sigmoid将logits转换为概率\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        # 将维度展平\n",
    "        batch_size = targets.size(0)\n",
    "        probs = probs.view(batch_size, -1)\n",
    "        targets = targets.view(batch_size, -1)\n",
    "\n",
    "        # 计算交集\n",
    "        intersection = (probs * targets).sum(dim=1)\n",
    "\n",
    "        # 计算Dice系数\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            probs.sum(dim=1) + targets.sum(dim=1) + self.smooth)\n",
    "\n",
    "        # 返回Dice损失\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# 评估指标：Dice系数\n",
    "def dice_coefficient(y_pred, y_true, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"计算预测掩码和真实掩码之间的Dice系数\"\"\"\n",
    "    assert y_pred.shape == y_true.shape, f\"预测形状 {y_pred.shape} 与目标形状 {y_true.shape} 不匹配\"\n",
    "    # 应用阈值将概率转换为二值掩码\n",
    "    y_pred = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    \n",
    "    # 压平张量\n",
    "    y_pred = y_pred.contiguous().view(-1)\n",
    "    y_true = y_true.contiguous().view(-1)\n",
    "    \n",
    "    # 计算交集\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    \n",
    "    # 计算Dice系数\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "    \n",
    "    return dice.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "papermill": {
     "duration": 0.015283,
     "end_time": "2025-04-30T04:46:05.401296",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.386013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 边界损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "papermill": {
     "duration": 0.026349,
     "end_time": "2025-04-30T04:46:05.443506",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.417157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt as distance_transform\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    计算边界损失。\n",
    "    基于论文: \"Boundary loss for highly unbalanced segmentation\"\n",
    "    https://arxiv.org/abs/1812.07032\n",
    "    \"\"\"\n",
    "    def __init__(self, theta0=3, theta=5):\n",
    "        super().__init__()\n",
    "        self.theta0 = theta0\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, pred_probs, gt_masks):\n",
    "        \"\"\"\n",
    "        计算边界损失。\n",
    "        Args:\n",
    "            pred_probs (torch.Tensor): 模型的概率图输出 (经过 Sigmoid), shape (N, 1, H, W)\n",
    "            gt_masks (torch.Tensor): 真实的二值掩码 (0 或 1), shape (N, 1, H, W)\n",
    "        Returns:\n",
    "            torch.Tensor: 边界损失值 (标量)\n",
    "        \"\"\"\n",
    "        n, c, _, _ = pred_probs.shape # 获取 Batch size 和 Channel\n",
    "\n",
    "        # --- 1. 计算距离图 ---\n",
    "        # 需要在 CPU 上使用 numpy 计算距离变换\n",
    "        gt_masks_npy = gt_masks.cpu().numpy().astype(np.uint8) # (N, 1, H, W)\n",
    "        dist_maps = np.zeros_like(gt_masks_npy, dtype=np.float32)\n",
    "\n",
    "        for i in range(n):\n",
    "            gt_mask_single = gt_masks_npy[i, 0, :, :] # (H, W)\n",
    "            # 计算内部距离 (前景到边界) 和外部距离 (背景到边界)\n",
    "            inside_dist = distance_transform(gt_mask_single)\n",
    "            outside_dist = distance_transform(1 - gt_mask_single)\n",
    "            # 合并成一个距离图，边界处为0，内部为正，外部为负 (或相反，取决于定义)\n",
    "            # 这里我们让边界内部为正，外部为负\n",
    "            dist_map = inside_dist - outside_dist\n",
    "            dist_maps[i, 0, :, :] = dist_map\n",
    "\n",
    "        # 将距离图转换回 Tensor 并移到目标设备\n",
    "        dist_maps_tensor = torch.from_numpy(dist_maps).to(pred_probs.device)\n",
    "\n",
    "        # --- 2. 计算边界区域的加权 ---\n",
    "        # 使用边界指示函数 phi(d) = 1 if |d| <= theta else 0 (近似)\n",
    "        # 这里使用一种更平滑的方式: 基于距离的加权，惩罚远离边界的错误预测\n",
    "        # 我们使用论文中的方法：将距离图限制在一个范围内并归一化\n",
    "        # 这里简化一下，直接使用距离图进行加权 (距离边界越远，乘积越大)\n",
    "        # 或者使用类似水平集函数的思想 phi(x) = exp(-alpha * |x|)\n",
    "        # 这里采用一个简单的方式：直接用距离图与预测概率相乘\n",
    "\n",
    "        # --- 3. 计算损失 ---\n",
    "        # 惩罚预测概率与符号距离的乘积\n",
    "        # 目标：前景(gt=1, dist>0) 预测概率(pred)应接近1，损失为 (1-pred)*dist\n",
    "        #       背景(gt=0, dist<0) 预测概率(pred)应接近0，损失为 pred*(-dist)\n",
    "        # 合并为: loss = pred * (-dist) if gt=0 else (1-pred)*dist\n",
    "        # 可以简化为: loss = |pred - gt| * |dist|  (近似, 需要验证)\n",
    "        # 或者直接使用论文中的积分形式： integral[ phi(gt_dist) * pred_prob ] dx\n",
    "        # 这里我们使用论文中的简化形式： L_B = mean( phi_g * pred_prob )\n",
    "        # 其中 phi_g 是和 gt boundary 相关的 level set function\n",
    "\n",
    "        # 简化实现: 计算预测概率与距离图的乘积的平均值\n",
    "        # 我们希望在边界附近 (dist 接近 0) 的乘积小，在远离边界的错误区域乘积大\n",
    "        # 使用绝对距离可能更直观\n",
    "        abs_dist_maps = torch.abs(dist_maps_tensor)\n",
    "        # loss_b = (pred_probs * abs_dist_maps).mean() # 简单版本\n",
    "\n",
    "        # 尝试更接近原文的实现：\n",
    "        # 计算 level set function phi_g (这里用 gt_masks 近似边界区域)\n",
    "        # 惩罚边界区域 (gt_masks=1 附近) 的低概率 和 非边界区域 (gt_masks=0 附近) 的高概率\n",
    "        # 这里直接使用论文提供的另一种形式：L_B = mean(gt * log(pred) + (1-gt) * log(1-pred)) * weight_map\n",
    "        # weight_map 基于距离变换\n",
    "\n",
    "        # 采用更直接的距离加权损失:\n",
    "        # 对前景像素，惩罚 (1-probs) * dist_inside\n",
    "        # 对背景像素，惩罚 probs * dist_outside\n",
    "        # 需要分别计算内外距离图\n",
    "        dist_inside_maps = np.zeros_like(gt_masks_npy, dtype=np.float32)\n",
    "        dist_outside_maps = np.zeros_like(gt_masks_npy, dtype=np.float32)\n",
    "        for i in range(n):\n",
    "            gt_mask_single = gt_masks_npy[i, 0, :, :]\n",
    "            dist_inside_maps[i, 0, :, :] = distance_transform(gt_mask_single)\n",
    "            dist_outside_maps[i, 0, :, :] = distance_transform(1 - gt_mask_single)\n",
    "\n",
    "        dist_inside_tensor = torch.from_numpy(dist_inside_maps).to(pred_probs.device)\n",
    "        dist_outside_tensor = torch.from_numpy(dist_outside_maps).to(pred_probs.device)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = (1 - gt_masks) * pred_probs * dist_outside_tensor + \\\n",
    "               gt_masks * (1 - pred_probs) * dist_inside_tensor\n",
    "\n",
    "        # 对整个 Batch 和空间维度求平均\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "papermill": {
     "duration": 0.015798,
     "end_time": "2025-04-30T04:46:05.475363",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.459565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 组合损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "papermill": {
     "duration": 0.024196,
     "end_time": "2025-04-30T04:46:05.515366",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.491170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        # BCEWithLogitsLoss 实例本身不存储 pos_weight, 在 forward 中传入\n",
    "        self.bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss_fn = DiceLoss()\n",
    "\n",
    "    def forward(self, logits, targets, pos_weight=None):\n",
    "        \"\"\"\n",
    "        计算组合损失。\n",
    "        :param logits: 模型输出 (N, 1, H, W)\n",
    "        :param targets: 真实掩码 (N, 1, H, W)\n",
    "        :param pos_weight: 正样本权重 (scalar) for BCE loss.\n",
    "        \"\"\"\n",
    "        # 更新BCE损失的pos_weight参数\n",
    "        self.bce_loss_fn.pos_weight = pos_weight\n",
    "        bce = self.bce_loss_fn(logits, targets)\n",
    "\n",
    "        dice = self.dice_loss_fn(logits, targets)\n",
    "        return self.bce_weight * bce + self.dice_weight * dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "papermill": {
     "duration": 0.023097,
     "end_time": "2025-04-30T04:46:05.554070",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.530973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 组合损失 (加入边界损失) ---\n",
    "class CombinedLossWithBoundary(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5, boundary_weight=1.0): # 增加边界损失权重\n",
    "        super(CombinedLossWithBoundary, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.boundary_weight = boundary_weight # 新增权重\n",
    "        self.bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss_fn = DiceLoss()\n",
    "        self.boundary_loss_fn = BoundaryLoss() # 实例化边界损失\n",
    "\n",
    "    def forward(self, logits, targets, pos_weight=None):\n",
    "        # 更新BCE损失的pos_weight参数\n",
    "        self.bce_loss_fn.pos_weight = pos_weight\n",
    "        bce = self.bce_loss_fn(logits, targets)\n",
    "\n",
    "        dice = self.dice_loss_fn(logits, targets)\n",
    "\n",
    "        # 计算边界损失 (需要概率图和真实掩码)\n",
    "        # 注意：BoundaryLoss 内部会计算 sigmoid\n",
    "        # 但我们这里传入 probs 和 targets 确保输入一致性\n",
    "        probs = torch.sigmoid(logits)\n",
    "        boundary = self.boundary_loss_fn(probs, targets)\n",
    "\n",
    "        # 计算加权总损失\n",
    "        total_loss = self.bce_weight * bce + \\\n",
    "                     self.dice_weight * dice + \\\n",
    "                     self.boundary_weight * boundary # 加入边界损失\n",
    "        #print(f\"bce: {bce.item():.4f}, dice: {dice.item():.4f}, boundary: {boundary.item():.4f}\")\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "id": "ff097418",
    "language": "python",
    "papermill": {
     "duration": 0.022134,
     "end_time": "2025-04-30T04:46:05.592338",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.570204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化损失函数\n",
    "criterion = CombinedLossWithBoundary(bce_weight=0.6, dice_weight=0.4, boundary_weight=0.01).to(device)\n",
    "\n",
    "# bce: 0.8842, dice: 0.3501, boundary: 15.5918\n",
    "# bce: 0.9119, dice: 0.3842, boundary: 18.1574\n",
    "# bce: 0.7916, dice: 0.3559, boundary: 18.3994\n",
    "\n",
    "#criterion = CombinedLoss(bce_weight=0.6, dice_weight=0.4).to(device)\n",
    "\n",
    "try:\n",
    "    print(f\"使用的损失函数: {type(criterion).__name__}\")\n",
    "    print(f\"  - BCE 权重: {criterion.bce_weight}\")\n",
    "    print(f\"  - Dice 权重: {criterion.dice_weight}\")\n",
    "    print(f\"  - Boundary 权重: {criterion.boundary_weight}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "9ee6f7d9",
    "language": "markdown",
    "papermill": {
     "duration": 0.015676,
     "end_time": "2025-04-30T04:46:05.623796",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.608120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam优化器和学习率调度器，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "9cfd0144",
    "language": "python",
    "papermill": {
     "duration": 0.022342,
     "end_time": "2025-04-30T04:46:05.661936",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.639594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置优化器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=7e-5)\n",
    "\n",
    "# 学习率调度器\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6) # 使用基线超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "d6ea8258",
    "language": "markdown",
    "papermill": {
     "duration": 0.015846,
     "end_time": "2025-04-30T04:46:05.693442",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.677596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播、参数更新，并记录训练过程中的指标。同时实现早停机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "id": "67252228",
    "language": "python",
    "papermill": {
     "duration": 0.026333,
     "end_time": "2025-04-30T04:46:05.735608",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.709275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max', verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 在性能没有提升多少轮后停止训练。\n",
    "            min_delta (float): 被认为是性能提升的最小变化量。\n",
    "            mode (str): 'min' 或 'max'。监控指标是越小越好还是越大越好。\n",
    "            verbose (bool): 是否打印早停信息。\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state_dict_cpu = None # 直接存储 CPU 上的 state_dict\n",
    "\n",
    "        if self.mode not in ['min', 'max']:\n",
    "            raise ValueError(\"mode 必须是 'min' 或 'max'\")\n",
    "\n",
    "        self.delta_sign = 1 if mode == 'max' else -1\n",
    "\n",
    "    def __call__(self, val_score, model_state_dict_cpu):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            val_score (float): 当前验证分数。\n",
    "            model_state_dict_cpu (dict): 模型当前的 state_dict (已移至 CPU)。\n",
    "        \"\"\"\n",
    "        score = val_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state_dict_cpu = deepcopy(model_state_dict_cpu) # 保存第一个状态\n",
    "            if self.verbose:\n",
    "                tqdm.write(f\"EarlyStopping: 初始化最佳分数为 {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升 (乘以 delta_sign 以统一处理 min/max)\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            self.best_score = score\n",
    "            self.best_model_state_dict_cpu = deepcopy(model_state_dict_cpu) # 保存更好的状态\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                tqdm.write(f\"EarlyStopping: 发现改进。最佳分数更新为 {self.best_score:.4f}。计数器重置。\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                tqdm.write(f'EarlyStopping计数器: {self.counter}/{self.patience}。最佳分数仍为 {self.best_score:.4f}。')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    tqdm.write(\"EarlyStopping: 已达到耐心值，触发早停。\")\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        \"\"\"将最佳权重加载回模型\"\"\"\n",
    "        if self.best_model_state_dict_cpu:\n",
    "            # 需要将 state_dict 移回模型所在的设备\n",
    "            device = next(model.parameters()).device\n",
    "            best_state_device = {k: v.to(device) for k, v in self.best_model_state_dict_cpu.items()}\n",
    "            model.load_state_dict(best_state_device)\n",
    "            if self.verbose:\n",
    "                print(\"已将最佳模型权重加载回模型。\")\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(\"警告：未找到可加载的最佳模型权重。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "8226a404",
    "language": "python",
    "papermill": {
     "duration": 0.038115,
     "end_time": "2025-04-30T04:46:05.789521",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.751406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持单核TPU、CUDA和CPU。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 要训练的模型 (应已移动到目标 device)。\n",
    "        train_loader (DataLoader): 训练数据加载器。\n",
    "        val_loader (DataLoader): 验证数据加载器。\n",
    "        criterion (nn.Module): 损失函数。\n",
    "        optimizer: 优化器。\n",
    "        scheduler: 学习率调度器。\n",
    "        num_epochs (int): 训练的总轮数。\n",
    "        device (torch.device or str): 目标设备 ('cpu', 'cuda', or xm.xla_device())。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (最终验证Dice系数, 训练Dice历史, 验证Dice历史, 最佳模型在CPU上的state_dict)\n",
    "            如果验证加载器为 None，则最终验证 Dice 为 0，验证历史为空。\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    is_tpu = 'xla' in str(device)\n",
    "    print(f\"\\n--- 开始训练 ---\")\n",
    "    print(f\"设备: {device}\")\n",
    "    print(f\"轮数: {num_epochs}\")\n",
    "    print(f\"优化器: {type(optimizer).__name__}\")\n",
    "    print(f\"学习率调度器: {type(scheduler).__name__}\")\n",
    "    print(f\"损失函数: {type(criterion).__name__}\")\n",
    "\n",
    "    # 初始化 EarlyStopping\n",
    "    # 注意：如果 val_loader 为 None，早停将基于不存在的验证分数，实际上不会起作用，\n",
    "    # 但我们仍然创建它以保持代码结构一致。训练将运行完所有 num_epochs。\n",
    "    # 在这种情况下，我们保存最后一轮的模型。\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max', min_delta=0.001, verbose=True)\n",
    "\n",
    "    # 配置混合精度 (仅用于 CUDA)\n",
    "    use_amp = not is_tpu and torch.cuda.is_available()\n",
    "    scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    print(f\"使用混合精度 (AMP): {use_amp}\")\n",
    "\n",
    "    train_dice_history = []\n",
    "    val_dice_history = []\n",
    "    best_model_state_dict_cpu = None # 存储在CPU上的最佳权重\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # --- 训练阶段 ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_samples = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
    "\n",
    "        for images, masks in train_loader_tqdm:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # --- 计算 pos_weight (移至设备) ---\n",
    "            num_pixels = masks.numel()\n",
    "            num_pos = torch.sum(masks)\n",
    "            num_neg = num_pixels - num_pos\n",
    "            # 避免除以零，并确保 pos_weight 合理\n",
    "            pos_weight_value = torch.clamp(num_neg / (num_pos + 1e-6), min=1.0) # 至少为1，防止过分抑制前景\n",
    "            pos_weight_tensor = torch.tensor([pos_weight_value], device=device)\n",
    "\n",
    "            # --- 前向传播 (根据需要使用 AMP) ---\n",
    "            with torch.amp.autocast(device_type=str(device).split(':')[0], enabled=use_amp):\n",
    "                outputs = model(images)\n",
    "                # 检查模型输出是否是字典 (DeepLabV3 训练时返回字典)\n",
    "                if isinstance(outputs, collections.OrderedDict):\n",
    "                    outputs = outputs['out'] # 取主输出\n",
    "                # 确保掩码尺寸与输出匹配\n",
    "                masks_downsampled = Fnn.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                loss = criterion(outputs, masks_downsampled, pos_weight=pos_weight_tensor)\n",
    "\n",
    "            # --- 反向传播和优化 ---\n",
    "            if is_tpu:\n",
    "                loss.backward()\n",
    "                # xm.optimizer_step 会处理梯度同步（如果需要）和权重更新\n",
    "                xm.optimizer_step(optimizer)\n",
    "                # 对于单核 TPU，通常不需要显式的 xm.mark_step() 在这里\n",
    "            else: # CPU 或 CUDA\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # --- 累积指标 ---\n",
    "            batch_size = images.size(0)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            # dice_coefficient 应能在各种设备上运行\n",
    "            current_dice = dice_coefficient(outputs.detach(), masks_downsampled.detach())\n",
    "            train_dice += current_dice * batch_size\n",
    "            train_samples += batch_size\n",
    "\n",
    "            # --- 更新进度条 ---\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{current_dice:.4f}',\n",
    "                'lr': f'{current_lr:.1e}',\n",
    "                'pw': f'{pos_weight_value.item():.2f}'\n",
    "            })\n",
    "\n",
    "        # --- 计算平均训练指标 ---\n",
    "        if train_samples > 0:\n",
    "            train_loss /= train_samples\n",
    "            train_dice /= train_samples\n",
    "        else:\n",
    "            train_loss, train_dice = 0.0, 0.0 # 处理空 loader 的情况\n",
    "        train_dice_history.append(train_dice)\n",
    "\n",
    "        # --- 验证阶段 (如果 val_loader 存在) ---\n",
    "        current_val_dice = 0.0 # 初始化本轮验证分数\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_dice = 0.0\n",
    "            val_samples = 0\n",
    "            val_loader_tqdm = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader_tqdm:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                    # 前向传播 (验证时通常不使用 AMP autocast，但也可以用)\n",
    "                    outputs = model(images)\n",
    "                    # 检查模型输出是否是字典 (DeepLabV3 训练时返回字典)\n",
    "                    if isinstance(outputs, collections.OrderedDict):\n",
    "                        outputs = outputs['out'] # 取主输出\n",
    "                    masks_downsampled = Fnn.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                    # 验证时不使用 pos_weight\n",
    "                    loss = criterion(outputs, masks_downsampled, pos_weight=None)\n",
    "\n",
    "                    # --- 累积指标 ---\n",
    "                    batch_size = images.size(0)\n",
    "                    val_loss += loss.item() * batch_size\n",
    "                    current_dice_val = dice_coefficient(outputs, masks_downsampled)\n",
    "                    val_dice += current_dice_val * batch_size\n",
    "                    val_samples += batch_size\n",
    "\n",
    "                    val_loader_tqdm.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'dice': f'{current_dice_val:.4f}'\n",
    "                        })\n",
    "\n",
    "\n",
    "            # --- 计算平均验证指标 ---\n",
    "            if val_samples > 0:\n",
    "                val_loss /= val_samples\n",
    "                val_dice /= val_samples\n",
    "            else:\n",
    "                val_loss, val_dice = 0.0, 0.0 # 处理空 loader\n",
    "            val_dice_history.append(val_dice)\n",
    "            current_val_dice = val_dice # 更新本轮验证分数用于早停\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, \"\n",
    "                    f\"LR: {current_lr:.1e}, Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "            # --- 早停检查 (仅当有验证集时) ---\n",
    "            # 获取当前模型状态到 CPU\n",
    "            current_model_state_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            early_stopping(current_val_dice, current_model_state_cpu) # 使用修改后的 ES 类\n",
    "            if early_stopping.early_stop:\n",
    "                best_model_state_dict_cpu = early_stopping.best_model_state_dict_cpu # 获取最佳状态\n",
    "                break # 跳出 epoch 循环\n",
    "\n",
    "        else:\n",
    "            # 如果没有验证集，直接打印训练结果\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, \"\n",
    "                    f\"LR: {current_lr:.1e}, Duration: {epoch_duration:.2f}s\")\n",
    "            # 没有验证集，无法早停，将保存最后一轮的模型状态\n",
    "            if epoch == num_epochs - 1: # 如果是最后一轮\n",
    "                best_model_state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "\n",
    "        # --- 更新学习率 ---\n",
    "        # CosineAnnealingLR 在每个 epoch 后调用 step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # --- 训练结束处理 ---\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(\"\\n--- 训练完成 ---\")\n",
    "\n",
    "    # 如果没有提前停止，并且有最佳权重记录 (来自验证过程)\n",
    "    if not early_stopping.early_stop and early_stopping.best_model_state_dict_cpu is not None:\n",
    "        best_model_state_dict_cpu = early_stopping.best_model_state_dict_cpu\n",
    "        print(f\"训练完成 {num_epochs} 轮。使用验证集找到的最佳模型权重。\")\n",
    "    elif early_stopping.early_stop:\n",
    "        print(f\"训练因早停而在第 {epoch + 1} 轮结束。\")\n",
    "        # best_model_state_dict_cpu 已在 break 前被赋值\n",
    "    elif best_model_state_dict_cpu is None: # 训练完成但从未有过最佳状态(例如val_loader=None)\n",
    "        print(\"警告：训练完成，但没有记录最佳模型权重（可能因为没有验证集）。将使用最后一轮的模型权重。\")\n",
    "        # 此时 best_model_state_dict_cpu 应该已经被赋值为最后一轮的状态\n",
    "        if best_model_state_dict_cpu is None: # 双重检查，理论上不应发生\n",
    "            best_model_state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "\n",
    "    # --- 使用最佳模型进行最终评估 (如果 val_loader 存在) ---\n",
    "    final_val_dice = 0.0\n",
    "    if val_loader and best_model_state_dict_cpu:\n",
    "        print(\"\\n使用最佳权重在验证集上进行最终评估...\")\n",
    "        # 将最佳权重加载回模型 (确保移回正确的设备)\n",
    "        best_state_device = {k: v.to(device) for k, v in best_model_state_dict_cpu.items()}\n",
    "        model.load_state_dict(best_state_device)\n",
    "        model.eval()\n",
    "        val_samples_final = 0\n",
    "        val_dice_final = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=\"Final Validation\", leave=False):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                # 检查模型输出是否是字典 (DeepLabV3 训练时返回字典)\n",
    "                if isinstance(outputs, collections.OrderedDict):\n",
    "                    outputs = outputs['out'] # 取主输出\n",
    "                masks_downsampled = Fnn.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "                batch_size = images.size(0)\n",
    "                val_dice_final += dice_coefficient(outputs, masks_downsampled) * batch_size\n",
    "                val_samples_final += batch_size\n",
    "        if val_samples_final > 0:\n",
    "            final_val_dice = val_dice_final / val_samples_final\n",
    "        else:\n",
    "            final_val_dice = 0.0\n",
    "        print(f\"最终(最佳)验证 Dice 系数: {final_val_dice:.4f}\")\n",
    "    elif not val_loader:\n",
    "        print(\"没有提供验证集，跳过最终验证评估。\")\n",
    "    else: # 有 val_loader 但没有 best_model_state_dict_cpu\n",
    "        print(\"警告：无法获取最佳模型权重，无法进行最终验证评估。\")\n",
    "\n",
    "\n",
    "    print(f\"总训练耗时: {total_training_time:.2f} 秒\")\n",
    "\n",
    "    # 返回最终验证 Dice 和 CPU 上的最佳 state_dict\n",
    "    return final_val_dice, train_dice_history, val_dice_history, best_model_state_dict_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "papermill": {
     "duration": 0.015289,
     "end_time": "2025-04-30T04:46:05.821103",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.805814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "papermill": {
     "duration": 3644.812565,
     "end_time": "2025-04-30T05:46:50.649268",
     "exception": false,
     "start_time": "2025-04-30T04:46:05.836703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "best_dice, train_dice_history, val_dice_history, best_model_weights = train_validate_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler, # 如果是ReduceLROnPlateau, scheduler.step(val_dice)\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "papermill": {
     "duration": 0.022885,
     "end_time": "2025-04-30T05:46:50.695664",
     "exception": false,
     "start_time": "2025-04-30T05:46:50.672779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存\n",
    "保存训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "papermill": {
     "duration": 0.197876,
     "end_time": "2025-04-30T05:46:50.915776",
     "exception": false,
     "start_time": "2025-04-30T05:46:50.717900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    \"\"\"保存模型参数到指定路径\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "model_save_path=f'/kaggle/working/{type(model).__name__}_pterygium_seg_{best_dice:.3f}_{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}.pth'\n",
    "save_model(model,model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "papermill": {
     "duration": 0.022385,
     "end_time": "2025-04-30T05:46:50.960938",
     "exception": false,
     "start_time": "2025-04-30T05:46:50.938553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 可视化学习曲线，分割结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "papermill": {
     "duration": 5.088276,
     "end_time": "2025-04-30T05:46:56.071715",
     "exception": false,
     "start_time": "2025-04-30T05:46:50.983439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化学习曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_dice_history) + 1), train_dice_history, label='训练Dice系数')\n",
    "plt.plot(range(1, len(val_dice_history) + 1), val_dice_history, label='验证Dice系数')\n",
    "plt.title('训练和验证Dice系数')\n",
    "plt.xlabel('轮次')\n",
    "plt.ylabel('Dice系数')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 可视化分割结果\n",
    "def visualize_segmentation(model, dataloader, num_samples=5):\n",
    "    \"\"\"可视化分割结果\"\"\"\n",
    "    model.eval()\n",
    "    dataiter = iter(dataloader)\n",
    "    \n",
    "    # 获取一批数据\n",
    "    try:\n",
    "        images, masks = next(dataiter)\n",
    "    except StopIteration:\n",
    "        print(\"数据集太小，无法获取足够的样本。\")\n",
    "        return\n",
    "    \n",
    "    # 限制样本数\n",
    "    num_samples = min(num_samples, images.size(0))\n",
    "    \n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        outputs = model(images)\n",
    "        # 检查模型输出是否是字典 (DeepLabV3 训练时返回字典)\n",
    "        if isinstance(outputs, collections.OrderedDict):\n",
    "            outputs = outputs['out'] # 取主输出\n",
    "        print(f\"Outputs Min: {outputs.min()}, Max: {outputs.max()}, Mean: {outputs.mean()}\")\n",
    "        pred_masks = (torch.sigmoid(outputs) > 0.5).float()\n",
    "    \n",
    "    # 反标准化图像以便可视化\n",
    "    images_np = []\n",
    "    for img in images[:num_samples]:\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)  # 转为HWC格式\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        images_np.append(img)\n",
    "    \n",
    "    # 准备掩码和预测\n",
    "    masks_np = masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    pred_masks_np = pred_masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 原始图像\n",
    "        axes[i, 0].imshow(images_np[i])\n",
    "        axes[i, 0].set_title('原始图像')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 真实掩码\n",
    "        axes[i, 1].imshow(masks_np[i], cmap='gray')\n",
    "        axes[i, 1].set_title('真实掩码')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 预测掩码\n",
    "        axes[i, 2].imshow(pred_masks_np[i], cmap='gray')\n",
    "        masks_downsampled = Fnn.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
    "        dice = dice_coefficient(outputs[i:i+1], masks_downsampled[i:i+1])\n",
    "        axes[i, 2].set_title(f'预测掩码 (Dice: {dice:.4f})')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    visualize_segmentation(model, val_loader, num_samples=5) # 可视化验证集(resize后)的结果\n",
    "except Exception as e:\n",
    "    print(f\"可视化分割结果时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "papermill": {
     "duration": 0.039712,
     "end_time": "2025-04-30T05:46:56.149633",
     "exception": false,
     "start_time": "2025-04-30T05:46:56.109921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "papermill": {
     "duration": 0.047137,
     "end_time": "2025-04-30T05:46:56.233904",
     "exception": false,
     "start_time": "2025-04-30T05:46:56.186767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置模型路径\n",
    "if platform.system() == \"Windows\":\n",
    "    classification_model_path = 'w1.pth'\n",
    "    model_save_path = 'work2model_dice-0.859_2025-04-24-08-47-19.pth'\n",
    "else:\n",
    "    # 在 Kaggle 中使用的路径\n",
    "    classification_model_path = '/kaggle/input/pterygium-classification/pytorch/default/1/ResNet34Classifier_pterygium_classifier.pth'\n",
    "    if 'model_save_path' not in locals().keys():\n",
    "        model_save_path = '/kaggle/input/pterygiumseg/pytorch/default/5/UNet_pterygium_seg_0.933_2025-04-24-21-38-00.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "papermill": {
     "duration": 0.034356,
     "end_time": "2025-04-30T05:46:56.303246",
     "exception": false,
     "start_time": "2025-04-30T05:46:56.268890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型预测与应用\n",
    "\n",
    "遍历测试图像，加载它们，进行预处理，然后使用加载的模型进行预测，最后将预测的掩码保存下来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "papermill": {
     "duration": 0.034576,
     "end_time": "2025-04-30T05:46:56.372364",
     "exception": false,
     "start_time": "2025-04-30T05:46:56.337788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 定义分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "papermill": {
     "duration": 1.277245,
     "end_time": "2025-04-30T05:46:57.684212",
     "exception": false,
     "start_time": "2025-04-30T05:46:56.406967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义test集的变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 构建 ResNet34 模型\n",
    "from torchvision.models import ResNet34_Weights\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 前向传播\n",
    "        outputs = model(image)\n",
    "        # 检查模型输出是否是字典 (DeepLabV3 训练时返回字典)\n",
    "        if isinstance(outputs, collections.OrderedDict):\n",
    "            outputs = outputs['out'] # 取主输出\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "classification_model = ResNet34Classifier(num_classes=3)\n",
    "classification_model.load_state_dict(torch.load(classification_model_path, map_location=device, weights_only=True))\n",
    "classification_model = classification_model.to(device)\n",
    "classification_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {
    "papermill": {
     "duration": 0.034611,
     "end_time": "2025-04-30T05:46:57.753846",
     "exception": false,
     "start_time": "2025-04-30T05:46:57.719235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. 加载训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "papermill": {
     "duration": 0.852097,
     "end_time": "2025-04-30T05:46:58.641432",
     "exception": false,
     "start_time": "2025-04-30T05:46:57.789335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_model_select == 'unet':\n",
    "    loaded_model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "elif train_model_select == 'unet_attention':\n",
    "    loaded_model = UNetAttention(n_classes=1, bilinear=True, dropout_p=0.5).to(device)\n",
    "elif train_model_select == 'deeplabv3':\n",
    "    loaded_model = create_deeplabv3(backbone_name='resnet50', num_classes=1, pretrained_backbone=True).to(device)\n",
    "\n",
    "# 加载最佳权重 (假设 best_model_weights 变量包含 state_dict)\n",
    "if 'best_model_weights' in locals() and best_model_weights is not None:\n",
    "    loaded_model.load_state_dict(best_model_weights)\n",
    "    print(\"成功加载训练好的模型权重。\")\n",
    "else:\n",
    "    # 如果没有 best_model_weights，尝试从文件加载（需要先保存）\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))\n",
    "        print(f\"从 {model_save_path} 加载模型权重。\")\n",
    "    else:\n",
    "        print(\"警告: 未找到训练好的模型权重 (best_model_weights 或文件)。模型将使用随机初始化的权重。\")\n",
    "\n",
    "loaded_model.eval(); # 设置为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "papermill": {
     "duration": 0.034588,
     "end_time": "2025-04-30T05:46:58.711517",
     "exception": false,
     "start_time": "2025-04-30T05:46:58.676929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 定义 Tiling 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "papermill": {
     "duration": 0.050158,
     "end_time": "2025-04-30T05:46:58.796591",
     "exception": false,
     "start_time": "2025-04-30T05:46:58.746433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_probability_map_from_tensor_with_tiling(model, image_tensor, patch_size, stride, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    处理单个大图张量，使用 Tiling (Unfold/Fold + 重叠平均) 进行分割预测，\n",
    "    返回与输入张量相同尺寸的平均概率图。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 训练好的分割模型。\n",
    "        image_tensor (torch.Tensor): 输入图像张量 (1 x C x H x W)。\n",
    "        patch_size (int): Patch 大小 (边长)。\n",
    "        stride (int): 切割 Patch 时的步长。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        batch_size (int): 推理时的批次大小。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 预测的裁剪回输入张量尺寸的平均概率图 (1 x N_Classes x H_in x W_in)。\n",
    "                        返回的概率图已应用 Sigmoid，值在 [0, 1] 之间。\n",
    "                        如果处理失败，返回 None。\n",
    "    \"\"\"\n",
    "    if image_tensor is None or image_tensor.ndim != 4 or image_tensor.shape[0] != 1:\n",
    "        print(f\"错误: 输入图像张量格式不正确。期望 (1, C, H, W)，实际 {image_tensor.shape if image_tensor is not None else 'None'}\")\n",
    "        return None\n",
    "\n",
    "    model.eval() # 确保模型在评估模式\n",
    "\n",
    "    B, C, img_h, img_w = image_tensor.shape\n",
    "\n",
    "    # --- 1. 图像填充 (如果需要) ---\n",
    "    # 计算所需的 padding 以便能被 patch_size 完美覆盖且步长对齐\n",
    "    # Note: Unfold/Fold handles partial patches at the border if stride doesn't align perfectly,\n",
    "    # but padding ensures a full grid of patches.\n",
    "    pad_w_needed = (patch_size - (img_w % patch_size)) % patch_size\n",
    "    pad_h_needed = (patch_size - (img_h % patch_size)) % patch_size\n",
    "\n",
    "    # Recalculate needed padding based on stride for a complete grid\n",
    "    # ((img_dim - patch_size) // stride) * stride + patch_size is the minimal size\n",
    "    # that allows a full tiling grid. Add stride if remainder exists.\n",
    "    target_h = ((img_h - patch_size + stride) // stride) * stride + patch_size if img_h >= patch_size else patch_size\n",
    "    target_w = ((img_w - patch_size + stride) // stride) * stride + patch_size if img_w >= patch_size else patch_size\n",
    "\n",
    "    pad_h = target_h - img_h\n",
    "    pad_w = target_w - img_w\n",
    "\n",
    "    # Padding: (pad_left, pad_right, pad_top, pad_bottom) - for Tensor\n",
    "    padding = (0, pad_w, 0, pad_h)\n",
    "    \n",
    "    # Apply padding using reflection mode\n",
    "    padded_image_tensor = Fnn.pad(image_tensor, padding, mode='reflect')\n",
    "    padded_h_actual = padded_image_tensor.shape[2]\n",
    "    padded_w_actual = padded_image_tensor.shape[3]\n",
    "\n",
    "    # --- 2. 使用 Unfold 提取 Patches ---\n",
    "    unfold = nn.Unfold(kernel_size=(patch_size, patch_size), stride=stride)\n",
    "    # 输入: (B, C, H, W) -> 输出: (B, C * ks[0] * ks[1], L) L是patch数量\n",
    "    patches_unfolded = unfold(padded_image_tensor)\n",
    "    B, C_ks_ks, L = patches_unfolded.shape\n",
    "\n",
    "    # 将 unfolded patches 变形为模型所需的格式: (L, C, patch_size, patch_size)\n",
    "    patches_for_model = patches_unfolded.permute(0, 2, 1).reshape(L, C, patch_size, patch_size)\n",
    "    del patches_unfolded # 释放内存\n",
    "    if device.type == 'cuda': torch.cuda.empty_cache() # 清理显存\n",
    "\n",
    "    # --- 3. 分批进行模型推理 ---\n",
    "    all_outputs_logits = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, L, batch_size):\n",
    "            batch_patches = patches_for_model[i:i+batch_size].to(device) # 将当前批次移到设备\n",
    "            model_outputs = model(batch_patches) # Get the model output (might be a dict)\n",
    "            if isinstance(model_outputs, collections.OrderedDict):\n",
    "                # For segmentation models like DeepLabV3, 'out' key contains main output\n",
    "                batch_outputs_logits = model_outputs.get('out', model_outputs) # Use .get for robustness\n",
    "            else:\n",
    "                # Assume it's already the main output tensor in eval mode for other models like UNet\n",
    "                batch_outputs_logits = model_outputs\n",
    "\n",
    "            # Ensure output logits have 4 dimensions (N, C, H, W)\n",
    "            if batch_outputs_logits.ndim == 3:\n",
    "                batch_outputs_logits = batch_outputs_logits.unsqueeze(1) # Add channel dim if missing\n",
    "\n",
    "            all_outputs_logits.append(batch_outputs_logits.cpu()) # 将结果移回CPU以节省GPU内存\n",
    "            del batch_patches, batch_outputs_logits # 释放批次显存\n",
    "            if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "    # 合并所有批次的结果\n",
    "    outputs_logits_all_patches = torch.cat(all_outputs_logits, dim=0) # (L, N_Classes, H_out, W_out)\n",
    "    del all_outputs_logits, patches_for_model # 释放内存\n",
    "\n",
    "    # 获取模型输出的 patch 尺寸\n",
    "    L_cat, N_Classes, out_patch_h, out_patch_w = outputs_logits_all_patches.shape\n",
    "\n",
    "\n",
    "    # --- 4. 填充/缩放模型输出 Patch 并使用 Fold 重建 Logits 图 ---\n",
    "    # If model output patch size differs from input patch size, interpolate\n",
    "    if out_patch_h != patch_size or out_patch_w != patch_size:\n",
    "        # print(f\"警告: 模型输出 Patch 尺寸 ({out_patch_h}x{out_patch_w}) 与输入 Patch 尺寸 ({patch_size}x{patch_size}) 不匹配! 将上采样...\")\n",
    "        outputs_logits_all_patches_rescaled = Fnn.interpolate(\n",
    "            outputs_logits_all_patches,\n",
    "            size=(patch_size, patch_size),\n",
    "            mode='bilinear', # 双线性插值适用于 logits/概率\n",
    "            align_corners=True\n",
    "        )\n",
    "        # print(f\"输出 Patch 已上采样到 {outputs_logits_all_patches_rescaled.shape[2:]}\")\n",
    "    else:\n",
    "        outputs_logits_all_patches_rescaled = outputs_logits_all_patches # 尺寸一致，无需插值\n",
    "\n",
    "\n",
    "    # Reshape the *rescaled* outputs for Fold\n",
    "    # Shape needed: (B, N_Classes * patch_size * patch_size, L)\n",
    "    outputs_for_fold = outputs_logits_all_patches_rescaled.reshape(L_cat, N_Classes * patch_size * patch_size).permute(1, 0).unsqueeze(0) # (1, N_Classes*patch_size*patch_size, L_cat)\n",
    "    del outputs_logits_all_patches, outputs_logits_all_patches_rescaled # Free memory\n",
    "\n",
    "    # Define Fold operation using the *input* patch_size as kernel_size\n",
    "    fold_logits = nn.Fold(output_size=(padded_h_actual, padded_w_actual), # Fold 输出尺寸是填充后图像的尺寸\n",
    "                        kernel_size=(patch_size, patch_size), # Fold kernel size matches Unfold kernel size\n",
    "                        stride=stride)\n",
    "\n",
    "    # Execute Fold operation for logits (on device)\n",
    "    # Move to device only right before fold to potentially save GPU memory\n",
    "    output_logits_map = fold_logits(outputs_for_fold.to(device)) # (1, N_Classes, H_padded, W_padded)\n",
    "    del outputs_for_fold # Free memory\n",
    "\n",
    "    # --- 5. 计算 Count Map (使用与 Logits Fold 一致的参数) ---\n",
    "    input_ones_for_fold = torch.ones(1, 1 * patch_size * patch_size, L_cat, device=device)\n",
    "    fold_count = nn.Fold(output_size=(padded_h_actual, padded_w_actual),\n",
    "                        kernel_size=(patch_size, patch_size),\n",
    "                        stride=stride)\n",
    "    count_map = fold_count(input_ones_for_fold) # (1, 1, H_padded, W_padded)\n",
    "    count_map = count_map.clamp(min=1.0) # Prevent division by zero\n",
    "    del input_ones_for_fold # Free memory\n",
    "\n",
    "    # --- 6. 计算平均 Logits，转换为概率图，并裁剪 ---\n",
    "    avg_logits_map = (output_logits_map / count_map).to('cpu')\n",
    "    del output_logits_map, count_map # Free memory\n",
    "    if device.type == 'cuda': torch.cuda.empty_cache() # 清理显存\n",
    "\n",
    "    # 将平均 Logits 转换为概率图\n",
    "    avg_prob_map = torch.sigmoid(avg_logits_map) # (1, N_Classes, H_padded, W_padded)\n",
    "    del avg_logits_map\n",
    "\n",
    "    # 裁剪回原始输入张量尺寸 (去掉 padding)\n",
    "    avg_prob_map_cropped = avg_prob_map[:, :, :img_h, :img_w] # (1, N_Classes, H, W)\n",
    "\n",
    "    return avg_prob_map_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "papermill": {
     "duration": 0.045164,
     "end_time": "2025-04-30T05:46:58.877640",
     "exception": false,
     "start_time": "2025-04-30T05:46:58.832476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_image_mask(image_path, mask_path=None, target_size=None, debug_mode=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    加载图像和可选的掩码，应用预处理（ToTensor, Normalize），\n",
    "    并根据 debug_mode 进行缩放。\n",
    "\n",
    "    Args:\n",
    "        image_path (str): 图像文件路径。\n",
    "        mask_path (str, optional): 掩码文件路径。默认为 None。\n",
    "        target_size (tuple, optional): 缩放目标尺寸 (W, H)。如果 None，则不额外缩放。\n",
    "                                        请注意，debug_mode 缩放优先于此。\n",
    "        debug_mode (bool): 是否启用调试模式，缩放至原始尺寸的 1/4。\n",
    "        device (str or torch.device): 将处理后的张量移动到的设备。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (image_tensor (1 x C x H x W), mask_tensor (1 x 1 x H x W, 0/1 float), original_size (W, H))\n",
    "                如果加载或处理失败，返回 (None, None, None)。\n",
    "                返回的 Tensor 已经在指定的 device 上。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_pil = Image.open(image_path).convert('RGB')\n",
    "        original_w, original_h = img_pil.size\n",
    "\n",
    "        mask_pil = None\n",
    "        if mask_path and os.path.exists(mask_path):\n",
    "            mask_pil = Image.open(mask_path).convert('RGB')\n",
    "            mask_w, mask_h = mask_pil.size\n",
    "            if mask_w != original_w or mask_h != original_h:\n",
    "                print(f\"警告: 图像 {os.path.basename(image_path)} 和掩码尺寸不匹配，跳过掩码加载。\")\n",
    "                mask_pil = None\n",
    "\n",
    "        # --- 调试模式下缩放 ---\n",
    "        if debug_mode:\n",
    "            new_w, new_h = original_w // 4, original_h // 4\n",
    "            img_pil = img_pil.resize((new_w, new_h), Image.Resampling.BICUBIC if hasattr(Image, 'Resampling') else Image.BICUBIC)\n",
    "            if mask_pil:\n",
    "                mask_pil = mask_pil.resize((new_w, new_h), Image.Resampling.NEAREST if hasattr(Image, 'Resampling') else Image.NEAREST)\n",
    "            #print(f\"调试模式: 图像 {os.path.basename(image_path)} 缩放至 {new_w}x{new_h}\")\n",
    "\n",
    "        # --- 额外目标尺寸缩放 (如果在 debug_mode 后需要) ---\n",
    "        # 注意：目前的设计 debug_mode 缩放是固定的 1/4，target_size 参数暂时未被 find_best_segmentation_threshold_binary_search 使用。\n",
    "        # 保留此参数以备将来扩展。如果同时设置 debug_mode=True 和 target_size，debug_mode 缩放优先。\n",
    "        # if not debug_mode and target_size and img_pil.size != target_size:\n",
    "        #      img_pil = img_pil.resize(target_size, Image.Resampling.BICUBIC if hasattr(Image, 'Resampling') else Image.BICUBIC)\n",
    "        #      if mask_pil:\n",
    "        #           mask_pil = mask_pil.resize(target_size, Image.Resampling.NEAREST if hasattr(Image, 'Resampling') else Image.NEAREST)\n",
    "        #      print(f\"图像 {os.path.basename(image_path)} 缩放至目标尺寸 {target_size}\")\n",
    "\n",
    "        # 定义预处理 (ToTensor + Normalize)\n",
    "        preprocess_img = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # 处理图像\n",
    "        image_tensor = preprocess_img(img_pil).unsqueeze(0).to(device) # (1, C, H_proc, W_proc)\n",
    "\n",
    "        # 处理掩码 (如果存在)\n",
    "        mask_tensor = None\n",
    "        if mask_pil:\n",
    "            mask_np_rgb = np.array(mask_pil)\n",
    "            mask_binary_np = (mask_np_rgb[:, :, 0] == 128).astype(np.float32) # 0/1 float32\n",
    "            mask_tensor = torch.from_numpy(mask_binary_np).unsqueeze(0).unsqueeze(0).to(device) # (1, 1, H_proc, W_proc)\n",
    "\n",
    "\n",
    "        # 返回处理后的张量和原始图像的尺寸 (用于最后的插值放大)\n",
    "        return image_tensor, mask_tensor, (original_w, original_h)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {image_path}\" + (f\" 或 {mask_path}\" if mask_path else \"\"))\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 加载或预处理图像时出错 {os.path.basename(image_path)}: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "papermill": {
     "duration": 0.043639,
     "end_time": "2025-04-30T05:46:58.956160",
     "exception": false,
     "start_time": "2025-04-30T05:46:58.912521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_single_image_for_segmentation(\n",
    "    model,\n",
    "    image_path,\n",
    "    patch_size,\n",
    "    stride, # 这是 predict_stride\n",
    "    device,\n",
    "    batch_size, # 这是 segmentation_batch_size\n",
    "    threshold,\n",
    "    debug_mode=False # 新增参数\n",
    "):\n",
    "    \"\"\"\n",
    "    处理单个大图文件，使用 Tiling (Unfold/Fold + 重叠平均) 进行分割预测，\n",
    "    应用后处理，并在调试模式下将结果插值放大回原图尺寸。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 训练好的分割模型。\n",
    "        image_path (str): 原始大图路径。\n",
    "        patch_size (int): Patch 大小 (边长)。\n",
    "        stride (int): 切割 Patch 时的步长 (预测步长)。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        batch_size (int): 分割模型推理时的批次大小。\n",
    "        threshold (float): 二值化概率阈值。\n",
    "        debug_mode (bool): 是否启用调试模式，处理缩放后的图像并放大结果。\n",
    "    \"\"\"\n",
    "    # --- 1. 加载并预处理图像 (根据 debug_mode 决定是否缩放) ---\n",
    "    image_tensor, _, original_size = load_and_preprocess_image_mask(\n",
    "        image_path,\n",
    "        debug_mode=debug_mode,\n",
    "        device=device # 将加载的张量移到设备\n",
    "    )\n",
    "\n",
    "    if image_tensor is None:\n",
    "        print(f\"警告: 加载或预处理图像 {os.path.basename(image_path)} 失败。\")\n",
    "        return None, None # 如果加载失败，返回 None\n",
    "\n",
    "    # --- 2. 获取缩放后的概率图 (predict_probability_map_from_tensor_with_tiling 会处理填充) ---\n",
    "    # prob_map_tensor 会是 image_tensor 输入时的尺寸 (1, 1, H_proc, W_proc)\n",
    "    prob_map_tensor = predict_probability_map_from_tensor_with_tiling(\n",
    "        model, image_tensor, patch_size, stride, device, batch_size\n",
    "    )\n",
    "\n",
    "    # 检查预测是否成功\n",
    "    if prob_map_tensor is None:\n",
    "        print(f\"警告: 生成 {os.path.basename(image_path)} 的概率图失败。\")\n",
    "        return None, None # 如果概率图获取失败，返回 None\n",
    "\n",
    "    # --- 3. 后处理概率图 (在缩放后的尺寸上进行) ---\n",
    "    # postprocess_probability_map 返回 0/1 numpy 数组\n",
    "    processed_mask_np_01_scaled, model_output_mask_np_01_scaled = postprocess_probability_map(\n",
    "        prob_map_tensor, threshold\n",
    "    )\n",
    "    \n",
    "    prob_map_np_scaled = prob_map_tensor.squeeze().cpu().numpy() \n",
    "\n",
    "    if processed_mask_np_01_scaled is None:\n",
    "        print(f\"警告: 后处理 {os.path.basename(image_path)} 失败。\")\n",
    "        return None, None # 如果后处理失败，返回 None\n",
    "\n",
    "    # --- 4. 将结果插值放大回原始尺寸 (如果 debug_mode 为 True) ---\n",
    "    # Note: cv2.resize 期望 (width, height) 顺序\n",
    "    target_wh = original_size # (W, H)\n",
    "\n",
    "    # 将 0/1 numpy 数组缩放\n",
    "    # 使用 cv2.INTER_NEAREST 最近邻插值，确保二值性\n",
    "    final_mask_resized = cv2.resize(processed_mask_np_01_scaled.astype(np.uint8), target_wh, interpolation=cv2.INTER_NEAREST)\n",
    "    final_mask_model_output_resized = cv2.resize(model_output_mask_np_01_scaled.astype(np.uint8), target_wh, interpolation=cv2.INTER_NEAREST)\n",
    "    final_mask_prob_map = cv2.resize(prob_map_np_scaled.astype(np.uint8), target_wh, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return (final_mask_resized,\n",
    "            final_mask_model_output_resized,\n",
    "            final_mask_prob_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "papermill": {
     "duration": 0.051819,
     "end_time": "2025-04-30T05:46:59.042895",
     "exception": false,
     "start_time": "2025-04-30T05:46:58.991076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import DEBUG\n",
    "\n",
    "\n",
    "def predict_masks_for_directory(\n",
    "    segmentation_model,\n",
    "    classification_model,\n",
    "    image_dir, # 指向待预测图像的目录 (如 val_img)\n",
    "    output_mask_dir,\n",
    "    output_mask_model_output_dir,\n",
    "    output_prob_map_dir,\n",
    "    patch_size,\n",
    "    predict_stride,\n",
    "    device,\n",
    "    segmentation_batch_size,\n",
    "    segmentation_threshold,\n",
    "    classification_transform,\n",
    "    debug_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    遍历目录中的图像文件，使用级联方法进行预测，并保存分割掩码。\n",
    "    在调试模式下，分割处理将在缩放后的图像上进行，结果将被放大回原始尺寸。\n",
    "\n",
    "    Args:\n",
    "        segmentation_model (nn.Module): 训练好的分割模型。\n",
    "        classification_model (nn.Module): 训练好的分类模型 (用于过滤健康图像)。\n",
    "        image_dir (str): 包含待预测图像文件的目录。\n",
    "        output_mask_dir (str): 保存最终后处理预测掩码的目录。\n",
    "        output_mask_model_output_dir (str): 保存模型直接输出 (阈值化后) 掩码的目录。\n",
    "        output_prob_map_dir (str): 保存模型输出概率图的目录。\n",
    "        patch_size (int): 分割模型 Patch 大小 (边长)。\n",
    "        predict_stride (int): 分割模型预测时的步长。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        segmentation_batch_size (int): 分割模型推理时的批次大小。\n",
    "        segmentation_threshold (float): 分割结果的二值化阈值。\n",
    "        classification_transform: 分类模型需要的预处理变换。\n",
    "        debug_mode (bool): 是否启用调试模式，处理缩放后的图像和放大结果。\n",
    "    \"\"\"\n",
    "\n",
    "    shutil.rmtree(output_mask_dir, ignore_errors=True)\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "    shutil.rmtree(output_mask_model_output_dir, ignore_errors=True)\n",
    "    os.makedirs(output_mask_model_output_dir, exist_ok=True)\n",
    "\n",
    "    shutil.rmtree(output_prob_map_dir, ignore_errors=True)\n",
    "    os.makedirs(output_prob_map_dir, exist_ok=True)\n",
    "\n",
    "    # 查找所有待预测图像 (假设文件是 .png)\n",
    "    test_image_paths = glob.glob(os.path.join(image_dir, \"*.png\"))\n",
    "    if not test_image_paths:\n",
    "        print(f\"警告: 在目录 {image_dir} 中未找到任何 .png 图像文件。预测停止。\")\n",
    "        return # 没有图像文件，直接返回\n",
    "\n",
    "    print(f\"找到 {len(test_image_paths)} 张待预测图像于 {image_dir}\")\n",
    "    if debug_mode:\n",
    "        print(\"注意: 调试模式下，分割预测在 1/4 缩放后的图像上进行，结果将放大回原图尺寸。\")\n",
    "\n",
    "    # 统计\n",
    "    skipped_healthy_count = 0\n",
    "    processed_segmented_count = 0\n",
    "    segmentation_failed_count = 0 # 统计分割处理失败的图像\n",
    "\n",
    "    # 确保分类模型在评估模式\n",
    "    classification_model.eval()\n",
    "\n",
    "    # 遍历测试图像并进行预测\n",
    "    for img_path in tqdm(test_image_paths, desc=\"处理预测图像\"):\n",
    "        base_name = os.path.basename(img_path)\n",
    "        save_name = f\"{os.path.splitext(base_name)[0]}.png\" # 统一保存为png\n",
    "        save_path_processed = os.path.join(output_mask_dir, save_name)\n",
    "        save_path_model_output = os.path.join(output_mask_model_output_dir, save_name)\n",
    "        save_path_prob_map = os.path.join(output_prob_map_dir, save_name)\n",
    "\n",
    "        # --- 获取原始图像尺寸 (用于创建空掩码或放大结果) ---\n",
    "        try:\n",
    "            with Image.open(img_path) as img_pil:\n",
    "                original_w, original_h = img_pil.size\n",
    "        except Exception as e:\n",
    "            print(f\"警告: 无法获取原始图像 {base_name} 尺寸: {e}。跳过此图像。\")\n",
    "            segmentation_failed_count += 1\n",
    "            continue # 无法获取尺寸，跳过整个图像\n",
    "\n",
    "        # --- 级联：使用分类模型判断 ---\n",
    "        try:\n",
    "            # 分类模型不受 debug mode 缩放影响\n",
    "            predicted_class = predict_image(classification_model, img_path, classification_transform, device)\n",
    "            if DEBUG_MODE: predicted_class = 1\n",
    "        except Exception as e:\n",
    "            print(f\"警告: 分类预测图像 {base_name} 时出错: {e}。将此图像视为非健康并尝试分割。\")\n",
    "            predicted_class = 1 # 遇到错误，为了不跳过，假定为非健康\n",
    "\n",
    "        if predicted_class == 0: # 预测为健康 (类别 0)\n",
    "            try:\n",
    "                # 创建原始尺寸的全黑空掩码\n",
    "                empty_mask_np_rgb = np.zeros((original_h, original_w, 3), dtype=np.uint8)\n",
    "                empty_mask_image = Image.fromarray(empty_mask_np_rgb, mode='RGB')\n",
    "                empty_mask_image.save(save_path_processed)\n",
    "                empty_mask_image.save(save_path_model_output)\n",
    "                empty_mask_image.save(save_path_prob_map)\n",
    "                skipped_healthy_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"为健康图像 {base_name} 创建或保存空掩码时出错: {e}\")\n",
    "            continue # 跳过分割处理\n",
    "\n",
    "        # --- 如果不是健康 (类别 > 0)，则执行分割 ---\n",
    "        # 调用单文件处理函数 (它会根据 debug_mode 处理缩放和放大)\n",
    "        processed_mask_np_01, model_output_mask_np_01, prob_map_np = process_single_image_for_segmentation(\n",
    "            model=segmentation_model,\n",
    "            image_path=img_path,\n",
    "            patch_size=patch_size,\n",
    "            stride=predict_stride, # 使用预测步长\n",
    "            device=device,\n",
    "            batch_size=segmentation_batch_size,\n",
    "            threshold=segmentation_threshold, # 使用传入的调整后阈值\n",
    "            debug_mode=DEBUG_MODE\n",
    "        )\n",
    "\n",
    "        if processed_mask_np_01 is not None and model_output_mask_np_01 is not None and prob_map_np is not None:\n",
    "            try:\n",
    "                # 1. 保存后处理的二值掩码 (0/1 -> RGB 128,0,0)\n",
    "                h, w = processed_mask_np_01.shape\n",
    "                rgb_mask_processed = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "                rgb_mask_processed[processed_mask_np_01 == 1, 0] = 128 # R通道设为128\n",
    "                mask_image_processed = Image.fromarray(rgb_mask_processed, mode='RGB')\n",
    "                mask_image_processed.save(save_path_processed)\n",
    "                # 2. 保存模型直接输出的二值掩码 (0/1 -> RGB 128,0,0)\n",
    "                ha, wa = model_output_mask_np_01.shape\n",
    "                rgb_mask_model_output = np.zeros((ha, wa, 3), dtype=np.uint8)\n",
    "                rgb_mask_model_output[model_output_mask_np_01 == 1, 0] = 128 # R通道设为128\n",
    "                mask_image_model_output = Image.fromarray(rgb_mask_model_output, mode='RGB')\n",
    "                mask_image_model_output.save(save_path_model_output)\n",
    "                # 3. 保存原始概率图 (float [0, 1] -> uint8 [0, 255] -> RGB)\n",
    "                # 缩放概率值到 0-255 并转换为 uint8\n",
    "                prob_map_np_uint8 = (prob_map_np * 255).astype(np.uint8)\n",
    "                # 将单通道 uint8 数组堆叠为 RGB 图像 (R=G=B)\n",
    "                prob_map_rgb = np.stack([prob_map_np_uint8] * 3, axis=-1)\n",
    "                Image.fromarray(prob_map_rgb, mode='RGB').save(save_path_prob_map)\n",
    "                processed_segmented_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"保存分割掩码时出错 {base_name}: {e}\")\n",
    "                segmentation_failed_count += 1 # 统计保存失败也算处理失败\n",
    "\n",
    "        else:\n",
    "            # process_single_image_for_segmentation 返回 None (处理失败)\n",
    "            print(f\"警告：分割处理图像 {base_name} 失败，将保存空掩码。\")\n",
    "            segmentation_failed_count += 1\n",
    "            try:\n",
    "                # 如果分割处理失败，也创建原始尺寸的空掩码作为占位符\n",
    "                empty_mask_np_rgb = np.zeros((original_h, original_w, 3), dtype=np.uint8)\n",
    "                empty_mask_image = Image.fromarray(empty_mask_np_rgb, mode='RGB')\n",
    "                empty_mask_image.save(save_path_processed)\n",
    "                empty_mask_image.save(save_path_model_output) # 处理失败的模型原始输出也是空\n",
    "            except Exception as e:\n",
    "                print(f\"为处理失败的图像 {base_name} 创建或保存空掩码时再次出错: {e}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n预测处理完成。\")\n",
    "    print(f\"总共找到图像: {len(test_image_paths)}\")\n",
    "    print(f\"其中 {skipped_healthy_count} 张被分类为健康并跳过分割。\")\n",
    "    print(f\"对其余 {processed_segmented_count} 张图像进行了成功分割并保存了掩码。\")\n",
    "    print(f\"有 {segmentation_failed_count} 张图像的分割处理失败。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "papermill": {
     "duration": 0.044373,
     "end_time": "2025-04-30T05:46:59.122028",
     "exception": false,
     "start_time": "2025-04-30T05:46:59.077655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_probability_map(prob_map_tensor, threshold=0.5):\n",
    "    \"\"\"\n",
    "    对分割模型的概率图输出进行阈值化和后处理 (开运算, MCC, 闭运算/填充空洞)。\n",
    "\n",
    "    Args:\n",
    "        prob_map_tensor (torch.Tensor): 输入的概率图张量 (1 x N_Classes x H x W)，值在 [0, 1] 之间。\n",
    "                                        应已裁剪回原始图像尺寸。\n",
    "        threshold (float): 将概率图二值化的阈值。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (预测的后处理二值掩码 (numpy array, H x W), 模型直接输出的二值掩码 (numpy array, H x W))\n",
    "                返回的都是 0/1 的 NumPy 数组，不是 RGB 图像。\n",
    "                如果输入无效 (例如概率图为 None)，返回 (None, None)。\n",
    "    \"\"\"\n",
    "    if prob_map_tensor is None:\n",
    "        return None, None\n",
    "\n",
    "    # 确保输入是 CPU 上的 Tensor\n",
    "    if prob_map_tensor.device.type != 'cpu':\n",
    "        prob_map_tensor = prob_map_tensor.cpu()\n",
    "\n",
    "    # 转换为 NumPy 数组 (移除批次和类别维度，假设 N_Classes=1)\n",
    "    prob_map_np = prob_map_tensor.squeeze().numpy() # (H, W) float [0, 1]\n",
    "\n",
    "    # --- 阈值化 ---\n",
    "    # 模型直接输出的二值掩码 (无后处理，仅阈值化)\n",
    "    final_mask_model_output_raw = prob_map_np # Get 0/1 float array before threshold\n",
    "    final_mask_model_output = (final_mask_model_output_raw > threshold).astype(np.uint8) # Apply threshold\n",
    "\n",
    "    # --- 开始后处理 (在阈值化后的二值掩码上进行) ---\n",
    "    final_mask = final_mask_model_output.copy() # 从模型直接输出并阈值化后的结果开始\n",
    "\n",
    "    # --- 1.开运算断开细小连接 ---\n",
    "    if np.sum(final_mask) > 0:\n",
    "        selem_opening = disk(6)\n",
    "        final_mask_opened = binary_opening(final_mask, selem_opening)\n",
    "        final_mask = final_mask_opened.astype(np.uint8)\n",
    "\n",
    "    # --- 2.保留最大连通区域 (MCC) ---\n",
    "    final_mask_binary = (final_mask > 0).astype(np.uint8)\n",
    "    if np.sum(final_mask_binary) > 0:\n",
    "        labeled_mask = label(final_mask_binary)\n",
    "        if labeled_mask.max() == 0:\n",
    "            final_mask = np.zeros_like(final_mask)\n",
    "        else:\n",
    "            # Find the largest component label\n",
    "            unique_labels, counts = np.unique(labeled_mask[labeled_mask > 0], return_counts=True)\n",
    "            if len(unique_labels) > 0:\n",
    "                largest_component_label = unique_labels[np.argmax(counts)]\n",
    "                # Only keep the largest component\n",
    "                final_mask = (labeled_mask == largest_component_label).astype(np.uint8)\n",
    "            else: # Should not happen if labeled_mask.max() > 0\n",
    "                final_mask = np.zeros_like(final_mask)\n",
    "    else:\n",
    "        final_mask = np.zeros_like(final_mask) # If mask is empty, MCC result is also empty\n",
    "\n",
    "    # --- 3.填充小空洞 ---\n",
    "    if np.sum(final_mask) > 0:\n",
    "        final_mask_filled = binary_fill_holes(final_mask)\n",
    "        final_mask = final_mask_filled.astype(np.uint8)\n",
    "\n",
    "    # --- 后处理结束 ---\n",
    "\n",
    "    return final_mask, final_mask_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {
    "papermill": {
     "duration": 0.034671,
     "end_time": "2025-04-30T05:46:59.191438",
     "exception": false,
     "start_time": "2025-04-30T05:46:59.156767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.探测最佳阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "papermill": {
     "duration": 0.046502,
     "end_time": "2025-04-30T05:46:59.273593",
     "exception": false,
     "start_time": "2025-04-30T05:46:59.227091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coefficient_from_probs(prob_map, y_true, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"计算预测概率图和真实掩码之间的Dice系数，直接使用概率图和阈值。\"\"\"\n",
    "    # 确保输入是浮点类型\n",
    "    y_true = y_true.float()\n",
    "    prob_map = prob_map.float()\n",
    "\n",
    "    # 应用阈值将概率转换为二值掩码\n",
    "    y_pred = (prob_map > threshold).float()\n",
    "\n",
    "    # 压平张量 (确保维度一致，对于单个样本，N=1, C=1)\n",
    "    y_pred = y_pred.contiguous().view(-1)\n",
    "    y_true = y_true.contiguous().view(-1)\n",
    "\n",
    "    # 计算交集\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "\n",
    "    # 计算Dice系数\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "\n",
    "    return dice.item()\n",
    "\n",
    "def calculate_average_dice_for_samples(\n",
    "    threshold,\n",
    "    prob_maps,   # List of probability map tensors (already on CPU)\n",
    "    gt_masks,    # List of ground truth mask tensors (already on CPU)\n",
    "    ):\n",
    "    \"\"\"\n",
    "    计算给定阈值在预先计算好的概率图和真实掩码样本集上的平均Dice系数。\n",
    "\n",
    "    Args:\n",
    "        threshold (float): 待评估的分割阈值。\n",
    "        prob_maps (list): 包含每个样本概率图的列表 (torch.Tensor, 1x1xHxW, CPU)。\n",
    "        gt_masks (list): 包含每个样本真实掩码的列表 (torch.Tensor, 1x1xHxW, CPU)。\n",
    "\n",
    "    Returns:\n",
    "        float: 给定阈值下的平均Dice系数。\n",
    "    \"\"\"\n",
    "    if not prob_maps or len(prob_maps) != len(gt_masks):\n",
    "        return 0.0 # 无效输入\n",
    "\n",
    "    total_dice = 0.0\n",
    "    for i in range(len(prob_maps)):\n",
    "        prob_map = prob_maps[i]\n",
    "        gt_mask = gt_masks[i]\n",
    "        \n",
    "        # 确保尺寸匹配（虽然 predict_probability_map_with_tiling 和加载时已处理，这里再次检查）\n",
    "        if prob_map.shape != gt_mask.shape:\n",
    "            print(f\"警告: 样本 {i} 的概率图和掩码尺寸不匹配 ({prob_map.shape} vs {gt_mask.shape})，跳过。\")\n",
    "            continue\n",
    "\n",
    "        total_dice += dice_coefficient_from_probs(prob_map, gt_mask, threshold=threshold)\n",
    "\n",
    "    return total_dice / len(prob_maps) if len(prob_maps) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "papermill": {
     "duration": 0.055547,
     "end_time": "2025-04-30T05:46:59.365098",
     "exception": false,
     "start_time": "2025-04-30T05:46:59.309551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_segmentation_threshold_binary_search(\n",
    "    segmentation_model,\n",
    "    image_dir,        # 指向 train 目录 (包含 0001/, 0002/ 等子文件夹)\n",
    "    label_file_path,  # 指向 train_classification_label.xlsx\n",
    "    patch_size,\n",
    "    predict_stride,\n",
    "    device,\n",
    "    segmentation_batch_size,\n",
    "    num_tuning_samples=15, # 用于阈值调优的样本数量 (增加样本数提高稳定性)\n",
    "    search_range=(0.40, 0.99), # 搜索范围\n",
    "    search_precision=0.01,    # 目标精度\n",
    "    debug_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    在训练集子集上使用区间逼近法自动寻找最佳分割阈值。\n",
    "    在调试模式下，使用缩放后的图像和对应的缩放掩码进行调优。\n",
    "\n",
    "    Args:\n",
    "        segmentation_model (nn.Module): 训练好的分割模型。\n",
    "        image_dir (str): 包含原始训练图像文件夹 (如 0001, 0002...) 的目录。\n",
    "        label_file_path (str): 包含图像标签的Excel文件路径。\n",
    "        patch_size (int): 分割模型 Patch 大小 (边长)。\n",
    "        predict_stride (int): 分割模型预测时的步长。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        segmentation_batch_size (int): 分割模型推理时的批次大小。\n",
    "        num_tuning_samples (int): 用于阈值调优的随机样本数量。\n",
    "        search_range (tuple): 搜索的阈值范围 (low, high)。\n",
    "        search_precision (float): 目标精度，搜索停止时的区间宽度。\n",
    "        debug_mode (bool): 是否启用调试模式，处理缩放后的图像和掩码。\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        float: 在测试样本上获得最高平均 Dice 的最佳阈值。\n",
    "                如果处理失败或没有找到有病样本，返回一个默认阈值 (如 0.5)。\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 开始自动探测最佳分割阈值 (区间逼近) ---\")\n",
    "    if debug_mode:\n",
    "         print(\"注意: 调试模式下，阈值调优在 1/4 缩放后的图像上进行。\")\n",
    "    segmentation_model.eval() # 确保模型在评估模式\n",
    "\n",
    "    low, high = search_range\n",
    "    precision = search_precision\n",
    "\n",
    "    # 1. 读取标签并筛选有翼状胬肉的样本\n",
    "    try:\n",
    "        labels_df = pd.read_excel(label_file_path)\n",
    "        # 筛选出翼状胬肉样本 (标签 1 和 2)\n",
    "        pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        pterygium_folders = pterygium_df['Image'].astype(int).apply(lambda x: f\"{x:04d}\").tolist()\n",
    "\n",
    "        if not pterygium_folders:\n",
    "            print(\"警告: 在标签文件中未找到任何翼状胬肉样本。无法进行阈值调优。使用默认阈值 0.5。\")\n",
    "            return 0.5 # 没有有病样本，返回默认阈值\n",
    "\n",
    "        # 随机选择样本进行调优\n",
    "        num_tuning_samples = min(num_tuning_samples, len(pterygium_folders))\n",
    "        if num_tuning_samples == 0:\n",
    "            print(\"警告: 翼状胬肉样本数量不足以进行阈值调优。使用默认阈值 0.5。\")\n",
    "            return 0.5\n",
    "        sampled_folders = random.sample(pterygium_folders, num_tuning_samples)\n",
    "        print(f\"随机选择了 {num_tuning_samples} 个翼状胬肉样本进行阈值调优。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 标签文件未找到 {label_file_path}。无法进行阈值调优。使用默认阈值 0.5。\")\n",
    "        return 0.5\n",
    "    except Exception as e:\n",
    "        print(f\"读取或处理标签文件时出错: {e}。无法进行阈值调优。使用默认阈值 0.5。\")\n",
    "        return 0.5\n",
    "\n",
    "    # 2. 对选定的样本计算概率图和加载真实掩码 (处理缩放)\n",
    "    sample_prob_maps = [] # 存储每个样本的概率图 (CPU, 缩放后的尺寸)\n",
    "    sample_gt_masks = []  # 存储每个样本的真实掩码 (CPU, 0/1 Tensor, 缩放后的尺寸)\n",
    "    processed_tuning_count = 0\n",
    "\n",
    "    print(f\"\\n正在计算 {len(sampled_folders)} 个调优样本的概率图并加载真实掩码 (可能已缩放)...\")\n",
    "    for folder_name in tqdm(sampled_folders, desc=\"准备调优样本数据\"):\n",
    "        image_path = os.path.join(image_dir, folder_name, f\"{folder_name}.png\")\n",
    "        mask_path = os.path.join(image_dir, folder_name, f\"{folder_name}_label.png\")\n",
    "\n",
    "        if not os.path.exists(image_path) or not os.path.exists(mask_path):\n",
    "            print(f\"警告: 调优样本文件未找到 {folder_name} ({image_path} 或 {mask_path})，跳过此样本。\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 加载并预处理图像和掩码 (load_and_preprocess_image_mask 会根据 debug_mode 缩放)\n",
    "            image_tensor, gt_mask_tensor, _ = load_and_preprocess_image_mask(\n",
    "                 image_path,\n",
    "                 mask_path=mask_path,\n",
    "                 debug_mode=debug_mode,\n",
    "                 device=device # 加载到设备\n",
    "            )\n",
    "\n",
    "            if image_tensor is None or gt_mask_tensor is None:\n",
    "                 print(f\"警告: 加载或预处理调优样本 {folder_name} 的图像或掩码失败，跳过。\")\n",
    "                 continue\n",
    "\n",
    "            # 获取概率图 (predict_probability_map_from_tensor_with_tiling 接受 tensor)\n",
    "            # prob_map_tensor 会是 image_tensor 的尺寸 (1, 1, H_proc, W_proc)\n",
    "            prob_map_tensor = predict_probability_map_from_tensor_with_tiling(\n",
    "                segmentation_model, image_tensor, patch_size, predict_stride, device, segmentation_batch_size\n",
    "            )\n",
    "\n",
    "            if prob_map_tensor is None:\n",
    "                print(f\"警告: 获取调优样本 {folder_name} 的概率图失败，跳过。\")\n",
    "                # 清理显存\n",
    "                del image_tensor, gt_mask_tensor\n",
    "                if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "            # 确保真实掩码和概率图尺寸一致 (它们都应该是缩放后的尺寸)\n",
    "            if gt_mask_tensor.shape != prob_map_tensor.shape:\n",
    "                print(f\"警告: 调优样本 {folder_name} 的真实掩码尺寸 {gt_mask_tensor.shape} 与概率图尺寸 {prob_map_tensor.shape} 不匹配，跳过。\")\n",
    "                 # 清理显存\n",
    "                del image_tensor, gt_mask_tensor, prob_map_tensor\n",
    "                if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "            # 将数据移回 CPU 存储以备后续快速访问\n",
    "            sample_prob_maps.append(prob_map_tensor.cpu())\n",
    "            sample_gt_masks.append(gt_mask_tensor.cpu())\n",
    "\n",
    "            processed_tuning_count += 1\n",
    "\n",
    "             # 清理显存\n",
    "            del image_tensor, gt_mask_tensor, prob_map_tensor\n",
    "            if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"处理调优样本 {folder_name} 时出错: {e}，跳过。\")\n",
    "            if device.type == 'cuda': torch.cuda.empty_cache() # 尝试清理显存\n",
    "\n",
    "\n",
    "    if processed_tuning_count == 0:\n",
    "        print(\"警告: 所有用于阈值调优的样本处理失败。无法进行阈值调优。使用默认阈值 0.5。\")\n",
    "        return 0.5 # 所有样本处理失败，返回默认阈值\n",
    "\n",
    "    # 3. 执行区间逼近搜索\n",
    "    best_threshold = low # 初始化最佳阈值为区间的起始点\n",
    "    best_avg_dice = -1.0\n",
    "\n",
    "    print(f\"\\n开始在范围 [{low:.2f}, {high:.2f}] 内进行阈值区间逼近搜索 (精度要求: {precision:.2f})...\")\n",
    "\n",
    "    # ... 区间逼近搜索逻辑保持不变，它在 sample_prob_maps 和 sample_gt_masks (CPU 上的列表) 上运行 ...\n",
    "    # 这部分逻辑不涉及设备和张量操作，所以无需修改\n",
    "\n",
    "    # 初始评估区间的两端点和中点，确保 best_avg_dice 有初始值\n",
    "    initial_thresholds = sorted(list(set([low, high] + [low + (high - low) / 2.0])))\n",
    "    # 增加一些中间点评估，特别在范围较大的时候\n",
    "    if (high - low) > 0.1: # 如果范围大于0.1，增加更多采样点\n",
    "        initial_thresholds.extend([low + (high - low) * i / 10.0 for i in range(1, 10)])\n",
    "        initial_thresholds = sorted(list(set(initial_thresholds)))\n",
    "\n",
    "\n",
    "    for t in initial_thresholds:\n",
    "         if t >= search_range[0] and t <= search_range[1]: # 确保在原始搜索范围内\n",
    "            avg_dice = calculate_average_dice_for_samples(t, sample_prob_maps, sample_gt_masks)\n",
    "            if avg_dice > best_avg_dice:\n",
    "                best_avg_dice = avg_dice\n",
    "                best_threshold = t\n",
    "\n",
    "\n",
    "    # 三分法迭代\n",
    "    search_iterations = 0\n",
    "    max_iterations = 100 # 避免极端情况下的死循环\n",
    "\n",
    "    pbar_search = tqdm(total=int(np.ceil(np.log((search_range[1] - search_range[0]) / precision) / np.log(1.5))) + 5, desc=\"搜索迭代\", leave=False) # 粗略估计迭代次数，加点余量\n",
    "\n",
    "    current_low, current_high = low, high # 使用临时变量进行迭代\n",
    "    while (current_high - current_low) > precision and search_iterations < max_iterations:\n",
    "        search_iterations += 1\n",
    "        # 三分点\n",
    "        m1 = current_low + (current_high - current_low) / 3.0\n",
    "        m2 = current_high - (current_high - current_low) / 3.0\n",
    "\n",
    "        # 计算两个点的平均 Dice\n",
    "        avg_dice_m1 = calculate_average_dice_for_samples(m1, sample_prob_maps, sample_gt_masks)\n",
    "        avg_dice_m2 = calculate_average_dice_for_samples(m2, sample_prob_maps, sample_gt_masks)\n",
    "\n",
    "        # 更新最佳阈值 (可能会在 m1 或 m2)\n",
    "        if avg_dice_m1 > best_avg_dice:\n",
    "            best_avg_dice = avg_dice_m1\n",
    "            best_threshold = m1\n",
    "        if avg_dice_m2 > best_avg_dice:\n",
    "            best_avg_dice = avg_dice_m2\n",
    "            best_threshold = m2\n",
    "\n",
    "        # 缩小搜索区间\n",
    "        if avg_dice_m1 < avg_dice_m2:\n",
    "            current_low = m1\n",
    "        else:\n",
    "            current_high = m2\n",
    "\n",
    "        pbar_search.update(1) # 每迭代一次更新进度条\n",
    "\n",
    "\n",
    "    pbar_search.close() # 关闭进度条\n",
    "\n",
    "    # 在最后缩小后的区间 [low, high] 内，最佳阈值应该是记录的 best_threshold\n",
    "    # 也可以选择评估最终区间的端点\n",
    "    avg_dice_low_final = calculate_average_dice_for_samples(current_low, sample_prob_maps, sample_gt_masks)\n",
    "    avg_dice_high_final = calculate_average_dice_for_samples(current_high, sample_prob_maps, sample_gt_masks)\n",
    "\n",
    "    if avg_dice_low_final > best_avg_dice:\n",
    "        best_avg_dice = avg_dice_low_final\n",
    "        best_threshold = current_low\n",
    "    if avg_dice_high_final > best_avg_dice:\n",
    "        best_avg_dice = avg_dice_high_final\n",
    "        best_threshold = current_high\n",
    "\n",
    "\n",
    "    print(\"\\n--- 阈值调优结果 ---\")\n",
    "    print(f\"经过 {search_iterations} 次迭代，最终搜索区间 (可能): [{current_low:.4f}, {current_high:.4f}]\") # 打印迭代后的区间\n",
    "    print(f\"找到的最佳阈值: {best_threshold:.4f} (在调优样本上平均 Dice: {best_avg_dice:.4f})\")\n",
    "    print(\"--- 阈值调优完成 ---\")\n",
    "\n",
    "    # 返回最佳阈值\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "papermill": {
     "duration": 78.388978,
     "end_time": "2025-04-30T05:48:17.796573",
     "exception": false,
     "start_time": "2025-04-30T05:46:59.407595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_inference_batch_size = int(2.5*(tpu_batch_size if _xla_available else (cuda_batch_size if torch.cuda.is_available() else windows_batch_size))) # 可以根据显存调整\n",
    "\n",
    "# 调用函数找到最佳阈值\n",
    "prediction_threshold = find_best_segmentation_threshold_binary_search(\n",
    "    segmentation_model=loaded_model,\n",
    "    image_dir=INPUT_IMAGE_DIR ,\n",
    "    label_file_path=label_file,\n",
    "    patch_size=patch_size,\n",
    "    predict_stride=predict_stride,\n",
    "    device=device,\n",
    "    segmentation_batch_size=segmentation_inference_batch_size,\n",
    "    num_tuning_samples=60,\n",
    "    search_range=(0.40, 0.99),\n",
    "    search_precision=0.01,\n",
    "    debug_mode=DEBUG_MODE\n",
    ")\n",
    "\n",
    "prediction_threshold_rounded = round(prediction_threshold, 2)-0.1\n",
    "print(f\"用于最终预测的四舍五入阈值: {prediction_threshold_rounded:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {
    "papermill": {
     "duration": 0.034804,
     "end_time": "2025-04-30T05:48:17.869675",
     "exception": false,
     "start_time": "2025-04-30T05:48:17.834871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. 对测试图像进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "papermill": {
     "duration": 0.034729,
     "end_time": "2025-04-30T05:48:17.941236",
     "exception": false,
     "start_time": "2025-04-30T05:48:17.906507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 单张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "papermill": {
     "duration": 4.29771,
     "end_time": "2025-04-30T05:48:22.273463",
     "exception": false,
     "start_time": "2025-04-30T05:48:17.975753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from doctest import debug\n",
    "from re import DEBUG\n",
    "\n",
    "\n",
    "test_single_image_path = '/kaggle/input/pterygium/val_img/val_img/0473.png'\n",
    "\n",
    "# 确保测试图片存在\n",
    "if not os.path.exists(test_single_image_path):\n",
    "    print(f\"错误: 测试单张图片未找到: {test_single_image_path}\")\n",
    "    print(\"请修改 'test_single_image_path' 变量为有效的图片路径。\")\n",
    "else:\n",
    "    print(f\"\\n--- 正在测试单张图片: {os.path.basename(test_single_image_path)} ---\")\n",
    "\n",
    "    segmentation_batch_size_single = int(2.5*(tpu_batch_size if _xla_available else (cuda_batch_size if torch.cuda.is_available() else windows_batch_size)))\n",
    "    try:\n",
    "        processed_mask_np_01, model_output_mask_np_01,prob_map = process_single_image_for_segmentation(\n",
    "            model=loaded_model, # 分割模型\n",
    "            image_path=test_single_image_path,\n",
    "            patch_size=patch_size,\n",
    "            stride=predict_stride,\n",
    "            device=device,\n",
    "            batch_size=segmentation_batch_size_single,\n",
    "            threshold=prediction_threshold,\n",
    "            debug_mode=DEBUG_MODE\n",
    "        )\n",
    "\n",
    "        # --- 可视化结果 ---\n",
    "        if processed_mask_np_01 is not None:\n",
    "            try:\n",
    "                # 加载原始图像用于显示\n",
    "                original_image_pil = Image.open(test_single_image_path).convert('RGB')\n",
    "                original_image_np = np.array(original_image_pil) # HWC, uint8\n",
    "\n",
    "                # 确保掩码尺寸与原图尺寸一致\n",
    "                if original_image_np.shape[:2] != processed_mask_np_01.shape:\n",
    "                     print(f\"警告: 分割结果尺寸 {processed_mask_np_01.shape} 与原图尺寸 {original_image_np.shape[:2]} 不匹配，可能存在问题。\")\n",
    "                     # 如果尺寸不匹配，插值到原图尺寸 (可选，但可能不准确)\n",
    "                     # processed_mask_np_01 = cv2.resize(processed_mask_np_01, (original_image_np.shape[1], original_image_np.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                # 创建 RGB 格式的可视化掩码 (前景为红色 128,0,0)\n",
    "                # 注意：这不是保存到文件的格式，只是为了方便 plt.imshow 可视化\n",
    "                visual_mask_rgb = np.zeros_like(original_image_np)\n",
    "                visual_mask_rgb[processed_mask_np_01 == 1, 0] = 128 # R通道设为128\n",
    "\n",
    "                # 将原始图像和掩码叠加显示 (可选，用于更直观展示)\n",
    "                # overlay_img = original_image_np.copy()\n",
    "                # overlay_img[processed_mask_np_01 == 1] = visual_mask_rgb[processed_mask_np_01 == 1] # 将红色前景区域叠加到原图\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "                # 显示原始图像\n",
    "                axes[0].imshow(original_image_np)\n",
    "                axes[0].set_title(f\"原始图像: {os.path.basename(test_single_image_path)}\")\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                # 显示后处理的预测掩码 (0/1 数组)\n",
    "                # 使用 'gray' cmap 可以清晰显示二值掩码\n",
    "                axes[1].imshow(processed_mask_np_01, cmap='gray', vmin=0, vmax=1) # vmin/vmax确保颜色映射正确\n",
    "                axes[1].set_title(f\"后处理预测掩码 (阈值: {prediction_threshold:.2f})\")\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # 如果你想显示模型直接输出的掩码 (无后处理)，可以添加第三个图\n",
    "                # fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                # axes[2].imshow(model_output_mask_np_01, cmap='gray', vmin=0, vmax=1)\n",
    "                # axes[2].set_title(f\"模型原始输出掩码 (阈值: {prediction_threshold:.2f})\")\n",
    "                # axes[2].axis('off')\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"可视化预测结果时出错: {e}\")\n",
    "        else:\n",
    "            print(f\"调用 process_single_image_for_segmentation 处理 {os.path.basename(test_single_image_path)} 失败，无法可视化。\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理单张图片 {os.path.basename(test_single_image_path)} 时出错: {e}\")\n",
    "        processed_mask_np_01 = None # 处理失败，设置为 None\n",
    "        model_output_mask_np_01 = None # 处理失败，设置为 None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {
    "papermill": {
     "duration": 0.042221,
     "end_time": "2025-04-30T05:48:22.359214",
     "exception": false,
     "start_time": "2025-04-30T05:48:22.316993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 批量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "papermill": {
     "duration": 380.898014,
     "end_time": "2025-04-30T05:54:43.297945",
     "exception": false,
     "start_time": "2025-04-30T05:48:22.399931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 调用新的目录处理函数进行预测\n",
    "predict_masks_for_directory(\n",
    "    segmentation_model=loaded_model,\n",
    "    classification_model=classification_model,\n",
    "    image_dir=val_image_dir,\n",
    "    output_mask_dir=output_mask_dir,\n",
    "    output_mask_model_output_dir=output_mask_model_output_dir,\n",
    "    output_prob_map_dir=output_mask_prob_dir,\n",
    "    patch_size=patch_size,\n",
    "    predict_stride=predict_stride,\n",
    "    device=device,\n",
    "    segmentation_batch_size=int(2.5*(tpu_batch_size if _xla_available else (cuda_batch_size if torch.cuda.is_available() else windows_batch_size))),\n",
    "    segmentation_threshold=prediction_threshold,\n",
    "    classification_transform=val_transform,\n",
    "    debug_mode=DEBUG_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "papermill": {
     "duration": 41.34156,
     "end_time": "2025-04-30T05:55:24.681365",
     "exception": false,
     "start_time": "2025-04-30T05:54:43.339805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_visualize = 10\n",
    "\n",
    "if not val_image_dir or not os.path.isdir(val_image_dir):\n",
    "    print(f\"错误：找不到或无效的测试图像目录 {val_image_dir}，无法进行可视化。\")\n",
    "else:\n",
    "    # 获取目录下所有 .png 图像文件的完整路径列表\n",
    "    all_val_image_files = glob.glob(os.path.join(val_image_dir, '*.png')) # 你可以根据需要修改 '*.png'\n",
    "\n",
    "    if not all_val_image_files:\n",
    "        print(f\"警告: 在目录 {val_image_dir} 中未找到图像文件，无法可视化。\")\n",
    "    else:\n",
    "        # 确保样本数量不超过实际找到的文件数量\n",
    "        num_visualize = min(num_visualize, len(all_val_image_files))\n",
    "\n",
    "        if num_visualize > 0:\n",
    "            # 从文件路径列表中随机抽样\n",
    "            sample_paths = random.sample(all_val_image_files, num_visualize)\n",
    "            print(f\"\\n可视化 {num_visualize} 个预测结果...\")\n",
    "\n",
    "            for img_path in sample_paths: # 现在 img_path 是一个有效的图像文件路径字符串\n",
    "                try:\n",
    "                    # 加载原始图像\n",
    "                    original_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    # 构建对应的预测掩码文件的路径\n",
    "                    base_name = os.path.basename(img_path)\n",
    "                    file_stem = os.path.splitext(base_name)[0]\n",
    "                    mask_filename = f\"{file_stem}.png\" # 假设保存的掩码文件名与原图名相同\n",
    "                    predicted_mask_path = os.path.join(output_mask_dir, mask_filename)\n",
    "\n",
    "                    # 检查预测掩码文件是否存在并加载\n",
    "                    if os.path.exists(predicted_mask_path):\n",
    "                        predicted_mask_image = Image.open(predicted_mask_path) # 加载之前保存的RGB掩码\n",
    "\n",
    "                        # 创建绘图\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                        # 显示原始图像\n",
    "                        axes[0].imshow(original_image)\n",
    "                        axes[0].set_title(f\"原始图像: {base_name}\")\n",
    "                        axes[0].axis('off')\n",
    "\n",
    "                        # 显示对应的预测掩码\n",
    "                        axes[1].imshow(predicted_mask_image) # 显示加载的对应掩码\n",
    "                        axes[1].set_title(\"预测掩码 (RGB 128,0,0)\")\n",
    "                        axes[1].axis('off')\n",
    "\n",
    "                        plt.tight_layout() # 调整布局防止重叠\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print(f\"警告：找不到预测掩码文件 {predicted_mask_path}，无法可视化此样本。\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    # 这个 except 现在处理的是真正的文件加载或绘图错误\n",
    "                    print(f\"可视化图像 {img_path} 时出错: {e}\")\n",
    "        else:\n",
    "            print(\"没有测试图像可供可视化 (num_visualize <= 0 或未找到文件)。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {
    "papermill": {
     "duration": 0.089854,
     "end_time": "2025-04-30T05:55:24.862583",
     "exception": false,
     "start_time": "2025-04-30T05:55:24.772729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. 压缩结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "papermill": {
     "duration": 0.093152,
     "end_time": "2025-04-30T05:55:25.037513",
     "exception": false,
     "start_time": "2025-04-30T05:55:24.944361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zip_directory(directory_path):\n",
    "    zip_file_path = f\"{directory_path}.zip\"\n",
    "    if os.path.exists(directory_path) and os.listdir(directory_path):\n",
    "        print(f\"开始压缩目录: {directory_path}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                files_to_zip = glob.glob(os.path.join(directory_path, '*'))\n",
    "                files_to_zip = [f for f in files_to_zip if os.path.isfile(f)]\n",
    "\n",
    "                if not files_to_zip:\n",
    "                    print(f\"警告: 目录 {directory_path} 为空或只包含子目录，无需压缩文件。\")\n",
    "                else:\n",
    "                    # 使用arcname只保留文件名，避免在zip文件中包含完整的原始路径结构\n",
    "                    for file in tqdm(files_to_zip, desc=f\"压缩文件到 {os.path.basename(zip_file_path)}\"):\n",
    "                        zipf.write(file, arcname=os.path.basename(file))\n",
    "                    print(f\"预测结果已成功压缩到: {zip_file_path}\")\n",
    "\n",
    "                    print(f\"删除原始掩码文件于: {directory_path}\")\n",
    "                    shutil.rmtree(directory_path)\n",
    "                    print(f\"原始目录 {directory_path} 已被删除。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"处理目录 {directory_path} 时发生错误: {e}\")\n",
    "    else:\n",
    "        print(f\"目录 {directory_path} 不存在或为空，跳过压缩和删除步骤。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "papermill": {
     "duration": 0.306445,
     "end_time": "2025-04-30T05:55:25.424977",
     "exception": false,
     "start_time": "2025-04-30T05:55:25.118532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    print(\"检测到Colab或Kaggle环境，将进行结果压缩和清理。\")\n",
    "    zip_directory(output_mask_dir)\n",
    "    zip_directory(output_mask_model_output_dir)\n",
    "    zip_directory(output_mask_prob_dir)\n",
    "\n",
    "print(\"\\n预测处理完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "papermill": {
     "duration": 1.223166,
     "end_time": "2025-04-30T05:55:26.730968",
     "exception": false,
     "start_time": "2025-04-30T05:55:25.507802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(OUTPUT_PATCH_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {
    "papermill": {
     "duration": 0.082893,
     "end_time": "2025-04-30T05:55:26.896956",
     "exception": false,
     "start_time": "2025-04-30T05:55:26.814063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {
    "papermill": {
     "duration": 0.083502,
     "end_time": "2025-04-30T05:55:27.065371",
     "exception": false,
     "start_time": "2025-04-30T05:55:26.981869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SHAP分析\n",
    "16G显存居然不够跑SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "papermill": {
     "duration": 0.090333,
     "end_time": "2025-04-30T05:55:27.237423",
     "exception": false,
     "start_time": "2025-04-30T05:55:27.147090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## --- 1. 准备工作 ---\n",
    "## 确保模型已加载最佳权重并处于评估模式\n",
    "#if 'loaded_model' not in locals().keys():\n",
    "#    print(\"错误：模型未加载。执行模型加载步骤。\")\n",
    "#    loaded_model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "#    if os.path.exists(model_save_path):\n",
    "#        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))\n",
    "#        print(f\"从 {model_save_path} 重新加载模型权重。\")\n",
    "#    else:\n",
    "#        raise FileNotFoundError(\"无法找到模型权重文件。\")\n",
    "#\n",
    "#loaded_model.eval()\n",
    "#\n",
    "## 确保验证数据集和加载器存在\n",
    "#if 'val_dataset_offline' not in locals() or val_dataset_offline is None or 'val_loader' not in locals() or val_loader is None:\n",
    "#    print(\"错误：验证数据集或加载器未定义。无法执行 SHAP 分析。\")\n",
    "#    raise \"错误：验证数据集或加载器未定义。无法执行 SHAP 分析。\"\n",
    "#\n",
    "#print(f\"使用包含 {len(val_dataset_offline)} 个样本的验证集进行 SHAP 分析。\")\n",
    "#\n",
    "## --- 2. 计算每个验证样本的 Dice 分数 ---\n",
    "#val_results = [] # 存储 (dice_score, image_tensor, mask_tensor, index)\n",
    "#print(\"正在计算验证集中每个样本的 Dice 分数...\")\n",
    "#with torch.no_grad():\n",
    "#    # 使用原始的 val_loader，但确保 batch_size=1 以便单独处理\n",
    "#    # 或者创建一个新的 batch_size=1 的 loader\n",
    "#    temp_val_loader = DataLoader(\n",
    "#        val_dataset_offline,\n",
    "#        batch_size=1, # 每次处理一个样本\n",
    "#        shuffle=False, # 保持顺序\n",
    "#        num_workers=num_workers,\n",
    "#        pin_memory=not _xla_available and torch.cuda.is_available()\n",
    "#    )\n",
    "#\n",
    "#    for idx, (image, mask) in enumerate(tqdm(temp_val_loader, desc=\"Calculating Dice per sample\")):\n",
    "#        image, mask = image.to(device), mask.to(device)\n",
    "#        output = loaded_model(image)\n",
    "#        # 确保掩码尺寸匹配\n",
    "#        mask_downsampled = Fnn.interpolate(mask, size=output.shape[2:], mode='nearest')\n",
    "#        dice = dice_coefficient(output, mask_downsampled) # 计算单个样本的 Dice\n",
    "#        # 将数据移回 CPU 存储\n",
    "#        val_results.append((dice, image.cpu(), mask.cpu(), idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "papermill": {
     "duration": 0.093831,
     "end_time": "2025-04-30T05:55:27.414152",
     "exception": false,
     "start_time": "2025-04-30T05:55:27.320321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## --- 3. 排序并选择样本 ---\n",
    "#if device.type == 'cuda':\n",
    "#    torch.cuda.empty_cache()\n",
    "#val_results.sort(key=lambda x: x[0]) # 按 Dice 分数升序排序\n",
    "#num_explain = min(1, len(val_results) // 2)\n",
    "#if num_explain == 0 and len(val_results) > 0:\n",
    "#    num_explain = 1 # 至少解释一个，如果数据集很小\n",
    "#if len(val_results) < 2:\n",
    "#    print(\"验证集样本太少，无法选择最好和最差的样本进行解释。\")\n",
    "#else:\n",
    "#    worst_samples = val_results[:num_explain]\n",
    "#    best_samples = val_results[-num_explain:]\n",
    "#    print(f\"已选择 {num_explain} 个表现最差和 {num_explain} 个表现最好的样本进行解释。\")\n",
    "#\n",
    "#    # --- 4. 准备 SHAP 背景数据 ---\n",
    "#    num_background_samples = 32 # 选择少量训练样本作为背景\n",
    "#    if 'train_dataset_offline' in locals() and len(train_dataset_offline) >= num_background_samples:\n",
    "#        background_indices = np.random.choice(len(train_dataset_offline), num_background_samples, replace=False)\n",
    "#        # 只取图像部分，并确保在正确的设备上\n",
    "#        background_data = torch.stack([train_dataset_offline[i][0] for i in background_indices]).to(device)\n",
    "#        print(f\"使用 {num_background_samples} 个训练样本作为 SHAP 背景数据。\")\n",
    "#    \n",
    "#        # --- 5. 创建 SHAP 解释器 ---\n",
    "#        class SegmentationModelWrapperForSHAP(nn.Module):\n",
    "#            def __init__(self, model):\n",
    "#                super().__init__()\n",
    "#                self.model = model\n",
    "#\n",
    "#            def forward(self, x):\n",
    "#                logits = self.model(x) # (N, 1, H, W)\n",
    "#                # 对空间和通道维度求和\n",
    "#                scalar_output_per_sample = torch.sum(logits, dim=(1, 2, 3)) # Shape: (N,)\n",
    "#                return scalar_output_per_sample.unsqueeze(1) # Returns shape: (N, 1)\n",
    "#\n",
    "#        # 确保原始模型在评估模式和正确设备上\n",
    "#        loaded_model.eval()\n",
    "#        loaded_model.to(device)\n",
    "#\n",
    "#        # 创建包装后的模型实例，并移到设备\n",
    "#        shap_compatible_model = SegmentationModelWrapperForSHAP(loaded_model).to(device)\n",
    "#        shap_compatible_model.eval()\n",
    "#\n",
    "#        print(\"创建 SHAP 解释器...\")\n",
    "#        explainer = shap.GradientExplainer(shap_compatible_model, background_data)\n",
    "#    \n",
    "#        # --- 6. 解释表现最差的样本 ---\n",
    "#        print(\"\\n--- 解释表现最差的样本 ---\")\n",
    "#        worst_images_tensor = torch.cat([s[1] for s in worst_samples], dim=0).to(device)\n",
    "#        worst_masks_tensor = torch.cat([s[2] for s in worst_samples], dim=0) # CPU\n",
    "#        worst_dices = [s[0] for s in worst_samples]\n",
    "#        print(f\"计算 {len(worst_samples)} 个最差样本的 SHAP 值...\")\n",
    "#        # shap_values 的形状: (N, C, H, W)，其中 C=1 (模型输出通道)\n",
    "#        shap_values_worst = explainer.shap_values(worst_images_tensor)\n",
    "#        print(\"SHAP 值计算完成。\")\n",
    "#        # 准备可视化数据\n",
    "#        # 反归一化图像\n",
    "#        images_np_worst = []\n",
    "#        mean = np.array([0.485, 0.456, 0.406])\n",
    "#        std = np.array([0.229, 0.224, 0.225])\n",
    "#        for img_tensor in worst_images_tensor.cpu():\n",
    "#            img_np = img_tensor.numpy().transpose(1, 2, 0) # CHW -> HWC\n",
    "#            img_np = std * img_np + mean\n",
    "#            img_np = np.clip(img_np, 0, 1)\n",
    "#            images_np_worst.append(img_np)\n",
    "#        images_np_worst = np.array(images_np_worst)\n",
    "#        # 准备 SHAP 值和标签用于绘图\n",
    "#        # shap_values_worst 是 (N, 1, H, W)\n",
    "#        # image_plot 需要 (N, H, W, C) 或 (N, C, H, W)\n",
    "#        # 我们将 SHAP 值视为单通道 \"图像\"\n",
    "#        shap_values_plot_worst = shap_values_worst.transpose(0, 2, 3, 1) # N, H, W, 1\n",
    "#        # 创建标签，包含 Dice 分数\n",
    "#        labels_worst = np.array([[f\"Dice: {d:.3f}\"] for d in worst_dices])\n",
    "#        print(\"生成最差样本的 SHAP 图像...\")\n",
    "#        # 由于 shap.image_plot 对多输出的处理方式，我们直接传入 shap_values_worst\n",
    "#        # 它会将这个单通道解释绘制出来\n",
    "#        shap.image_plot(shap_values_worst,\n",
    "#                        worst_images_tensor.cpu(), # 显示原始（归一化后）图像可能更清晰\n",
    "#                        # images_np_worst, # 或者显示反归一化图像\n",
    "#                        labels=labels_worst,\n",
    "#                        show=True)\n",
    "#        # --- 7. 解释表现最好的样本 ---\n",
    "#        print(\"\\n--- 解释表现最好的样本 ---\")\n",
    "#        best_images_tensor = torch.cat([s[1] for s in best_samples], dim=0).to(device)\n",
    "#        best_masks_tensor = torch.cat([s[2] for s in best_samples], dim=0) # CPU\n",
    "#        best_dices = [s[0] for s in best_samples]\n",
    "#        print(f\"计算 {len(best_samples)} 个最好样本的 SHAP 值...\")\n",
    "#        shap_values_best = explainer.shap_values(best_images_tensor)\n",
    "#        print(\"SHAP 值计算完成。\")\n",
    "#        # 准备可视化数据\n",
    "#        images_np_best = []\n",
    "#        for img_tensor in best_images_tensor.cpu():\n",
    "#            img_np = img_tensor.numpy().transpose(1, 2, 0) # CHW -> HWC\n",
    "#            img_np = std * img_np + mean\n",
    "#            img_np = np.clip(img_np, 0, 1)\n",
    "#            images_np_best.append(img_np)\n",
    "#        images_np_best = np.array(images_np_best)\n",
    "#        shap_values_plot_best = shap_values_best.transpose(0, 2, 3, 1) # N, H, W, 1\n",
    "#        labels_best = np.array([[f\"Dice: {d:.3f}\"] for d in best_dices])\n",
    "#        print(\"生成最好样本的 SHAP 图像...\")\n",
    "#        shap.image_plot(shap_values_best,\n",
    "#                        best_images_tensor.cpu(),\n",
    "#                        # images_np_best,\n",
    "#                        labels=labels_best,\n",
    "#                        show=True)\n",
    "#        \n",
    "#        # 清理 GPU 内存\n",
    "#        del worst_images_tensor, shap_values_worst, best_images_tensor, shap_values_best, background_data, explainer\n",
    "#        if device.type == 'cuda':\n",
    "#            torch.cuda.empty_cache()\n",
    "#    elif 'train_dataset_offline' not in locals():\n",
    "#        print(\"错误：找不到训练数据集 'train_dataset_offline'，无法选择 SHAP 背景数据。\")\n",
    "#    else:\n",
    "#        print(f\"错误：训练数据集样本数量 ({len(train_dataset_offline)}) 不足 {num_background_samples} 个，无法选择 SHAP 背景数据。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {
    "papermill": {
     "duration": 0.081657,
     "end_time": "2025-04-30T05:55:27.577531",
     "exception": false,
     "start_time": "2025-04-30T05:55:27.495874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 以测试集为例进行模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "papermill": {
     "duration": 324.283177,
     "end_time": "2025-04-30T06:00:51.941694",
     "exception": false,
     "start_time": "2025-04-30T05:55:27.658517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries\n",
    "import numpy as np\n",
    "import random\n",
    "def calculate_dice_np(mask_pred, mask_true, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    计算两个 0/1 NumPy 掩码之间的 Dice 系数。\n",
    "\n",
    "    Args:\n",
    "        mask_pred (numpy.ndarray): 预测掩码 (0 或 1)。\n",
    "        mask_true (numpy.ndarray): 真实掩码 (0 或 1)。\n",
    "        smooth (float): 平滑项，用于防止除以零。\n",
    "\n",
    "    Returns:\n",
    "        float: Dice 系数。\n",
    "    \"\"\"\n",
    "    # 确保是二值数组\n",
    "    mask_pred = mask_pred.astype(bool)\n",
    "    mask_true = mask_true.astype(bool)\n",
    "\n",
    "    intersection = np.sum(mask_pred & mask_true)\n",
    "    sum_masks = np.sum(mask_pred) + np.sum(mask_true)\n",
    "\n",
    "    if sum_masks == 0:\n",
    "        # 如果两个掩码都完全是背景，Dice 通常被认为是 1 (完美匹配)\n",
    "        return 1.0\n",
    "    else:\n",
    "        return (2. * intersection + smooth) / (sum_masks + smooth)\n",
    "\n",
    "def calculate_hd95_np(mask_pred, mask_true, voxel_spacing=(1, 1)):\n",
    "    \"\"\"\n",
    "    计算两个 0/1 NumPy 掩码之间的 95% Hausdorff 距离。\n",
    "    (基于 scipy.ndimage.distance_transform_edt)\n",
    "\n",
    "    Args:\n",
    "        mask_pred (numpy.ndarray): 预测掩码 (0 或 1)。\n",
    "        mask_true (numpy.ndarray): 真实掩码 (0 或 1)。\n",
    "        voxel_spacing (tuple): 图像的体素间距 (高, 宽)。默认为 (1, 1)。\n",
    "\n",
    "    Returns:\n",
    "        float: 95% Hausdorff 距离。如果任一掩码为空但另一个不为空，返回一个大数值 (表示无限距离)。\n",
    "               如果两个掩码都为空，返回 0。如果两个掩码完全相同，返回 0。\n",
    "    \"\"\"\n",
    "    # 确保是二值布尔数组\n",
    "    mask_pred = mask_pred.astype(bool)\n",
    "    mask_true = mask_true.astype(bool)\n",
    "\n",
    "    # 处理全背景或全前景的特殊情况\n",
    "    if np.all(~mask_true) and np.all(~mask_pred): # 两个都空\n",
    "        return 0.0\n",
    "    if np.all(mask_true) and np.all(mask_pred): # 两个都满 (理论上分割不会预测全满)\n",
    "         return 0.0\n",
    "\n",
    "    # 如果一个为空但另一个不为空\n",
    "    if np.all(~mask_true) and np.any(mask_pred):\n",
    "        return float('inf') # 或者一个很大的数，如 10000\n",
    "    if np.any(mask_true) and np.all(~mask_pred):\n",
    "        return float('inf') # 或者一个很大的数\n",
    "\n",
    "    # 计算距离变换 (距离从非零像素到最近的零像素)\n",
    "    # 为了计算边界间的距离，我们需要距离变换是从零像素到非零像素\n",
    "    # dist_true: 距离真实前景的距离 (前景内部为0，背景为正)\n",
    "    # dist_pred: 距离预测前景的距离 (前景内部为0，背景为正)\n",
    "    dist_true = distance_transform_edt(~mask_true, sampling=voxel_spacing)\n",
    "    dist_pred = distance_transform_edt(~mask_pred, sampling=voxel_spacing)\n",
    "\n",
    "    # 找到边界像素\n",
    "    # level=0.5 在 0/1 之间寻找边界\n",
    "    boundary_true = find_boundaries(mask_true, mode='inner', connectivity=1)\n",
    "    boundary_pred = find_boundaries(mask_pred, mode='inner', connectivity=1)\n",
    "\n",
    "    # 计算从预测边界到真实边界的距离 (使用真实距离图在预测边界处的值)\n",
    "    # dist_true[boundary_pred]: 预测边界点到最近的真实前景像素的距离\n",
    "    distances_pred_to_true = dist_true[boundary_pred]\n",
    "\n",
    "    # 计算从真实边界到预测边界的距离 (使用预测距离图在真实边界处的值)\n",
    "    distances_true_to_pred = dist_pred[boundary_true]\n",
    "\n",
    "    # 计算 95th 百分位数\n",
    "    # 需要处理边界是空的情况，虽然前面已经排除了掩码全空的情况\n",
    "    # 但有可能一个掩码非空，但边界是空的 (例如 1x1 的掩码)\n",
    "    hd1 = np.percentile(distances_pred_to_true, 95) if distances_pred_to_true.size > 0 else float('inf')\n",
    "    hd2 = np.percentile(distances_true_to_pred, 95) if distances_true_to_pred.size > 0 else float('inf')\n",
    "\n",
    "    # Hausdorff 距离是两个有向距离的最大值\n",
    "    hausdorff_distance = max(hd1, hd2)\n",
    "\n",
    "    # 如果计算结果是无穷大，可能是因为某个边界是空的（虽然掩码本身非空）\n",
    "    # 在实际图像分割中，这种情况很少见，除非 patch 太小或形态学处理异常\n",
    "    # 如果 mask_pred 和 mask_true shape 相同且非空，通常不会出现 inf\n",
    "    if np.isinf(hausdorff_distance):\n",
    "        print(\"警告: 计算 HD95 得到 Inf，可能因为边界为空。\")\n",
    "        # 可以选择返回一个预设的大值，而不是 inf\n",
    "        return 10000.0 # 返回一个较大的有限值\n",
    "\n",
    "    return hausdorff_distance\n",
    "\n",
    "def evaluate_full_images_random_subset(\n",
    "    segmentation_model,\n",
    "    original_train_image_dir, # 指向训练集原始大图的根目录 (如 /kaggle/input/pterygium/train/train)\n",
    "    val_original_ids,         # 在数据加载时被划分为验证集的原始图像 ID 列表 (如 ['0473', '0512', ...])\n",
    "    patch_size,\n",
    "    predict_stride,\n",
    "    device,\n",
    "    segmentation_batch_size,\n",
    "    segmentation_threshold,\n",
    "    num_evaluation_samples=10,\n",
    "    debug_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    在随机选择的验证集原始图像子集上评估分割模型的性能 (Dice 和 HD95)。\n",
    "\n",
    "    Args:\n",
    "        segmentation_model (nn.Module): 训练好的分割模型。\n",
    "        original_train_image_dir (str): 包含原始训练图像子文件夹 (如 0001, 0002...) 的目录。\n",
    "        val_original_ids (list): 在数据加载时被用于验证集的原始图像 ID 列表。\n",
    "        patch_size (int): 分割模型 Patch 大小 (边长)。\n",
    "        predict_stride (int): 切割 Patch 时的步长 (预测步长)。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        segmentation_batch_size (int): 分割模型推理时的批次大小。\n",
    "        segmentation_threshold (float): 分割结果的二值化阈值。\n",
    "        num_evaluation_samples (int): 用于评估的随机样本数量。\n",
    "        debug_mode (bool): 是否启用调试模式 (影响 process_single_image_for_segmentation)。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (平均Dice系数, 平均HD95)\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 开始在随机 {num_evaluation_samples} 个验证集原始图像上评估 ---\")\n",
    "    if not val_original_ids:\n",
    "        print(\"错误: 验证集原始图像 ID 列表为空。无法进行评估。\")\n",
    "        return 0.0, float('inf')\n",
    "\n",
    "    # 随机选择评估样本的原始图像 ID\n",
    "    num_evaluation_samples = min(num_evaluation_samples, len(val_original_ids))\n",
    "    if num_evaluation_samples == 0:\n",
    "         print(\"警告: 没有足够的验证集原始图像进行评估。\")\n",
    "         return 0.0, float('inf')\n",
    "\n",
    "    sampled_ids = random.sample(val_original_ids, num_evaluation_samples)\n",
    "    print(f\"已选择以下 {len(sampled_ids)} 个原始图像 ID 进行评估: {sampled_ids}\")\n",
    "\n",
    "    dice_scores = []\n",
    "    hd95_scores = []\n",
    "    processed_count = 0\n",
    "\n",
    "    # 确保模型在评估模式\n",
    "    segmentation_model.eval()\n",
    "\n",
    "    # 遍历选定的 ID 进行评估\n",
    "    for img_id in tqdm(sampled_ids, desc=\"评估原始图像\"):\n",
    "        img_folder_path = os.path.join(original_train_image_dir, img_id)\n",
    "        image_path = os.path.join(img_folder_path, f\"{img_id}.png\")\n",
    "        mask_path_gt = os.path.join(img_folder_path, f\"{img_id}_label.png\") # 真实掩码路径\n",
    "\n",
    "        if not os.path.exists(image_path) or not os.path.exists(mask_path_gt):\n",
    "            print(f\"警告: 评估图像或真实掩码文件未找到 {img_id}，跳过。\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- 获取预测掩码 (0/1 NumPy array, 已是原始尺寸) ---\n",
    "            # 注意: 这里我们不使用分类模型，直接对所有选中的图像进行分割，\n",
    "            #       因为我们选择的是 val_ids 中的有病样本，它们理论上都有翼状胬肉。\n",
    "            #       如果 val_ids 可能包含健康样本，则需要在这里集成分类过滤。\n",
    "            #       根据之前的逻辑，val_ids 是从所有独特原始 ID 中划分的，可能包含健康ID。\n",
    "            #       为了准确评估分割模型本身在有病样本上的表现，最好只评估有病样本。\n",
    "            #       但是，如果目的是评估整个级联流程，则应该包含健康样本并期望空掩码。\n",
    "            #       这里我们假设评估分割模型本身，所以选择的是 val_ids 中有 pterygium > 0 的 ID。\n",
    "            #       根据之前的 train/val split 逻辑，val_ids 来自所有唯一 ID，其中包含健康和病灶。\n",
    "            #       为了简化和符合“对应的mask”评估，我们直接使用 process_single_image_for_segmentation\n",
    "            #       如果它返回空掩码（对于健康样本），Dice 和 HD95 计算函数会处理。\n",
    "\n",
    "            processed_mask_np, _ , _ = process_single_image_for_segmentation(\n",
    "                model=segmentation_model,\n",
    "                image_path=image_path,\n",
    "                patch_size=patch_size,\n",
    "                stride=predict_stride,\n",
    "                device=device,\n",
    "                batch_size=segmentation_batch_size,\n",
    "                threshold=segmentation_threshold,\n",
    "                debug_mode=debug_mode\n",
    "            )\n",
    "\n",
    "            if processed_mask_np is None:\n",
    "                 print(f\"警告: 对图像 {img_id} 进行分割预测失败，跳过评估。\")\n",
    "                 continue # 预测失败，无法评估\n",
    "\n",
    "            # --- 加载真实掩码 (0/1 NumPy array) ---\n",
    "            # 注意: load_and_preprocess_image_mask 返回的是 Tensor，且会应用 debug_mode 缩放\n",
    "            # 我们需要加载原始尺寸的 NumPy 掩码作为 Ground Truth\n",
    "            gt_mask_pil = Image.open(mask_path_gt).convert('RGB')\n",
    "            gt_mask_np_rgb = np.array(gt_mask_pil)\n",
    "            gt_mask_np = (gt_mask_np_rgb[:, :, 0] == 128).astype(np.uint8) # 0/1 uint8\n",
    "\n",
    "            # 确保预测和真实掩码尺寸匹配\n",
    "            if processed_mask_np.shape != gt_mask_np.shape:\n",
    "                print(f\"警告: 图像 {img_id} 的预测掩码尺寸 {processed_mask_np.shape} 与真实掩码尺寸 {gt_mask_np.shape} 不匹配，跳过。\")\n",
    "                continue # 尺寸不匹配，跳过评估\n",
    "\n",
    "            # --- 计算指标 ---\n",
    "            dice = calculate_dice_np(processed_mask_np, gt_mask_np)\n",
    "            hd95 = calculate_hd95_np(processed_mask_np, gt_mask_np)\n",
    "\n",
    "            dice_scores.append(dice)\n",
    "            hd95_scores.append(hd95)\n",
    "            processed_count += 1\n",
    "\n",
    "            # 可选: 打印单个样本分数\n",
    "            # print(f\"样本 {img_id}: Dice={dice:.4f}, HD95={hd95:.2f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"评估图像 {img_id} 时出错: {e}，跳过。\")\n",
    "            # 尝试清理显存\n",
    "            if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # --- 计算平均分数 ---\n",
    "    avg_dice = np.mean(dice_scores) if dice_scores else 0.0\n",
    "    avg_hd95 = np.mean(hd95_scores) if hd95_scores else float('inf') # 如果没有计算到HD95，平均值设为无穷大\n",
    "\n",
    "    print(\"\\n--- 评估结果 ---\")\n",
    "    print(f\"在 {processed_count} 个样本上计算得到:\")\n",
    "    print(f\"平均 Dice 系数: {avg_dice:.4f}\")\n",
    "    if np.isinf(avg_hd95):\n",
    "         print(\"平均 HD95: Infinity (可能因为某些样本处理失败或没有有效边界)\")\n",
    "    else:\n",
    "        print(f\"平均 HD95: {avg_hd95:.2f}\")\n",
    "    print(\"----------------\")\n",
    "\n",
    "    return avg_dice, avg_hd95\n",
    "\n",
    "if 'loaded_model' not in locals().keys():\n",
    "    print(\"错误: 模型未加载。请先运行模型加载单元格。\")\n",
    "elif 'val_ids' not in locals().keys() or not val_ids:\n",
    "    print(\"错误: 验证集原始图像 ID 列表 (val_ids) 不存在或为空。请先成功运行数据加载单元格。\")\n",
    "else:\n",
    "    try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "            # 筛选出翼状胬肉样本 (标签 > 0) 的原始图像 ID\n",
    "            pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "            pterygium_original_ids = pterygium_df['Image'].astype(int).apply(lambda x: f\"{x:04d}\").tolist()\n",
    "            # 找到同时在验证集划分中且有翼状胬肉的图像 ID\n",
    "            val_pterygium_ids = [img_id for img_id in val_ids if img_id in pterygium_original_ids]\n",
    "    except Exception as e:\n",
    "        print(f'筛选翼状胬肉样本时出错，{e}。使用原始ID继续评估。')\n",
    "        val_pterygium_ids = val_ids\n",
    "\n",
    "    avg_dice_eval, avg_hd95_eval = evaluate_full_images_random_subset(\n",
    "        segmentation_model=loaded_model,\n",
    "        original_train_image_dir=INPUT_IMAGE_DIR,\n",
    "        val_original_ids=val_pterygium_ids,\n",
    "        patch_size=patch_size,\n",
    "        predict_stride=predict_stride,\n",
    "        device=device,\n",
    "        segmentation_batch_size=segmentation_inference_batch_size,\n",
    "        segmentation_threshold=prediction_threshold,\n",
    "        num_evaluation_samples=min(100, len(val_pterygium_ids)),\n",
    "        debug_mode=DEBUG_MODE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 318068,
     "modelInstanceId": 297546,
     "sourceId": 356962,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4574.001279,
   "end_time": "2025-04-30T06:00:55.987717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-30T04:44:41.986438",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
