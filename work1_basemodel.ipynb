{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.00543,
     "end_time": "2025-04-13T01:53:45.044748",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.039318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/work1_basemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "I8rV7E66jSoG",
    "papermill": {
     "duration": 0.004352,
     "end_time": "2025-04-13T01:53:45.053747",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.049395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 训练参数设置 =================\n",
    "train_lr=7e-4\n",
    "train_weight_decay=1e-4\n",
    "train_model=ResNet34Classifier # type: ignore\n",
    "num_epochs = 25\n",
    "log_interval = 10  # 每隔多少个批次打印一次日志\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "#colab_val_zip_path = \"/content/drive/My Drive/val.zip\"\n",
    "#colab_val_extract_path = \"/content/val/\"\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# =================== SHAP设置 =================\n",
    "shap_scaling_factor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():\n",
    "    \"\"\"\n",
    "    检查是否可能缺少 GUI 后端（例如，在无头服务器上运行）。\n",
    "    如果是这种情况，将 Matplotlib 后端设置为 'Agg' 以避免错误。\n",
    "\n",
    "    应该在首次导入 `matplotlib.pyplot` 之前调用此函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        # 尝试获取 IPython 实例\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "e-siDBWjjSo6",
    "papermill": {
     "duration": 11.426914,
     "end_time": "2025-04-13T01:53:56.485296",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.058382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shap\n",
    "import sys\n",
    "from PIL import Image\n",
    "import platform\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        os.system(r'wget -O simhei.ttf \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"')\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "FqZSY8dujSo8",
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-04-13T01:53:56.494490",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.490079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80",
    "papermill": {
     "duration": 0.023889,
     "end_time": "2025-04-13T01:53:56.522681",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.498792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # Google Drive 有每日下载次数限制，可能会导致下载失败\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.004176,
     "end_time": "2025-04-13T01:53:56.531483",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.527307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据 Resize\n",
    "这一步骤是将图像调整为224x224的大小，以适应模型输入要求。\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 428.90724,
     "end_time": "2025-04-13T02:01:05.443030",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.535790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "target_size = (224, 224) # 目标尺寸\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# --- Transformation Definition ---\n",
    "# We will perform Resize on GPU. ToTensor conversion happens before moving to GPU.\n",
    "# Normalization will be done *online* during training dataloading, not offline.\n",
    "resize_transform = transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "# BILINEAR is a good default. antialias=True is recommended for downsampling.\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_name = f\"{int(image_name):04d}\"\n",
    "        if os.path.exists(os.path.join(base_input_dir, f\"{image_name}.png\")):\n",
    "            # 验证集图像路径\n",
    "            input_path = os.path.join(base_input_dir, f\"{image_name}.png\")\n",
    "            os.makedirs(base_output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(base_output_dir, f\"{image_name}.{output_format.lower()}\")\n",
    "        else:\n",
    "            # 训练集图像路径\n",
    "            input_path = os.path.join(base_input_dir, image_name, f\"{image_name}.png\")\n",
    "            # Create corresponding output subdirectory if it doesn't exist\n",
    "            output_folder_path = os.path.join(base_output_dir, image_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "            output_path = os.path.join(output_folder_path, f\"{image_name}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "if not platform.system() == \"Windows\":\n",
    "    if 'google.colab' in sys.modules:\n",
    "        original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    elif os.path.exists(\"/kaggle/working\"):\n",
    "        original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    else:\n",
    "        print(\"错误: 无法识别的环境\")\n",
    "        exit(1)\n",
    "    image_dir = output_dir\n",
    "\n",
    "    print(f\"输入目录: {original_image_dir}\")\n",
    "    print(f\"输出目录: {output_dir}\")\n",
    "    print(f\"目标尺寸: {target_size}\")\n",
    "\n",
    "    # Create the main output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据，跳过resize步骤\")\n",
    "    else:\n",
    "        # Read label file to know which images to process\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 标签文件未找到 {label_file}\")\n",
    "            sys.exit(1) # Exit if label file is missing\n",
    "\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "\n",
    "        # Iterate through images listed in the label file\n",
    "        for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "            if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "        print(f\"\\n处理完成!\")\n",
    "        print(f\"成功处理图像数: {success_count}\")\n",
    "        print(f\"处理失败图像数: {error_count}\")\n",
    "        print(f\"处理后的图像保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "okNIq-rfjSo-",
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-04-13T02:01:05.452384",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.448028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 模拟高光的数据增强策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class AddRandomHighlight:\n",
    "    \"\"\"\n",
    "    一个 torchvision transform，用于在 PIL 图像上随机添加圆形高光。\n",
    "\n",
    "    参数:\n",
    "        p (float): 应用此变换的概率 (0 到 1)。\n",
    "        max_highlights (int): 单张图像上添加的最大高光数量（实际数量将在1到max_highlights之间随机选择）。\n",
    "        radius_range (tuple): 一个包含两个整数的元组 (min_radius, max_radius)，指定高光圆形的半径范围。\n",
    "        color (tuple): 一个包含三个整数的元组 (R, G, B)，指定高光的颜色 (默认为白色)。\n",
    "    \"\"\"\n",
    "    def __init__(self, p=0.5, max_highlights=3, radius_range=(5, 15), color=(255, 255, 255)):\n",
    "        if not 0.0 <= p <= 1.0:\n",
    "            raise ValueError(f\"概率 p 必须在 [0, 1] 范围内, 但得到 {p}\")\n",
    "        if not (isinstance(max_highlights, int) and max_highlights >= 1):\n",
    "            raise ValueError(f\"最大高光数 max_highlights 必须是 >= 1 的整数, 但得到 {max_highlights}\")\n",
    "        if not (isinstance(radius_range, tuple) and len(radius_range) == 2 and\n",
    "                isinstance(radius_range[0], int) and isinstance(radius_range[1], int) and\n",
    "                0 < radius_range[0] <= radius_range[1]):\n",
    "            raise ValueError(f\"半径范围 radius_range 必须是 (min, max) 形式的正整数元组，且 min <= max, 但得到 {radius_range}\")\n",
    "        if not (isinstance(color, tuple) and len(color) == 3 and all(0 <= c <= 255 for c in color)):\n",
    "            raise ValueError(f\"颜色 color 必须是 (R, G, B) 形式的元组，且值在 [0, 255] 范围内, 但得到 {color}\")\n",
    "            \n",
    "        self.p = p\n",
    "        self.max_highlights = max_highlights\n",
    "        self.radius_range = radius_range\n",
    "        self.color = color\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        对输入的 PIL 图像应用变换。\n",
    "\n",
    "        参数:\n",
    "            img (PIL.Image.Image): 输入的 PIL 图像。\n",
    "\n",
    "        返回:\n",
    "            PIL.Image.Image: 可能添加了高光的 PIL 图像。\n",
    "        \"\"\"\n",
    "        # 以概率 p 应用此变换\n",
    "        if random.random() < self.p:\n",
    "            # 复制图像以避免修改原始图像（如果原始图像后续还需使用）\n",
    "            # 如果这是 Compose 链中的一步，通常不需要显式复制\n",
    "            # img = img.copy() # 如果需要确保不修改原始输入，取消注释此行\n",
    "\n",
    "            # 随机决定生成多少个高光 (至少1个)\n",
    "            # 根据用户要求“小于四个”，我们生成 1 到 max_highlights (这里是3) 个\n",
    "            num_highlights = random.randint(1, self.max_highlights)\n",
    "            \n",
    "            # 获取图像尺寸\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 创建 ImageDraw 对象以在图像上绘制\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            for _ in range(num_highlights):\n",
    "                # 随机选择半径\n",
    "                radius = random.randint(self.radius_range[0], self.radius_range[1])\n",
    "                \n",
    "                # 随机选择圆心位置\n",
    "                # 确保圆心位置加上半径不会超出图像边界太多（允许部分圆在边缘）\n",
    "                # 稍微限制圆心范围，避免完全生成在图像外的圆心\n",
    "                center_x = random.randint(0, width - 1) \n",
    "                center_y = random.randint(0, height - 1)\n",
    "\n",
    "                # 计算圆形的边界框 (left, top, right, bottom)\n",
    "                # ellipse 方法绘制的是指定边界框内的椭圆，如果边界框是正方形，则为圆形\n",
    "                left = center_x - radius\n",
    "                top = center_y - radius\n",
    "                right = center_x + radius\n",
    "                bottom = center_y + radius\n",
    "                \n",
    "                # 绘制实心圆形高光\n",
    "                draw.ellipse([left, top, right, bottom], fill=self.color)\n",
    "            \n",
    "        # 返回处理后的图像（可能是原始图像或添加了高光的图像）\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 提供一个清晰的表示形式，方便调试\n",
    "        return f\"{self.__class__.__name__}(p={self.p}, max_highlights={self.max_highlights}, radius_range={self.radius_range}, color={self.color})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 应用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "11JDwC__jSo-",
    "papermill": {
     "duration": 1.465971,
     "end_time": "2025-04-13T02:01:06.922765",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.456794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # 先放大一点\n",
    "    transforms.RandomCrop((224, 224)), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=20), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    AddRandomHighlight(p=0.3, max_highlights=3, radius_range=(5, 12)), # 试试添加高光抑制模型关注高光问题\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=420, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=val_transform) # 使用验证变换\n",
    "\n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "eGn3VBzHjSo_",
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-04-13T02:01:06.932847",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.928379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建 ResNet 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b",
    "papermill": {
     "duration": 0.692259,
     "end_time": "2025-04-13T02:01:07.629659",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.937400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "    \n",
    "# 构建 ResNet34 模型\n",
    "from torchvision.models import ResNet34_Weights\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "    \n",
    "# 构建 ResNet50 模型\n",
    "from torchvision.models import ResNet50_Weights\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "# 定义模型\n",
    "model = train_model(num_classes=3).to(device)\n",
    "\n",
    "# 将模型移动到 GPU（如果可用）\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "dCYYlSWDjSpB",
    "papermill": {
     "duration": 0.005309,
     "end_time": "2025-04-13T02:01:07.640990",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.635681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 定义带正则化项的损失函数\n",
    "实现一个包含正则化项的损失函数，使用交叉熵损失作为基础，并添加特定的正则化项来抑制高光问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "9tVvDaYLjSpB",
    "papermill": {
     "duration": 0.012467,
     "end_time": "2025-04-13T02:01:07.658402",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.645935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义损失函数，包含正则化项以抑制高光问题\n",
    "class HighlightRegularizedLoss(nn.Module):\n",
    "    def __init__(self, base_loss_fn, lambda_reg=0.01):\n",
    "        super(HighlightRegularizedLoss, self).__init__()\n",
    "        self.base_loss_fn = base_loss_fn\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets, inputs):\n",
    "        # 基础损失（交叉熵损失）\n",
    "        base_loss = self.base_loss_fn(outputs, targets)\n",
    "\n",
    "        # 正则化项：抑制高光问题（假设高光区域的像素值接近1）\n",
    "        highlight_penalty = torch.mean(torch.clamp(inputs - 0.9, min=0) ** 2)\n",
    "\n",
    "        # 总损失\n",
    "        total_loss = base_loss #+ self.lambda_reg * highlight_penalty\n",
    "        return total_loss\n",
    "\n",
    "# 定义基础损失函数（交叉熵损失）\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义包含正则化项的损失函数\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "SjMzFIyejSpC",
    "papermill": {
     "duration": 0.004709,
     "end_time": "2025-04-13T02:01:07.668189",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.663480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 配置优化器和训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "0NUONUTJjSpC",
    "papermill": {
     "duration": 0.011721,
     "end_time": "2025-04-13T02:01:07.685038",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.673317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置优化器和学习率调度器\n",
    "# 在Adam优化器中添加 weight_decay 参数实现L2正则化\n",
    "optimizer = optim.AdamW(model.parameters(), lr=train_lr, weight_decay=train_weight_decay)\n",
    "\n",
    "# 定义学习率调度器，采用余弦退火调度策略\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "0dKuzXaHjSpD",
    "papermill": {
     "duration": 0.005112,
     "end_time": "2025-04-13T02:01:07.695500",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.690388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播和参数更新，并记录训练过程中的指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": 0.014088,
     "end_time": "2025-04-13T02:01:07.714614",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.700526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义早停类\n",
    "from copy import deepcopy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta # 允许的最小提升量\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "\n",
    "        # 根据模式确定比较操作\n",
    "        if self.mode == 'min':\n",
    "            self.delta_sign = -1 # 对于最小值模式，分数需要减少 delta\n",
    "        else: # mode == 'max'\n",
    "            self.delta_sign = 1 # 对于最大值模式，分数需要增加 delta\n",
    "\n",
    "    def __call__(self, val_score, model):\n",
    "        score = val_score # 直接使用验证分数\n",
    "\n",
    "        if self.best_score is None:\n",
    "            # 第一次调用，初始化最佳分数并保存权重\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            tqdm.write(f\"EarlyStopping: Initialized best score to {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            # 有足够的提升\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            tqdm.write(f\"EarlyStopping: Improvement found. Best score updated to {self.best_score:.4f}. Counter reset.\")\n",
    "        else:\n",
    "            # 没有足够的提升\n",
    "            self.counter += 1\n",
    "            tqdm.write(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best score remains {self.best_score:.4f}.')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                tqdm.write(\"EarlyStopping: Patience reached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "9wq254XdjSpD",
    "papermill": {
     "duration": 49.831481,
     "end_time": "2025-04-13T02:01:57.551548",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.720067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, run_identifier=\"Run\"):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持早停。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 要训练的模型实例。\n",
    "        train_loader (DataLoader): 训练数据加载器。\n",
    "        val_loader (DataLoader): 验证数据加载器。\n",
    "        criterion (nn.Module): 损失函数。\n",
    "        optimizer (Optimizer): 优化器。\n",
    "        scheduler (LRScheduler): 学习率调度器。\n",
    "        num_epochs (int): 最大训练轮数。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        run_identifier (str): 用于日志输出的运行标识符。\n",
    "\n",
    "    Returns:\n",
    "        tuple: 包含以下元素的元组:\n",
    "            - float: 最佳验证准确率 (%)。\n",
    "            - float: 最佳验证Macro F1分数。\n",
    "            - list: 每个epoch的验证准确率历史。\n",
    "            - dict: 最佳模型的state_dict。\n",
    "    \"\"\"\n",
    "    start_time_run = time.time()\n",
    "    print(f\"\\n--- {run_identifier}: 开始训练 ---\")\n",
    "\n",
    "    # 初始化此运行所需的状态对象\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max') # 与之前相同的早停设置\n",
    "    val_accuracy_history = [] # 存储当前运行的验证准确率历史\n",
    "    best_model_state_dict = None # 存储最佳模型的状态\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- 训练阶段 ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'{run_identifier} Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader_tqdm):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(inputs)\n",
    "                # 确保 criterion 也接收 inputs 如果它需要的话 (比如你的 HighlightRegularizedLoss)\n",
    "                if isinstance(criterion, HighlightRegularizedLoss):\n",
    "                    loss = criterion(outputs, targets, inputs)\n",
    "                else:\n",
    "                    loss = criterion(outputs, targets) # 标准损失函数\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%',\n",
    "                'lr': f'{current_lr:.1e}'\n",
    "            })\n",
    "\n",
    "        scheduler.step() # 每个epoch后更新学习率\n",
    "\n",
    "        # --- 验证阶段 ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(inputs)\n",
    "                    if isinstance(criterion, HighlightRegularizedLoss):\n",
    "                        loss = criterion(outputs, targets, inputs)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "        tqdm.write(f\"{run_identifier} Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "                f\"Train Acc: {100. * correct / total:.2f}%, Val Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "                f\"Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # --- 早停检查 ---\n",
    "        # 注意: EarlyStopping现在在内部使用tqdm.write\n",
    "        early_stopping(val_accuracy, model)\n",
    "        if early_stopping.early_stop:\n",
    "            tqdm.write(f\"{run_identifier}: EarlyStopping triggered at epoch {epoch + 1}.\")\n",
    "            best_model_state_dict = early_stopping.best_model_weights # 获取最佳权重\n",
    "            break # 提前结束训练\n",
    "\n",
    "    # 如果训练正常完成（未早停），也要保存最后的最佳权重\n",
    "    if not early_stopping.early_stop:\n",
    "        tqdm.write(f\"{run_identifier}: Training finished after {num_epochs} epochs.\")\n",
    "        best_model_state_dict = early_stopping.best_model_weights # 获取最后记录的最佳权重\n",
    "\n",
    "    # --- 使用最佳模型进行最终评估 ---\n",
    "    if best_model_state_dict:\n",
    "        model.load_state_dict(best_model_state_dict) # 加载最佳权重\n",
    "        model.eval()\n",
    "        final_all_targets = []\n",
    "        final_all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                final_all_targets.extend(targets.cpu().numpy())\n",
    "                final_all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        final_accuracy = accuracy_score(final_all_targets, final_all_predictions) * 100\n",
    "        final_macro_f1 = f1_score(final_all_targets, final_all_predictions, average='macro')\n",
    "    else:\n",
    "        # 如果由于某种原因没有最佳权重（例如训练在第一个epoch就停止且未改进）\n",
    "        final_accuracy = 0.0\n",
    "        final_macro_f1 = 0.0\n",
    "        tqdm.write(f\"{run_identifier}: Warning - Could not obtain best model weights.\")\n",
    "\n",
    "\n",
    "    end_time_run = time.time()\n",
    "    print(f\"--- {run_identifier}: 训练完成 ---\")\n",
    "    print(f\"最终验证准确率: {final_accuracy:.4f}%\")\n",
    "    print(f\"最终验证Macro F1: {final_macro_f1:.4f}\")\n",
    "    print(f\"本次运行耗时: {end_time_run - start_time_run:.2f} 秒\")\n",
    "\n",
    "    return final_accuracy, final_macro_f1, val_accuracy_history, best_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=num_epochs, # 使用之前定义的 num_epochs\n",
    "        device=device,\n",
    "        run_identifier=None\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "peWRUqyKjSpE",
    "papermill": {
     "duration": 0.006745,
     "end_time": "2025-04-13T02:01:57.566762",
     "exception": false,
     "start_time": "2025-04-13T02:01:57.560017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型性能\n",
    "在验证集上评估模型性能，计算准确率、混淆矩阵、F1分数等指标，并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "xzQdrZkTjSpE",
    "papermill": {
     "duration": 1.208724,
     "end_time": "2025-04-13T02:01:58.782451",
     "exception": false,
     "start_time": "2025-04-13T02:01:57.573727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 评估模型性能\n",
    "model.eval()  # 设置模型为评估模式\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "misclassified_indices = []\n",
    "misclassified_info = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测结果\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # 检查错误分类\n",
    "        misclassified_mask = predicted != targets\n",
    "        batch_indices = torch.arange(idx * val_loader.batch_size, (idx * val_loader.batch_size) + inputs.size(0))\n",
    "        batch_misclassified_indices = batch_indices[misclassified_mask.cpu()].tolist()\n",
    "        misclassified_indices.extend(batch_misclassified_indices)\n",
    "\n",
    "        # 收集所有目标和预测\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "macro_precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "macro_f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "print(f\"验证集准确率: {accuracy:.4f}\")\n",
    "print(f\"验证集Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"验证集Macro F1分数: {macro_f1:.4f}\")\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"健康\", \"建议观察\", \"建议手术\"],\n",
    "            yticklabels=[\"健康\", \"建议观察\", \"建议手术\"])\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.show()\n",
    "\n",
    "# 获取错误分类图像的文件名和标签信息\n",
    "if misclassified_indices:\n",
    "    print(f\"\\n发现 {len(misclassified_indices)} 个错误分类的样本。\")\n",
    "    # val_df 是之前划分验证集时创建的 DataFrame\n",
    "    misclassified_samples_df = val_df.iloc[misclassified_indices].copy() \n",
    "    misclassified_samples_df['Predicted'] = [all_predictions[i] for i in misclassified_indices]\n",
    "    misclassified_info = []\n",
    "    for i, row in misclassified_samples_df.iterrows():\n",
    "        image_folder = f\"{int(row['Image']):04d}\"\n",
    "        # 确定图像路径是来自原始目录还是resize后的目录\n",
    "        # 注意：这里假设 val_dataset 使用的是 resize 后的 image_dir\n",
    "        image_path = os.path.join(val_dataset.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "        if not os.path.exists(image_path):\n",
    "            # 如果resize后的路径不存在，尝试原始路径（如果resize在notebook中进行）\n",
    "            original_val_image_dir = val_image_dir # 使用全局定义的验证集路径\n",
    "            image_path = os.path.join(original_val_image_dir, f\"{image_folder}.png\")\n",
    "\n",
    "        misclassified_info.append({\n",
    "            'image_path': image_path,\n",
    "            'true_label': int(row['Pterygium']),\n",
    "            'predicted_label': int(row['Predicted'])\n",
    "        })\n",
    "    print(\"部分错误分类样本信息:\")\n",
    "    for info in misclassified_info[:5]: # 只显示前5个\n",
    "        print(f\"  路径: {os.path.basename(info['image_path'])}, 真实: {info['true_label']}, 预测: {info['predicted_label']}\")\n",
    "else:\n",
    "    print(\"\\n验证集上没有发现错误分类的样本。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# 使用 SHAP 解释部分正确分类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 找出正确分类的样本 ---\n",
    "correctly_classified_indices = [i for i, (true, pred) in enumerate(zip(all_targets, all_predictions)) if true == pred]\n",
    "\n",
    "if len(correctly_classified_indices) >= 3:\n",
    "    print(f\"\\n从 {len(correctly_classified_indices)} 个正确分类的样本中随机选择 3 个进行 SHAP 解释...\")\n",
    "    \n",
    "    # --- 随机选择 3 个 ---\n",
    "    selected_indices = random.sample(correctly_classified_indices, 3)\n",
    "    print(f\"选择的验证集索引: {selected_indices}\")\n",
    "\n",
    "    # --- 准备选择的样本 ---\n",
    "    explain_info_correct = []\n",
    "    explain_images_pil_correct = []\n",
    "    explain_images_tensor_correct = []\n",
    "\n",
    "    for index in selected_indices:\n",
    "        # 从 val_df 获取图像信息\n",
    "        row = val_df.iloc[index] \n",
    "        image_name = row['Image']\n",
    "        true_label = int(row['Pterygium'])\n",
    "        \n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        # 确定图像路径 (同之前的逻辑)\n",
    "        image_path = os.path.join(val_dataset.image_dir, image_folder, f\"{image_folder}.png\") # 假设用resize后的\n",
    "        if not os.path.exists(image_path) and 'original_image_dir' in globals(): # 如果resize后的找不到，尝试原始的\n",
    "            image_path = os.path.join(original_image_dir, image_folder, f\"{image_folder}.png\") # 需要确保 original_image_dir 已定义\n",
    "        elif not os.path.exists(image_path): # 如果原始的也找不到，尝试全局验证集路径\n",
    "            original_val_image_dir = val_image_dir \n",
    "            image_path = os.path.join(original_val_image_dir, f\"{image_folder}.png\")\n",
    "\n",
    "\n",
    "        explain_info_correct.append({\n",
    "            'image_path': image_path,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': true_label # 因为是正确分类的样本\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            explain_images_pil_correct.append(img) # 保存原始PIL图像\n",
    "            # 使用验证集变换\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device) \n",
    "            explain_images_tensor_correct.append(img_tensor)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"警告: 找不到图像 {image_path}，跳过解释。\")\n",
    "            # 从 explain_info_correct 中移除对应的条目，以防后续处理出错\n",
    "            explain_info_correct.pop() \n",
    "        except Exception as e:\n",
    "            print(f\"加载或预处理图像 {image_path} 时出错: {e}，跳过解释。\")\n",
    "            explain_info_correct.pop()\n",
    "\n",
    "    if not explain_images_tensor_correct:\n",
    "        print(\"没有可供解释的图像。\")\n",
    "    else:\n",
    "        # 合并为一个批次\n",
    "        explain_batch_correct = torch.cat(explain_images_tensor_correct, dim=0)\n",
    "        num_explain_correct = explain_batch_correct.shape[0] # 实际成功加载的数量\n",
    "        print(f\"成功加载 {num_explain_correct} 个图像进行解释。\")\n",
    "\n",
    "        # --- 准备背景数据 (同之前逻辑) ---\n",
    "        num_background_samples = 64 # 可以调整数量\n",
    "        background_indices = np.random.choice(len(train_dataset), num_background_samples, replace=False)\n",
    "        # 确保获取的是图像张量 train_dataset[i][0]\n",
    "        background_data = torch.stack([train_dataset[i][0] for i in background_indices]).to(device) \n",
    "        print(f\"使用 {num_background_samples} 个训练样本作为 SHAP 背景数据。\")\n",
    "\n",
    "        # --- 创建 SHAP 解释器 ---\n",
    "        # 确保模型处于评估模式\n",
    "        model.eval() \n",
    "        explainer_correct = shap.GradientExplainer(model, background_data)\n",
    "\n",
    "        # --- 计算 SHAP 值 ---\n",
    "        print(\"正在计算正确分类样本的 SHAP 值...\")\n",
    "        shap_values_correct = explainer_correct.shap_values(explain_batch_correct)\n",
    "        print(\"SHAP 值计算完成。\")\n",
    "\n",
    "        # --- 准备可视化 ---\n",
    "        shap_values_np_correct = np.array(shap_values_correct) # (num_classes, num_samples, C, H, W)\n",
    "        images_np_correct = explain_batch_correct.cpu().numpy().transpose(0, 2, 3, 1) # NCHW -> NHWC\n",
    "\n",
    "        # 反归一化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        images_np_denorm_correct = std * images_np_correct + mean\n",
    "        images_np_denorm_correct = np.clip(images_np_denorm_correct, 0, 1)\n",
    "\n",
    "        # 准备标签和标题\n",
    "        class_names=[\"健康\", \"建议观察\", \"建议手术\"]\n",
    "        plot_labels_correct = np.array([class_names] * num_explain_correct) \n",
    "        \n",
    "        sample_titles_correct = [f\"样本 (文件: {os.path.basename(info['image_path'])})\\n分类成功 真实/预测: {class_names[info['true_label']]}\" \n",
    "                                for info in explain_info_correct]\n",
    "\n",
    "        # 调整 SHAP 值格式\n",
    "        shap_values_plot_correct = np.stack([sv.transpose(0, 2, 3, 1) for sv in shap_values_correct], axis=-1) # N, H, W, C, num_classes\n",
    "\n",
    "        # --- 可视化前先显示图像和标题 ---\n",
    "        #print(\"显示选择的正确分类样本及其标签:\")\n",
    "        #plt.figure(figsize=(5 * num_explain_correct, 5)) # 调整图像大小\n",
    "        #for i in range(num_explain_correct):\n",
    "        #    plt.subplot(1, num_explain_correct, i + 1)\n",
    "        #    plt.imshow(images_np_denorm_correct[i])\n",
    "        #    plt.title(sample_titles_correct[i], fontsize=10) # 调整字体大小\n",
    "        #    plt.axis('off')\n",
    "        #plt.tight_layout() # 调整布局防止标题重叠\n",
    "        #plt.show()\n",
    "        \n",
    "        # --- 可视化 SHAP 结果 ---\n",
    "        print(\"生成 SHAP 图像...\")\n",
    "        for i in range(num_explain_correct): # 使用实际成功加载的样本数量\n",
    "            # 获取第 i 个样本的 SHAP 值 (对所有类别)\n",
    "            # 确保 SHAP 值列表中的每个元素都是一个包含**单个样本**的批次 (形状为 1, ...)\n",
    "            shap_values_for_sample_i_list = []\n",
    "            for sv_per_class in shap_values_correct: # 遍历每个类别的 SHAP 数组\n",
    "                # 从该类别的 SHAP 数组中提取第 i 个样本，使用切片 [i:i+1] 保留批次维度\n",
    "                sv_sample_i = sv_per_class[i:i+1] # 形状: (1, C, H, W) 或 (1, H, W, C)\n",
    "\n",
    "                # (可选) 如果 SHAP 值是 NCHW 格式 (1, C, H, W)，转换为 NHWC (1, H, W, C) 以匹配 image_plot 的期望\n",
    "                # 进行一个简单的形状检查来判断是否需要转置\n",
    "                # 假设 C 通常是 3 或 1 (对于灰度图)，H, W 远大于 C\n",
    "                if sv_sample_i.ndim == 4 and sv_sample_i.shape[1] <= 4 and sv_sample_i.shape[2] > 4: # 粗略判断 NCHW\n",
    "                    # 从 (1, C, H, W) 转置到 (1, H, W, C)\n",
    "                    sv_sample_i = sv_sample_i.transpose(0, 2, 3, 1)\n",
    "\n",
    "                shap_values_for_sample_i_list.append(sv_sample_i)\n",
    "\n",
    "\n",
    "            # 获取第 i 个样本的图像数据 (保持批次维度为 1)\n",
    "            image_for_sample_i_batch = images_np_denorm_correct[i:i+1] # 形状: (1, H, W, C)\n",
    "\n",
    "            # 调用 shap.image_plot 绘制当前样本的解释\n",
    "            # pixel_values 需要 (N, H, W, C) -> 我们传入 (1, H, W, C)\n",
    "            # shap_values 需要 list of (N, ...) -> 我们传入 list of (1, H, W, C)\n",
    "            # labels 需要 list of strings (类别名称) -> 我们传入 class_names\n",
    "            shap.image_plot(\n",
    "                [sv * shap_scaling_factor for sv in shap_values_for_sample_i_list], # 对每个类的 SHAP 值应用缩放\n",
    "                image_for_sample_i_batch,\n",
    "                labels=class_names, # 使用类别名称作为列标签\n",
    "                show=False # 不立即显示，以便添加标题\n",
    "            )\n",
    "\n",
    "            # 获取当前生成的 matplotlib 图\n",
    "            fig = plt.gcf()\n",
    "            # 在图的顶部添加自定义的总体标题\n",
    "            fig.suptitle(sample_titles_correct[i], fontsize=12, y=1.02) # y 调整标题位置\n",
    "\n",
    "            # 现在显示带有标题的图\n",
    "            plt.show()\n",
    "\n",
    "elif len(correctly_classified_indices) > 0:\n",
    "    print(f\"\\n正确分类的样本数量 ({len(correctly_classified_indices)}) 不足 3 个，无法选择 3 个进行解释。\")\n",
    "else:\n",
    "    print(\"\\n验证集中没有正确分类的样本可供解释。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# 使用 SHAP 解释错误分类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if misclassified_info:\n",
    "    print(\"\\n--- 使用 SHAP 解释部分错误分类样本 ---\")\n",
    "    \n",
    "    # 1. 选择要解释的样本 (选择前 N 个)\n",
    "    num_explain = min(10, len(misclassified_info))\n",
    "    explain_info = misclassified_info[:num_explain]\n",
    "    explain_images_pil = []\n",
    "    explain_images_tensor = []\n",
    "\n",
    "    print(f\"准备解释 {num_explain} 个样本...\")\n",
    "    for info in explain_info:\n",
    "        try:\n",
    "            img = Image.open(info['image_path']).convert(\"RGB\")\n",
    "            explain_images_pil.append(img) # 保存原始PIL图像用于绘图标题\n",
    "            # 使用验证集的变换进行预处理，并移动到设备\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "            explain_images_tensor.append(img_tensor)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"警告: 找不到图像 {info['image_path']}，跳过解释。\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载或预处理图像 {info['image_path']} 时出错: {e}，跳过解释。\")\n",
    "\n",
    "    if not explain_images_tensor:\n",
    "        print(\"没有可供解释的图像。\")\n",
    "    else:\n",
    "        # 合并为一个批次\n",
    "        explain_batch = torch.cat(explain_images_tensor, dim=0)\n",
    "\n",
    "        # 2. 准备背景数据 (使用训练集的一小部分)\n",
    "        num_background_samples = 64\n",
    "        background_indices = np.random.choice(len(train_dataset), num_background_samples, replace=False)\n",
    "        background_data = torch.stack([train_dataset[i][0] for i in background_indices]).to(device) \n",
    "\n",
    "        print(f\"使用 {num_background_samples} 个训练样本作为 SHAP 背景数据。\")\n",
    "\n",
    "        # 3. 创建 SHAP 解释器\n",
    "        # 对于 PyTorch 模型，GradientExplainer 或 DeepExplainer 是常用选择\n",
    "        # GradientExplainer 通常更通用\n",
    "        explainer = shap.GradientExplainer(model, background_data)\n",
    "\n",
    "        # 4. 计算 SHAP 值\n",
    "        print(\"正在计算 SHAP 值...\")\n",
    "\n",
    "        shap_values = explainer.shap_values(explain_batch)\n",
    "        print(\"SHAP 值计算完成。\")\n",
    "\n",
    "        # --- 检查 SHAP 值 ---\n",
    "        shap_values_np = np.array(shap_values) # 转换为 NumPy 数组方便操作\n",
    "        print(f\"SHAP 值数组形状: {shap_values_np.shape}\") # 应该是 (num_classes, num_samples, C, H, W)\n",
    "        print(f\"所有 SHAP 值的最小值: {shap_values_np.min()}\")\n",
    "        print(f\"所有 SHAP 值的最大值: {shap_values_np.max()}\")\n",
    "        print(f\"所有 SHAP 值的平均绝对值: {np.mean(np.abs(shap_values_np))}\")\n",
    "        # --- 检查结束 ---\n",
    "\n",
    "        # 5. 可视化 SHAP 结果\n",
    "        # shap_values 对于多分类任务，是一个列表，每个元素对应一个类的 SHAP 值 (NumPy array)\n",
    "        # 形状通常是 [num_classes, num_samples, C, H, W]\n",
    "        # image_plot 需要 NumPy array，格式为 [N, H, W, C] 或 [N, C, H, W]\n",
    "        # 我们需要将 SHAP 值和图像数据移回 CPU 并转换为 NumPy\n",
    "\n",
    "        images_np = explain_batch.cpu().numpy().transpose(0, 2, 3, 1) # NCHW -> NHWC\n",
    "\n",
    "        # 反归一化图像以便更好地可视化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        images_np_denorm = std * images_np + mean\n",
    "        images_np_denorm = np.clip(images_np_denorm, 0, 1)\n",
    "\n",
    "        # 准备标签用于绘图\n",
    "        class_names=[\"健康\", \"建议观察\", \"建议手术\"]\n",
    "        plot_labels = np.array([class_names] * num_explain) \n",
    "            \n",
    "        # 获取每个样本的真实和预测标签字符串，用于单独显示或在图外显示\n",
    "        true_labels = [info['true_label'] for info in explain_info]\n",
    "        predicted_labels = [info['predicted_label'] for info in explain_info]\n",
    "        sample_titles = [f\"样本 {idx+1} (文件: {os.path.basename(explain_info[idx]['image_path'])})\\n真实: {class_names[tl]}, 预测: {class_names[pl]}\" \n",
    "                        for idx, (tl, pl) in enumerate(zip(true_labels, predicted_labels))]\n",
    "\n",
    "        # 调整 shap_values 格式以匹配 image_plot 的期望\n",
    "        shap_values_np = [sv.transpose(0, 2, 3, 1) for sv in shap_values] # NCHW -> NHWC for each class\n",
    "        shap_values_plot = np.stack(shap_values_np, axis=-1) # Stack along the last axis -> [N, H, W, C, num_classes]\n",
    "\n",
    "        print(\"生成 SHAP 图像...\")\n",
    "        # --- (可选) 在调用 image_plot 之前单独显示每个样本及其 True/Pred 标签 ---\n",
    "        #for i in range(num_explain):\n",
    "        #    plt.figure()\n",
    "        #    plt.imshow(images_np_denorm[i])\n",
    "        #    plt.title(sample_titles[i])\n",
    "        #    plt.axis('off')\n",
    "        #    plt.show()\n",
    "\n",
    "        #shap.image_plot(shap_values_plot * shap_scaling_factor,\n",
    "        #                images_np_denorm, \n",
    "        #                labels=plot_labels, # 为每个类别提供标签\n",
    "        #                true_labels=None, # true_labels 已包含在 labels 中\n",
    "        #                show=True) # 直接显示图像\n",
    "\n",
    "        for i in range(num_explain):\n",
    "            # 获取第 i 个样本的 SHAP 值 (对所有类别)\n",
    "            # 确保 SHAP 值和图像数据都保持批次维度为 1\n",
    "            # explainer.shap_values 返回的是 list of (N, C, H, W) or (N, H, W, C)\n",
    "            # 我们需要将其处理成 list of (1, H, W, C)\n",
    "            shap_values_for_sample_i_list = []\n",
    "            for sv_per_class in shap_values: # Loop through classes\n",
    "                # sv_per_class shape is (num_samples, C, H, W) or (num_samples, H, W, C)\n",
    "                # Extract the i-th sample, keeping batch dim: (1, C, H, W) or (1, H, W, C)\n",
    "                sv_sample_i = sv_per_class[i:i+1] \n",
    "                \n",
    "                # Ensure it's in NHWC format (Batch, Height, Width, Channel) for image_plot if needed\n",
    "                # Assuming sv_per_class was (N, C, H, W) as is common for PyTorch outputs\n",
    "                if sv_sample_i.shape[1] == images_np_denorm.shape[-1] and sv_sample_i.shape[2:] == images_np_denorm.shape[1:3]: # Simple check for NCHW\n",
    "                     # Transpose from (1, C, H, W) to (1, H, W, C)\n",
    "                    sv_sample_i = sv_sample_i.transpose(0, 2, 3, 1) \n",
    "                # else: assume it's already (1, H, W, C) or (1, H, W)\n",
    "\n",
    "                shap_values_for_sample_i_list.append(sv_sample_i)\n",
    "\n",
    "\n",
    "            # 获取第 i 个样本的图像数据 (保持批次维度为 1)\n",
    "            image_for_sample_i_batch = images_np_denorm[i:i+1] # (1, H, W, C)\n",
    "\n",
    "            # 调用 shap.image_plot 绘制当前样本的解释\n",
    "            # pixel_values 需要 (N, H, W, C) -> image_for_sample_i_batch is (1, H, W, C)\n",
    "            # shap_values 需要 list of (N, C, H, W) or list of (N, H, W, C) -> shap_values_for_sample_i_list is list of (1, H, W, C)\n",
    "            # labels 需要 list of strings (类别名称) -> class_names is list of strings\n",
    "            shap.image_plot(\n",
    "                [sv * shap_scaling_factor for sv in shap_values_for_sample_i_list], # Apply scaling to SHAP values, pass list of (1, H, W, C)\n",
    "                image_for_sample_i_batch, # (1, H, W, C)\n",
    "                labels=class_names, # Use class names for columns\n",
    "                show=False # Don't show yet, add title first\n",
    "            )\n",
    "\n",
    "            # 获取当前生成的 matplotlib 图和轴\n",
    "            fig = plt.gcf()\n",
    "            # 添加总体的标题\n",
    "            fig.suptitle(sample_titles[i], fontsize=12, y=1.02) # y 调整标题位置，避免与子图重叠\n",
    "\n",
    "            # 现在显示带有标题的图\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"\\n没有错误分类的样本可供 SHAP 解释。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2025-04-13T02:01:58.797761",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.790330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "papermill": {
     "duration": 0.083802,
     "end_time": "2025-04-13T02:01:58.888785",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.804983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载模型参数\n",
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    print(f\"模型参数已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 保存训练好的模型\n",
    "model_save_path = f\"./{train_model.__name__}_pterygium_classifier_base.pth\"\n",
    "save_model(model, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "y6VojVHqjSpF",
    "papermill": {
     "duration": 0.007359,
     "end_time": "2025-04-13T02:01:58.904324",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.896965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型测试和预测\n",
    "使用训练好的模型对新图像进行预测，并展示几个预测示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "W3PhSqxEjSpF",
    "papermill": {
     "duration": 0.318951,
     "end_time": "2025-04-13T02:01:59.230622",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.911671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型测试和预测\n",
    "import shutil\n",
    "\n",
    "\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "def test_model_on_val(model, device, input_dir, temp_dir, transform):\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "    # 删除临时目录中的旧文件\n",
    "    for img_path in glob.glob(os.path.join(temp_dir, \"*.png\")):\n",
    "        os.remove(img_path)\n",
    "    results = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Processing images\", leave=True):\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]  # ...获取文件名（不带扩展）...\n",
    "        output_path = os.path.join(temp_dir, f\"{base_name}.{output_format.lower()}\")\n",
    "        if not os.path.exists(output_path):\n",
    "            try:\n",
    "                if resize_and_save_image({\"Image\": base_name}, input_dir, temp_dir, resize_transform, device):\n",
    "                    predicted_class = predict_image(model, output_path, transform, device)\n",
    "                    results.append({\"Image\": base_name, \"Pterygium\": predicted_class})\n",
    "                else:\n",
    "                    tqdm.write(f\"Resize失败: {img_path}\")\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"处理图像 {img_path} 时出错: {e}\")\n",
    "    \n",
    "    results.sort(key=lambda x: int(x[\"Image\"]))\n",
    "    df = pd.DataFrame(results, columns=[\"Image\", \"Pterygium\"])\n",
    "    result_path = os.path.join(kaggle_temp_path, \"Classification_Results.xlsx\")\n",
    "    df.to_excel(result_path, index=False)\n",
    "    print(f\"分类结果已保存到 {result_path}\")\n",
    "    print(f'删除验证集缓存数据 {temp_dir}')\n",
    "    for img_path in glob.glob(os.path.join(temp_dir, \"*.png\")):\n",
    "        os.remove(img_path)\n",
    "\n",
    "# 加载保存的模型并进行推理\n",
    "loaded_model = train_model(num_classes=3)\n",
    "loaded_model = load_model(loaded_model, model_save_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "papermill": {
     "duration": 0.057612,
     "end_time": "2025-04-13T02:01:59.296113",
     "exception": false,
     "start_time": "2025-04-13T02:01:59.238501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # 单文件推理\n",
    "    test_image_path = \"./test_images/sample_image.png\"  # 替换为实际测试图像路径\n",
    "    predicted_class = predict_image(loaded_model, test_image_path, val_transform, device)\n",
    "    class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "    print(f\"加载模型后预测结果: 图像 {os.path.basename(test_image_path)}, 预测类别: {class_names[predicted_class]}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "papermill": {
     "duration": 140.716871,
     "end_time": "2025-04-13T02:04:20.020553",
     "exception": false,
     "start_time": "2025-04-13T02:01:59.303682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 验证集推理\n",
    "val_temp_dir = os.path.join(kaggle_temp_path, \"val_resized\")\n",
    "test_model_on_val(loaded_model, device, val_image_dir, val_temp_dir, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "papermill": {
     "duration": 0.007368,
     "end_time": "2025-04-13T02:04:20.035996",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.028628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 基线模型波动范围检测\n",
    "K 折交叉验证 (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "papermill": {
     "duration": 295.540911,
     "end_time": "2025-04-13T02:09:15.584272",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.043361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# --- 交叉验证参数 ---\n",
    "K = 5  # 折数\n",
    "base_seed = 420 # 用于 KFold 分割的随机种子\n",
    "\n",
    "# --- 存储结果 ---\n",
    "fold_final_val_accuracies = []\n",
    "fold_final_macro_f1_scores = []\n",
    "fold_learning_curves = []\n",
    "# fold_best_model_state_dicts = [] # 如果需要保存每折的最佳模型权重\n",
    "\n",
    "# --- 准备完整数据集 (加载一次，稍后根据需要应用变换) ---\n",
    "try:\n",
    "    full_labels_df = pd.read_excel(label_file)\n",
    "    # 获取用于分层的标签数组\n",
    "    all_original_labels = full_labels_df['Pterygium'].values\n",
    "    # 创建基础数据集实例 (稍后在创建 Subset 时应用变换)\n",
    "    # 需要两个实例：一个应用训练变换，一个应用验证变换\n",
    "    base_train_dataset = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=train_transform)\n",
    "    base_val_dataset = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=val_transform)\n",
    "    # 确保数据集大小和标签数量匹配\n",
    "    assert len(base_train_dataset) == len(all_original_labels), \"Dataset size and label count mismatch!\"\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing full dataset for K-Fold: {e}\")\n",
    "    # 如果无法准备数据，则跳过交叉验证\n",
    "    # (或者根据需要添加退出逻辑)\n",
    "    K = 0 # 设置 K 为 0 以跳过循环\n",
    "\n",
    "# --- 定义损失函数 (可以在循环外定义，因为无状态) ---\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01) # 正则项仍未启用\n",
    "\n",
    "# --- 创建 KFold 分割器 ---\n",
    "if K > 0:\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=base_seed)\n",
    "    print(f\"开始进行 {K}-Fold Cross-Validation...\")\n",
    "else:\n",
    "    print(\"Skipping K-Fold Cross-Validation due to data preparation error or K=0.\")\n",
    "\n",
    "# --- K-Fold 循环 ---\n",
    "current_fold_num = 0 # 手动跟踪折数，因为 enumerate(skf.split(...)) 的第一个元素是 fold index\n",
    "for train_idx, val_idx in skf.split(np.arange(len(base_train_dataset)), all_original_labels):\n",
    "    current_fold_num += 1\n",
    "    fold_id_str = f\"Fold {current_fold_num}/{K}\"\n",
    "    print(f\"\\n--- 开始 {fold_id_str} ---\")\n",
    "\n",
    "    # --- 1. 创建当前折的 Subsets ---\n",
    "    # 使用带有相应变换的基础数据集创建 Subset\n",
    "    train_subset = Subset(base_train_dataset, train_idx)\n",
    "    val_subset = Subset(base_val_dataset, val_idx)\n",
    "    print(f\"Fold {current_fold_num}: Train size={len(train_subset)}, Val size={len(val_subset)}\")\n",
    "\n",
    "    # --- 2. 创建当前折的 DataLoaders ---\n",
    "    train_loader_fold = DataLoader(train_subset,\n",
    "                                batch_size=64,\n",
    "                                shuffle=True, # 训练集需要 shuffle\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "    val_loader_fold = DataLoader(val_subset,\n",
    "                                batch_size=64,\n",
    "                                shuffle=False, # 验证集不需要 shuffle\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "\n",
    "    # --- 3. 为当前折创建新的模型、优化器和调度器实例 ---\n",
    "    model_fold = train_model(num_classes=3).to(device) # 使用与之前相同的模型\n",
    "    optimizer_fold = optim.AdamW(model_fold.parameters(), lr=train_lr, weight_decay=train_weight_decay) # 使用基线超参数\n",
    "    scheduler_fold = optim.lr_scheduler.CosineAnnealingLR(optimizer_fold, T_max=num_epochs, eta_min=1e-6) # T_max 应为总 epochs\n",
    "\n",
    "    # --- 4. 调用训练和验证函数 ---\n",
    "    final_acc, final_f1, history, best_state = train_validate_model(\n",
    "        model=model_fold,\n",
    "        train_loader=train_loader_fold,\n",
    "        val_loader=val_loader_fold,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_fold,\n",
    "        scheduler=scheduler_fold,\n",
    "        num_epochs=num_epochs, # 使用之前定义的 num_epochs\n",
    "        device=device,\n",
    "        run_identifier=fold_id_str # 传递折信息给日志\n",
    "    )\n",
    "\n",
    "    # --- 5. 存储当前折的结果 ---\n",
    "    fold_final_val_accuracies.append(final_acc)\n",
    "    fold_final_macro_f1_scores.append(final_f1)\n",
    "    fold_learning_curves.append(history)\n",
    "    # if best_state: # 如果需要保存每折的最佳模型权重\n",
    "    #     fold_best_model_state_dicts.append(best_state)\n",
    "\n",
    "# --- 6. K-Fold 循环结束后，进行分析和可视化 ---\n",
    "if K > 0 and fold_final_val_accuracies: # 确保有结果可分析\n",
    "    print(\"\\n--- K-Fold Cross-Validation 结果分析 ---\")\n",
    "\n",
    "    # 计算平均值和标准差\n",
    "    mean_accuracy = np.mean(fold_final_val_accuracies)\n",
    "    std_accuracy = np.std(fold_final_val_accuracies)\n",
    "    mean_f1 = np.mean(fold_final_macro_f1_scores)\n",
    "    std_f1 = np.std(fold_final_macro_f1_scores)\n",
    "\n",
    "    print(f\"平均验证准确率 (across {K} folds): {mean_accuracy:.4f}%\")\n",
    "    print(f\"验证准确率标准差 (across {K} folds): {std_accuracy:.4f}%\")\n",
    "    print(f\"平均验证Macro F1 (across {K} folds): {mean_f1:.4f}\")\n",
    "    print(f\"验证Macro F1标准差 (across {K} folds): {std_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n每折的最终验证准确率:\")\n",
    "    for i, acc in enumerate(fold_final_val_accuracies):\n",
    "        print(f\"  Fold {i+1}: {acc:.4f}%\")\n",
    "\n",
    "    print(\"\\n每折的最终验证Macro F1:\")\n",
    "    for i, f1 in enumerate(fold_final_macro_f1_scores):\n",
    "        print(f\"  Fold {i+1}: {f1:.4f}\")\n",
    "\n",
    "    # --- 7. 可视化学习曲线 ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, curve in enumerate(fold_learning_curves):\n",
    "        epochs_run = range(1, len(curve) + 1)\n",
    "        plt.plot(epochs_run, curve, label=f'Fold {i+1}', alpha=0.7)\n",
    "\n",
    "    plt.title(f'{K}-Fold Cross-Validation: 验证准确率学习曲线')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('验证准确率 (%)')\n",
    "    plt.legend(loc='lower right', ncol=min(K, 5)) # 控制图例列数\n",
    "    plt.grid(True)\n",
    "    # 动态调整Y轴范围\n",
    "    min_y_val = np.min([min(c) for c in fold_learning_curves if c]) if any(fold_learning_curves) else 80\n",
    "    max_y_val = np.max([max(c) for c in fold_learning_curves if c]) if any(fold_learning_curves) else 100\n",
    "    plt.ylim(bottom=max(0, min_y_val - 2), top=min(100, max_y_val + 2))\n",
    "    plt.show()\n",
    "\n",
    "elif K > 0:\n",
    "    print(\"\\nK-Fold Cross-Validation ran, but no results were collected (possibly due to errors in training).\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231745112,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 937.871658,
   "end_time": "2025-04-13T02:09:18.610590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T01:53:40.738932",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
