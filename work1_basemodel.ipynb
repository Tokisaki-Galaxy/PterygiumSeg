{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.00543,
     "end_time": "2025-04-13T01:53:45.044748",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.039318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/work1_basemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "I8rV7E66jSoG",
    "papermill": {
     "duration": 0.004352,
     "end_time": "2025-04-13T01:53:45.053747",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.049395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():\n",
    "    \"\"\"\n",
    "    检查是否可能缺少 GUI 后端（例如，在无头服务器上运行）。\n",
    "    如果是这种情况，将 Matplotlib 后端设置为 'Agg' 以避免错误。\n",
    "\n",
    "    应该在首次导入 `matplotlib.pyplot` 之前调用此函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        # 尝试获取 IPython 实例\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "e-siDBWjjSo6",
    "papermill": {
     "duration": 11.426914,
     "end_time": "2025-04-13T01:53:56.485296",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.058382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shap\n",
    "import sys\n",
    "from PIL import Image\n",
    "import platform\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        os.system(r'wget -O simhei.ttf \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"')\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "#colab_val_zip_path = \"/content/drive/My Drive/val.zip\"\n",
    "#colab_val_extract_path = \"/content/val/\"\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# =================== SHAP设置 =================\n",
    "shape_scaling_factor = 100\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "FqZSY8dujSo8",
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-04-13T01:53:56.494490",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.490079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80",
    "papermill": {
     "duration": 0.023889,
     "end_time": "2025-04-13T01:53:56.522681",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.498792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # Google Drive 有每日下载次数限制，可能会导致下载失败\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.004176,
     "end_time": "2025-04-13T01:53:56.531483",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.527307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据 Resize\n",
    "这一步骤是将图像调整为224x224的大小，以适应模型输入要求。\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 428.90724,
     "end_time": "2025-04-13T02:01:05.443030",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.535790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "target_size = (224, 224) # 目标尺寸\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# --- Transformation Definition ---\n",
    "# We will perform Resize on GPU. ToTensor conversion happens before moving to GPU.\n",
    "# Normalization will be done *online* during training dataloading, not offline.\n",
    "resize_transform = transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "# BILINEAR is a good default. antialias=True is recommended for downsampling.\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_name = f\"{int(image_name):04d}\"\n",
    "        if os.path.exists(os.path.join(base_input_dir, f\"{image_name}.png\")):\n",
    "            # 验证集图像路径\n",
    "            input_path = os.path.join(base_input_dir, f\"{image_name}.png\")\n",
    "            os.makedirs(base_output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(base_output_dir, f\"{image_name}.{output_format.lower()}\")\n",
    "        else:\n",
    "            # 训练集图像路径\n",
    "            input_path = os.path.join(base_input_dir, image_name, f\"{image_name}.png\")\n",
    "            # Create corresponding output subdirectory if it doesn't exist\n",
    "            output_folder_path = os.path.join(base_output_dir, image_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "            output_path = os.path.join(output_folder_path, f\"{image_name}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "if not platform.system() == \"Windows\":\n",
    "    if 'google.colab' in sys.modules:\n",
    "        original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    elif os.path.exists(\"/kaggle/working\"):\n",
    "        original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    else:\n",
    "        print(\"错误: 无法识别的环境\")\n",
    "        exit(1)\n",
    "    image_dir = output_dir\n",
    "\n",
    "    print(f\"输入目录: {original_image_dir}\")\n",
    "    print(f\"输出目录: {output_dir}\")\n",
    "    print(f\"目标尺寸: {target_size}\")\n",
    "\n",
    "    # Create the main output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据，跳过resize步骤\")\n",
    "    else:\n",
    "        # Read label file to know which images to process\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 标签文件未找到 {label_file}\")\n",
    "            sys.exit(1) # Exit if label file is missing\n",
    "\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "\n",
    "        # Iterate through images listed in the label file\n",
    "        for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "            if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "        print(f\"\\n处理完成!\")\n",
    "        print(f\"成功处理图像数: {success_count}\")\n",
    "        print(f\"处理失败图像数: {error_count}\")\n",
    "        print(f\"处理后的图像保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "okNIq-rfjSo-",
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-04-13T02:01:05.452384",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.448028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "11JDwC__jSo-",
    "papermill": {
     "duration": 1.465971,
     "end_time": "2025-04-13T02:01:06.922765",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.456794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # 先放大一点\n",
    "    transforms.RandomCrop((224, 224)), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=15), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换 (无需数据增强)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=420, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=val_transform) # 使用验证变换\n",
    "\n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "eGn3VBzHjSo_",
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-04-13T02:01:06.932847",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.928379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 构建 ResNet 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b",
    "papermill": {
     "duration": 0.692259,
     "end_time": "2025-04-13T02:01:07.629659",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.937400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "    \n",
    "# 构建 ResNet34 模型\n",
    "from torchvision.models import ResNet34_Weights\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ResNet34Classifier, self).__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "    \n",
    "# 构建 ResNet34 模型\n",
    "from torchvision.models import ResNet50_Weights\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ResNet50Classifier, self).__init__()\n",
    "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate), # 添加 Dropout 层\n",
    "            nn.Linear(in_features, num_classes) # 添加新的全连接层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "# 定义模型\n",
    "model = ResNet18Classifier(num_classes=3).to(device)\n",
    "\n",
    "# 将模型移动到 GPU（如果可用）\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "dCYYlSWDjSpB",
    "papermill": {
     "duration": 0.005309,
     "end_time": "2025-04-13T02:01:07.640990",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.635681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 定义带正则化项的损失函数\n",
    "实现一个包含正则化项的损失函数，使用交叉熵损失作为基础，并添加特定的正则化项来抑制高光问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "9tVvDaYLjSpB",
    "papermill": {
     "duration": 0.012467,
     "end_time": "2025-04-13T02:01:07.658402",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.645935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义损失函数，包含正则化项以抑制高光问题\n",
    "class HighlightRegularizedLoss(nn.Module):\n",
    "    def __init__(self, base_loss_fn, lambda_reg=0.01):\n",
    "        super(HighlightRegularizedLoss, self).__init__()\n",
    "        self.base_loss_fn = base_loss_fn\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets, inputs):\n",
    "        # 基础损失（交叉熵损失）\n",
    "        base_loss = self.base_loss_fn(outputs, targets)\n",
    "\n",
    "        # 正则化项：抑制高光问题（假设高光区域的像素值接近1）\n",
    "        highlight_penalty = torch.mean(torch.clamp(inputs - 0.9, min=0) ** 2)\n",
    "\n",
    "        # 总损失\n",
    "        total_loss = base_loss #+ self.lambda_reg * highlight_penalty\n",
    "        return total_loss\n",
    "\n",
    "# 定义基础损失函数（交叉熵损失）\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义包含正则化项的损失函数\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "SjMzFIyejSpC",
    "papermill": {
     "duration": 0.004709,
     "end_time": "2025-04-13T02:01:07.668189",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.663480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 配置优化器和训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "0NUONUTJjSpC",
    "papermill": {
     "duration": 0.011721,
     "end_time": "2025-04-13T02:01:07.685038",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.673317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置优化器和学习率调度器\n",
    "# 在Adam优化器中添加 weight_decay 参数实现L2正则化\n",
    "optimizer = optim.AdamW(model.parameters(), lr=7e-4, weight_decay=1e-4)\n",
    "\n",
    "# 定义学习率调度器，采用余弦退火调度策略\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-6)\n",
    "\n",
    "# 设置其他训练参数\n",
    "num_epochs = 25  # 训练的总轮数\n",
    "log_interval = 10  # 每隔多少个批次打印一次日志"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "0dKuzXaHjSpD",
    "papermill": {
     "duration": 0.005112,
     "end_time": "2025-04-13T02:01:07.695500",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.690388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播和参数更新，并记录训练过程中的指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": 0.014088,
     "end_time": "2025-04-13T02:01:07.714614",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.700526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义早停类\n",
    "from copy import deepcopy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta # 允许的最小提升量\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "\n",
    "        # 根据模式确定比较操作\n",
    "        if self.mode == 'min':\n",
    "            self.delta_sign = -1 # 对于最小值模式，分数需要减少 delta\n",
    "        else: # mode == 'max'\n",
    "            self.delta_sign = 1 # 对于最大值模式，分数需要增加 delta\n",
    "\n",
    "    def __call__(self, val_score, model):\n",
    "        score = val_score # 直接使用验证分数\n",
    "\n",
    "        if self.best_score is None:\n",
    "            # 第一次调用，初始化最佳分数并保存权重\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            tqdm.write(f\"EarlyStopping: Initialized best score to {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            # 有足够的提升\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            tqdm.write(f\"EarlyStopping: Improvement found. Best score updated to {self.best_score:.4f}. Counter reset.\")\n",
    "        else:\n",
    "            # 没有足够的提升\n",
    "            self.counter += 1\n",
    "            tqdm.write(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best score remains {self.best_score:.4f}.')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                tqdm.write(\"EarlyStopping: Patience reached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "9wq254XdjSpD",
    "papermill": {
     "duration": 49.831481,
     "end_time": "2025-04-13T02:01:57.551548",
     "exception": false,
     "start_time": "2025-04-13T02:01:07.720067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, run_identifier=\"Run\"):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持早停。\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 要训练的模型实例。\n",
    "        train_loader (DataLoader): 训练数据加载器。\n",
    "        val_loader (DataLoader): 验证数据加载器。\n",
    "        criterion (nn.Module): 损失函数。\n",
    "        optimizer (Optimizer): 优化器。\n",
    "        scheduler (LRScheduler): 学习率调度器。\n",
    "        num_epochs (int): 最大训练轮数。\n",
    "        device (torch.device): 计算设备 ('cuda' or 'cpu')。\n",
    "        run_identifier (str): 用于日志输出的运行标识符。\n",
    "\n",
    "    Returns:\n",
    "        tuple: 包含以下元素的元组:\n",
    "            - float: 最佳验证准确率 (%)。\n",
    "            - float: 最佳验证Macro F1分数。\n",
    "            - list: 每个epoch的验证准确率历史。\n",
    "            - dict: 最佳模型的state_dict。\n",
    "    \"\"\"\n",
    "    start_time_run = time.time()\n",
    "    print(f\"\\n--- {run_identifier}: 开始训练 ---\")\n",
    "\n",
    "    # 初始化此运行所需的状态对象\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max') # 与之前相同的早停设置\n",
    "    val_accuracy_history = [] # 存储当前运行的验证准确率历史\n",
    "    best_model_state_dict = None # 存储最佳模型的状态\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- 训练阶段 ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'{run_identifier} Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader_tqdm):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(inputs)\n",
    "                # 确保 criterion 也接收 inputs 如果它需要的话 (比如你的 HighlightRegularizedLoss)\n",
    "                if isinstance(criterion, HighlightRegularizedLoss):\n",
    "                    loss = criterion(outputs, targets, inputs)\n",
    "                else:\n",
    "                    loss = criterion(outputs, targets) # 标准损失函数\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%',\n",
    "                'lr': f'{current_lr:.1e}'\n",
    "            })\n",
    "\n",
    "        scheduler.step() # 每个epoch后更新学习率\n",
    "\n",
    "        # --- 验证阶段 ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(inputs)\n",
    "                    if isinstance(criterion, HighlightRegularizedLoss):\n",
    "                        loss = criterion(outputs, targets, inputs)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "        tqdm.write(f\"{run_identifier} Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "                f\"Train Acc: {100. * correct / total:.2f}%, Val Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "                f\"Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # --- 早停检查 ---\n",
    "        # 注意: EarlyStopping现在在内部使用tqdm.write\n",
    "        early_stopping(val_accuracy, model)\n",
    "        if early_stopping.early_stop:\n",
    "            tqdm.write(f\"{run_identifier}: EarlyStopping triggered at epoch {epoch + 1}.\")\n",
    "            best_model_state_dict = early_stopping.best_model_weights # 获取最佳权重\n",
    "            break # 提前结束训练\n",
    "\n",
    "    # 如果训练正常完成（未早停），也要保存最后的最佳权重\n",
    "    if not early_stopping.early_stop:\n",
    "        tqdm.write(f\"{run_identifier}: Training finished after {num_epochs} epochs.\")\n",
    "        best_model_state_dict = early_stopping.best_model_weights # 获取最后记录的最佳权重\n",
    "\n",
    "    # --- 使用最佳模型进行最终评估 ---\n",
    "    if best_model_state_dict:\n",
    "        model.load_state_dict(best_model_state_dict) # 加载最佳权重\n",
    "        model.eval()\n",
    "        final_all_targets = []\n",
    "        final_all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                final_all_targets.extend(targets.cpu().numpy())\n",
    "                final_all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        final_accuracy = accuracy_score(final_all_targets, final_all_predictions) * 100\n",
    "        final_macro_f1 = f1_score(final_all_targets, final_all_predictions, average='macro')\n",
    "    else:\n",
    "        # 如果由于某种原因没有最佳权重（例如训练在第一个epoch就停止且未改进）\n",
    "        final_accuracy = 0.0\n",
    "        final_macro_f1 = 0.0\n",
    "        tqdm.write(f\"{run_identifier}: Warning - Could not obtain best model weights.\")\n",
    "\n",
    "\n",
    "    end_time_run = time.time()\n",
    "    print(f\"--- {run_identifier}: 训练完成 ---\")\n",
    "    print(f\"最终验证准确率: {final_accuracy:.4f}%\")\n",
    "    print(f\"最终验证Macro F1: {final_macro_f1:.4f}\")\n",
    "    print(f\"本次运行耗时: {end_time_run - start_time_run:.2f} 秒\")\n",
    "\n",
    "    return final_accuracy, final_macro_f1, val_accuracy_history, best_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=num_epochs, # 使用之前定义的 num_epochs\n",
    "        device=device,\n",
    "        run_identifier=None\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "peWRUqyKjSpE",
    "papermill": {
     "duration": 0.006745,
     "end_time": "2025-04-13T02:01:57.566762",
     "exception": false,
     "start_time": "2025-04-13T02:01:57.560017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型性能\n",
    "在验证集上评估模型性能，计算准确率、混淆矩阵、F1分数等指标，并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "xzQdrZkTjSpE",
    "papermill": {
     "duration": 1.208724,
     "end_time": "2025-04-13T02:01:58.782451",
     "exception": false,
     "start_time": "2025-04-13T02:01:57.573727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 评估模型性能\n",
    "model.eval()  # 设置模型为评估模式\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "misclassified_indices = []\n",
    "misclassified_info = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测结果\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # 检查错误分类\n",
    "        misclassified_mask = predicted != targets\n",
    "        batch_indices = torch.arange(idx * val_loader.batch_size, (idx * val_loader.batch_size) + inputs.size(0))\n",
    "        batch_misclassified_indices = batch_indices[misclassified_mask.cpu()].tolist()\n",
    "        misclassified_indices.extend(batch_misclassified_indices)\n",
    "\n",
    "        # 收集所有目标和预测\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "macro_precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "macro_f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "print(f\"验证集准确率: {accuracy:.4f}\")\n",
    "print(f\"验证集Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"验证集Macro F1分数: {macro_f1:.4f}\")\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"健康\", \"建议观察\", \"建议手术\"],\n",
    "            yticklabels=[\"健康\", \"建议观察\", \"建议手术\"])\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.show()\n",
    "\n",
    "# 获取错误分类图像的文件名和标签信息\n",
    "if misclassified_indices:\n",
    "    print(f\"\\n发现 {len(misclassified_indices)} 个错误分类的样本。\")\n",
    "    # val_df 是之前划分验证集时创建的 DataFrame\n",
    "    misclassified_samples_df = val_df.iloc[misclassified_indices].copy() \n",
    "    misclassified_samples_df['Predicted'] = [all_predictions[i] for i in misclassified_indices]\n",
    "    misclassified_info = []\n",
    "    for i, row in misclassified_samples_df.iterrows():\n",
    "        image_folder = f\"{int(row['Image']):04d}\"\n",
    "        # 确定图像路径是来自原始目录还是resize后的目录\n",
    "        # 注意：这里假设 val_dataset 使用的是 resize 后的 image_dir\n",
    "        image_path = os.path.join(val_dataset.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "        if not os.path.exists(image_path):\n",
    "            # 如果resize后的路径不存在，尝试原始路径（如果resize在notebook中进行）\n",
    "            original_val_image_dir = val_image_dir # 使用全局定义的验证集路径\n",
    "            image_path = os.path.join(original_val_image_dir, f\"{image_folder}.png\")\n",
    "\n",
    "        misclassified_info.append({\n",
    "            'image_path': image_path,\n",
    "            'true_label': int(row['Pterygium']),\n",
    "            'predicted_label': int(row['Predicted'])\n",
    "        })\n",
    "    print(\"部分错误分类样本信息:\")\n",
    "    for info in misclassified_info[:5]: # 只显示前5个\n",
    "        print(f\"  路径: {os.path.basename(info['image_path'])}, 真实: {info['true_label']}, 预测: {info['predicted_label']}\")\n",
    "else:\n",
    "    print(\"\\n验证集上没有发现错误分类的样本。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# 使用 SHAP 解释部分正确分类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 找出正确分类的样本 ---\n",
    "correctly_classified_indices = [i for i, (true, pred) in enumerate(zip(all_targets, all_predictions)) if true == pred]\n",
    "\n",
    "if len(correctly_classified_indices) >= 3:\n",
    "    print(f\"\\n从 {len(correctly_classified_indices)} 个正确分类的样本中随机选择 3 个进行 SHAP 解释...\")\n",
    "    \n",
    "    # --- 随机选择 3 个 ---\n",
    "    selected_indices = random.sample(correctly_classified_indices, 3)\n",
    "    print(f\"选择的验证集索引: {selected_indices}\")\n",
    "\n",
    "    # --- 准备选择的样本 ---\n",
    "    explain_info_correct = []\n",
    "    explain_images_pil_correct = []\n",
    "    explain_images_tensor_correct = []\n",
    "\n",
    "    for index in selected_indices:\n",
    "        # 从 val_df 获取图像信息\n",
    "        row = val_df.iloc[index] \n",
    "        image_name = row['Image']\n",
    "        true_label = int(row['Pterygium'])\n",
    "        \n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        # 确定图像路径 (同之前的逻辑)\n",
    "        image_path = os.path.join(val_dataset.image_dir, image_folder, f\"{image_folder}.png\") # 假设用resize后的\n",
    "        if not os.path.exists(image_path) and 'original_image_dir' in globals(): # 如果resize后的找不到，尝试原始的\n",
    "            image_path = os.path.join(original_image_dir, image_folder, f\"{image_folder}.png\") # 需要确保 original_image_dir 已定义\n",
    "        elif not os.path.exists(image_path): # 如果原始的也找不到，尝试全局验证集路径\n",
    "            original_val_image_dir = val_image_dir \n",
    "            image_path = os.path.join(original_val_image_dir, f\"{image_folder}.png\")\n",
    "\n",
    "\n",
    "        explain_info_correct.append({\n",
    "            'image_path': image_path,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': true_label # 因为是正确分类的样本\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            explain_images_pil_correct.append(img) # 保存原始PIL图像\n",
    "            # 使用验证集变换\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device) \n",
    "            explain_images_tensor_correct.append(img_tensor)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"警告: 找不到图像 {image_path}，跳过解释。\")\n",
    "            # 从 explain_info_correct 中移除对应的条目，以防后续处理出错\n",
    "            explain_info_correct.pop() \n",
    "        except Exception as e:\n",
    "            print(f\"加载或预处理图像 {image_path} 时出错: {e}，跳过解释。\")\n",
    "            explain_info_correct.pop()\n",
    "\n",
    "    if not explain_images_tensor_correct:\n",
    "        print(\"没有可供解释的图像。\")\n",
    "    else:\n",
    "        # 合并为一个批次\n",
    "        explain_batch_correct = torch.cat(explain_images_tensor_correct, dim=0)\n",
    "        num_explain_correct = explain_batch_correct.shape[0] # 实际成功加载的数量\n",
    "        print(f\"成功加载 {num_explain_correct} 个图像进行解释。\")\n",
    "\n",
    "        # --- 准备背景数据 (同之前逻辑) ---\n",
    "        num_background_samples = 64 # 可以调整数量\n",
    "        background_indices = np.random.choice(len(train_dataset), num_background_samples, replace=False)\n",
    "        # 确保获取的是图像张量 train_dataset[i][0]\n",
    "        background_data = torch.stack([train_dataset[i][0] for i in background_indices]).to(device) \n",
    "        print(f\"使用 {num_background_samples} 个训练样本作为 SHAP 背景数据。\")\n",
    "\n",
    "        # --- 创建 SHAP 解释器 ---\n",
    "        # 确保模型处于评估模式\n",
    "        model.eval() \n",
    "        explainer_correct = shap.GradientExplainer(model, background_data)\n",
    "\n",
    "        # --- 计算 SHAP 值 ---\n",
    "        print(\"正在计算正确分类样本的 SHAP 值...\")\n",
    "        shap_values_correct = explainer_correct.shap_values(explain_batch_correct)\n",
    "        print(\"SHAP 值计算完成。\")\n",
    "\n",
    "        # --- 准备可视化 ---\n",
    "        shap_values_np_correct = np.array(shap_values_correct) # (num_classes, num_samples, C, H, W)\n",
    "        images_np_correct = explain_batch_correct.cpu().numpy().transpose(0, 2, 3, 1) # NCHW -> NHWC\n",
    "\n",
    "        # 反归一化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        images_np_denorm_correct = std * images_np_correct + mean\n",
    "        images_np_denorm_correct = np.clip(images_np_denorm_correct, 0, 1)\n",
    "\n",
    "        # 准备标签和标题\n",
    "        class_names=[\"健康\", \"建议观察\", \"建议手术\"]\n",
    "        plot_labels_correct = np.array([class_names] * num_explain_correct) \n",
    "        \n",
    "        sample_titles_correct = [f\"样本 (文件: {os.path.basename(info['image_path'])})\\n真实/预测: {class_names[info['true_label']]}\" \n",
    "                                for info in explain_info_correct]\n",
    "\n",
    "        # 调整 SHAP 值格式\n",
    "        shap_values_plot_correct = np.stack([sv.transpose(0, 2, 3, 1) for sv in shap_values_correct], axis=-1) # N, H, W, C, num_classes\n",
    "\n",
    "        # --- 可视化前先显示图像和标题 ---\n",
    "        #print(\"显示选择的正确分类样本及其标签:\")\n",
    "        #plt.figure(figsize=(5 * num_explain_correct, 5)) # 调整图像大小\n",
    "        #for i in range(num_explain_correct):\n",
    "        #    plt.subplot(1, num_explain_correct, i + 1)\n",
    "        #    plt.imshow(images_np_denorm_correct[i])\n",
    "        #    plt.title(sample_titles_correct[i], fontsize=10) # 调整字体大小\n",
    "        #    plt.axis('off')\n",
    "        #plt.tight_layout() # 调整布局防止标题重叠\n",
    "        #plt.show()\n",
    "        \n",
    "        # --- 可视化 SHAP 结果 ---\n",
    "        print(\"生成 SHAP 图像...\")\n",
    "        # 注意：shap.image_plot 可能会在一个图中显示所有样本和类别，标题需要看上面分开显示的图\n",
    "        # 尝试乘以一个系数来增强可视化效果（如果值太小）\n",
    "        shap.image_plot(shap_values_plot_correct * shap_scaling_factor, \n",
    "                        images_np_denorm_correct, \n",
    "                        labels=plot_labels_correct, \n",
    "                        show=True) # 直接显示\n",
    "\n",
    "elif len(correctly_classified_indices) > 0:\n",
    "    print(f\"\\n正确分类的样本数量 ({len(correctly_classified_indices)}) 不足 3 个，无法选择 3 个进行解释。\")\n",
    "else:\n",
    "    print(\"\\n验证集中没有正确分类的样本可供解释。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# 使用 SHAP 解释错误分类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if misclassified_info:\n",
    "    print(\"\\n--- 使用 SHAP 解释部分错误分类样本 ---\")\n",
    "    \n",
    "    # 1. 选择要解释的样本 (选择前 N 个)\n",
    "    num_explain = min(10, len(misclassified_info))\n",
    "    explain_info = misclassified_info[:num_explain]\n",
    "    explain_images_pil = []\n",
    "    explain_images_tensor = []\n",
    "\n",
    "    print(f\"准备解释 {num_explain} 个样本...\")\n",
    "    for info in explain_info:\n",
    "        try:\n",
    "            img = Image.open(info['image_path']).convert(\"RGB\")\n",
    "            explain_images_pil.append(img) # 保存原始PIL图像用于绘图标题\n",
    "            # 使用验证集的变换进行预处理，并移动到设备\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "            explain_images_tensor.append(img_tensor)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"警告: 找不到图像 {info['image_path']}，跳过解释。\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载或预处理图像 {info['image_path']} 时出错: {e}，跳过解释。\")\n",
    "\n",
    "    if not explain_images_tensor:\n",
    "        print(\"没有可供解释的图像。\")\n",
    "    else:\n",
    "        # 合并为一个批次\n",
    "        explain_batch = torch.cat(explain_images_tensor, dim=0)\n",
    "\n",
    "        # 2. 准备背景数据 (使用训练集的一小部分)\n",
    "        num_background_samples = 64\n",
    "        background_indices = np.random.choice(len(train_dataset), num_background_samples, replace=False)\n",
    "        background_data = torch.stack([train_dataset[i][0] for i in background_indices]).to(device) \n",
    "\n",
    "        print(f\"使用 {num_background_samples} 个训练样本作为 SHAP 背景数据。\")\n",
    "\n",
    "        # 3. 创建 SHAP 解释器\n",
    "        # 对于 PyTorch 模型，GradientExplainer 或 DeepExplainer 是常用选择\n",
    "        # GradientExplainer 通常更通用\n",
    "        explainer = shap.GradientExplainer(model, background_data)\n",
    "\n",
    "        # 4. 计算 SHAP 值\n",
    "        print(\"正在计算 SHAP 值...\")\n",
    "\n",
    "        shap_values = explainer.shap_values(explain_batch)\n",
    "        print(\"SHAP 值计算完成。\")\n",
    "\n",
    "        # --- 检查 SHAP 值 ---\n",
    "        shap_values_np = np.array(shap_values) # 转换为 NumPy 数组方便操作\n",
    "        print(f\"SHAP 值数组形状: {shap_values_np.shape}\") # 应该是 (num_classes, num_samples, C, H, W)\n",
    "        print(f\"所有 SHAP 值的最小值: {shap_values_np.min()}\")\n",
    "        print(f\"所有 SHAP 值的最大值: {shap_values_np.max()}\")\n",
    "        print(f\"所有 SHAP 值的平均绝对值: {np.mean(np.abs(shap_values_np))}\")\n",
    "        # --- 检查结束 ---\n",
    "\n",
    "        # 5. 可视化 SHAP 结果\n",
    "        # shap_values 对于多分类任务，是一个列表，每个元素对应一个类的 SHAP 值 (NumPy array)\n",
    "        # 形状通常是 [num_classes, num_samples, C, H, W]\n",
    "        # image_plot 需要 NumPy array，格式为 [N, H, W, C] 或 [N, C, H, W]\n",
    "        # 我们需要将 SHAP 值和图像数据移回 CPU 并转换为 NumPy\n",
    "\n",
    "        images_np = explain_batch.cpu().numpy().transpose(0, 2, 3, 1) # NCHW -> NHWC\n",
    "\n",
    "        # 反归一化图像以便更好地可视化\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        images_np_denorm = std * images_np + mean\n",
    "        images_np_denorm = np.clip(images_np_denorm, 0, 1)\n",
    "\n",
    "        # 准备标签用于绘图\n",
    "        class_names=[\"健康\", \"建议观察\", \"建议手术\"]\n",
    "        plot_labels = np.array([class_names] * num_explain) \n",
    "            \n",
    "        # 获取每个样本的真实和预测标签字符串，用于单独显示或在图外显示\n",
    "        true_labels = [info['true_label'] for info in explain_info]\n",
    "        predicted_labels = [info['predicted_label'] for info in explain_info]\n",
    "        sample_titles = [f\"样本 {idx+1} (文件: {os.path.basename(explain_info[idx]['image_path'])})\\n真实: {class_names[tl]}, 预测: {class_names[pl]}\" \n",
    "                        for idx, (tl, pl) in enumerate(zip(true_labels, predicted_labels))]\n",
    "\n",
    "        # 调整 shap_values 格式以匹配 image_plot 的期望\n",
    "        shap_values_np = [sv.transpose(0, 2, 3, 1) for sv in shap_values] # NCHW -> NHWC for each class\n",
    "        shap_values_plot = np.stack(shap_values_np, axis=-1) # Stack along the last axis -> [N, H, W, C, num_classes]\n",
    "\n",
    "        print(\"生成 SHAP 图像...\")\n",
    "        # --- (可选) 在调用 image_plot 之前单独显示每个样本及其 True/Pred 标签 ---\n",
    "        #for i in range(num_explain):\n",
    "        #    plt.figure()\n",
    "        #    plt.imshow(images_np_denorm[i])\n",
    "        #    plt.title(sample_titles[i])\n",
    "        #    plt.axis('off')\n",
    "        #    plt.show()\n",
    "\n",
    "        shap.image_plot(shap_values_plot * shap_scaling_factor,\n",
    "                        images_np_denorm, \n",
    "                        labels=plot_labels, # 为每个类别提供标签\n",
    "                        true_labels=None, # true_labels 已包含在 labels 中\n",
    "                        show=True) # 直接显示图像\n",
    "\n",
    "else:\n",
    "    print(\"\\n没有错误分类的样本可供 SHAP 解释。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2025-04-13T02:01:58.797761",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.790330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "papermill": {
     "duration": 0.083802,
     "end_time": "2025-04-13T02:01:58.888785",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.804983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载模型参数\n",
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    print(f\"模型参数已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 保存训练好的模型\n",
    "model_save_path = \"./resnet18base_pterygium_classifier_base.pth\"\n",
    "save_model(model, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "y6VojVHqjSpF",
    "papermill": {
     "duration": 0.007359,
     "end_time": "2025-04-13T02:01:58.904324",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.896965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型测试和预测\n",
    "使用训练好的模型对新图像进行预测，并展示几个预测示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "W3PhSqxEjSpF",
    "papermill": {
     "duration": 0.318951,
     "end_time": "2025-04-13T02:01:59.230622",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.911671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型测试和预测\n",
    "import shutil\n",
    "\n",
    "\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "def test_model_on_val(model, device, input_dir, temp_dir, transform):\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "    # 删除临时目录中的旧文件\n",
    "    for img_path in glob.glob(os.path.join(temp_dir, \"*.png\")):\n",
    "        os.remove(img_path)\n",
    "    results = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Processing images\", leave=True):\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]  # ...获取文件名（不带扩展）...\n",
    "        output_path = os.path.join(temp_dir, f\"{base_name}.{output_format.lower()}\")\n",
    "        if not os.path.exists(output_path):\n",
    "            try:\n",
    "                if resize_and_save_image({\"Image\": base_name}, input_dir, temp_dir, resize_transform, device):\n",
    "                    predicted_class = predict_image(model, output_path, transform, device)\n",
    "                    results.append({\"Image\": base_name, \"Pterygium\": predicted_class})\n",
    "                else:\n",
    "                    tqdm.write(f\"Resize失败: {img_path}\")\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"处理图像 {img_path} 时出错: {e}\")\n",
    "    \n",
    "    results.sort(key=lambda x: int(x[\"Image\"]))\n",
    "    df = pd.DataFrame(results, columns=[\"Image\", \"Pterygium\"])\n",
    "    result_path = os.path.join(kaggle_temp_path, \"Classification_Results.xlsx\")\n",
    "    shutil.rmtree(result_path,ignore_errors=True)\n",
    "    df.to_excel(result_path, index=False)\n",
    "    print(f\"分类结果已保存到 {result_path}\")\n",
    "    print(f'删除验证集缓存数据 {temp_dir}')\n",
    "    for img_path in glob.glob(os.path.join(temp_dir, \"*.png\")):\n",
    "        os.remove(img_path)\n",
    "\n",
    "# 加载保存的模型并进行推理\n",
    "loaded_model = ResNet18Classifier(num_classes=3)\n",
    "loaded_model = load_model(loaded_model, model_save_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "papermill": {
     "duration": 0.057612,
     "end_time": "2025-04-13T02:01:59.296113",
     "exception": false,
     "start_time": "2025-04-13T02:01:59.238501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # 单文件推理\n",
    "    test_image_path = \"./test_images/sample_image.png\"  # 替换为实际测试图像路径\n",
    "    predicted_class = predict_image(loaded_model, test_image_path, val_transform, device)\n",
    "    class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "    print(f\"加载模型后预测结果: 图像 {os.path.basename(test_image_path)}, 预测类别: {class_names[predicted_class]}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "papermill": {
     "duration": 140.716871,
     "end_time": "2025-04-13T02:04:20.020553",
     "exception": false,
     "start_time": "2025-04-13T02:01:59.303682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 验证集推理\n",
    "val_temp_dir = os.path.join(kaggle_temp_path, \"val_resized\")\n",
    "test_model_on_val(loaded_model, device, val_image_dir, val_temp_dir, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "papermill": {
     "duration": 0.007368,
     "end_time": "2025-04-13T02:04:20.035996",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.028628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 基线模型波动范围检测\n",
    "为了理解模型性能的自然波动范围，我们将使用完全相同的设置重复训练过程10次。\n",
    "每次运行都会重新初始化模型权重、优化器和早停策略。\n",
    "我们将记录每次运行最终的验证集准确率和Macro F1分数，并计算平均值和标准差。\n",
    "同时，我们也会保存每次运行的学习曲线（验证准确率随epoch的变化）并进行可视化。\n",
    "\n",
    "**警告:** 这将花费大约10倍的单次训练时间！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "papermill": {
     "duration": 295.540911,
     "end_time": "2025-04-13T02:09:15.584272",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.043361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 实验参数 ---\n",
    "num_runs = 5  # 重复运行的次数\n",
    "base_seed = 420 # 基础随机种子，每次运行会递增\n",
    "\n",
    "# --- 存储结果 ---\n",
    "all_final_val_accuracies = []\n",
    "all_final_macro_f1_scores = []\n",
    "all_learning_curves = [] # 存储每个run的验证准确率历史\n",
    "# best_model_state_dicts = [] # 如果需要保存每次运行的最佳模型权重\n",
    "\n",
    "# --- 定义损失函数 (可以在循环外定义，因为无状态) ---\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "# 注意：确保 HighlightRegularizedLoss 类已经定义\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01) # 再次注意：正则项仍未启用\n",
    "\n",
    "# --- 开始多次运行循环 ---\n",
    "print(f\"开始进行 {num_runs} 次独立训练运行以评估波动性...\")\n",
    "\n",
    "for run in range(num_runs):\n",
    "    run_id_str = f\"Run {run + 1}/{num_runs}\"\n",
    "    print(f\"\\n--- 开始 {run_id_str} ---\")\n",
    "\n",
    "    # --- 1. 设置随机种子 ---\n",
    "    current_seed = base_seed + run * 1000\n",
    "    torch.manual_seed(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "    random.seed(current_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(current_seed)\n",
    "        # 下面两行可确保重复性，但是降低性能\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # --- 2. 创建此运行所需的模型、优化器和调度器实例 ---\n",
    "    # **每次循环都必须创建新的实例**\n",
    "    model = ResNet18Classifier(num_classes=3).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=7e-4, weight_decay=1e-4) # 使用基线超参数\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-6) # 使用基线超参数\n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "    \n",
    "    # --- 3. 调用训练函数 ---\n",
    "    # train_loader 和 val_loader 是之前已经定义好的\n",
    "    final_acc, final_f1, history, best_state = train_validate_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        run_identifier=run_id_str\n",
    "    )\n",
    "\n",
    "    # --- 4. 存储结果 ---\n",
    "    all_final_val_accuracies.append(final_acc)\n",
    "    all_final_macro_f1_scores.append(final_f1)\n",
    "    all_learning_curves.append(history)\n",
    "    # if best_state: # 如果需要保存权重\n",
    "    #     best_model_state_dicts.append(best_state)\n",
    "\n",
    "# --- 5. 多次运行结束后，进行分析和可视化 ---\n",
    "print(\"\\n--- 多次运行结果分析 ---\")\n",
    "\n",
    "# 计算平均值和标准差\n",
    "mean_accuracy = np.mean(all_final_val_accuracies)\n",
    "std_accuracy = np.std(all_final_val_accuracies)\n",
    "mean_f1 = np.mean(all_final_macro_f1_scores)\n",
    "std_f1 = np.std(all_final_macro_f1_scores)\n",
    "\n",
    "print(f\"平均验证准确率: {mean_accuracy:.4f}%\")\n",
    "print(f\"验证准确率标准差: {std_accuracy:.4f}%\")\n",
    "print(f\"平均验证Macro F1: {mean_f1:.4f}\")\n",
    "print(f\"验证Macro F1标准差: {std_f1:.4f}\")\n",
    "\n",
    "print(\"\\n每次运行的最终验证准确率:\")\n",
    "for i, acc in enumerate(all_final_val_accuracies):\n",
    "    print(f\"  Run {i+1}: {acc:.4f}%\")\n",
    "\n",
    "print(\"\\n每次运行的最终验证Macro F1:\")\n",
    "for i, f1 in enumerate(all_final_macro_f1_scores):\n",
    "    print(f\"  Run {i+1}: {f1:.4f}\")\n",
    "\n",
    "# --- 6. 可视化学习曲线 (与之前相同) ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, curve in enumerate(all_learning_curves):\n",
    "    epochs_run = range(1, len(curve) + 1)\n",
    "    plt.plot(epochs_run, curve, label=f'Run {i+1}', alpha=0.7)\n",
    "\n",
    "plt.title('不同运行的验证准确率学习曲线')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('验证准确率 (%)')\n",
    "plt.legend(loc='lower right', ncol=2)\n",
    "plt.grid(True)\n",
    "# 动态调整Y轴范围，确保所有曲线可见\n",
    "min_y_val = np.min([min(c) for c in all_learning_curves if c]) if any(all_learning_curves) else 80 # 如果有数据则取最小值，否则默认80\n",
    "max_y_val = np.max([max(c) for c in all_learning_curves if c]) if any(all_learning_curves) else 100 # 如果有数据则取最大值，否则默认100\n",
    "plt.ylim(bottom=max(0, min_y_val - 2), top=min(100, max_y_val + 2)) # 确保在[0, 100]范围内，并留出边距\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231745112,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 937.871658,
   "end_time": "2025-04-13T02:09:18.610590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T01:53:40.738932",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
