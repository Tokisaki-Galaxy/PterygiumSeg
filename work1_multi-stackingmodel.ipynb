{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翼状胬肉诊断模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8rV7E66jSoG",
    "papermill": {
     "duration": 0.004352,
     "end_time": "2025-04-13T01:53:45.053747",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.049395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "base_seed = 420 # 用于 KFold 分割的随机种子\n",
    "\n",
    "# --- 定义两阶段 Stacking 的基础 CNN 模型列表 ---\n",
    "# Stage 1: 二分类 (正常 vs 有病)\n",
    "CNN_FEATURE_EXTRACTORS_STAGE1 = ['ResNet18Classifier','EfficientNetB0Classifier', 'DenseNet121Classifier']\n",
    "# Stage 2: 二分类 (观察 vs 手术) - 仅用于 Stage 1 预测为有病 (>0) 的情况\n",
    "CNN_FEATURE_EXTRACTORS_STAGE2 = ['ResNet50Classifier','EfficientNetB4Classifier', 'DenseNet201Classifier']\n",
    "\n",
    "# --- CNN 微调参数 (在每折内部使用) ---\n",
    "cnn_micro_train_stage1_params = {\n",
    "    'num_epochs': 25,    # 在每折中微调 CNN 的 epoch 数\n",
    "    'lr': 4e-4,          # 微调的学习率\n",
    "    'weight_decay': 2e-4,# 微调的权重衰减\n",
    "    'patience': 5\n",
    "}\n",
    "\n",
    "cnn_micro_train_stage2_params = {\n",
    "    'num_epochs': 35,\n",
    "    'lr': 4e-4,\n",
    "    'weight_decay': 2e-4,\n",
    "    'patience': 7\n",
    "}\n",
    "\n",
    "# --- 元模型类型选择 ---\n",
    "# 可选: 'LightGBM', 'LogisticRegression'\n",
    "META_MODEL_TYPE = 'LightGBM'\n",
    "# --- Logistic Regression 超参数 ---\n",
    "logreg_params = {\n",
    "    'solver': 'lbfgs',      # 求解器，lbfgs 通常适用于小数据集和多类问题\n",
    "    'multi_class': 'auto',  # 多类问题策略，'auto' 会根据数据自动选择 'ovr' 或 'multinomial'\n",
    "    'max_iter': 1000,       # 迭代次数，确保收敛\n",
    "    'random_state': base_seed, # 随机种子\n",
    "    'n_jobs': -1            # 使用所有可用核心\n",
    "}\n",
    "# --- LightGBM 超参数 ---\n",
    "lgbm_params = {\n",
    "    'objective': 'binary',     # 二分类任务\n",
    "    'metric': 'binary_logloss',# Log Loss 作为评估指标\n",
    "    'boosting_type': 'gbdt',   # 梯度提升决策树\n",
    "    'n_estimators': 1000,      # 树的数量 (配合早停使用，可以设置得大一些)\n",
    "    'learning_rate': 0.03,     # 学习率\n",
    "    'num_leaves': 20,          # 控制树的复杂度，防止过拟合\n",
    "    'max_depth': -1,           # 树的最大深度，-1表示不限制 (配合 num_leaves 控制)\n",
    "    'seed': base_seed,         # 随机种子\n",
    "    'n_jobs': -1,              # 使用所有可用核心\n",
    "    'verbose': -1,             # 不打印中间信息\n",
    "    'colsample_bytree': 0.7,   # 每棵树随机采样的特征比例\n",
    "    'subsample': 0.7,          # 每棵树随机采样的样本比例\n",
    "    'reg_alpha': 0.3,          # L1 正则化\n",
    "    'reg_lambda': 0.3,         # L2 正则化\n",
    "    'min_child_samples': 30    # 叶子节点的最小样本数\n",
    "}\n",
    "\n",
    "# ================== 缩放参数设置 =================\n",
    "TARGET_SIZE = (512, 512)\n",
    "TRAIN_SIZE = (512, 512)\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "#colab_val_zip_path = \"/content/drive/My Drive/val.zip\"\n",
    "#colab_val_extract_path = \"/content/val/\"\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# =================== SHAP设置 =================\n",
    "shap_scaling_factor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():\n",
    "    \"\"\"\n",
    "    检查是否可能缺少 GUI 后端（例如，在无头服务器上运行）。\n",
    "    如果是这种情况，将 Matplotlib 后端设置为 'Agg' 以避免错误。\n",
    "\n",
    "    应该在首次导入 `matplotlib.pyplot` 之前调用此函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        # 尝试获取 IPython 实例\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-siDBWjjSo6",
    "papermill": {
     "duration": 11.426914,
     "end_time": "2025-04-13T01:53:56.485296",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.058382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "import shap\n",
    "import sys\n",
    "from PIL import Image\n",
    "import platform\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        subprocess.run(['wget','-q','-O', 'simhei.ttf', \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"], check=True)\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqZSY8dujSo8",
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-04-13T01:53:56.494490",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.490079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80",
    "papermill": {
     "duration": 0.023889,
     "end_time": "2025-04-13T01:53:56.522681",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.498792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('.env'):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('.env')\n",
    "\n",
    "R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID', '')\n",
    "R2_SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', '')\n",
    "R2_BUCKET_NAME = os.environ.get('R2_BUCKET_NAME', '')\n",
    "R2_ENDPOINT_URL = os.environ.get('R2_ENDPOINT_URL', '')\n",
    "\n",
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive # type: ignore\n",
    "        from google.colab import userdata # type: ignore\n",
    "        drive.mount('/content/drive')\n",
    "        R2_ACCESS_KEY_ID = userdata.get(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = userdata.get(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = userdata.get(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = userdata.get(\"R2_ENDPOINT_URL\")\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # Google Drive 有每日下载次数限制，可能会导致下载失败\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "\n",
    "        from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "        user_secrets = UserSecretsClient()\n",
    "        R2_ACCESS_KEY_ID = user_secrets.get_secret(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = user_secrets.get_secret(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = user_secrets.get_secret(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = user_secrets.get_secret(\"R2_ENDPOINT_URL\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类，用于读取图像和标签，并支持阶段性标签映射和过滤\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, initial_labels_df, image_dir, transform=None, stage=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param initial_labels_df: 包含图像原始标签的 Pandas DataFrame\n",
    "        :param image_dir: 图像文件夹路径 (应是resize后的图像路径)\n",
    "        :param transform: 图像变换操作\n",
    "        :param stage: 指定数据集用于哪个阶段 ('stage1', 'stage2')。\n",
    "                    'stage1': 标签 0->0, 1->1, 2->1 (二分类: 正常 vs 有病)\n",
    "                    'stage2': 过滤原标签 1, 2 的数据, 标签 1->0, 2->1 (二分类: 建议观察 vs 建议手术)\n",
    "                    None: 标签保持原样 0, 1, 2 (三分类)\n",
    "        \"\"\"\n",
    "        self.original_labels_df = initial_labels_df.copy()\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "        \n",
    "        # 根据阶段过滤和映射标签\n",
    "        if self.stage == 'stage1':\n",
    "            self.labels_df = self.original_labels_df.copy()\n",
    "            # 阶段1标签映射: 0 -> 0, 1 -> 1, 2 -> 1\n",
    "            self.labels_df['Pterygium'] = self.labels_df['Pterygium'].apply(lambda x: 0 if x == 0 else 1)\n",
    "            print(f\"数据集初始化为 Stage 1 (正常 vs 有病), 标签映射 0->0, >0->1. 数据量: {len(self.labels_df)}\")\n",
    "            print(f\"阶段 1 标签分布: \\n{self.labels_df['Pterygium'].value_counts()}\")\n",
    "        elif self.stage == 'stage2':\n",
    "            # 阶段2数据过滤: 只保留原标签为 1 或 2 的数据\n",
    "            self.labels_df = self.original_labels_df[self.original_labels_df['Pterygium'].isin([1, 2])].copy()\n",
    "            # 阶段2标签映射: 1 -> 0, 2 -> 1\n",
    "            self.labels_df['Pterygium'] = self.labels_df['Pterygium'].apply(lambda x: 0 if x == 1 else 1)\n",
    "            print(f\"数据集初始化为 Stage 2 (建议观察 vs 建议手术), 过滤原标签 0 数据. 数据量: {len(self.labels_df)}\")\n",
    "            print(f\"阶段 2 标签映射 1->0, 2->1. 阶段 2 标签分布: \\n{self.labels_df['Pterygium'].value_counts()}\")\n",
    "        else: # Default: original 3-class labels\n",
    "            self.labels_df = self.original_labels_df.copy()\n",
    "            print(f\"数据集初始化为原始三分类 (0, 1, 2). 数据量: {len(self.labels_df)}\")\n",
    "            print(f\"原始标签分布: \\n{self.labels_df['Pterygium'].value_counts()}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签 (已根据阶段进行映射)\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium'] # Use the potentially mapped label\n",
    "\n",
    "        # 图像文件路径构建 (假设resize后的图像保存在 image_dir/0001/0001.png 或 image_dir/0001.png)\n",
    "        # resize_and_save_image 函数对于训练集是保存在子文件夹，验证集是直接保存在根目录\n",
    "        image_folder_name = f\"{int(image_name):04d}\"\n",
    "        image_path_in_folder = os.path.join(self.image_dir, image_folder_name, f\"{image_folder_name}.{output_format.lower()}\")\n",
    "        image_path_in_root = os.path.join(self.image_dir, f\"{image_folder_name}.{output_format.lower()}\")\n",
    "\n",
    "        if os.path.exists(image_path_in_folder):\n",
    "            image_path = image_path_in_folder\n",
    "        elif os.path.exists(image_path_in_root):\n",
    "            image_path = image_path_in_root\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Image file not found for {image_name} at expected paths: {image_path_in_folder} or {image_path_in_root}\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004176,
     "end_time": "2025-04-13T01:53:56.531483",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.527307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 数据 Resize\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_r2_client():\n",
    "    \"\"\"尝试创建并返回一个配置好的 boto3 R2 客户端。\"\"\"\n",
    "    # 确认环境变量已加载 (这些变量应在之前的单元格中设置)\n",
    "    required_vars = ['R2_ENDPOINT_URL', 'R2_ACCESS_KEY_ID', 'R2_SECRET_ACCESS_KEY', 'R2_BUCKET_NAME']\n",
    "    if not all(var in globals() and globals()[var] for var in required_vars):\n",
    "        print(\"R2 配置不完整（缺少 Endpoint URL, Access Key, Secret Key 或 Bucket Name）。跳过 R2 缓存。\")\n",
    "        return None, False # 返回 None 和 R2 未配置标志\n",
    "\n",
    "    global r2_configured # 声明我们要修改全局变量\n",
    "    r2_configured = True # 标记 R2 已配置\n",
    "\n",
    "    try:\n",
    "        print(\"正在创建 R2 (boto3 S3) 客户端...\")\n",
    "        s3_client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=R2_ENDPOINT_URL,\n",
    "            aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "            region_name='auto', # R2 通常使用 'auto'\n",
    "            config=botocore.config.Config(signature_version='s3v4') # 明确签名版本\n",
    "        )\n",
    "        # 尝试列出 buckets (可选，作为连接测试)\n",
    "        # s3_client.list_buckets()\n",
    "        print(\"R2 客户端创建成功。\")\n",
    "        return s3_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"创建 R2 客户端时出错: {e}\")\n",
    "        r2_configured = False # 出错则标记为未配置\n",
    "        return None, False\n",
    "\n",
    "def check_r2_cache(s3_client, bucket_name, cache_key):\n",
    "    \"\"\"检查指定的缓存键是否存在于 R2 存储桶中。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False # 文件未找到\n",
    "        else:\n",
    "            # 其他错误 (如权限问题)\n",
    "            print(f\"检查 R2 缓存时出错 (Key: {cache_key}): {e}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"检查 R2 缓存时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_from_r2(s3_client, bucket_name, cache_key, local_path):\n",
    "    \"\"\"从 R2 下载文件到本地路径，带进度条。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        # 获取文件大小以显示进度\n",
    "        response = s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        total_size = int(response.get('ContentLength', 0))\n",
    "\n",
    "        print(f\"正在从 R2 下载 {cache_key} 到 {local_path} ({total_size / (1024*1024):.2f} MB)...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Filename=local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 下载完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"从 R2 下载文件时出错 (Key: {cache_key}): {e}\")\n",
    "        # 如果文件下载失败，尝试删除本地可能不完整的文件\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"下载 R2 文件时发生未知错误: {e}\")\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def upload_to_r2(s3_client, bucket_name, local_path, cache_key):\n",
    "    \"\"\"将本地文件上传到 R2，带进度条。\"\"\"\n",
    "    if not s3_client or not os.path.exists(local_path):\n",
    "        print(f\"上传 R2 失败：客户端未初始化或本地文件不存在 ({local_path})。\")\n",
    "        return False\n",
    "    try:\n",
    "        total_size = os.path.getsize(local_path)\n",
    "        print(f\"正在上传 {local_path} ({total_size / (1024*1024):.2f} MB) 到 R2 作为 {cache_key}...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 上传完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"上传文件到 R2 时出错 (Key: {cache_key}): {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"上传 R2 文件时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"压缩指定文件夹的内容到 zip 文件。\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"错误：要压缩的文件夹不存在 {folder_path}\")\n",
    "        return False\n",
    "    print(f\"正在压缩目录 {folder_path} 到 {zip_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # 获取文件夹内的所有文件和子文件夹\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for filename in files:\n",
    "                    file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "            # 使用 tqdm 显示压缩进度 (按文件数)\n",
    "            with tqdm(total=len(file_paths), desc=\"压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                for file in file_paths:\n",
    "                    # 计算文件在 zip 中的相对路径\n",
    "                    arcname = os.path.relpath(file, folder_path)\n",
    "                    zipf.write(file, arcname)\n",
    "                    pbar.update(1)\n",
    "        print(\"目录压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"压缩目录时出错: {e}\")\n",
    "        # 如果压缩失败，删除可能不完整的 zip 文件\n",
    "        if os.path.exists(zip_path):\n",
    "            try: os.remove(zip_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def unzip_directory(zip_path, extract_to_folder):\n",
    "    \"\"\"解压缩 zip 文件到指定文件夹。\"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"错误：要解压的 zip 文件不存在 {zip_path}\")\n",
    "        return False\n",
    "    print(f\"正在解压缩文件 {zip_path} 到 {extract_to_folder}...\")\n",
    "    try:\n",
    "        os.makedirs(extract_to_folder, exist_ok=True) # 确保目标文件夹存在\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # 获取 zip 文件中的成员数量以显示进度\n",
    "            total_files = len(zip_ref.namelist())\n",
    "            with tqdm(total=total_files, desc=\"解压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                # 使用 extractall 并更新进度条可能不直接，改为逐个提取\n",
    "                for member in zip_ref.infolist():\n",
    "                    zip_ref.extract(member, extract_to_folder)\n",
    "                    pbar.update(1)\n",
    "                    # 或者直接用 extractall，进度条可能不准确但更快\n",
    "                    # zip_ref.extractall(extract_to_folder)\n",
    "        print(\"文件解压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"解压缩文件时出错: {e}\")\n",
    "        # 如果解压失败，可以选择是否删除不完整的解压目录\n",
    "        # if os.path.exists(extract_to_folder):\n",
    "        #     shutil.rmtree(extract_to_folder)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Resize(TARGET_SIZE, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_name = f\"{int(image_name):04d}\"\n",
    "        if os.path.exists(os.path.join(base_input_dir, f\"{image_name}.png\")):\n",
    "            # 验证集图像路径\n",
    "            input_path = os.path.join(base_input_dir, f\"{image_name}.png\")\n",
    "            os.makedirs(base_output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(base_output_dir, f\"{image_name}.{output_format.lower()}\")\n",
    "        else:\n",
    "            # 训练集图像路径\n",
    "            input_path = os.path.join(base_input_dir, image_name, f\"{image_name}.png\")\n",
    "            # Create corresponding output subdirectory if it doesn't exist\n",
    "            output_folder_path = os.path.join(base_output_dir, image_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "            output_path = os.path.join(output_folder_path, f\"{image_name}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    print('在 Google Colab 环境中运行')\n",
    "    original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "    output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    temp_dir = colab_extract_path\n",
    "elif os.path.exists(\"/kaggle/working\"):\n",
    "    print('在 Kaggle 环境中运行')\n",
    "    original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "    output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    temp_dir = kaggle_temp_path\n",
    "else:\n",
    "    print(\"错误: 无法识别的非 Windows 环境（可能是Linux），需要手动处理\")\n",
    "    exit(1)\n",
    "\n",
    "if original_image_dir:\n",
    "    print(f\"原始输入目录: {original_image_dir}\")\n",
    "    print(f\"目标输出目录: {output_dir}\")\n",
    "    print(f\"临时文件目录: {temp_dir}\")\n",
    "    print(f\"目标尺寸: {TARGET_SIZE}\")\n",
    "\n",
    "    # 创建 R2 客户端并检查配置\n",
    "    s3_client, r2_configured = create_r2_client()\n",
    "    r2_cache_key = f\"work1_resized_{TARGET_SIZE[0]}x{TARGET_SIZE[1]}.zip\"\n",
    "    print(f\"生成的 R2 缓存键: {r2_cache_key}\")\n",
    "    r2_local_zip_path = os.path.join(temp_dir, r2_cache_key)\n",
    "    resize_done = False\n",
    "    if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据在本地，跳过resize步骤\")\n",
    "        resize_done = True\n",
    "\n",
    "    # --- If not found locally, try R2 cache ---\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if not resize_done and r2_configured:\n",
    "        print(f\"本地目录 {output_dir} 为空或不存在，尝试检查 R2 缓存...\")\n",
    "        if check_r2_cache(s3_client, R2_BUCKET_NAME, r2_cache_key):\n",
    "            print(f\"检测到 R2 缓存文件: {r2_cache_key}. 尝试下载...\")\n",
    "            # Download the cache\n",
    "            if download_from_r2(s3_client, R2_BUCKET_NAME, r2_cache_key, r2_local_zip_path):\n",
    "                print(f\"R2 缓存下载成功。正在解压到 {output_dir}...\")\n",
    "                # Unzip the cache\n",
    "                # Ensure output_dir is clean before extracting to avoid mixing old/new files\n",
    "                if os.path.exists(output_dir):\n",
    "                    try: shutil.rmtree(output_dir)\n",
    "                    except Exception as e: print(f\"警告: 清理旧的输出目录失败: {e}\")\n",
    "                os.makedirs(output_dir, exist_ok=True) # Recreate empty directory\n",
    "                if unzip_directory(r2_local_zip_path, output_dir):\n",
    "                    print(\"R2 缓存解压成功。跳过本地resize步骤。\")\n",
    "                    resize_done = True # Data loaded from R2 cache\n",
    "                    # Clean up the temporary zip file after extraction\n",
    "                    if os.path.exists(r2_local_zip_path):\n",
    "                        try: os.remove(r2_local_zip_path)\n",
    "                        except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存解压失败。将执行本地resize。\")\n",
    "                    resize_done = False # Reset flag to perform local resize\n",
    "                    # Clean up potentially incomplete extraction directory\n",
    "                    if os.path.exists(output_dir):\n",
    "                        try: shutil.rmtree(output_dir)\n",
    "                        except Exception as e: print(f\"警告: 清理不完整输出目录失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 从 R2 下载缓存失败。将执行本地resize。\")\n",
    "                resize_done = False # Reset flag to perform local resize\n",
    "        else:\n",
    "            print(\"未检测到 R2 缓存文件。将执行本地resize。\")\n",
    "            resize_done = False # Ensure flag is false\n",
    "    elif not resize_done and not r2_configured:\n",
    "        print(\"R2 未配置或初始化失败，将执行本地resize。\")\n",
    "        resize_done = False # Ensure flag is false\n",
    "    # --- Perform local resizing if not done by cache ---\n",
    "    if not resize_done:\n",
    "        print(\"执行本地图像resize...\")\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading label file {label_file}: {e}\")\n",
    "            sys.exit(1)\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        # Create the main output directory BEFORE starting the loop (done above, but ensure it exists)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # Iterate through images listed in the label file\n",
    "        # Use original_image_dir as input base for resizing\n",
    "        for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "            if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "        print(f\"\\n本地处理完成!\")\n",
    "        print(f\"成功处理图像数: {success_count}\")\n",
    "        print(f\"处理失败图像数: {error_count}\")\n",
    "        print(f\"处理后的图像保存在: {output_dir}\")\n",
    "        # --- Upload resized data to R2 cache if configured and resizing was successful ---\n",
    "        if r2_configured and success_count > 0: # Only upload if some files were processed successfully\n",
    "            print(f\"将本地resize后的数据上传到 R2 缓存 ({r2_cache_key})...\")\n",
    "            # Create a zip file of the output directory\n",
    "            if zip_directory(output_dir, r2_local_zip_path):\n",
    "                # Upload the zip file\n",
    "                if upload_to_r2(s3_client, R2_BUCKET_NAME, r2_local_zip_path, r2_cache_key):\n",
    "                    print(\"R2 缓存上传成功。\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存上传失败。\")\n",
    "                # Clean up the temporary local zip file after upload attempt\n",
    "                if os.path.exists(r2_local_zip_path):\n",
    "                    try: os.remove(r2_local_zip_path)\n",
    "                    except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 创建本地 zip 文件失败，跳过 R2 上传。\")\n",
    "        elif not r2_configured:\n",
    "            print(\"R2 未配置，跳过上传resize后的数据。\")\n",
    "        elif success_count == 0:\n",
    "            print(\"本地resize失败（成功处理图像数为0），跳过R2上传。\")\n",
    "    image_dir = output_dir\n",
    "else:\n",
    "    print(\"未识别的非 Windows 环境，跳过图片resize步骤。\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okNIq-rfjSo-",
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-04-13T02:01:05.452384",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.448028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟高光的数据增强策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class AddRandomHighlight:\n",
    "    \"\"\"\n",
    "    一个 torchvision transform，用于在 PIL 图像上随机添加圆形高光。\n",
    "\n",
    "    参数:\n",
    "        p (float): 应用此变换的概率 (0 到 1)。\n",
    "        max_highlights (int): 单张图像上添加的最大高光数量（实际数量将在1到max_highlights之间随机选择）。\n",
    "        radius_range (tuple): 一个包含两个整数的元组 (min_radius, max_radius)，指定高光圆形的半径范围。\n",
    "        color (tuple): 一个包含三个整数的元组 (R, G, B)，指定高光的颜色 (默认为白色)。\n",
    "    \"\"\"\n",
    "    def __init__(self, p=0.5, max_highlights=3, radius_range=(5, 15), color=(255, 255, 255)):\n",
    "        if not 0.0 <= p <= 1.0:\n",
    "            raise ValueError(f\"概率 p 必须在 [0, 1] 范围内, 但得到 {p}\")\n",
    "        if not (isinstance(max_highlights, int) and max_highlights >= 1):\n",
    "            raise ValueError(f\"最大高光数 max_highlights 必须是 >= 1 的整数, 但得到 {max_highlights}\")\n",
    "        if not (isinstance(radius_range, tuple) and len(radius_range) == 2 and\n",
    "                isinstance(radius_range[0], int) and isinstance(radius_range[1], int) and\n",
    "                0 < radius_range[0] <= radius_range[1]):\n",
    "            raise ValueError(f\"半径范围 radius_range 必须是 (min, max) 形式的正整数元组，且 min <= max, 但得到 {radius_range}\")\n",
    "        if not (isinstance(color, tuple) and len(color) == 3 and all(0 <= c <= 255 for c in color)):\n",
    "            raise ValueError(f\"颜色 color 必须是 (R, G, B) 形式的元组，且值在 [0, 255] 范围内, 但得到 {color}\")\n",
    "            \n",
    "        self.p = p\n",
    "        self.max_highlights = max_highlights\n",
    "        self.radius_range = radius_range\n",
    "        self.color = color\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        对输入的 PIL 图像应用变换。\n",
    "\n",
    "        参数:\n",
    "            img (PIL.Image.Image): 输入的 PIL 图像。\n",
    "\n",
    "        返回:\n",
    "            PIL.Image.Image: 可能添加了高光的 PIL 图像。\n",
    "        \"\"\"\n",
    "        # 以概率 p 应用此变换\n",
    "        if random.random() < self.p:\n",
    "            # 复制图像以避免修改原始图像（如果原始图像后续还需使用）\n",
    "            # 如果这是 Compose 链中的一步，通常不需要显式复制\n",
    "            # img = img.copy() # 如果需要确保不修改原始输入，取消注释此行\n",
    "\n",
    "            # 随机决定生成多少个高光 (至少1个)\n",
    "            # 根据用户要求“小于四个”，我们生成 1 到 max_highlights (这里是3) 个\n",
    "            num_highlights = random.randint(1, self.max_highlights)\n",
    "            \n",
    "            # 获取图像尺寸\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 创建 ImageDraw 对象以在图像上绘制\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            for _ in range(num_highlights):\n",
    "                # 随机选择半径\n",
    "                radius = random.randint(self.radius_range[0], self.radius_range[1])\n",
    "                \n",
    "                # 随机选择圆心位置\n",
    "                # 确保圆心位置加上半径不会超出图像边界太多（允许部分圆在边缘）\n",
    "                # 稍微限制圆心范围，避免完全生成在图像外的圆心\n",
    "                center_x = random.randint(0, width - 1) \n",
    "                center_y = random.randint(0, height - 1)\n",
    "\n",
    "                # 计算圆形的边界框 (left, top, right, bottom)\n",
    "                # ellipse 方法绘制的是指定边界框内的椭圆，如果边界框是正方形，则为圆形\n",
    "                left = center_x - radius\n",
    "                top = center_y - radius\n",
    "                right = center_x + radius\n",
    "                bottom = center_y + radius\n",
    "                \n",
    "                # 绘制实心圆形高光\n",
    "                draw.ellipse([left, top, right, bottom], fill=self.color)\n",
    "            \n",
    "        # 返回处理后的图像（可能是原始图像或添加了高光的图像）\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 提供一个清晰的表示形式，方便调试\n",
    "        return f\"{self.__class__.__name__}(p={self.p}, max_highlights={self.max_highlights}, radius_range={self.radius_range}, color={self.color})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11JDwC__jSo-",
    "papermill": {
     "duration": 1.465971,
     "end_time": "2025-04-13T02:01:06.922765",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.456794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((int(TRAIN_SIZE[0]*1.2), int(TRAIN_SIZE[1]*1.2))), # 先放大一点\n",
    "    transforms.RandomCrop(TRAIN_SIZE), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=20), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    AddRandomHighlight(p=0.3, max_highlights=3, radius_range=(5, 12)), # 添加高光抑制模型关注高光问题\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(TRAIN_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=420, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 读取标签文件\n",
    "if 'label_file' not in globals() or not os.path.exists(label_file):\n",
    "    print(\"错误: 标签文件路径未设置或文件不存在。请检查前面的数据准备步骤。\")\n",
    "    sys.exit(\"标签文件未找到，无法继续。\")\n",
    "full_labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 过滤掉标签不是 0, 1, 2 的数据（如果存在的话）\n",
    "full_labels_df = full_labels_df[full_labels_df['Pterygium'].isin([0, 1, 2])].reset_index(drop=True)\n",
    "\n",
    "# 创建基础数据集实例，不应用变换 (变换在创建 Subset 时按需应用)\n",
    "# 这个数据集将用于根据索引创建 Subset\n",
    "base_full_dataset_no_transform = PterygiumDataset(initial_labels_df=full_labels_df, image_dir=image_dir, transform=None,stage=None)\n",
    "\n",
    "print(f\"成功加载完整数据集，共 {len(base_full_dataset_no_transform)} 张图像。\")\n",
    "# 存储原始标签，用于 Stage 1 K-Fold split 和最终评估\n",
    "all_original_labels = base_full_dataset_no_transform.labels_df['Pterygium'].values\n",
    "all_original_indices = base_full_dataset_no_transform.labels_df.index.values # 存储DataFrame的索引，用于后续映射\n",
    "\n",
    "# 准备 Stage 1 标签 (0: 正常, 1: 有病)\n",
    "# 映射规则: 0 -> 0, 1 -> 1, 2 -> 1\n",
    "stage1_labels = np.where(all_original_labels > 0, 1, 0)\n",
    "\n",
    "# 准备 Stage 2 数据和标签 (仅限原始标签 1 或 2 的数据)\n",
    "stage2_indices = np.where(all_original_labels > 0)[0] # 找到原始标签 > 0 的索引\n",
    "stage2_original_labels = all_original_labels[stage2_indices] # 对应的原始标签 (1或2)\n",
    "# Note: Stage 2 labels will be the original 1 and 2.\n",
    "# We might map them to 0 and 1 internally for Stage 2 model training,\n",
    "# but need to map back for combined prediction. Let's keep them as 1 and 2\n",
    "# and set num_class=2 in lgbm_params, relying on LightGBM/LogReg to handle these labels.\n",
    "# Or, map 1->0, 2->1 for training and then map back 0->1, 1->2 for final prediction.\n",
    "# Let's map 1->0, 2->1 for training Stage 2 meta-model for consistency with 0-based indexing.\n",
    "stage2_train_labels_mapped = np.where(stage2_original_labels == 1, 0, 1) # Map 1 -> 0, 2 -> 1 for Stage 2 training\n",
    "\n",
    "print(f\"Stage 1 数据量: {len(all_original_labels)} ({np.sum(stage1_labels == 0)} 正常, {np.sum(stage1_labels == 1)} 有病)\")\n",
    "print(f\"Stage 2 (有病) 数据量: {len(stage2_indices)} ({np.sum(stage2_original_labels == 1)} 观察, {np.sum(stage2_original_labels == 2)} 手术)\")\n",
    "\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(initial_labels_df=train_df, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(initial_labels_df=val_df, image_dir=image_dir, transform=val_transform) # 使用验证变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGn3VBzHjSo_",
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-04-13T02:01:06.932847",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.928379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 构建 ResNet 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b",
    "papermill": {
     "duration": 0.692259,
     "end_time": "2025-04-13T02:01:07.629659",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.937400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
    "\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "class ResNet101Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet101 = models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "        in_features = self.resnet101.fc.in_features\n",
    "        self.resnet101.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet101(x)\n",
    "\n",
    "class ResNet152Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet152 = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "        in_features = self.resnet152.fc.in_features\n",
    "        self.resnet152.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet152(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import EfficientNet_B0_Weights, efficientnet_b0, efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "class EfficientNetB0Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5): # num_classes 将根据阶段设置为 2\n",
    "        super().__init__()\n",
    "        self.efficientnet = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.efficientnet.classifier[-1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "class EfficientNetB4Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 EfficientNetB4 预训练模型\n",
    "        self.efficientnet = efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "        # EfficientNet 的分类器是一个 Sequential 模块 (Dropout, Linear)\n",
    "        # 获取最终 Linear 层的输入特征数\n",
    "        in_features = self.efficientnet.classifier[-1].in_features \n",
    "        # 替换整个分类器模块\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, densenet201, DenseNet121_Weights, DenseNet201_Weights\n",
    "\n",
    "class DenseNet121Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 DenseNet121 预训练模型\n",
    "        self.densenet = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        # DenseNet 的分类器是一个 Linear 层\n",
    "        # 获取 Linear 层的输入特征数\n",
    "        in_features = self.densenet.classifier.in_features\n",
    "        # 替换分类器层 (为了与 ResNet 保持一致，使用 Sequential 包含 Dropout 和 Linear)\n",
    "        self.densenet.classifier = nn.Sequential( \n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "    \n",
    "class DenseNet201Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5): # num_classes 将根据阶段设置为 2\n",
    "        super().__init__()\n",
    "        self.densenet = densenet201(weights=DenseNet201_Weights.IMAGENET1K_V1)\n",
    "        in_features = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建ConvNeXt Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "class ConvNeXtBaseClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 ConvNeXt Base 预训练模型\n",
    "        self.convnext = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # ConvNeXt 的分类器结构是 Sequential(LayerNorm2d, Flatten, Linear)\n",
    "        # 我们需要替换最后的 Linear 层，并在其前面添加 Dropout\n",
    "        original_classifier_layers = list(self.convnext.classifier.children())\n",
    "        \n",
    "        # 获取原始 Linear 层的输入特征数\n",
    "        original_linear_layer = original_classifier_layers[-1]\n",
    "        in_features = original_linear_layer.in_features\n",
    "        \n",
    "        # 构建新的分类器 Sequential: 保留之前的层 -> 添加 Dropout -> 添加新的 Linear 层\n",
    "        new_classifier_layers = original_classifier_layers[:-1] # 保留 LayerNorm2d 和 Flatten\n",
    "        new_classifier_layers.append(nn.Dropout(p=dropout_rate)) # 添加 Dropout\n",
    "        new_classifier_layers.append(nn.Linear(in_features, num_classes)) # 添加新的 Linear 层\n",
    "\n",
    "        # 替换原模型的分类器模块\n",
    "        self.convnext.classifier = nn.Sequential(*new_classifier_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        return self.convnext(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2025-04-13T02:01:58.797761",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.790330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.083802,
     "end_time": "2025-04-13T02:01:58.888785",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.804983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存 Boosting 模型\n",
    "def save_boosting_model(model, path):\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Boosting 模型已保存到 {path}\")\n",
    "\n",
    "# 加载 Boosting 模型\n",
    "def load_boosting_model(path):\n",
    "    model = joblib.load(path)\n",
    "    print(f\"Boosting 模型已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 保存 CNN 模型参数 (如果需要在预测时加载 CNN 特征提取器，例如在最终预测阶段)\n",
    "def save_cnn_state_dict(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"CNN 模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载 CNN 模型参数\n",
    "def load_cnn_state_dict(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    print(f\"CNN 模型参数已从 {path} 加载\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Ensemble K 折交叉验证 (两阶段)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 存储 K-Fold 结果 ---\n",
    "# 用于收集所有折的 OOF 预测和标签\n",
    "all_oof_indices_stage1 = []\n",
    "all_oof_meta_features_stage1 = []\n",
    "all_oof_labels_stage1 = [] # Stage 1 (0 vs 1) labels\n",
    "\n",
    "all_oof_indices_stage2 = []\n",
    "all_oof_meta_features_stage2 = []\n",
    "all_oof_labels_stage2 = [] # Stage 2 (1 vs 2) original labels\n",
    "\n",
    "# --- 创建 Stage 1 KFold 分割器 (基于 Stage 1 标签) ---\n",
    "if K > 0 and len(stage1_labels) > 0:\n",
    "    skf_stage1 = StratifiedKFold(n_splits=K, shuffle=True, random_state=base_seed)\n",
    "    print(f\"开始进行 Stage 1 ({K}-Fold Cross-Validation: 0 vs >0)...\")\n",
    "else:\n",
    "    print(\"Skipping Stage 1 K-Fold Cross-Validation due to data preparation error or K=0.\")\n",
    "    K = 0 # Ensure K=0 if data is missing\n",
    "\n",
    "# --- Stage 1 K-Fold 循环 ---\n",
    "if K > 0:\n",
    "    current_fold_num = 0\n",
    "    # Iterate on the indices of the full dataset\n",
    "    for train_idx_fold_stage1, val_idx_fold_stage1 in skf_stage1.split(np.arange(len(base_full_dataset_no_transform)), stage1_labels):\n",
    "        current_fold_num += 1\n",
    "        fold_id_str = f\"Stage 1 - Fold {current_fold_num}/{K}\"\n",
    "        print(f\"\\n--- 开始 {fold_id_str} ---\")\n",
    "\n",
    "        # --- 1. 创建当前折的 Subset 数据集和 DataLoader ---\n",
    "        # 使用原始数据集，但通过索引和变换创建 Subset\n",
    "        train_dataset_fold_stage1 = Subset(base_full_dataset_no_transform, train_idx_fold_stage1)\n",
    "        val_dataset_fold_stage1 = Subset(base_full_dataset_no_transform, val_idx_fold_stage1)\n",
    "        \n",
    "        # 为 Subset 应用变换\n",
    "        train_dataset_fold_stage1.dataset.transform = train_transform\n",
    "        val_dataset_fold_stage1.dataset.transform = val_transform\n",
    "\n",
    "        train_loader_fold_stage1 = DataLoader(train_dataset_fold_stage1,\n",
    "                                            batch_size=64 if TRAIN_SIZE[0] <257 else 30,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=2 if platform.system() == \"Windows\" else 8,\n",
    "                                            pin_memory=False)\n",
    "        val_loader_fold_stage1 = DataLoader(val_dataset_fold_stage1,\n",
    "                                            batch_size=64 if TRAIN_SIZE[0] <257 else 30,\n",
    "                                            shuffle=False, # 验证集不 shuffle\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=2 if platform.system() == \"Windows\" else 8,\n",
    "                                            pin_memory=False)\n",
    "        print(f\"{fold_id_str}: Train size={len(train_dataset_fold_stage1)}, Val size={len(val_dataset_fold_stage1)}\")\n",
    "\n",
    "        # --- 2. 微调 Stage 1 CNN 基础分类器 ---\n",
    "        print(f\"--- {fold_id_str}: 微调 CNN 基础分类器 (Level-0 Models) ---\")\n",
    "        \n",
    "        fold_cnn_finetuned_classifiers_stage1 = {} # 存储微调好的完整 CNN 分类器\n",
    "\n",
    "        # CNN base models for Stage 1 predict num_classes=2 (0 or 1)\n",
    "        num_classes_stage1_cnn = 2 \n",
    "        \n",
    "        for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE1:\n",
    "            print(f\"  微调 {cnn_name} (Stage 1)...\")\n",
    "            # 创建一个新的 CNN 模型实例 (带分类头), 输出层适应 2 类\n",
    "            cnn_model_for_finetuning_stage1 = globals()[cnn_name](num_classes=num_classes_stage1_cnn).to(device)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            best_model_state_dict = None\n",
    "            \n",
    "            cnn_optimizer = optim.AdamW(cnn_model_for_finetuning_stage1.parameters(), \n",
    "                                        lr=cnn_micro_train_stage1_params['lr'], \n",
    "                                        weight_decay=cnn_micro_train_stage1_params['weight_decay'])\n",
    "            cnn_scheduler = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer, \n",
    "                                                                T_max=cnn_micro_train_stage1_params['num_epochs'], \n",
    "                                                                eta_min=1e-6)\n",
    "            cnn_criterion = nn.CrossEntropyLoss()\n",
    "            scaler_cnn = torch.amp.GradScaler('cuda') \n",
    "            \n",
    "            start_time_cnn_finetune = time.time()\n",
    "            \n",
    "            for cnn_epoch in range(cnn_micro_train_stage1_params['num_epochs']):\n",
    "                cnn_model_for_finetuning_stage1.train()\n",
    "                train_loss_cnn = 0\n",
    "                train_correct_cnn = 0\n",
    "                train_total_cnn = 0\n",
    "                \n",
    "                cnn_train_loader_tqdm = tqdm(train_loader_fold_stage1, desc=f'  {cnn_name} Stage 1 Epoch {cnn_epoch+1}/{cnn_micro_train_stage1_params[\"num_epochs\"]}', leave=False)\n",
    "                \n",
    "                for batch_idx, (inputs, targets_orig) in enumerate(cnn_train_loader_tqdm):\n",
    "                    # Map original labels to Stage 1 labels (0 or 1) for CNN training\n",
    "                    targets_stage1 = torch.where(targets_orig > 0, 1, 0).to(device)\n",
    "                    inputs = inputs.to(device)\n",
    "                    \n",
    "                    cnn_optimizer.zero_grad()\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_model_for_finetuning_stage1(inputs)\n",
    "                        loss = cnn_criterion(outputs, targets_stage1) # Use Stage 1 labels for loss\n",
    "                    scaler_cnn.scale(loss).backward()\n",
    "                    scaler_cnn.step(cnn_optimizer)\n",
    "                    scaler_cnn.update()\n",
    "                    train_loss_cnn += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    train_total_cnn += targets_stage1.size(0)\n",
    "                    train_correct_cnn += predicted.eq(targets_stage1).sum().item()\n",
    "                    \n",
    "                    cnn_train_loader_tqdm.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'acc': f'{100. * train_correct_cnn / train_total_cnn:.2f}%',\n",
    "                        'lr': f'{cnn_optimizer.param_groups[0][\"lr\"]:.1e}'\n",
    "                    })\n",
    "                cnn_scheduler.step() # Update CNN learning rate\n",
    "\n",
    "                # --- 基于验证集损失的早停 ---\n",
    "                cnn_model_for_finetuning_stage1.eval()\n",
    "                val_loss_cnn = 0\n",
    "                val_total_cnn = 0\n",
    "                with torch.no_grad():\n",
    "                    for inputs, targets_orig in val_loader_fold_stage1:\n",
    "                        targets_stage1_val = torch.where(targets_orig > 0, 1, 0).to(device) # Use Stage 1 mapped labels for validation loss\n",
    "                        inputs = inputs.to(device)\n",
    "                        with torch.amp.autocast('cuda'):\n",
    "                            outputs = cnn_model_for_finetuning_stage1(inputs)\n",
    "                            loss = cnn_criterion(outputs, targets_stage1_val)\n",
    "                        val_loss_cnn += loss.item()\n",
    "                        val_total_cnn += targets_stage1_val.size(0)\n",
    "\n",
    "                avg_val_loss = val_loss_cnn / len(val_loader_fold_stage1) if len(val_loader_fold_stage1) > 0 else float('inf')\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 1 Epoch {cnn_epoch+1}: Train Loss {train_loss_cnn/len(train_loader_fold_stage1):.4f}, Val Loss {avg_val_loss:.4f}\")\n",
    "\n",
    "                # Initialize best_val_loss and best_model_state_dict before the epoch loop\n",
    "                if 'best_val_loss' not in locals() or avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0 # Reset patience\n",
    "                    best_model_state_dict = cnn_model_for_finetuning_stage1.state_dict() # Save best model state\n",
    "                    print(f\"    {fold_id_str} {cnn_name} Val Loss improved. Saving model state.\")\n",
    "                else:\n",
    "                    patience_counter += 1 # Increment patience if no improvement\n",
    "                    print(f\"    {fold_id_str} {cnn_name} Val Loss did not improve. Patience: {patience_counter}/{cnn_micro_train_stage1_params['patience']}\")\n",
    "\n",
    "                cnn_model_for_finetuning_stage1.train() # Set model back to train mode\n",
    "\n",
    "                if patience_counter >= cnn_micro_train_stage1_params['patience']:\n",
    "                    print(f\"\\n    {fold_id_str} {cnn_name} Stage 1 Early stopping triggered at epoch {cnn_epoch+1}.\")\n",
    "                    break\n",
    "\n",
    "            # --- 训练结束后，加载验证集上表现最好的模型状态 ---\n",
    "            if best_model_state_dict is not None:\n",
    "                cnn_model_for_finetuning_stage1.load_state_dict(best_model_state_dict)\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 1: Loaded best model state based on validation loss.\")\n",
    "            else:\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 1: No best model state saved (maybe due to inf loss?). Using last epoch model state.\")\n",
    "\n",
    "            end_time_cnn_finetune = time.time()\n",
    "            print(f\"  微调 {cnn_name} (Stage 1) 完成，耗时: {end_time_cnn_finetune - start_time_cnn_finetune:.2f} 秒\")\n",
    "\n",
    "            # --- 评估微调后的基础 CNN 分类器在验证集上的性能 (for reporting base model performance, not essential for stacking) ---\n",
    "            # This evaluation is on the Stage 1 task (0 vs 1)\n",
    "            print(f\"  评估微调后的基础模型 {cnn_name} (Stage 1) 在 Stage 1 验证集上...\")\n",
    "            cnn_model_for_finetuning_stage1.eval() \n",
    "            val_correct_cnn_base_stage1 = 0\n",
    "            val_total_cnn_base_stage1 = 0\n",
    "            all_val_labels_cnn_base_stage1 = []\n",
    "            all_val_preds_cnn_base_stage1 = []\n",
    "\n",
    "            with torch.no_grad(): \n",
    "                cnn_val_loader_tqdm_base = tqdm(val_loader_fold_stage1, desc=f'  Evaluating Base {cnn_name} (Stage 1)', leave=False)\n",
    "                for batch_idx, (inputs, targets_orig) in enumerate(cnn_val_loader_tqdm_base):\n",
    "                    targets_stage1_val = torch.where(targets_orig > 0, 1, 0).to(device)\n",
    "                    inputs = inputs.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_model_for_finetuning_stage1(inputs)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    val_total_cnn_base_stage1 += targets_stage1_val.size(0)\n",
    "                    val_correct_cnn_base_stage1 += predicted.eq(targets_stage1_val).sum().item()\n",
    "                    all_val_labels_cnn_base_stage1.extend(targets_stage1_val.cpu().numpy())\n",
    "                    all_val_preds_cnn_base_stage1.extend(predicted.cpu().numpy())\n",
    "\n",
    "            cnn_val_accuracy_base_stage1 = 100. * val_correct_cnn_base_stage1 / val_total_cnn_base_stage1 if val_total_cnn_base_stage1 > 0 else 0\n",
    "            cnn_val_macro_precision_base_stage1 = precision_score(all_val_labels_cnn_base_stage1, all_val_preds_cnn_base_stage1, average='macro', zero_division=0)\n",
    "            cnn_val_macro_f1_base_stage1 = f1_score(all_val_labels_cnn_base_stage1, all_val_preds_cnn_base_stage1, average='macro', zero_division=0)\n",
    "            print(f\"    {fold_id_str} Base {cnn_name} Val Acc (Stage 1): {cnn_val_accuracy_base_stage1:.2f}%, Macro Precision: {cnn_val_macro_precision_base_stage1:.4f}, Macro F1: {cnn_val_macro_f1_base_stage1:.4f}\")\n",
    "            \n",
    "            # Store the finetuned classifier\n",
    "            cnn_model_for_finetuning_stage1.eval() \n",
    "            fold_cnn_finetuned_classifiers_stage1[cnn_name] = cnn_model_for_finetuning_stage1\n",
    "\n",
    "        # --- 3. 生成 Stage 1 元特征 (来自微调后的 Stage 1 CNN 在当前折验证集上的预测概率) ---\n",
    "        print(f\"--- {fold_id_str}: 生成元特征 (用于 Stage 1 元模型训练) ---\")\n",
    "        \n",
    "        current_val_meta_features_stage1_list = []   \n",
    "        current_val_labels_stage1_list = [] # Stage 1 labels (0 or 1) for validation data in this fold\n",
    "\n",
    "        # Get the actual indices for this fold's validation set\n",
    "        current_val_indices_fold_stage1 = val_idx_fold_stage1 \n",
    "        \n",
    "        # Collect Stage 1 labels for this fold's validation set\n",
    "        current_val_labels_stage1 = stage1_labels[current_val_indices_fold_stage1]\n",
    "\n",
    "        # 对每个微调好的 Stage 1 CNN 获取其在当前折验证集上的预测概率\n",
    "        for cnn_name, cnn_classifier_model in fold_cnn_finetuned_classifiers_stage1.items():\n",
    "            cnn_classifier_model.eval() \n",
    "            current_val_probs_fold_list = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets_orig in tqdm(val_loader_fold_stage1, desc=f\"元特征(Stage 1 Val) from {cnn_name}\", leave=False):\n",
    "                    # No need to map targets here, just use inputs\n",
    "                    inputs = inputs.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_classifier_model(inputs)\n",
    "                        probabilities = torch.softmax(outputs, dim=1) # Get probabilities (2 classes for Stage 1 CNNs)\n",
    "                    current_val_probs_fold_list.append(probabilities.cpu().numpy())\n",
    "            \n",
    "            current_val_meta_features_stage1_list.append(np.concatenate(current_val_probs_fold_list, axis=0))\n",
    "\n",
    "        # Concatenate meta-features for this fold's validation set\n",
    "        X_val_fold_meta_stage1 = np.concatenate(current_val_meta_features_stage1_list, axis=1)\n",
    "        \n",
    "        # Store for later training of the final Stage 1 meta-model\n",
    "        all_oof_indices_stage1.extend(current_val_indices_fold_stage1)\n",
    "        all_oof_meta_features_stage1.append(X_val_fold_meta_stage1)\n",
    "        all_oof_labels_stage1.extend(current_val_labels_stage1) # Store the Stage 1 labels for this fold\n",
    "\n",
    "\n",
    "    # --- Combine Stage 1 OOF data after the loop ---\n",
    "    if all_oof_meta_features_stage1:\n",
    "        X_oof_stage1 = np.concatenate(all_oof_meta_features_stage1, axis=0)\n",
    "        y_oof_stage1 = np.array(all_oof_labels_stage1)\n",
    "        oof_indices_stage1_array = np.array(all_oof_indices_stage1) # Array for easier indexing\n",
    "        print(f\"\\nStage 1 OOF meta-features shape: {X_oof_stage1.shape}\")\n",
    "        print(f\"Stage 1 OOF labels shape: {y_oof_stage1.shape}\")\n",
    "    else:\n",
    "        print(\"\\n错误: 未生成 Stage 1 OOF 元特征。跳过 Stage 1 元模型训练和后续步骤。\")\n",
    "        K = 0 # Set K=0 to stop further processing if Stage 1 OOF failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Combine Stage 1 OOF data after the loop ---\n",
    "if all_oof_meta_features_stage1:\n",
    "    X_oof_stage1 = np.concatenate(all_oof_meta_features_stage1, axis=0)\n",
    "    y_oof_stage1 = np.array(all_oof_labels_stage1)\n",
    "    oof_indices_stage1_array = np.array(all_oof_indices_stage1) # Array for easier indexing\n",
    "    print(f\"\\nStage 1 OOF meta-features shape: {X_oof_stage1.shape}\")\n",
    "    print(f\"Stage 1 OOF labels shape: {y_oof_stage1.shape}\")\n",
    "else:\n",
    "    print(\"\\n错误: 未生成 Stage 1 OOF 元特征。跳过 Stage 1 元模型训练和后续步骤。\")\n",
    "    K = 0 # Set K=0 to stop further processing if Stage 1 OOF failed\n",
    "\n",
    "# --- 清理 Stage 1 K-Fold 训练的模型占用的 GPU 内存 ---\n",
    "print(\"\\n清理 Stage 1 K-Fold 模型占用的 GPU 内存...\")\n",
    "del fold_cnn_finetuned_classifiers_stage1,train_loader_fold_stage1,val_loader_fold_stage1,train_dataset_fold_stage1,val_dataset_fold_stage1\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Stage 1 K-Fold 模型内存清理完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 创建 Stage 2 KFold 分割器 (基于 Stage 2 数据和标签) ---\n",
    "# Filter data for Stage 2 BEFORE splitting\n",
    "stage2_original_df = base_full_dataset_no_transform.labels_df.iloc[stage2_indices].copy().reset_index(drop=True)\n",
    "# Map original labels 1, 2 to 0, 1 for Stage 2 model training\n",
    "stage2_mapped_labels = np.where(stage2_original_df['Pterygium'] == 1, 0, 1)\n",
    "\n",
    "if K > 0 and len(stage2_mapped_labels) > 0:\n",
    "    skf_stage2 = StratifiedKFold(n_splits=K, shuffle=True, random_state=base_seed)\n",
    "    print(f\"\\n开始进行 Stage 2 ({K}-Fold Cross-Validation: 1 vs 2) on {len(stage2_mapped_labels)} samples...\")\n",
    "else:\n",
    "    print(\"\\nSkipping Stage 2 K-Fold Cross-Validation due to insufficient Stage 2 data or K=0.\")\n",
    "\n",
    "# --- Stage 2 K-Fold 循环 ---\n",
    "if K > 0 and len(stage2_mapped_labels) > 0:\n",
    "    current_fold_num = 0\n",
    "    # Iterate on the indices of the stage2_original_df\n",
    "    for train_idx_fold_stage2_relative, val_idx_fold_stage2_relative in skf_stage2.split(np.arange(len(stage2_original_df)), stage2_mapped_labels):\n",
    "        current_fold_num += 1\n",
    "        fold_id_str = f\"Stage 2 - Fold {current_fold_num}/{K}\"\n",
    "        print(f\"\\n--- 开始 {fold_id_str} ---\")\n",
    "\n",
    "        # --- Map relative Stage 2 indices back to original full dataset indices ---\n",
    "        train_idx_fold_stage2_original = stage2_indices[train_idx_fold_stage2_relative]\n",
    "        val_idx_fold_stage2_original = stage2_indices[val_idx_fold_stage2_relative]\n",
    "\n",
    "        # --- 1. 创建当前折的 Subset 数据集和 DataLoader (使用原始数据集和映射后的索引) ---\n",
    "        train_dataset_fold_stage2 = Subset(base_full_dataset_no_transform, train_idx_fold_stage2_original)\n",
    "        val_dataset_fold_stage2 = Subset(base_full_dataset_no_transform, val_idx_fold_stage2_original)\n",
    "\n",
    "        # Apply transforms\n",
    "        train_dataset_fold_stage2.dataset.transform = train_transform\n",
    "        val_dataset_fold_stage2.dataset.transform = val_transform\n",
    "\n",
    "        train_loader_fold_stage2 = DataLoader(train_dataset_fold_stage2,\n",
    "                                            batch_size=64 if TRAIN_SIZE[0] <257 else 20, # 根据GPU内存调整\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                            pin_memory=False)\n",
    "        val_loader_fold_stage2 = DataLoader(val_dataset_fold_stage2,\n",
    "                                            batch_size=64 if TRAIN_SIZE[0] <257 else 20, # 根据GPU内存调整\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                            pin_memory=False)\n",
    "        print(f\"{fold_id_str}: Train size={len(train_dataset_fold_stage2)}, Val size={len(val_dataset_fold_stage2)}\")\n",
    "\n",
    "        # --- 2. 微调 Stage 2 CNN 基础分类器 ---\n",
    "        print(f\"--- {fold_id_str}: 微调 CNN 基础分类器 (Level-0 Models) ---\")\n",
    "        \n",
    "        fold_cnn_finetuned_classifiers_stage2 = {} # 存储微调好的完整 CNN 分类器\n",
    "\n",
    "        # CNN base models for Stage 2 predict num_classes=2 (for mapped labels 0 or 1)\n",
    "        num_classes_stage2_cnn = 2 \n",
    "        \n",
    "        for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE2:\n",
    "            print(f\"  微调 {cnn_name} (Stage 2)...\")\n",
    "            # 创建一个新的 CNN 模型实例 (带分类头), 输出层适应 2 类\n",
    "            cnn_model_for_finetuning_stage2 = globals()[cnn_name](num_classes=num_classes_stage2_cnn).to(device)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            best_model_state_dict = None\n",
    "            \n",
    "            cnn_optimizer = optim.AdamW(cnn_model_for_finetuning_stage2.parameters(), \n",
    "                                        lr=cnn_micro_train_stage2_params['lr'], \n",
    "                                        weight_decay=cnn_micro_train_stage2_params['weight_decay'])\n",
    "            cnn_scheduler = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer, \n",
    "                                                                T_max=cnn_micro_train_stage2_params['num_epochs'], \n",
    "                                                                eta_min=1e-6)\n",
    "            cnn_criterion = nn.CrossEntropyLoss()\n",
    "            scaler_cnn = torch.amp.GradScaler('cuda') \n",
    "            \n",
    "            start_time_cnn_finetune = time.time()\n",
    "            \n",
    "            for cnn_epoch in range(cnn_micro_train_stage2_params['num_epochs']):\n",
    "                cnn_model_for_finetuning_stage2.train()\n",
    "                train_loss_cnn = 0\n",
    "                train_correct_cnn = 0\n",
    "                train_total_cnn = 0\n",
    "                \n",
    "                cnn_train_loader_tqdm = tqdm(train_loader_fold_stage2, desc=f'  {cnn_name} Stage 2 Epoch {cnn_epoch+1}/{cnn_micro_train_stage2_params[\"num_epochs\"]}', leave=False)\n",
    "                \n",
    "                for batch_idx, (inputs, targets_orig) in enumerate(cnn_train_loader_tqdm):\n",
    "                    # Map original labels (1 or 2) to Stage 2 training labels (0 or 1) for CNN training\n",
    "                    targets_stage2_mapped = torch.where(targets_orig == 1, 0, 1).to(device)\n",
    "                    inputs = inputs.to(device)\n",
    "                    \n",
    "                    cnn_optimizer.zero_grad()\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_model_for_finetuning_stage2(inputs)\n",
    "                        loss = cnn_criterion(outputs, targets_stage2_mapped) # Use MAPPED Stage 2 labels for loss\n",
    "                    scaler_cnn.scale(loss).backward()\n",
    "                    scaler_cnn.step(cnn_optimizer)\n",
    "                    scaler_cnn.update()\n",
    "                    train_loss_cnn += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    train_total_cnn += targets_stage2_mapped.size(0)\n",
    "                    train_correct_cnn += predicted.eq(targets_stage2_mapped).sum().item()\n",
    "                    \n",
    "                    cnn_train_loader_tqdm.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'acc': f'{100. * train_correct_cnn / train_total_cnn:.2f}%',\n",
    "                        'lr': f'{cnn_optimizer.param_groups[0][\"lr\"]:.1e}'\n",
    "                    })\n",
    "                cnn_scheduler.step() # Update CNN learning rate\n",
    "\n",
    "                # --- 基于验证集损失的早停 ---\n",
    "                cnn_model_for_finetuning_stage2.eval() # Set model to evaluation mode\n",
    "                val_loss_cnn = 0\n",
    "                val_total_cnn = 0\n",
    "                with torch.no_grad():\n",
    "                    for inputs, targets_orig in val_loader_fold_stage2:\n",
    "                        # Use Stage 2 mapped labels (1->0, 2->1) for validation loss\n",
    "                        targets_stage2_mapped_val = torch.where(targets_orig == 1, 0, 1).to(device) \n",
    "                        inputs = inputs.to(device)\n",
    "                        with torch.amp.autocast('cuda'):\n",
    "                            outputs = cnn_model_for_finetuning_stage2(inputs)\n",
    "                            loss = cnn_criterion(outputs, targets_stage2_mapped_val)\n",
    "                        val_loss_cnn += loss.item()\n",
    "                        val_total_cnn += targets_stage2_mapped_val.size(0) # Use mapped targets size\n",
    "\n",
    "                avg_val_loss = val_loss_cnn / len(val_loader_fold_stage2) if len(val_loader_fold_stage2) > 0 else float('inf')\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 2 Epoch {cnn_epoch+1}: Train Loss {train_loss_cnn/len(train_loader_fold_stage2):.4f}, Val Loss {avg_val_loss:.4f}\")\n",
    "\n",
    "                # Initialize best_val_loss and best_model_state_dict before the epoch loop\n",
    "                if 'best_val_loss' not in locals() or avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0 # Reset patience\n",
    "                    best_model_state_dict = cnn_model_for_finetuning_stage2.state_dict() # Save best model state\n",
    "                    print(f\"    {fold_id_str} {cnn_name} Val Loss improved. Saving model state.\")\n",
    "                else:\n",
    "                    patience_counter += 1 # Increment patience if no improvement\n",
    "                    print(f\"    {fold_id_str} {cnn_name} Val Loss did not improve. Patience: {patience_counter}/{cnn_micro_train_stage2_params['patience']}\")\n",
    "\n",
    "                cnn_model_for_finetuning_stage2.train() # Set model back to train mode\n",
    "\n",
    "                if patience_counter >= cnn_micro_train_stage2_params['patience']:\n",
    "                    print(f\"\\n    {fold_id_str} {cnn_name} Stage 2 Early stopping triggered at epoch {cnn_epoch+1}.\")\n",
    "                    break\n",
    "\n",
    "            # --- 训练结束后，加载验证集上表现最好的模型状态 ---\n",
    "            if best_model_state_dict is not None:\n",
    "                cnn_model_for_finetuning_stage2.load_state_dict(best_model_state_dict)\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 2: Loaded best model state based on validation loss.\")\n",
    "            else:\n",
    "                print(f\"    {fold_id_str} {cnn_name} Stage 2: No best model state saved (maybe due to inf loss?). Using last epoch model state.\")\n",
    "        \n",
    "            end_time_cnn_finetune = time.time()\n",
    "            print(f\"  微调 {cnn_name} (Stage 2) 完成，耗时: {end_time_cnn_finetune - start_time_cnn_finetune:.2f} 秒\")\n",
    "\n",
    "            # --- 评估微调后的基础 CNN 分类器在 Stage 2 验证集上的性能 ---\n",
    "            # This evaluation is on the Stage 2 task (1 vs 2), using mapped labels (0 vs 1) for evaluation metrics calculation\n",
    "            print(f\"  评估微调后的基础模型 {cnn_name} (Stage 2) 在 Stage 2 验证集上...\")\n",
    "            cnn_model_for_finetuning_stage2.eval() \n",
    "            val_correct_cnn_base_stage2 = 0\n",
    "            val_total_cnn_base_stage2 = 0\n",
    "            all_val_labels_cnn_base_stage2_mapped = []\n",
    "            all_val_preds_cnn_base_stage2_mapped = []\n",
    "\n",
    "            with torch.no_grad(): \n",
    "                cnn_val_loader_tqdm_base = tqdm(val_loader_fold_stage2, desc=f'  Evaluating Base {cnn_name} (Stage 2)', leave=False)\n",
    "                for batch_idx, (inputs, targets_orig) in enumerate(cnn_val_loader_tqdm_base):\n",
    "                    targets_stage2_mapped_val = torch.where(targets_orig == 1, 0, 1).to(device)\n",
    "                    inputs = inputs.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_model_for_finetuning_stage2(inputs)\n",
    "                    _, predicted_mapped = outputs.max(1)\n",
    "                    val_total_cnn_base_stage2 += targets_stage2_mapped_val.size(0)\n",
    "                    val_correct_cnn_base_stage2 += predicted_mapped.eq(targets_stage2_mapped_val).sum().item()\n",
    "                    all_val_labels_cnn_base_stage2_mapped.extend(targets_stage2_mapped_val.cpu().numpy())\n",
    "                    all_val_preds_cnn_base_stage2_mapped.extend(predicted_mapped.cpu().numpy())\n",
    "\n",
    "            cnn_val_accuracy_base_stage2 = 100. * val_correct_cnn_base_stage2 / val_total_cnn_base_stage2 if val_total_cnn_base_stage2 > 0 else 0\n",
    "            cnn_val_macro_precision_base_stage2 = precision_score(all_val_labels_cnn_base_stage2_mapped, all_val_preds_cnn_base_stage2_mapped, average='macro', zero_division=0)\n",
    "            cnn_val_macro_f1_base_stage2 = f1_score(all_val_labels_cnn_base_stage2_mapped, all_val_preds_cnn_base_stage2_mapped, average='macro', zero_division=0)\n",
    "            print(f\"    {fold_id_str} Base {cnn_name} Val Acc (Stage 2, Mapped): {cnn_val_accuracy_base_stage2:.2f}%, Macro Precision: {cnn_val_macro_precision_base_stage2:.4f}, Macro F1: {cnn_val_macro_f1_base_stage2:.4f}\")\n",
    "            \n",
    "            # Store the finetuned classifier\n",
    "            cnn_model_for_finetuning_stage2.eval() \n",
    "            fold_cnn_finetuned_classifiers_stage2[cnn_name] = cnn_model_for_finetuning_stage2\n",
    "\n",
    "\n",
    "        # --- 3. 生成 Stage 2 元特征 (来自微调后的 Stage 2 CNN 在当前折 Stage 2 验证集上的预测概率) ---\n",
    "        print(f\"--- {fold_id_str}: 生成元特征 (用于 Stage 2 元模型训练) ---\")\n",
    "        \n",
    "        current_val_meta_features_stage2_list = []   \n",
    "        # Stage 2 labels (1 or 2) for validation data in this fold\n",
    "        current_val_labels_stage2 = all_original_labels[val_idx_fold_stage2_original]\n",
    "\n",
    "        # Get the actual indices for this fold's Stage 2 validation set\n",
    "        current_val_indices_fold_stage2 = val_idx_fold_stage2_original\n",
    "        \n",
    "        # 对每个微调好的 Stage 2 CNN 获取其在当前折 Stage 2 验证集上的预测概率\n",
    "        for cnn_name, cnn_classifier_model in fold_cnn_finetuned_classifiers_stage2.items():\n",
    "            cnn_classifier_model.eval() \n",
    "            current_val_probs_fold_list = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets_orig in tqdm(val_loader_fold_stage2, desc=f\"元特征(Stage 2 Val) from {cnn_name}\", leave=False):\n",
    "                    # No need to map targets here, just use inputs\n",
    "                    inputs = inputs.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = cnn_classifier_model(inputs)\n",
    "                        probabilities = torch.softmax(outputs, dim=1) # Get probabilities (2 classes for Stage 2 CNNs)\n",
    "                    current_val_probs_fold_list.append(probabilities.cpu().numpy())\n",
    "            \n",
    "            current_val_meta_features_stage2_list.append(np.concatenate(current_val_probs_fold_list, axis=0))\n",
    "\n",
    "        # Concatenate meta-features for this fold's Stage 2 validation set\n",
    "        X_val_fold_meta_stage2 = np.concatenate(current_val_meta_features_stage2_list, axis=1)\n",
    "        \n",
    "        # Store for later training of the final Stage 2 meta-model\n",
    "        all_oof_indices_stage2.extend(current_val_indices_fold_stage2)\n",
    "        all_oof_meta_features_stage2.append(X_val_fold_meta_stage2)\n",
    "        all_oof_labels_stage2.extend(current_val_labels_stage2) # Store the ORIGINAL Stage 2 labels (1 or 2) for this fold\n",
    "\n",
    "\n",
    "    # --- Combine Stage 2 OOF data after the loop ---\n",
    "    if all_oof_meta_features_stage2:\n",
    "        X_oof_stage2 = np.concatenate(all_oof_meta_features_stage2, axis=0)\n",
    "        y_oof_stage2 = np.array(all_oof_labels_stage2) # Original labels 1 or 2\n",
    "        oof_indices_stage2_array = np.array(all_oof_indices_stage2) # Array for easier indexing\n",
    "        print(f\"\\nStage 2 OOF meta-features shape: {X_oof_stage2.shape}\")\n",
    "        print(f\"Stage 2 OOF labels shape: {y_oof_stage2.shape}\")\n",
    "    else:\n",
    "        print(\"\\n错误: 未生成 Stage 2 OOF 元特征。跳过 Stage 2 元模型训练和后续步骤。\")\n",
    "        K = 0 # Set K=0 to stop further processing if Stage 2 OOF failed\n",
    "\n",
    "\n",
    "# --- Train Meta-Models on OOF data and Evaluate Combined Performance ---\n",
    "if K > 0 and all_oof_meta_features_stage1 and all_oof_meta_features_stage2:\n",
    "    print(\"\\n--- K-Fold 循环结束，开始训练元模型并评估组合性能 ---\")\n",
    "\n",
    "    # --- Train Stage 1 Meta-Model ---\n",
    "    print(f\"--- 训练 Stage 1 元模型 ({META_MODEL_TYPE}) on OOF data (0 vs 1) ---\")\n",
    "    \n",
    "    # Map Stage 1 OOF labels to 0 or 1 for meta-model training\n",
    "    y_oof_stage1_mapped = np.where(y_oof_stage1 > 0, 1, 0) \n",
    "\n",
    "    start_time_meta_stage1_train = time.time()\n",
    "    meta_model_stage1_oof = None\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        meta_model_stage1_oof = lgb.LGBMClassifier(**lgbm_params)\n",
    "        # Use split Stage 1 OOF data for early stopping? No, OOF is already the validation. Train on the full OOF.\n",
    "        meta_model_stage1_oof.fit(X_oof_stage1, y_oof_stage1_mapped)\n",
    "        print(\"Stage 1 LightGBM 元模型 (OOF) 训练完成。\")\n",
    "    elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "        meta_model_stage1_oof = LogisticRegression(**logreg_params) # LogisticRegression handles multi_class=auto\n",
    "        meta_model_stage1_oof.fit(X_oof_stage1, y_oof_stage1_mapped)\n",
    "        print(\"Stage 1 Logistic Regression 元模型 (OOF) 训练完成。\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported META_MODEL_TYPE for Stage 1 OOF training: {META_MODEL_TYPE}\")\n",
    "    end_time_meta_stage1_train = time.time()\n",
    "    print(f\"Stage 1 元模型训练耗时: {end_time_meta_stage1_train - start_time_meta_stage1_train:.2f} 秒\")\n",
    "\n",
    "\n",
    "    # --- Train Stage 2 Meta-Model ---\n",
    "    print(f\"\\n--- 训练 Stage 2 元模型 ({META_MODEL_TYPE}) on OOF data (1 vs 2) ---\")\n",
    "\n",
    "    # Map Stage 2 OOF labels (original 1 or 2) to 0 or 1 for meta-model training\n",
    "    y_oof_stage2_mapped = np.where(y_oof_stage2 == 1, 0, 1) \n",
    "\n",
    "    start_time_meta_stage2_train = time.time()\n",
    "    meta_model_stage2_oof = None\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        meta_model_stage2_oof = lgb.LGBMClassifier(**lgbm_params)\n",
    "        # Use split Stage 2 OOF data for early stopping? No, OOF is already the validation. Train on the full OOF.\n",
    "        meta_model_stage2_oof.fit(X_oof_stage2, y_oof_stage2_mapped)\n",
    "        print(\"Stage 2 LightGBM 元模型 (OOF) 训练完成。\")\n",
    "    elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "        meta_model_stage2_oof = LogisticRegression(**logreg_params) # LogisticRegression handles multi_class=auto\n",
    "        meta_model_stage2_oof.fit(X_oof_stage2, y_oof_stage2_mapped)\n",
    "        print(\"Stage 2 Logistic Regression 元模型 (OOF) 训练完成。\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported META_MODEL_TYPE for Stage 2 OOF training: {META_MODEL_TYPE}\")\n",
    "    end_time_meta_stage2_train = time.time()\n",
    "    print(f\"Stage 2 元模型训练耗时: {end_time_meta_stage2_train - start_time_meta_stage2_train:.2f} 秒\")\n",
    "\n",
    "\n",
    "    # --- Combine Predictions and Evaluate Overall 3-Class Metrics on OOF data ---\n",
    "    print(\"\\n--- 评估 Stacking Ensemble (两阶段) 在 OOF 数据上的组合性能 (3 类) ---\")\n",
    "\n",
    "    # Predict Stage 1 outcome for all OOF samples\n",
    "    y_pred_stage1_oof_mapped = meta_model_stage1_oof.predict(X_oof_stage1) # 0 or 1\n",
    "\n",
    "    # Initialize final predictions array for all OOF samples\n",
    "    y_combined_pred_oof = np.zeros_like(y_oof_stage1_mapped)\n",
    "\n",
    "    # Samples predicted as Normal (0) by Stage 1\n",
    "    normal_predicted_indices_in_oof = oof_indices_stage1_array[y_pred_stage1_oof_mapped == 0]\n",
    "    y_combined_pred_oof[y_pred_stage1_oof_mapped == 0] = 0 # Final prediction is 0\n",
    "\n",
    "    # Samples predicted as Diseased (>0) by Stage 1\n",
    "    diseased_predicted_indices_in_oof = oof_indices_stage1_array[y_pred_stage1_oof_mapped == 1]\n",
    "\n",
    "    # For the samples predicted as diseased by Stage 1, we need Stage 2 prediction.\n",
    "    # We need to find which of these indices are present in the Stage 2 OOF data.\n",
    "    # This requires careful indexing. We can map the indices.\n",
    "    \n",
    "    # Create a mapping from original index to its position in Stage 2 OOF data\n",
    "    stage2_oof_index_map = {original_idx: i for i, original_idx in enumerate(oof_indices_stage2_array)}\n",
    "\n",
    "    # Find indices in X_oof_stage2 that correspond to samples predicted as diseased by Stage 1\n",
    "    # These are the samples we need to predict using the Stage 2 meta-model\n",
    "    indices_for_stage2_prediction_in_oof_stage2_data = [\n",
    "        stage2_oof_index_map[original_idx]\n",
    "        for original_idx in diseased_predicted_indices_in_oof\n",
    "        if original_idx in stage2_oof_index_map # Ensure the index exists in Stage 2 OOF (should always be true if Stage 1 predicted >0)\n",
    "    ]\n",
    "    \n",
    "    # Get the subset of Stage 2 OOF meta-features for these samples\n",
    "    X_oof_stage2_subset_for_prediction = X_oof_stage2[indices_for_stage2_prediction_in_oof_stage2_data]\n",
    "\n",
    "    # Predict using Stage 2 meta-model for these samples\n",
    "    if len(X_oof_stage2_subset_for_prediction) > 0:\n",
    "        y_pred_stage2_oof_mapped_subset = meta_model_stage2_oof.predict(X_oof_stage2_subset_for_prediction) # 0 or 1\n",
    "        # Map Stage 2 predictions back to original labels (0->1, 1->2)\n",
    "        y_pred_stage2_oof_original_subset = np.where(y_pred_stage2_oof_mapped_subset == 0, 1, 2) # 1 or 2\n",
    "\n",
    "        # Place these predictions into the correct locations in the combined prediction array\n",
    "        # We need the indices *in the y_combined_pred_oof array* that correspond to these Stage 2 predictions\n",
    "        # These are the indices in y_pred_stage1_oof_mapped == 1\n",
    "        indices_to_update_in_combined_oof = np.where(y_pred_stage1_oof_mapped == 1)[0]\n",
    "\n",
    "        # Ensure the lengths match - they should if the logic is correct\n",
    "        if len(indices_to_update_in_combined_oof) == len(y_pred_stage2_oof_original_subset):\n",
    "            y_combined_pred_oof[indices_to_update_in_combined_oof] = y_pred_stage2_oof_original_subset\n",
    "        else:\n",
    "            print(\"错误: Stage 1 预测为有病的数量与 Stage 2 对应 OOF 数据数量不匹配。组合预测可能出错。\")\n",
    "            # Fallback: Could set these to a default (e.g., 1), or raise error. Let's print warning and use Stage 1 prediction as fallback (will result in 1 for all)\n",
    "            y_combined_pred_oof[indices_to_update_in_combined_oof] = 1 # Fallback to 1 if Stage 2 fails\n",
    "\n",
    "    else:\n",
    "        print(\"Stage 1 未预测任何样本为有病 (>0)。Stage 2 模型未用于 OOF 预测。\")\n",
    "\n",
    "\n",
    "    # Get the true original labels corresponding to the OOF data indices\n",
    "    # This requires mapping back using oof_indices_stage1_array\n",
    "    y_true_oof_original = all_original_labels[oof_indices_stage1_array]\n",
    "\n",
    "    # Calculate metrics using the combined predictions and original true labels\n",
    "    oof_accuracy = accuracy_score(y_true_oof_original, y_combined_pred_oof)\n",
    "    oof_macro_precision = precision_score(y_true_oof_original, y_combined_pred_oof, average='macro', zero_division=0)\n",
    "    oof_macro_f1 = f1_score(y_true_oof_original, y_combined_pred_oof, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"\\n--- Stacked Ensemble (两阶段) K-Fold OOF 评估结果 (3 类) ---\")\n",
    "    print(f\"OOF 准确率: {oof_accuracy:.4f}\")\n",
    "    print(f\"OOF Macro Precision: {oof_macro_precision:.4f}\")\n",
    "    print(f\"OOF Macro F1: {oof_macro_f1:.4f}\")\n",
    "\n",
    "    # Optional: Confusion Matrix on OOF\n",
    "    conf_matrix_oof = confusion_matrix(y_true_oof_original, y_combined_pred_oof)\n",
    "    print(\"\\nOOF 混淆矩阵:\")\n",
    "    print(conf_matrix_oof)\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping K-Fold evaluation due to errors in previous steps.\")\n",
    "\n",
    "\n",
    "# --- Clean up temporary files if any were used ---\n",
    "# (No temporary files like excel were used in this revised K-fold)\n",
    "# if 'temp_dir_for_folds' in locals() and os.path.exists(temp_dir_for_folds):\n",
    "#     print(f\"清理临时文件夹: {temp_dir_for_folds}\")\n",
    "#     try:\n",
    "#         shutil.rmtree(temp_dir_for_folds)\n",
    "#     except Exception as e:\n",
    "#         print(f\"警告: 清理临时文件夹失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Combine Stage 2 OOF data after the loop ---\n",
    "if all_oof_meta_features_stage2:\n",
    "    X_oof_stage2 = np.concatenate(all_oof_meta_features_stage2, axis=0)\n",
    "    y_oof_stage2 = np.array(all_oof_labels_stage2) # Original labels 1 or 2\n",
    "    oof_indices_stage2_array = np.array(all_oof_indices_stage2) # Array for easier indexing\n",
    "    print(f\"\\nStage 2 OOF meta-features shape: {X_oof_stage2.shape}\")\n",
    "    print(f\"Stage 2 OOF labels shape: {y_oof_stage2.shape}\")\n",
    "else:\n",
    "    print(\"\\n错误: 未生成 Stage 2 OOF 元特征。跳过 Stage 2 元模型训练和后续步骤。\")\n",
    "    K = 0 # Set K=0 to stop further processing if Stage 2 OOF failed\n",
    "\n",
    "# --- 清理 Stage 2 K-Fold 训练的模型占用的 GPU 内存 ---\n",
    "print(\"\\n清理 Stage 2 K-Fold 模型占用的 GPU 内存...\")\n",
    "del fold_cnn_finetuned_classifiers_stage2,train_loader_fold_stage2,val_loader_fold_stage2,train_dataset_fold_stage2,val_dataset_fold_stage2\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Stage 2 K-Fold 模型内存清理完毕。\")\n",
    "\n",
    "# --- Train Meta-Models on OOF data and Evaluate Combined Performance ---\n",
    "if K > 0 and all_oof_meta_features_stage1 and all_oof_meta_features_stage2:\n",
    "    print(\"\\n--- K-Fold 循环结束，开始训练元模型并评估组合性能 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练最终用于提交的模型 (两阶段)\n",
    "使用整个 Stage 1 和 Stage 2 训练集训练 CNN 基础分类器，然后使用它们的预测概率作为元特征，训练最终的元模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 开始训练最终提交的两阶段 Stacking 集成模型 ---\")\n",
    "\n",
    "# Use the full_labels_df and base_full_dataset_no_transform defined earlier\n",
    "\n",
    "# --- Prepare data for Final Stage 1 Training ---\n",
    "# Stage 1 uses the entire dataset with mapped labels (0 or 1)\n",
    "final_stage1_labels_mapped = np.where(full_labels_df['Pterygium'] > 0, 1, 0)\n",
    "# Create a temporary DataFrame with mapped labels for DataLoader (or just use the full_labels_df and map inside)\n",
    "# Let's map inside the getitem for simplicity if we use Subset of the original dataset\n",
    "# Alternatively, create a new dataset class or modify PterygiumDataset to accept a label column name\n",
    "\n",
    "# Option 1: Modify PterygiumDataset slightly to take label column name (More flexible)\n",
    "class PterygiumDatasetWithLabelCol(Dataset):\n",
    "    def __init__(self, label_df, image_dir, label_col='Pterygium', transform=None):\n",
    "        self.labels_df = label_df.reset_index(drop=True) # Ensure continuous index\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_col = label_col\n",
    "        \n",
    "        self.image_paths = []\n",
    "        for index, row in self.labels_df.iterrows():\n",
    "            image_name = row['Image']\n",
    "            image_folder = f\"{int(image_name):04d}\"\n",
    "            potential_path_subfolder = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "            potential_path_direct = os.path.join(self.image_dir, f\"{image_folder}.png\")\n",
    "\n",
    "            if os.path.exists(potential_path_subfolder):\n",
    "                self.image_paths.append(potential_path_subfolder)\n",
    "            elif os.path.exists(potential_path_direct):\n",
    "                self.image_paths.append(potential_path_direct)\n",
    "            else:\n",
    "                print(f\"错误: Final training image file not found {image_folder}.png in {self.image_dir}\")\n",
    "                self.image_paths.append(None)\n",
    "        \n",
    "        # Filter out samples where image file was not found\n",
    "        valid_indices = [i for i, path in enumerate(self.image_paths) if path is not None]\n",
    "        if len(valid_indices) < len(self.labels_df):\n",
    "            print(f\"警告: 发现 {len(self.labels_df) - len(valid_indices)} 图像文件在 {image_dir} 中缺失，这些样本将被跳过。\")\n",
    "        self.labels_df = self.labels_df.iloc[valid_indices].reset_index(drop=True)\n",
    "        self.image_paths = [self.image_paths[i] for i in valid_indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels_df.iloc[idx][self.label_col]\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Add Stage 1 Mapped Label column to the full DataFrame\n",
    "full_labels_df_with_stage1 = full_labels_df.copy()\n",
    "full_labels_df_with_stage1['Pterygium_Stage1'] = np.where(full_labels_df_with_stage1['Pterygium'] > 0, 1, 0)\n",
    "\n",
    "final_train_dataset_stage1 = PterygiumDatasetWithLabelCol(\n",
    "    label_df=full_labels_df_with_stage1, \n",
    "    image_dir=image_dir, \n",
    "    label_col='Pterygium_Stage1', # Use Stage 1 mapped label\n",
    "    transform=train_transform # Use training transform\n",
    ")\n",
    "final_train_loader_stage1 = DataLoader(\n",
    "    final_train_dataset_stage1,\n",
    "    batch_size=64 if TRAIN_SIZE[0] <257 else 30,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# Prepare data for Final Stage 2 Training\n",
    "# Stage 2 uses the subset of data where original label is 1 or 2\n",
    "final_stage2_df_original = full_labels_df[full_labels_df['Pterygium'] > 0].copy()\n",
    "# Add Stage 2 Mapped Label column (1->0, 2->1) for training\n",
    "final_stage2_df_original['Pterygium_Stage2_Mapped'] = np.where(final_stage2_df_original['Pterygium'] == 1, 0, 1)\n",
    "\n",
    "\n",
    "final_train_dataset_stage2 = PterygiumDatasetWithLabelCol(\n",
    "    label_df=final_stage2_df_original, \n",
    "    image_dir=image_dir, \n",
    "    label_col='Pterygium_Stage2_Mapped', # Use Stage 2 mapped label for training\n",
    "    transform=train_transform # Use training transform\n",
    ")\n",
    "final_train_loader_stage2 = DataLoader(\n",
    "    final_train_dataset_stage2,\n",
    "    batch_size=64 if TRAIN_SIZE[0] <257 else 20,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# Data loader to generate meta-features for the *entire* training set (using val_transform)\n",
    "# Needed for training the final meta-models\n",
    "final_meta_train_dataset_full = PterygiumDatasetWithLabelCol(\n",
    "    label_df=full_labels_df, # Use original labels, but won't use them in meta-feature extraction\n",
    "    image_dir=image_dir,\n",
    "    label_col='Pterygium', # This column is not used in the loop below, just for dataset structure\n",
    "    transform=val_transform # Use validation transform for consistent meta-features\n",
    ")\n",
    "final_meta_train_loader_full = DataLoader(\n",
    "    final_meta_train_dataset_full,\n",
    "    batch_size=64,\n",
    "    shuffle=False, # Do not shuffle for meta-feature extraction\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "\n",
    "# Data loader to generate meta-features for the Stage 2 training subset (using val_transform)\n",
    "final_meta_train_dataset_stage2_subset = PterygiumDatasetWithLabelCol(\n",
    "    label_df=final_stage2_df_original, # Use the filtered Stage 2 DataFrame\n",
    "    image_dir=image_dir,\n",
    "    label_col='Pterygium', # Original label column\n",
    "    transform=val_transform # Use validation transform\n",
    ")\n",
    "final_meta_train_loader_stage2_subset = DataLoader(\n",
    "    final_meta_train_dataset_stage2_subset,\n",
    "    batch_size=64,\n",
    "    shuffle=False, # Do not shuffle\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "\n",
    "# --- 1. 训练最终 Stage 1 CNN 基础分类器 (在整个训练集上, 0 vs >0) ---\n",
    "print(\"--- 步骤 1: 训练最终 Stage 1 CNN 基础分类器 (在整个训练集上, 0 vs >0) ---\")\n",
    "\n",
    "final_cnn_classifiers_stage1 = {} # 存储最终训练好的完整 CNN 分类器\n",
    "\n",
    "num_classes_stage1_cnn = 2 # Stage 1 CNNs predict 2 classes (0 or 1)\n",
    "\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE1:\n",
    "    print(f\"  训练基础模型: {cnn_name} (Stage 1) 在完整数据集上...\")\n",
    "    cnn_model_for_final_training_stage1 = globals()[cnn_name](num_classes=num_classes_stage1_cnn).to(device)\n",
    "\n",
    "    final_train_epochs = cnn_micro_train_stage1_params.get('num_epochs_final', cnn_micro_train_stage1_params['num_epochs']) \n",
    "    \n",
    "    cnn_optimizer_final = optim.AdamW(cnn_model_for_final_training_stage1.parameters(), \n",
    "                                        lr=cnn_micro_train_stage1_params['lr'], \n",
    "                                        weight_decay=cnn_micro_train_stage1_params['weight_decay'])\n",
    "    cnn_scheduler_final = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer_final, \n",
    "                                                                T_max=final_train_epochs, \n",
    "                                                                eta_min=1e-6)\n",
    "    cnn_criterion_final = nn.CrossEntropyLoss()\n",
    "    scaler_cnn_final = torch.amp.GradScaler('cuda') \n",
    "    \n",
    "    start_time_cnn_final_train = time.time()\n",
    "    \n",
    "    for cnn_epoch in range(final_train_epochs):\n",
    "        cnn_model_for_final_training_stage1.train()\n",
    "        train_loss_cnn_final = 0\n",
    "        train_correct_cnn_final = 0\n",
    "        train_total_cnn_final = 0\n",
    "        \n",
    "        cnn_train_loader_final_tqdm = tqdm(final_train_loader_stage1, desc=f'  {cnn_name} Stage 1 Final Epoch {cnn_epoch+1}/{final_train_epochs}', leave=False)\n",
    "        \n",
    "        for batch_idx, (inputs, targets_stage1_mapped) in enumerate(cnn_train_loader_final_tqdm):\n",
    "            inputs, targets_stage1_mapped = inputs.to(device), targets_stage1_mapped.to(device)\n",
    "            cnn_optimizer_final.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = cnn_model_for_final_training_stage1(inputs)\n",
    "                loss = cnn_criterion_final(outputs, targets_stage1_mapped) # Use Stage 1 mapped labels\n",
    "            scaler_cnn_final.scale(loss).backward()\n",
    "            scaler_cnn_final.step(cnn_optimizer_final)\n",
    "            scaler_cnn_final.update()\n",
    "            \n",
    "            train_loss_cnn_final += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total_cnn_final += targets_stage1_mapped.size(0)\n",
    "            train_correct_cnn_final += predicted.eq(targets_stage1_mapped).sum().item()\n",
    "            \n",
    "            cnn_train_loader_final_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * train_correct_cnn_final / train_total_cnn_final:.2f}%' if train_total_cnn_final > 0 else '0.00%',\n",
    "                'lr': f'{cnn_optimizer_final.param_groups[0][\"lr\"]:.1e}'\n",
    "            })\n",
    "        cnn_scheduler_final.step()\n",
    "    \n",
    "    end_time_cnn_final_train = time.time()\n",
    "    print(f\"  训练 Stage 1 基础模型 {cnn_name} 完成，耗时: {end_time_cnn_final_train - start_time_cnn_final_train:.2f} 秒\")\n",
    "\n",
    "    cnn_model_for_final_training_stage1.eval() \n",
    "    final_cnn_classifiers_stage1[cnn_name] = cnn_model_for_final_training_stage1\n",
    "    \n",
    "    # Save Stage 1 base classifier state dict\n",
    "    base_classifier_save_path_stage1 = f'./final_{cnn_name}_stage1_base_classifier.pth'\n",
    "    save_cnn_state_dict(cnn_model_for_final_training_stage1, base_classifier_save_path_stage1)\n",
    "    print(f\"  Stage 1 基础分类器 {cnn_name} 已保存到 {base_classifier_save_path_stage1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 清理 Stage 1 最终训练模型占用的 GPU 内存 ---\")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Stage 1 最终训练模型内存清理完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 训练最终 Stage 2 CNN 基础分类器 (在 Stage 2 子集上, 1 vs 2) ---\n",
    "print(\"\\n--- 步骤 2: 训练最终 Stage 2 CNN 基础分类器 (在 Stage 2 子集上, 1 vs 2) ---\")\n",
    "\n",
    "final_cnn_classifiers_stage2 = {} # 存储最终训练好的完整 CNN 分类器\n",
    "\n",
    "num_classes_stage2_cnn = 2 # Stage 2 CNNs predict 2 classes (for mapped 0 or 1)\n",
    "\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE2:\n",
    "    print(f\"  训练基础模型: {cnn_name} (Stage 2) 在 Stage 2 数据集上...\")\n",
    "    cnn_model_for_final_training_stage2 = globals()[cnn_name](num_classes=num_classes_stage2_cnn).to(device)\n",
    "\n",
    "    # Use same training params as Stage 1 for consistency\n",
    "    final_train_epochs = cnn_micro_train_stage2_params.get('num_epochs_final', cnn_micro_train_stage2_params['num_epochs']) \n",
    "\n",
    "    cnn_optimizer_final = optim.AdamW(cnn_model_for_final_training_stage2.parameters(), \n",
    "                                        lr=cnn_micro_train_stage2_params['lr'], \n",
    "                                        weight_decay=cnn_micro_train_stage2_params['weight_decay'])\n",
    "    cnn_scheduler_final = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer_final, \n",
    "                                                                T_max=final_train_epochs, \n",
    "                                                                eta_min=1e-6)\n",
    "    cnn_criterion_final = nn.CrossEntropyLoss()\n",
    "    scaler_cnn_final = torch.amp.GradScaler('cuda') \n",
    "    \n",
    "    start_time_cnn_final_train = time.time()\n",
    "    \n",
    "    for cnn_epoch in range(final_train_epochs):\n",
    "        cnn_model_for_final_training_stage2.train()\n",
    "        train_loss_cnn_final = 0\n",
    "        train_correct_cnn_final = 0\n",
    "        train_total_cnn_final = 0\n",
    "        \n",
    "        cnn_train_loader_final_tqdm = tqdm(final_train_loader_stage2, desc=f'  {cnn_name} Stage 2 Final Epoch {cnn_epoch+1}/{final_train_epochs}', leave=False)\n",
    "        \n",
    "        for batch_idx, (inputs, targets_stage2_mapped) in enumerate(cnn_train_loader_final_tqdm):\n",
    "            inputs, targets_stage2_mapped = inputs.to(device), targets_stage2_mapped.to(device)\n",
    "            cnn_optimizer_final.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = cnn_model_for_final_training_stage2(inputs)\n",
    "                loss = cnn_criterion_final(outputs, targets_stage2_mapped) # Use Stage 2 mapped labels (0 or 1)\n",
    "            scaler_cnn_final.scale(loss).backward()\n",
    "            scaler_cnn_final.step(cnn_optimizer_final)\n",
    "            scaler_cnn_final.update()\n",
    "            \n",
    "            train_loss_cnn_final += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total_cnn_final += targets_stage2_mapped.size(0)\n",
    "            train_correct_cnn_final += predicted.eq(targets_stage2_mapped).sum().item()\n",
    "            \n",
    "            cnn_train_loader_final_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * train_correct_cnn_final / train_total_cnn_final:.2f}%' if train_total_cnn_final > 0 else '0.00%',\n",
    "                'lr': f'{cnn_optimizer_final.param_groups[0][\"lr\"]:.1e}'\n",
    "            })\n",
    "        cnn_scheduler_final.step()\n",
    "    \n",
    "    end_time_cnn_final_train = time.time()\n",
    "    print(f\"  训练 Stage 2 基础模型 {cnn_name} 完成，耗时: {end_time_cnn_final_train - start_time_cnn_final_train:.2f} 秒\")\n",
    "\n",
    "    cnn_model_for_final_training_stage2.eval() \n",
    "    final_cnn_classifiers_stage2[cnn_name] = cnn_model_for_final_training_stage2\n",
    "    \n",
    "    # Save Stage 2 base classifier state dict\n",
    "    base_classifier_save_path_stage2 = f'./final_{cnn_name}_stage2_base_classifier.pth'\n",
    "    save_cnn_state_dict(cnn_model_for_final_training_stage2, base_classifier_save_path_stage2)\n",
    "    print(f\"  Stage 2 基础分类器 {cnn_name} 已保存到 {base_classifier_save_path_stage2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 清理 Stage 2 最终训练模型占用的 GPU 内存 ---\")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Stage 2 最终训练模型内存清理完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 为 Stage 1 元模型提取最终训练特征 (从整个训练集，使用最终 Stage 1 CNN 分类器) ---\n",
    "print(\"\\n--- 步骤 3: 为 Stage 1 元模型提取整个训练集的预测概率 (元特征) ---\")\n",
    "\n",
    "final_train_meta_features_stage1_list = []\n",
    "\n",
    "if not final_cnn_classifiers_stage1:\n",
    "    print(\"错误：没有训练好的 Stage 1 基础CNN分类器。无法提取元特征。\")\n",
    "    # sys.exit(\"无法继续元特征提取。\")\n",
    "else:\n",
    "    # 对每个训练好的 Stage 1 CNN 分类器提取预测概率\n",
    "    for cnn_name, cnn_classifier_model in final_cnn_classifiers_stage1.items():\n",
    "        print(f\"  使用 Stage 1 基础模型 {cnn_name} 提取完整训练集预测概率...\")\n",
    "        cnn_classifier_model.eval()\n",
    "        current_final_train_probs_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Use final_meta_train_loader_full (entire training set, val_transform)\n",
    "            for inputs, _ in tqdm(final_meta_train_loader_full, desc=f\"元特征(Stage 1 Final Train) from {cnn_name}\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                #with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "                outputs = cnn_classifier_model(inputs)\n",
    "                probabilities = torch.softmax(outputs, dim=1) # 2 classes\n",
    "                current_final_train_probs_list.append(probabilities.cpu().numpy())\n",
    "        \n",
    "        final_train_meta_features_stage1_list.append(np.concatenate(current_final_train_probs_list, axis=0))\n",
    "\n",
    "    if not final_train_meta_features_stage1_list:\n",
    "        print(\"错误：未能生成 Stage 1 元特征。\")\n",
    "        # sys.exit(\"Stage 1 元特征生成失败。\")\n",
    "    else:\n",
    "        X_final_train_meta_stage1 = np.concatenate(final_train_meta_features_stage1_list, axis=1)\n",
    "        # The labels for Stage 1 meta-model training are the mapped labels (0 or 1) for the full training set\n",
    "        y_final_train_stage1_mapped = final_train_dataset_stage1.labels_df['Pterygium_Stage1'].values # Get labels from the dataset df\n",
    "        \n",
    "        print(f\"拼接后 Stage 1 最终训练集元特征形状: {X_final_train_meta_stage1.shape}\")\n",
    "        print(f\"Stage 1 最终训练集元标签形状: {y_final_train_stage1_mapped.shape}\")\n",
    "\n",
    "\n",
    "# --- 4. 为 Stage 2 元模型提取最终训练特征 (从 Stage 2 子集，使用最终 Stage 2 CNN 分类器) ---\n",
    "print(\"\\n--- 步骤 4: 为 Stage 2 元模型提取 Stage 2 训练子集的预测概率 (元特征) ---\")\n",
    "\n",
    "final_train_meta_features_stage2_list = []\n",
    "\n",
    "if not final_cnn_classifiers_stage2:\n",
    "    print(\"错误：没有训练好的 Stage 2 基础CNN分类器。无法提取元特征。\")\n",
    "    # sys.exit(\"无法继续元特征提取。\")\n",
    "else:\n",
    "    # 对每个训练好的 Stage 2 CNN 分类器提取预测概率\n",
    "    for cnn_name, cnn_classifier_model in final_cnn_classifiers_stage2.items():\n",
    "        print(f\"  使用 Stage 2 基础模型 {cnn_name} 提取 Stage 2 训练子集预测概率...\")\n",
    "        cnn_classifier_model.eval()\n",
    "        current_final_train_probs_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Use final_meta_train_loader_stage2_subset (Stage 2 training data, val_transform)\n",
    "            for inputs, _ in tqdm(final_meta_train_loader_stage2_subset, desc=f\"元特征(Stage 2 Final Train) from {cnn_name}\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                #with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "                outputs = cnn_classifier_model(inputs)\n",
    "                probabilities = torch.softmax(outputs, dim=1) # 2 classes\n",
    "                current_final_train_probs_list.append(probabilities.cpu().numpy())\n",
    "        \n",
    "        final_train_meta_features_stage2_list.append(np.concatenate(current_final_train_probs_list, axis=0))\n",
    "\n",
    "    if not final_train_meta_features_stage2_list:\n",
    "        print(\"错误：未能生成 Stage 2 元特征。\")\n",
    "        # sys.exit(\"Stage 2 元特征生成失败。\")\n",
    "    else:\n",
    "        X_final_train_meta_stage2 = np.concatenate(final_train_meta_features_stage2_list, axis=1)\n",
    "        # The labels for Stage 2 meta-model training are the mapped labels (0 or 1) for the Stage 2 subset\n",
    "        y_final_train_stage2_mapped = final_train_dataset_stage2.labels_df['Pterygium_Stage2_Mapped'].values # Get labels from the dataset df\n",
    "        # Store original Stage 2 labels for potential later checks if needed\n",
    "        y_final_train_stage2_original = final_train_dataset_stage2.labels_df['Pterygium'].values\n",
    "\n",
    "        print(f\"拼接后 Stage 2 最终训练集元特征形状: {X_final_train_meta_stage2.shape}\")\n",
    "        print(f\"Stage 2 最终训练集元标签形状: {y_final_train_stage2_mapped.shape}\")\n",
    "\n",
    "\n",
    "# --- 5. 训练最终的元模型 (Stage 1 和 Stage 2) ---\n",
    "print(f\"\\n--- 步骤 5: 训练最终 Stage 1 元模型 ({META_MODEL_TYPE}) ---\")\n",
    "\n",
    "final_meta_model_stage1 = None\n",
    "if 'X_final_train_meta_stage1' in locals() and 'y_final_train_stage1_mapped' in locals():\n",
    "    start_time_final_meta_train = time.time()\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        final_meta_model_stage1 = lgb.LGBMClassifier(**lgbm_params)\n",
    "        final_meta_model_stage1.fit(X_final_train_meta_stage1, y_final_train_stage1_mapped)\n",
    "        print(\"最终 Stage 1 LightGBM 元模型训练完成。\")\n",
    "    elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "        final_meta_model_stage1 = LogisticRegression(**logreg_params)\n",
    "        final_meta_model_stage1.fit(X_final_train_meta_stage1, y_final_train_stage1_mapped)\n",
    "        print(\"最终 Stage 1 Logistic Regression 元模型训练完成。\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported META_MODEL_TYPE for final Stage 1 training: {META_MODEL_TYPE}\")\n",
    "    end_time_final_meta_train = time.time()\n",
    "    print(f\"最终 Stage 1 元模型训练耗时: {end_time_final_meta_train - start_time_final_meta_train:.2f} 秒\")\n",
    "else:\n",
    "    print(\"错误: Stage 1 最终训练元特征或标签不存在。跳过 Stage 1 最终元模型训练。\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- 步骤 6: 训练最终 Stage 2 元模型 ({META_MODEL_TYPE}) ---\")\n",
    "\n",
    "final_meta_model_stage2 = None\n",
    "if 'X_final_train_meta_stage2' in locals() and 'y_final_train_stage2_mapped' in locals():\n",
    "    start_time_final_meta_train = time.time()\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        final_meta_model_stage2 = lgb.LGBMClassifier(**lgbm_params)\n",
    "        final_meta_model_stage2.fit(X_final_train_meta_stage2, y_final_train_stage2_mapped)\n",
    "        print(\"最终 Stage 2 LightGBM 元模型训练完成。\")\n",
    "    elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "        final_meta_model_stage2 = LogisticRegression(**logreg_params)\n",
    "        final_meta_model_stage2.fit(X_final_train_meta_stage2, y_final_train_stage2_mapped)\n",
    "        print(\"最终 Stage 2 Logistic Regression 元模型训练完成。\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported META_MODEL_TYPE for final Stage 2 training: {META_MODEL_TYPE}\")\n",
    "    end_time_final_meta_train = time.time()\n",
    "    print(f\"最终 Stage 2 元模型训练耗时: {end_time_final_meta_train - start_time_final_meta_train:.2f} 秒\")\n",
    "else:\n",
    "    print(\"错误: Stage 2 最终训练元特征或标签不存在。跳过 Stage 2 最终元模型训练。\")\n",
    "\n",
    "\n",
    "# --- 7. 保存最终的模型 ---\n",
    "print(\"\\n--- 步骤 7: 保存最终模型 ---\")\n",
    "\n",
    "if final_meta_model_stage1:\n",
    "    final_meta_model_save_path_stage1 = f\"./final_stacked_meta_classifier_stage1_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\" \n",
    "    save_boosting_model(final_meta_model_stage1, final_meta_model_save_path_stage1)\n",
    "else:\n",
    "    print(\" Stage 1 元模型未成功训练，未保存。\")\n",
    "\n",
    "if final_meta_model_stage2:\n",
    "    final_meta_model_save_path_stage2 = f\"./final_stacked_meta_classifier_stage2_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\" \n",
    "    save_boosting_model(final_meta_model_stage2, final_meta_model_save_path_stage2)\n",
    "else:\n",
    "    print(\" Stage 2 元模型未成功训练，未保存。\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 最终提交的两阶段 Stacking 集成模型训练完成 ---\")\n",
    "print(f\"基础CNN分类器已保存 (例如: ./final_{CNN_FEATURE_EXTRACTORS_STAGE1[0]}_stage1_base_classifier.pth)\")\n",
    "if final_meta_model_stage1:\n",
    "    print(f\"最终 Stage 1 元模型已保存到: {final_meta_model_save_path_stage1}\")\n",
    "if final_meta_model_stage2:\n",
    "    print(f\"最终 Stage 2 元模型已保存到: {final_meta_model_save_path_stage2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最终 Stacking 集成模型预测 (两阶段)\n",
    "加载训练好的 Stage 1 和 Stage 2 模型，并使用两阶段逻辑对新图像进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 开始加载最终模型进行预测 ---\")\n",
    "\n",
    "# Load Stage 1 Meta Model\n",
    "final_meta_model_load_path_stage1 = f\"./final_stacked_meta_classifier_stage1_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\"\n",
    "final_meta_model_stage1_loaded = load_boosting_model(final_meta_model_load_path_stage1)\n",
    "if not final_meta_model_stage1_loaded:\n",
    "    print(\"错误: Stage 1 最终元模型加载失败。预测将无法进行。\")\n",
    "    sys.exit(\"模型加载失败，无法进行预测。\")\n",
    "\n",
    "# Load Stage 2 Meta Model\n",
    "final_meta_model_load_path_stage2 = f\"./final_stacked_meta_classifier_stage2_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\"\n",
    "final_meta_model_stage2_loaded = load_boosting_model(final_meta_model_load_path_stage2)\n",
    "if not final_meta_model_stage2_loaded:\n",
    "    print(\"错误: Stage 2 最终元模型加载失败。预测将无法进行。\")\n",
    "    sys.exit(\"模型加载失败，无法进行预测。\")\n",
    "\n",
    "\n",
    "# Load Final Stage 1 CNN Base Classifiers\n",
    "final_cnn_classifiers_stage1_loaded = {}\n",
    "print(\"加载 Stage 1 CNN 基础分类器...\")\n",
    "all_base_stage1_loaded = True\n",
    "num_classes_stage1_cnn = 2 # Stage 1 CNNs were trained for 2 classes\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE1:\n",
    "    print(f\"  加载 {cnn_name} (Stage 1) 基础分类器...\")\n",
    "    base_classifier_model_instance = globals()[cnn_name](num_classes=num_classes_stage1_cnn) \n",
    "    final_cnn_state_dict_path = f'./final_{cnn_name}_stage1_base_classifier.pth'\n",
    "    loaded_model = load_cnn_state_dict(base_classifier_model_instance, final_cnn_state_dict_path, device)\n",
    "    if loaded_model:\n",
    "        loaded_model.eval() # Ensure eval mode\n",
    "        final_cnn_classifiers_stage1_loaded[cnn_name] = loaded_model\n",
    "    else:\n",
    "        all_base_stage1_loaded = False\n",
    "        final_cnn_classifiers_stage1_loaded[cnn_name] = None # Store None to indicate failure\n",
    "\n",
    "if not all_base_stage1_loaded:\n",
    "    print(\"警告: 一个或多个 Stage 1 基础CNN分类器未能加载。预测可能不准确或失败。\")\n",
    "    # Decide if this is a fatal error or just a warning\n",
    "    # sys.exit(\"Stage 1 基础模型加载不完整，无法预测。\")\n",
    "\n",
    "\n",
    "# Load Final Stage 2 CNN Base Classifiers\n",
    "final_cnn_classifiers_stage2_loaded = {}\n",
    "print(\"\\n加载 Stage 2 CNN 基础分类器...\")\n",
    "all_base_stage2_loaded = True\n",
    "num_classes_stage2_cnn = 2 # Stage 2 CNNs were trained for 2 classes\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS_STAGE2:\n",
    "    print(f\"  加载 {cnn_name} (Stage 2) 基础分类器...\")\n",
    "    base_classifier_model_instance = globals()[cnn_name](num_classes=num_classes_stage2_cnn) \n",
    "    final_cnn_state_dict_path = f'./final_{cnn_name}_stage2_base_classifier.pth'\n",
    "    loaded_model = load_cnn_state_dict(base_classifier_model_instance, final_cnn_state_dict_path, device)\n",
    "    if loaded_model:\n",
    "        loaded_model.eval() # Ensure eval mode\n",
    "        final_cnn_classifiers_stage2_loaded[cnn_name] = loaded_model\n",
    "    else:\n",
    "        all_base_stage2_loaded = False\n",
    "        final_cnn_classifiers_stage2_loaded[cnn_name] = None # Store None to indicate failure\n",
    "\n",
    "if not all_base_stage2_loaded:\n",
    "    print(\"警告: 一个或多个 Stage 2 基础CNN分类器未能加载。Stage 2 预测可能不准确或失败。\")\n",
    "    # Decide if this is a fatal error\n",
    "    # sys.exit(\"Stage 2 基础模型加载不完整，无法预测。\")\n",
    "\n",
    "\n",
    "def predict_single_image_two_stage(\n",
    "    cnn_base_classifiers_stage1_dict, \n",
    "    meta_model_stage1_instance,\n",
    "    cnn_base_classifiers_stage2_dict,\n",
    "    meta_model_stage2_instance,\n",
    "    image_path, \n",
    "    prediction_transform, \n",
    "    device_to_use):\n",
    "    \"\"\"\n",
    "    使用两阶段 Stacking Ensemble 模型对单张图像进行预测。\n",
    "\n",
    "    参数:\n",
    "        cnn_base_classifiers_stage1_dict (dict): 已加载的 Stage 1 基础CNN分类器字典。\n",
    "        meta_model_stage1_instance: 已加载的 Stage 1 元模型。\n",
    "        cnn_base_classifiers_stage2_dict (dict): 已加载的 Stage 2 基础CNN分类器字典。\n",
    "        meta_model_stage2_instance: 已加载的 Stage 2 元模型。\n",
    "        image_path (str): 待预测图像的路径。\n",
    "        prediction_transform: 应用于预测图像的 torchvision transform。\n",
    "        device_to_use: 'cuda' 或 'cpu'。\n",
    "\n",
    "    返回:\n",
    "        int or None: 预测的类别标签 (0, 1, or 2)，如果出错则为 None。\n",
    "    \"\"\"\n",
    "    # 1. 检查模型是否都已加载且有效\n",
    "    if not meta_model_stage1_instance or not meta_model_stage2_instance:\n",
    "        print(\"错误: Stage 1 或 Stage 2 元模型未加载。\")\n",
    "        return None\n",
    "    if not cnn_base_classifiers_stage1_dict or not all(cnn_base_classifiers_stage1_dict.values()):\n",
    "        print(\"错误: Stage 1 基础模型未完全加载。\")\n",
    "        return None\n",
    "    if not cnn_base_classifiers_stage2_dict or not all(cnn_base_classifiers_stage2_dict.values()):\n",
    "        print(\"错误: Stage 2 基础模型未完全加载。\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    # 2. 加载和预处理图像\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = prediction_transform(image).unsqueeze(0).to(device_to_use)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 预测图像文件未找到 {image_path}\")\n",
    "        return None \n",
    "    except Exception as e:\n",
    "        print(f\"错误处理预测图像 {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 3. Stage 1 预测: 生成 Stage 1 元特征并使用 Stage 1 元模型预测\n",
    "    meta_features_stage1_list = []\n",
    "    with torch.no_grad():\n",
    "        for cnn_name, cnn_classifier_model in cnn_base_classifiers_stage1_dict.items():\n",
    "            # We already checked for None above, but double check for safety\n",
    "            if cnn_classifier_model is None: continue\n",
    "            #with torch.amp.autocast('cuda' if device_to_use == 'cuda' else 'cpu', enabled=torch.cuda.is_available()):\n",
    "            outputs = cnn_classifier_model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1) # 2 classes for Stage 1\n",
    "            meta_features_stage1_list.append(probabilities.cpu().numpy())\n",
    "\n",
    "    if not meta_features_stage1_list or len(meta_features_stage1_list) != len(cnn_base_classifiers_stage1_dict):\n",
    "        print(\"错误: Stage 1 基础模型元特征生成失败。\")\n",
    "        return None\n",
    "        \n",
    "    image_meta_features_stage1 = np.concatenate(meta_features_stage1_list, axis=1)\n",
    "\n",
    "    # Predict Stage 1 outcome (0: Normal, 1: Diseased)\n",
    "    try:\n",
    "        # meta_model_stage1_instance predicts 0 or 1 (mapped Stage 1 labels)\n",
    "        predicted_stage1_mapped = meta_model_stage1_instance.predict(image_meta_features_stage1)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 元模型预测时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 4. Determine final prediction based on Stage 1 outcome\n",
    "    if predicted_stage1_mapped == 0:\n",
    "        # Predicted as Normal by Stage 1 -> Final prediction is 0\n",
    "        return 0\n",
    "    else:\n",
    "        # Predicted as Diseased by Stage 1 -> Proceed to Stage 2\n",
    "        # Generate Stage 2 Meta Features\n",
    "        meta_features_stage2_list = []\n",
    "        with torch.no_grad():\n",
    "            for cnn_name, cnn_classifier_model in cnn_base_classifiers_stage2_dict.items():\n",
    "                # We already checked for None above, but double check for safety\n",
    "                if cnn_classifier_model is None: continue\n",
    "                #with torch.amp.autocast('cuda' if device_to_use == 'cuda' else 'cpu', enabled=torch.cuda.is_available()):\n",
    "                outputs = cnn_classifier_model(image_tensor)\n",
    "                probabilities = torch.softmax(outputs, dim=1) # 2 classes for Stage 2\n",
    "                meta_features_stage2_list.append(probabilities.cpu().numpy())\n",
    "\n",
    "        if not meta_features_stage2_list or len(meta_features_stage2_list) != len(cnn_base_classifiers_stage2_dict):\n",
    "            print(\"错误: Stage 2 基础模型元特征生成失败。\")\n",
    "            # If Stage 2 meta-features fail, what should be the fallback?\n",
    "            # Cannot differentiate between 1 and 2. Maybe return 1 as a default for diseased?\n",
    "            return 1 # Fallback prediction if Stage 2 feature extraction fails\n",
    "            \n",
    "        image_meta_features_stage2 = np.concatenate(meta_features_stage2_list, axis=1)\n",
    "\n",
    "        # Predict Stage 2 outcome (0: Observe, 1: Surgery)\n",
    "        try:\n",
    "            # meta_model_stage2_instance predicts 0 or 1 (mapped Stage 2 labels)\n",
    "            predicted_stage2_mapped = meta_model_stage2_instance.predict(image_meta_features_stage2)[0]\n",
    "            # Map Stage 2 prediction back to original labels (0->1, 1->2)\n",
    "            final_prediction = 1 if predicted_stage2_mapped == 0 else 2\n",
    "            return final_prediction\n",
    "        except Exception as e:\n",
    "            print(f\"Stage 2 元模型预测时出错: {e}\")\n",
    "            # If Stage 2 meta-model prediction fails, fallback?\n",
    "            return 1 # Fallback prediction if Stage 2 meta-model prediction fails\n",
    "\n",
    "\n",
    "# --- Predict on Validation Directory ---\n",
    "def predict_on_image_directory_two_stage(\n",
    "    base_classifiers_stage1_loaded_dict, \n",
    "    meta_model_stage1_loaded_instance,\n",
    "    base_classifiers_stage2_loaded_dict,\n",
    "    meta_model_stage2_loaded_instance,\n",
    "    directory_path, \n",
    "    image_transform_for_prediction, \n",
    "    device_for_prediction,\n",
    "    output_excel_filename=\"Classification_Results_TwoStageStacking.xlsx\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    在指定目录中的所有图像上运行两阶段 Stacking 模型预测，并将结果保存到 Excel。\n",
    "    \"\"\"\n",
    "    if (not base_classifiers_stage1_loaded_dict or not all(base_classifiers_stage1_loaded_dict.values()) or \n",
    "        not meta_model_stage1_loaded_instance or \n",
    "        not base_classifiers_stage2_loaded_dict or not all(base_classifiers_stage2_loaded_dict.values()) or\n",
    "        not meta_model_stage2_loaded_instance):\n",
    "        print(\"错误: 部分或全部模型未成功加载，无法进行预测。\")\n",
    "        return\n",
    "\n",
    "    # Find all supported image files (.png) in the directory\n",
    "    image_paths = glob.glob(os.path.join(directory_path, \"*.png\")) \n",
    "    if not image_paths:\n",
    "        print(f\"警告: 在目录 {directory_path} 中未找到任何 .png 图像。\")\n",
    "        return\n",
    "\n",
    "    prediction_results = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Predicting images with Two-Stage Stacking Ensemble\", leave=True):\n",
    "        try:\n",
    "            predicted_label = predict_single_image_two_stage(\n",
    "                base_classifiers_stage1_loaded_dict, \n",
    "                meta_model_stage1_loaded_instance,\n",
    "                base_classifiers_stage2_loaded_dict,\n",
    "                meta_model_stage2_loaded_instance,\n",
    "                img_path, \n",
    "                image_transform_for_prediction, \n",
    "                device_for_prediction\n",
    "            )\n",
    "            \n",
    "            if predicted_label is not None:\n",
    "                # Extract image ID from filename (e.g., \"0001.png\" -> 1)\n",
    "                base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                try:\n",
    "                    image_id = int(base_name)\n",
    "                    prediction_results.append({\"Image\": image_id, \"Pterygium\": predicted_label})\n",
    "                except ValueError:\n",
    "                    tqdm.write(f\"警告: 无法从文件名 {base_name} 解析图像ID。跳过此图像。\")\n",
    "            else:\n",
    "                tqdm.write(f\"图像 {img_path} 的预测失败或返回 None。\")\n",
    "\n",
    "        except Exception as e: # Catch any unexpected errors during the loop\n",
    "            tqdm.write(f\"处理或预测图像 {img_path} 时发生意外错误: {e}\")\n",
    "            # Optionally append a result with -1 or some indicator for failed prediction\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            try:\n",
    "                 image_id = int(base_name)\n",
    "                 prediction_results.append({\"Image\": image_id, \"Pterygium\": -1}) # Use -1 to indicate failure\n",
    "            except ValueError:\n",
    "                 pass # Skip if ID cannot be parsed even for error reporting\n",
    "\n",
    "    if not prediction_results:\n",
    "        print(\"没有图像被成功预测。未生成结果文件。\")\n",
    "        return\n",
    "\n",
    "    # Sort results by Image ID\n",
    "    prediction_results.sort(key=lambda x: x[\"Image\"])\n",
    "    \n",
    "    # Convert results to Pandas DataFrame and save to Excel\n",
    "    results_df = pd.DataFrame(prediction_results, columns=[\"Image\", \"Pterygium\"])\n",
    "    \n",
    "    try:\n",
    "        results_df.to_excel(output_excel_filename, index=False)\n",
    "        print(f\"\\n分类结果已保存到 {output_excel_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 保存 Excel 文件失败: {e}\")\n",
    "\n",
    "\n",
    "# --- Call the prediction function on the validation directory ---\n",
    "if all_base_stage1_loaded and final_meta_model_stage1_loaded and all_base_stage2_loaded and final_meta_model_stage2_loaded:\n",
    "    print(f\"\\n开始对验证集目录 {val_image_dir} 中的图像进行预测...\")\n",
    "    # Use validation transform (val_transform) for prediction\n",
    "    predict_on_image_directory_two_stage(\n",
    "        final_cnn_classifiers_stage1_loaded, # Stage 1 base models\n",
    "        final_meta_model_stage1_loaded,     # Stage 1 meta model\n",
    "        final_cnn_classifiers_stage2_loaded, # Stage 2 base models\n",
    "        final_meta_model_stage2_loaded,     # Stage 2 meta model\n",
    "        val_image_dir,                      # Directory containing images to predict\n",
    "        val_transform,                      # Image preprocessing transform\n",
    "        device,                             # 'cuda' or 'cpu'\n",
    "        output_excel_filename=f\"Classification_Results_TwoStageStacking_{META_MODEL_TYPE.replace(' ', '_')}.xlsx\" \n",
    "    )\n",
    "else:\n",
    "    print(\"错误：最终模型未能完全加载。跳过在验证目录上的预测。\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231745112,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 937.871658,
   "end_time": "2025-04-13T02:09:18.610590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T01:53:40.738932",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
