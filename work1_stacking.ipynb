{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 翼状胬肉诊断模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "I8rV7E66jSoG",
    "papermill": {
     "duration": 0.004352,
     "end_time": "2025-04-13T01:53:45.053747",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.049395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 交叉验证参数 ---\n",
    "K = 5  # 折数\n",
    "base_seed = 420 # 用于 KFold 分割的随机种子\n",
    "# --- 定义要使用的 CNN 特征提取器列表 ---\n",
    "CNN_FEATURE_EXTRACTORS = ['ResNet50Classifier','ResNet101Classifier', 'EfficientNetB4Classifier', 'DenseNet121Classifier', 'ConvNeXtBaseClassifier']\n",
    "#CNN_FEATURE_EXTRACTORS = ['ResNet18Classifier', 'ResNet34Classifier', 'ResNet50Classifier', 'ResNet101Classifier', 'ResNet152Classifier']\n",
    "\n",
    "# --- CNN 微调参数 (在每折内部使用) ---\n",
    "cnn_micro_train_params = {\n",
    "    'num_epochs': 25,    # 在每折中微调 CNN 的 epoch 数\n",
    "    'lr': 4e-4,          # 微调的学习率\n",
    "    'weight_decay': 2e-4 # 微调的权重衰减\n",
    "}\n",
    "\n",
    "# --- 元模型类型选择 ---\n",
    "# 可选: 'LightGBM', 'LogisticRegression'\n",
    "META_MODEL_TYPE = 'LightGBM'\n",
    "# --- Logistic Regression 超参数 ---\n",
    "logreg_params = {\n",
    "    'solver': 'lbfgs',      # 求解器，lbfgs 通常适用于小数据集和多类问题\n",
    "    'multi_class': 'auto',  # 多类问题策略，'auto' 会根据数据自动选择 'ovr' 或 'multinomial'\n",
    "    'max_iter': 1000,       # 迭代次数，确保收敛\n",
    "    'random_state': base_seed, # 随机种子\n",
    "    'n_jobs': -1            # 使用所有可用核心\n",
    "}\n",
    "# --- LightGBM 超参数 ---\n",
    "lgbm_params = {\n",
    "    'objective': 'multiclass', # 多分类任务\n",
    "    'num_class': 3,            # 3 个类别\n",
    "    'metric': 'multi_logloss', # Log Loss 作为评估指标\n",
    "    'boosting_type': 'gbdt',   # 梯度提升决策树\n",
    "    'n_estimators': 1000,      # 树的数量 (配合早停使用，可以设置得大一些)\n",
    "    'learning_rate': 0.03,     # 学习率\n",
    "    'num_leaves': 20,          # 控制树的复杂度，防止过拟合\n",
    "    'max_depth': -1,           # 树的最大深度，-1表示不限制 (配合 num_leaves 控制)\n",
    "    'seed': base_seed,         # 随机种子\n",
    "    'n_jobs': -1,              # 使用所有可用核心\n",
    "    'verbose': -1,             # 不打印中间信息\n",
    "    'colsample_bytree': 0.7,   # 每棵树随机采样的特征比例\n",
    "    'subsample': 0.7,          # 每棵树随机采样的样本比例\n",
    "    'reg_alpha': 0.3,          # L1 正则化\n",
    "    'reg_lambda': 0.3,         # L2 正则化\n",
    "    'min_child_samples': 30    # 叶子节点的最小样本数\n",
    "}\n",
    "\n",
    "# ================== 缩放参数设置 =================\n",
    "TARGET_SIZE = (224, 224)\n",
    "TRAIN_SIZE = (224, 224)\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "#colab_val_zip_path = \"/content/drive/My Drive/val.zip\"\n",
    "#colab_val_extract_path = \"/content/val/\"\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# =================== SHAP设置 =================\n",
    "shap_scaling_factor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_agg_backend_if_no_gui():\n",
    "    \"\"\"\n",
    "    检查是否可能缺少 GUI 后端（例如，在无头服务器上运行）。\n",
    "    如果是这种情况，将 Matplotlib 后端设置为 'Agg' 以避免错误。\n",
    "\n",
    "    应该在首次导入 `matplotlib.pyplot` 之前调用此函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查是否在非 Windows 系统上且没有设置 DISPLAY 环境变量\n",
    "    # 这是判断是否缺少 GUI 的常见启发式方法\n",
    "    try:\n",
    "        # 尝试获取 IPython 实例\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        # 'ZMQInteractiveShell' 表示 Jupyter Notebook 或 QtConsole\n",
    "        # 'TerminalInteractiveShell' 表示 IPython 命令行\n",
    "        if 'Shell' in shell:\n",
    "            # Jupyter/IPython 环境\n",
    "            print('检测到jupyter环境')\n",
    "            get_ipython().run_line_magic('matplotlib', 'inline') # type: ignore\n",
    "            return True\n",
    "        else:\n",
    "            # 其他情况（理论上不应发生在此 try 块）\n",
    "            raise NameError\n",
    "    except NameError:\n",
    "        print(\"检测到可能没有 GUI 环境，将 Matplotlib 后端设置为 'Agg'。\")\n",
    "        matplotlib.use('Agg') # type: ignore\n",
    "        return False      # 标准 Python 解释器 (get_ipython 未定义)\n",
    "    except Exception as e:\n",
    "        print(f\"警告：尝试将 Matplotlib 后端设置为 'Agg' 时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "e-siDBWjjSo6",
    "papermill": {
     "duration": 11.426914,
     "end_time": "2025-04-13T01:53:56.485296",
     "exception": false,
     "start_time": "2025-04-13T01:53:45.058382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
    "from torchvision.models import EfficientNet_B4_Weights, DenseNet121_Weights, efficientnet_b4, densenet121\n",
    "from torch.utils.data import Subset\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "import shap\n",
    "import sys\n",
    "from PIL import Image\n",
    "import platform\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.autonotebook import tqdm # 好看！\n",
    "import matplotlib\n",
    "setup_matplotlib_agg_backend_if_no_gui()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        subprocess.run(['wget','-q','-O', 'simhei.ttf', \"https://cdn.jsdelivr.net/gh/Haixing-Hu/latex-chinese-fonts/chinese/%E9%BB%91%E4%BD%93/SimHei.ttf\"], check=True)\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuDNN benchmark 模式已启用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "FqZSY8dujSo8",
    "papermill": {
     "duration": 0.004411,
     "end_time": "2025-04-13T01:53:56.494490",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.490079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80",
    "papermill": {
     "duration": 0.023889,
     "end_time": "2025-04-13T01:53:56.522681",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.498792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('.env'):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('.env')\n",
    "\n",
    "R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID', '')\n",
    "R2_SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY', '')\n",
    "R2_BUCKET_NAME = os.environ.get('R2_BUCKET_NAME', '')\n",
    "R2_ENDPOINT_URL = os.environ.get('R2_ENDPOINT_URL', '')\n",
    "\n",
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive # type: ignore\n",
    "        from google.colab import userdata # type: ignore\n",
    "        drive.mount('/content/drive')\n",
    "        R2_ACCESS_KEY_ID = userdata.get(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = userdata.get(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = userdata.get(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = userdata.get(\"R2_ENDPOINT_URL\")\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # Google Drive 有每日下载次数限制，可能会导致下载失败\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "\n",
    "        from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "        user_secrets = UserSecretsClient()\n",
    "        R2_ACCESS_KEY_ID = user_secrets.get_secret(\"R2_ACCESS_KEY_ID\")\n",
    "        R2_SECRET_ACCESS_KEY = user_secrets.get_secret(\"R2_SECRET_ACCESS_KEY\")\n",
    "        R2_BUCKET_NAME = user_secrets.get_secret(\"R2_BUCKET_NAME\")\n",
    "        R2_ENDPOINT_URL = user_secrets.get_secret(\"R2_ENDPOINT_URL\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.004176,
     "end_time": "2025-04-13T01:53:56.531483",
     "exception": false,
     "start_time": "2025-04-13T01:53:56.527307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 数据 Resize\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 准备R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_r2_client():\n",
    "    \"\"\"尝试创建并返回一个配置好的 boto3 R2 客户端。\"\"\"\n",
    "    # 确认环境变量已加载 (这些变量应在之前的单元格中设置)\n",
    "    required_vars = ['R2_ENDPOINT_URL', 'R2_ACCESS_KEY_ID', 'R2_SECRET_ACCESS_KEY', 'R2_BUCKET_NAME']\n",
    "    if not all(var in globals() and globals()[var] for var in required_vars):\n",
    "        print(\"R2 配置不完整（缺少 Endpoint URL, Access Key, Secret Key 或 Bucket Name）。跳过 R2 缓存。\")\n",
    "        return None, False # 返回 None 和 R2 未配置标志\n",
    "\n",
    "    global r2_configured # 声明我们要修改全局变量\n",
    "    r2_configured = True # 标记 R2 已配置\n",
    "\n",
    "    try:\n",
    "        print(\"正在创建 R2 (boto3 S3) 客户端...\")\n",
    "        s3_client = boto3.client(\n",
    "            service_name='s3',\n",
    "            endpoint_url=R2_ENDPOINT_URL,\n",
    "            aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "            region_name='auto', # R2 通常使用 'auto'\n",
    "            config=botocore.config.Config(signature_version='s3v4') # 明确签名版本\n",
    "        )\n",
    "        # 尝试列出 buckets (可选，作为连接测试)\n",
    "        # s3_client.list_buckets()\n",
    "        print(\"R2 客户端创建成功。\")\n",
    "        return s3_client, True\n",
    "    except Exception as e:\n",
    "        print(f\"创建 R2 客户端时出错: {e}\")\n",
    "        r2_configured = False # 出错则标记为未配置\n",
    "        return None, False\n",
    "\n",
    "def check_r2_cache(s3_client, bucket_name, cache_key):\n",
    "    \"\"\"检查指定的缓存键是否存在于 R2 存储桶中。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False # 文件未找到\n",
    "        else:\n",
    "            # 其他错误 (如权限问题)\n",
    "            print(f\"检查 R2 缓存时出错 (Key: {cache_key}): {e}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"检查 R2 缓存时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_from_r2(s3_client, bucket_name, cache_key, local_path):\n",
    "    \"\"\"从 R2 下载文件到本地路径，带进度条。\"\"\"\n",
    "    if not s3_client: return False\n",
    "    try:\n",
    "        # 获取文件大小以显示进度\n",
    "        response = s3_client.head_object(Bucket=bucket_name, Key=cache_key)\n",
    "        total_size = int(response.get('ContentLength', 0))\n",
    "\n",
    "        print(f\"正在从 R2 下载 {cache_key} 到 {local_path} ({total_size / (1024*1024):.2f} MB)...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Filename=local_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 下载完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"从 R2 下载文件时出错 (Key: {cache_key}): {e}\")\n",
    "        # 如果文件下载失败，尝试删除本地可能不完整的文件\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"下载 R2 文件时发生未知错误: {e}\")\n",
    "        if os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def upload_to_r2(s3_client, bucket_name, local_path, cache_key):\n",
    "    \"\"\"将本地文件上传到 R2，带进度条。\"\"\"\n",
    "    if not s3_client or not os.path.exists(local_path):\n",
    "        print(f\"上传 R2 失败：客户端未初始化或本地文件不存在 ({local_path})。\")\n",
    "        return False\n",
    "    try:\n",
    "        total_size = os.path.getsize(local_path)\n",
    "        print(f\"正在上传 {local_path} ({total_size / (1024*1024):.2f} MB) 到 R2 作为 {cache_key}...\")\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=cache_key, leave=False) as pbar:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=cache_key,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "        print(f\"文件 {cache_key} 上传完成。\")\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"上传文件到 R2 时出错 (Key: {cache_key}): {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"上传 R2 文件时发生未知错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"压缩指定文件夹的内容到 zip 文件。\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"错误：要压缩的文件夹不存在 {folder_path}\")\n",
    "        return False\n",
    "    print(f\"正在压缩目录 {folder_path} 到 {zip_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # 获取文件夹内的所有文件和子文件夹\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for filename in files:\n",
    "                    file_paths.append(os.path.join(root, filename))\n",
    "\n",
    "            # 使用 tqdm 显示压缩进度 (按文件数)\n",
    "            with tqdm(total=len(file_paths), desc=\"压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                for file in file_paths:\n",
    "                    # 计算文件在 zip 中的相对路径\n",
    "                    arcname = os.path.relpath(file, folder_path)\n",
    "                    zipf.write(file, arcname)\n",
    "                    pbar.update(1)\n",
    "        print(\"目录压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"压缩目录时出错: {e}\")\n",
    "        # 如果压缩失败，删除可能不完整的 zip 文件\n",
    "        if os.path.exists(zip_path):\n",
    "            try: os.remove(zip_path)\n",
    "            except: pass\n",
    "        return False\n",
    "\n",
    "def unzip_directory(zip_path, extract_to_folder):\n",
    "    \"\"\"解压缩 zip 文件到指定文件夹。\"\"\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"错误：要解压的 zip 文件不存在 {zip_path}\")\n",
    "        return False\n",
    "    print(f\"正在解压缩文件 {zip_path} 到 {extract_to_folder}...\")\n",
    "    try:\n",
    "        os.makedirs(extract_to_folder, exist_ok=True) # 确保目标文件夹存在\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # 获取 zip 文件中的成员数量以显示进度\n",
    "            total_files = len(zip_ref.namelist())\n",
    "            with tqdm(total=total_files, desc=\"解压缩文件\", unit=\"file\", leave=False) as pbar:\n",
    "                # 使用 extractall 并更新进度条可能不直接，改为逐个提取\n",
    "                for member in zip_ref.infolist():\n",
    "                    zip_ref.extract(member, extract_to_folder)\n",
    "                    pbar.update(1)\n",
    "                    # 或者直接用 extractall，进度条可能不准确但更快\n",
    "                    # zip_ref.extractall(extract_to_folder)\n",
    "        print(\"文件解压缩完成。\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"解压缩文件时出错: {e}\")\n",
    "        # 如果解压失败，可以选择是否删除不完整的解压目录\n",
    "        # if os.path.exists(extract_to_folder):\n",
    "        #     shutil.rmtree(extract_to_folder)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Resize(TARGET_SIZE, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_name = f\"{int(image_name):04d}\"\n",
    "        if os.path.exists(os.path.join(base_input_dir, f\"{image_name}.png\")):\n",
    "            # 验证集图像路径\n",
    "            input_path = os.path.join(base_input_dir, f\"{image_name}.png\")\n",
    "            os.makedirs(base_output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(base_output_dir, f\"{image_name}.{output_format.lower()}\")\n",
    "        else:\n",
    "            # 训练集图像路径\n",
    "            input_path = os.path.join(base_input_dir, image_name, f\"{image_name}.png\")\n",
    "            # Create corresponding output subdirectory if it doesn't exist\n",
    "            output_folder_path = os.path.join(base_output_dir, image_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "            output_path = os.path.join(output_folder_path, f\"{image_name}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    print('在 Google Colab 环境中运行')\n",
    "    original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "    output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    temp_dir = colab_extract_path\n",
    "elif os.path.exists(\"/kaggle/working\"):\n",
    "    print('在 Kaggle 环境中运行')\n",
    "    original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "    output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    temp_dir = kaggle_temp_path\n",
    "else:\n",
    "    print(\"错误: 无法识别的非 Windows 环境（可能是Linux），需要手动处理\")\n",
    "    exit(1)\n",
    "\n",
    "if original_image_dir:\n",
    "    print(f\"原始输入目录: {original_image_dir}\")\n",
    "    print(f\"目标输出目录: {output_dir}\")\n",
    "    print(f\"临时文件目录: {temp_dir}\")\n",
    "    print(f\"目标尺寸: {TARGET_SIZE}\")\n",
    "\n",
    "    # 创建 R2 客户端并检查配置\n",
    "    s3_client, r2_configured = create_r2_client()\n",
    "    r2_cache_key = f\"work1_resized_{TARGET_SIZE[0]}x{TARGET_SIZE[1]}.zip\"\n",
    "    print(f\"生成的 R2 缓存键: {r2_cache_key}\")\n",
    "    r2_local_zip_path = os.path.join(temp_dir, r2_cache_key)\n",
    "    resize_done = False\n",
    "    if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据在本地，跳过resize步骤\")\n",
    "        resize_done = True\n",
    "\n",
    "    # --- If not found locally, try R2 cache ---\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if not resize_done and r2_configured:\n",
    "        print(f\"本地目录 {output_dir} 为空或不存在，尝试检查 R2 缓存...\")\n",
    "        if check_r2_cache(s3_client, R2_BUCKET_NAME, r2_cache_key):\n",
    "            print(f\"检测到 R2 缓存文件: {r2_cache_key}. 尝试下载...\")\n",
    "            # Download the cache\n",
    "            if download_from_r2(s3_client, R2_BUCKET_NAME, r2_cache_key, r2_local_zip_path):\n",
    "                print(f\"R2 缓存下载成功。正在解压到 {output_dir}...\")\n",
    "                # Unzip the cache\n",
    "                # Ensure output_dir is clean before extracting to avoid mixing old/new files\n",
    "                if os.path.exists(output_dir):\n",
    "                    try: shutil.rmtree(output_dir)\n",
    "                    except Exception as e: print(f\"警告: 清理旧的输出目录失败: {e}\")\n",
    "                os.makedirs(output_dir, exist_ok=True) # Recreate empty directory\n",
    "                if unzip_directory(r2_local_zip_path, output_dir):\n",
    "                    print(\"R2 缓存解压成功。跳过本地resize步骤。\")\n",
    "                    resize_done = True # Data loaded from R2 cache\n",
    "                    # Clean up the temporary zip file after extraction\n",
    "                    if os.path.exists(r2_local_zip_path):\n",
    "                        try: os.remove(r2_local_zip_path)\n",
    "                        except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存解压失败。将执行本地resize。\")\n",
    "                    resize_done = False # Reset flag to perform local resize\n",
    "                    # Clean up potentially incomplete extraction directory\n",
    "                    if os.path.exists(output_dir):\n",
    "                        try: shutil.rmtree(output_dir)\n",
    "                        except Exception as e: print(f\"警告: 清理不完整输出目录失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 从 R2 下载缓存失败。将执行本地resize。\")\n",
    "                resize_done = False # Reset flag to perform local resize\n",
    "        else:\n",
    "            print(\"未检测到 R2 缓存文件。将执行本地resize。\")\n",
    "            resize_done = False # Ensure flag is false\n",
    "    elif not resize_done and not r2_configured:\n",
    "        print(\"R2 未配置或初始化失败，将执行本地resize。\")\n",
    "        resize_done = False # Ensure flag is false\n",
    "    # --- Perform local resizing if not done by cache ---\n",
    "    if not resize_done:\n",
    "        print(\"执行本地图像resize...\")\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading label file {label_file}: {e}\")\n",
    "            sys.exit(1)\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        # Create the main output directory BEFORE starting the loop (done above, but ensure it exists)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # Iterate through images listed in the label file\n",
    "        # Use original_image_dir as input base for resizing\n",
    "        for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "            if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "        print(f\"\\n本地处理完成!\")\n",
    "        print(f\"成功处理图像数: {success_count}\")\n",
    "        print(f\"处理失败图像数: {error_count}\")\n",
    "        print(f\"处理后的图像保存在: {output_dir}\")\n",
    "        # --- Upload resized data to R2 cache if configured and resizing was successful ---\n",
    "        if r2_configured and success_count > 0: # Only upload if some files were processed successfully\n",
    "            print(f\"将本地resize后的数据上传到 R2 缓存 ({r2_cache_key})...\")\n",
    "            # Create a zip file of the output directory\n",
    "            if zip_directory(output_dir, r2_local_zip_path):\n",
    "                # Upload the zip file\n",
    "                if upload_to_r2(s3_client, R2_BUCKET_NAME, r2_local_zip_path, r2_cache_key):\n",
    "                    print(\"R2 缓存上传成功。\")\n",
    "                else:\n",
    "                    print(\"错误: R2 缓存上传失败。\")\n",
    "                # Clean up the temporary local zip file after upload attempt\n",
    "                if os.path.exists(r2_local_zip_path):\n",
    "                    try: os.remove(r2_local_zip_path)\n",
    "                    except Exception as e: print(f\"警告: 清理本地zip文件失败: {e}\")\n",
    "            else:\n",
    "                print(\"错误: 创建本地 zip 文件失败，跳过 R2 上传。\")\n",
    "        elif not r2_configured:\n",
    "            print(\"R2 未配置，跳过上传resize后的数据。\")\n",
    "        elif success_count == 0:\n",
    "            print(\"本地resize失败（成功处理图像数为0），跳过R2上传。\")\n",
    "    image_dir = output_dir\n",
    "else:\n",
    "    print(\"未识别的非 Windows 环境，跳过图片resize步骤。\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "okNIq-rfjSo-",
    "papermill": {
     "duration": 0.004356,
     "end_time": "2025-04-13T02:01:05.452384",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.448028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 模拟高光的数据增强策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class AddRandomHighlight:\n",
    "    \"\"\"\n",
    "    一个 torchvision transform，用于在 PIL 图像上随机添加圆形高光。\n",
    "\n",
    "    参数:\n",
    "        p (float): 应用此变换的概率 (0 到 1)。\n",
    "        max_highlights (int): 单张图像上添加的最大高光数量（实际数量将在1到max_highlights之间随机选择）。\n",
    "        radius_range (tuple): 一个包含两个整数的元组 (min_radius, max_radius)，指定高光圆形的半径范围。\n",
    "        color (tuple): 一个包含三个整数的元组 (R, G, B)，指定高光的颜色 (默认为白色)。\n",
    "    \"\"\"\n",
    "    def __init__(self, p=0.5, max_highlights=3, radius_range=(5, 15), color=(255, 255, 255)):\n",
    "        if not 0.0 <= p <= 1.0:\n",
    "            raise ValueError(f\"概率 p 必须在 [0, 1] 范围内, 但得到 {p}\")\n",
    "        if not (isinstance(max_highlights, int) and max_highlights >= 1):\n",
    "            raise ValueError(f\"最大高光数 max_highlights 必须是 >= 1 的整数, 但得到 {max_highlights}\")\n",
    "        if not (isinstance(radius_range, tuple) and len(radius_range) == 2 and\n",
    "                isinstance(radius_range[0], int) and isinstance(radius_range[1], int) and\n",
    "                0 < radius_range[0] <= radius_range[1]):\n",
    "            raise ValueError(f\"半径范围 radius_range 必须是 (min, max) 形式的正整数元组，且 min <= max, 但得到 {radius_range}\")\n",
    "        if not (isinstance(color, tuple) and len(color) == 3 and all(0 <= c <= 255 for c in color)):\n",
    "            raise ValueError(f\"颜色 color 必须是 (R, G, B) 形式的元组，且值在 [0, 255] 范围内, 但得到 {color}\")\n",
    "            \n",
    "        self.p = p\n",
    "        self.max_highlights = max_highlights\n",
    "        self.radius_range = radius_range\n",
    "        self.color = color\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        对输入的 PIL 图像应用变换。\n",
    "\n",
    "        参数:\n",
    "            img (PIL.Image.Image): 输入的 PIL 图像。\n",
    "\n",
    "        返回:\n",
    "            PIL.Image.Image: 可能添加了高光的 PIL 图像。\n",
    "        \"\"\"\n",
    "        # 以概率 p 应用此变换\n",
    "        if random.random() < self.p:\n",
    "            # 复制图像以避免修改原始图像（如果原始图像后续还需使用）\n",
    "            # 如果这是 Compose 链中的一步，通常不需要显式复制\n",
    "            # img = img.copy() # 如果需要确保不修改原始输入，取消注释此行\n",
    "\n",
    "            # 随机决定生成多少个高光 (至少1个)\n",
    "            # 根据用户要求“小于四个”，我们生成 1 到 max_highlights (这里是3) 个\n",
    "            num_highlights = random.randint(1, self.max_highlights)\n",
    "            \n",
    "            # 获取图像尺寸\n",
    "            width, height = img.size\n",
    "            \n",
    "            # 创建 ImageDraw 对象以在图像上绘制\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            for _ in range(num_highlights):\n",
    "                # 随机选择半径\n",
    "                radius = random.randint(self.radius_range[0], self.radius_range[1])\n",
    "                \n",
    "                # 随机选择圆心位置\n",
    "                # 确保圆心位置加上半径不会超出图像边界太多（允许部分圆在边缘）\n",
    "                # 稍微限制圆心范围，避免完全生成在图像外的圆心\n",
    "                center_x = random.randint(0, width - 1) \n",
    "                center_y = random.randint(0, height - 1)\n",
    "\n",
    "                # 计算圆形的边界框 (left, top, right, bottom)\n",
    "                # ellipse 方法绘制的是指定边界框内的椭圆，如果边界框是正方形，则为圆形\n",
    "                left = center_x - radius\n",
    "                top = center_y - radius\n",
    "                right = center_x + radius\n",
    "                bottom = center_y + radius\n",
    "                \n",
    "                # 绘制实心圆形高光\n",
    "                draw.ellipse([left, top, right, bottom], fill=self.color)\n",
    "            \n",
    "        # 返回处理后的图像（可能是原始图像或添加了高光的图像）\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        # 提供一个清晰的表示形式，方便调试\n",
    "        return f\"{self.__class__.__name__}(p={self.p}, max_highlights={self.max_highlights}, radius_range={self.radius_range}, color={self.color})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 应用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "11JDwC__jSo-",
    "papermill": {
     "duration": 1.465971,
     "end_time": "2025-04-13T02:01:06.922765",
     "exception": false,
     "start_time": "2025-04-13T02:01:05.456794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((int(TRAIN_SIZE[0]*1.2), int(TRAIN_SIZE[1]*1.2))), # 先放大一点\n",
    "    transforms.RandomCrop(TRAIN_SIZE), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=20), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    AddRandomHighlight(p=0.3, max_highlights=3, radius_range=(5, 12)), # 试试添加高光抑制模型关注高光问题\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(TRAIN_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=420, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=val_transform) # 使用验证变换\n",
    "\n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "                        prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                        pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "eGn3VBzHjSo_",
    "papermill": {
     "duration": 0.004468,
     "end_time": "2025-04-13T02:01:06.932847",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.928379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 构建 ResNet 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b",
    "papermill": {
     "duration": 0.692259,
     "end_time": "2025-04-13T02:01:07.629659",
     "exception": false,
     "start_time": "2025-04-13T02:01:06.937400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V2)\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet34 = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V2)\n",
    "        in_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n",
    "\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "    \n",
    "class ResNet101Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet101 = models.resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "        in_features = self.resnet101.fc.in_features\n",
    "        self.resnet101.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet101(x)\n",
    "\n",
    "class ResNet152Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet152 = models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)\n",
    "        in_features = self.resnet152.fc.in_features\n",
    "        self.resnet152.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.resnet152(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 构建EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB4Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 EfficientNetB4 预训练模型\n",
    "        self.efficientnet = efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "        # EfficientNet 的分类器是一个 Sequential 模块 (Dropout, Linear)\n",
    "        # 获取最终 Linear 层的输入特征数\n",
    "        in_features = self.efficientnet.classifier[-1].in_features \n",
    "        # 替换整个分类器模块\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 构建DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 DenseNet121 预训练模型\n",
    "        self.densenet = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        # DenseNet 的分类器是一个 Linear 层\n",
    "        # 获取 Linear 层的输入特征数\n",
    "        in_features = self.densenet.classifier.in_features\n",
    "        # 替换分类器层 (为了与 ResNet 保持一致，使用 Sequential 包含 Dropout 和 Linear)\n",
    "        self.densenet.classifier = nn.Sequential( \n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 构建ConvNeXt Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "class ConvNeXtBaseClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        # 加载 ConvNeXt Base 预训练模型\n",
    "        self.convnext = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # ConvNeXt 的分类器结构是 Sequential(LayerNorm2d, Flatten, Linear)\n",
    "        # 我们需要替换最后的 Linear 层，并在其前面添加 Dropout\n",
    "        original_classifier_layers = list(self.convnext.classifier.children())\n",
    "        \n",
    "        # 获取原始 Linear 层的输入特征数\n",
    "        original_linear_layer = original_classifier_layers[-1]\n",
    "        in_features = original_linear_layer.in_features\n",
    "        \n",
    "        # 构建新的分类器 Sequential: 保留之前的层 -> 添加 Dropout -> 添加新的 Linear 层\n",
    "        new_classifier_layers = original_classifier_layers[:-1] # 保留 LayerNorm2d 和 Flatten\n",
    "        new_classifier_layers.append(nn.Dropout(p=dropout_rate)) # 添加 Dropout\n",
    "        new_classifier_layers.append(nn.Linear(in_features, num_classes)) # 添加新的 Linear 层\n",
    "\n",
    "        # 替换原模型的分类器模块\n",
    "        self.convnext.classifier = nn.Sequential(*new_classifier_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        return self.convnext(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "papermill": {
     "duration": 0.007431,
     "end_time": "2025-04-13T02:01:58.797761",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.790330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "papermill": {
     "duration": 0.083802,
     "end_time": "2025-04-13T02:01:58.888785",
     "exception": false,
     "start_time": "2025-04-13T02:01:58.804983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存 Boosting 模型\n",
    "def save_boosting_model(model, path):\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Boosting 模型已保存到 {path}\")\n",
    "\n",
    "# 加载 Boosting 模型\n",
    "def load_boosting_model(path):\n",
    "    model = joblib.load(path)\n",
    "    print(f\"Boosting 模型已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 保存 CNN 模型参数 (如果需要在预测时加载 CNN 特征提取器，例如在最终预测阶段)\n",
    "def save_cnn_state_dict(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"CNN 模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载 CNN 模型参数\n",
    "def load_cnn_state_dict(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    print(f\"CNN 模型参数已从 {path} 加载\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "papermill": {
     "duration": 0.007368,
     "end_time": "2025-04-13T02:04:20.035996",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.028628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# stacking 基线模型 K 折交叉验证\n",
    "K 折交叉验证 (K=5)，在每折中训练 CNN 基础分类器，使用它们的预测概率作为元特征，然后训练 LightGBM 元模型，并评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "papermill": {
     "duration": 295.540911,
     "end_time": "2025-04-13T02:09:15.584272",
     "exception": false,
     "start_time": "2025-04-13T02:04:20.043361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 存储结果 ---\n",
    "fold_val_accuracies = []\n",
    "fold_val_macro_f1_scores = []\n",
    "fold_val_macro_precision_scores = [] # 评估指标包含 precision\n",
    "\n",
    "# --- 准备完整数据集 (加载一次，用于 KFold 分割和创建 Subset) ---\n",
    "try:\n",
    "    full_labels_df = pd.read_excel(label_file)\n",
    "    all_original_labels = full_labels_df['Pterygium'].values\n",
    "    # 创建基础数据集实例，不应用变换 (变换在创建 Subset 时按需应用)\n",
    "    base_full_dataset_no_transform = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=None)\n",
    "\n",
    "    # 确保数据集大小和标签数量匹配\n",
    "    assert len(base_full_dataset_no_transform) == len(all_original_labels), \"Dataset size and label count mismatch!\"\n",
    "    print(f\"成功加载完整数据集，共 {len(base_full_dataset_no_transform)} 张图像。\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing full dataset for K-Fold: {e}\")\n",
    "    K = 0 # 设置 K 为 0 以跳过循环\n",
    "\n",
    "# --- 创建 KFold 分割器 ---\n",
    "if K > 0:\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=base_seed)\n",
    "    print(f\"开始进行 {K}-Fold Cross-Validation (Stacking)...\")\n",
    "else:\n",
    "    print(\"Skipping K-Fold Cross-Validation due to data preparation error or K=0.\")\n",
    "\n",
    "# --- K-Fold 循环 ---\n",
    "current_fold_num = 0\n",
    "\n",
    "# 注意：这里直接迭代 skf.split() 结果，它提供了索引\n",
    "for train_idx_fold, val_idx_fold in skf.split(np.arange(len(base_full_dataset_no_transform)), all_original_labels):\n",
    "    current_fold_num += 1\n",
    "    fold_id_str = f\"Fold {current_fold_num}/{K}\"\n",
    "    print(f\"\\n--- 开始 {fold_id_str} ---\")\n",
    "\n",
    "    # --- 1. 创建当前折的 Subset 数据集和 DataLoader ---\n",
    "    fold_train_df = full_labels_df.iloc[train_idx_fold].copy()\n",
    "    fold_val_df = full_labels_df.iloc[val_idx_fold].copy()\n",
    "    \n",
    "    # 确定临时文件路径 (例如，在 /kaggle/working 或 /tmp)\n",
    "    if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "        temp_dir_for_folds = os.path.join(kaggle_temp_path, \"fold_labels\")\n",
    "    else: # Local or other non-kaggle/colab env\n",
    "        temp_dir_for_folds = \"./temp_fold_labels\"\n",
    "\n",
    "    os.makedirs(temp_dir_for_folds, exist_ok=True)\n",
    "    \n",
    "    fold_train_label_file = os.path.join(temp_dir_for_folds, f\"fold_{current_fold_num}_train_labels.xlsx\")\n",
    "    fold_val_label_file = os.path.join(temp_dir_for_folds, f\"fold_{current_fold_num}_val_labels.xlsx\")\n",
    "\n",
    "    fold_train_df.to_excel(fold_train_label_file, index=False)\n",
    "    fold_val_df.to_excel(fold_val_label_file, index=False)\n",
    "\n",
    "    train_dataset_fold = PterygiumDataset(label_file=fold_train_label_file, image_dir=image_dir, transform=train_transform)\n",
    "    val_dataset_fold = PterygiumDataset(label_file=fold_val_label_file, image_dir=image_dir, transform=val_transform)\n",
    "\n",
    "    train_loader_fold = DataLoader(train_dataset_fold,\n",
    "                                batch_size=64, # 根据GPU内存调整\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "    val_loader_fold = DataLoader(val_dataset_fold,\n",
    "                                batch_size=64, # 根据GPU内存调整\n",
    "                                shuffle=False,\n",
    "                                num_workers=num_workers,\n",
    "                                prefetch_factor=2 if platform.system() == \"Windows\" else 10,\n",
    "                                pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "    print(f\"Fold {current_fold_num}: Train size={len(train_dataset_fold)}, Val size={len(val_dataset_fold)}\")\n",
    "\n",
    "    # --- 2. 微调 CNN 基础分类器 (在当前折叠的训练集上) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 微调 CNN 基础分类器 (Level-0 Models) ---\")\n",
    "    \n",
    "    fold_cnn_finetuned_classifiers = {} # 存储微调好的完整 CNN 分类器\n",
    "    \n",
    "    for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "        print(f\"  微调 {cnn_name}...\")\n",
    "        # 创建一个新的 CNN 模型实例 (带分类头)\n",
    "        cnn_model_for_finetuning = globals()[cnn_name](num_classes=3).to(device)\n",
    "        \n",
    "        # 配置优化器和调度器\n",
    "        cnn_optimizer = optim.AdamW(cnn_model_for_finetuning.parameters(), \n",
    "                                    lr=cnn_micro_train_params['lr'], \n",
    "                                    weight_decay=cnn_micro_train_params['weight_decay'])\n",
    "        cnn_scheduler = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer, \n",
    "                                                            T_max=cnn_micro_train_params['num_epochs'], \n",
    "                                                            eta_min=1e-6)\n",
    "        cnn_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        start_time_cnn_finetune = time.time()\n",
    "        scaler_cnn = torch.amp.GradScaler('cuda') # AMP scaler\n",
    "        \n",
    "        for cnn_epoch in range(cnn_micro_train_params['num_epochs']):\n",
    "            cnn_model_for_finetuning.train()\n",
    "            train_loss_cnn = 0\n",
    "            train_correct_cnn = 0\n",
    "            train_total_cnn = 0\n",
    "            \n",
    "            cnn_train_loader_tqdm = tqdm(train_loader_fold, desc=f'  {cnn_name} Epoch {cnn_epoch+1}/{cnn_micro_train_params[\"num_epochs\"]}', leave=False)\n",
    "            \n",
    "            for batch_idx, (inputs, targets) in enumerate(cnn_train_loader_tqdm):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                cnn_optimizer.zero_grad()\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = cnn_model_for_finetuning(inputs)\n",
    "                    loss = cnn_criterion(outputs, targets)\n",
    "                scaler_cnn.scale(loss).backward()\n",
    "                scaler_cnn.step(cnn_optimizer)\n",
    "                scaler_cnn.update()\n",
    "                train_loss_cnn += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                train_total_cnn += targets.size(0)\n",
    "                train_correct_cnn += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                cnn_train_loader_tqdm.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100. * train_correct_cnn / train_total_cnn:.2f}%',\n",
    "                    'lr': f'{cnn_optimizer.param_groups[0][\"lr\"]:.1e}'\n",
    "                })\n",
    "            # 打印更频繁或在最后一次epoch打印训练结果\n",
    "            #if cnn_epoch % 5 == 0 or (cnn_epoch + 1) == cnn_micro_train_params['num_epochs']:\n",
    "            #     print(f\"    Fold {current_fold_num} {cnn_name} Epoch {cnn_epoch+1} Train Acc: {100. * train_correct_cnn / train_total_cnn:.2f}%, Avg Loss: {train_loss_cnn / len(train_loader_fold):.4f}\")\n",
    "            cnn_scheduler.step() # 更新 CNN 学习率\n",
    "    \n",
    "        end_time_cnn_finetune = time.time()\n",
    "        print(f\"  微调 {cnn_name} 完成，耗时: {end_time_cnn_finetune - start_time_cnn_finetune:.2f} 秒\")\n",
    "\n",
    "        # --- 评估微调后的基础 CNN 分类器在验证集上的性能 ---\n",
    "        print(f\"  评估微调后的基础模型 {cnn_name} 在验证集上...\")\n",
    "        cnn_model_for_finetuning.eval() # 设置为评估模式\n",
    "        val_correct_cnn_base = 0\n",
    "        val_total_cnn_base = 0\n",
    "        all_val_labels_cnn_base = []\n",
    "        all_val_preds_cnn_base = []\n",
    "\n",
    "        with torch.no_grad(): # 关闭梯度计算\n",
    "            cnn_val_loader_tqdm_base = tqdm(val_loader_fold, desc=f'  Evaluating Base {cnn_name}', leave=False)\n",
    "            for batch_idx, (inputs, targets) in enumerate(cnn_val_loader_tqdm_base):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                with torch.amp.autocast('cuda'): # 使用 AMP 进行推理\n",
    "                    outputs = cnn_model_for_finetuning(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total_cnn_base += targets.size(0)\n",
    "                val_correct_cnn_base += predicted.eq(targets).sum().item()\n",
    "                all_val_labels_cnn_base.extend(targets.cpu().numpy())\n",
    "                all_val_preds_cnn_base.extend(predicted.cpu().numpy())\n",
    "\n",
    "        cnn_val_accuracy_base = 100. * val_correct_cnn_base / val_total_cnn_base if val_total_cnn_base > 0 else 0\n",
    "        cnn_val_macro_precision_base = precision_score(all_val_labels_cnn_base, all_val_preds_cnn_base, average='macro', zero_division=0)\n",
    "        cnn_val_macro_f1_base = f1_score(all_val_labels_cnn_base, all_val_preds_cnn_base, average='macro', zero_division=0)\n",
    "        print(f\"    Fold {current_fold_num} Base {cnn_name} Val Acc: {cnn_val_accuracy_base:.2f}%, Macro Precision: {cnn_val_macro_precision_base:.4f}, Macro F1: {cnn_val_macro_f1_base:.4f}\")\n",
    "        \n",
    "        # 存储微调好的分类器\n",
    "        cnn_model_for_finetuning.eval() # 再次确保是评估模式\n",
    "        fold_cnn_finetuned_classifiers[cnn_name] = cnn_model_for_finetuning\n",
    "\n",
    "    # --- 3. 生成元特征 (来自微调后的 CNN 的预测概率) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 生成元特征 (用于元模型训练) ---\")\n",
    "    \n",
    "    train_meta_features_list_fold = [] # 存储当前折训练集的元特征（概率）\n",
    "    val_meta_features_list_fold = []   # 存储当前折验证集的元特征（概率）\n",
    "    \n",
    "    y_train_fold_labels_collected = None # 存储训练集标签 (只需收集一次)\n",
    "    y_val_fold_labels_collected = None   # 存储验证集标签 (只需收集一次)\n",
    "\n",
    "    # 对每个微调好的 CNN 获取其在训练集和验证集上的预测概率\n",
    "    for cnn_name, cnn_classifier_model in fold_cnn_finetuned_classifiers.items():\n",
    "        cnn_classifier_model.eval() # 确保是评估模式\n",
    "        \n",
    "        # -- 获取训练集的预测概率 --\n",
    "        current_train_probs_fold_list = []\n",
    "        current_train_labels_fold_temp_list = [] \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(train_loader_fold, desc=f\"元特征(训练集) from {cnn_name}\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = cnn_classifier_model(inputs)\n",
    "                    probabilities = torch.softmax(outputs, dim=1) # 获取概率\n",
    "                current_train_probs_fold_list.append(probabilities.cpu().numpy())\n",
    "                if y_train_fold_labels_collected is None: # 仅在处理第一个CNN时收集训练标签\n",
    "                    current_train_labels_fold_temp_list.append(targets.cpu().numpy())\n",
    "        \n",
    "        train_meta_features_list_fold.append(np.concatenate(current_train_probs_fold_list, axis=0))\n",
    "        if y_train_fold_labels_collected is None and current_train_labels_fold_temp_list:\n",
    "            y_train_fold_labels_collected = np.concatenate(current_train_labels_fold_temp_list, axis=0)\n",
    "\n",
    "        # -- 获取验证集的预测概率 --\n",
    "        current_val_probs_fold_list = []\n",
    "        current_val_labels_fold_temp_list = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader_fold, desc=f\"元特征(验证集) from {cnn_name}\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = cnn_classifier_model(inputs)\n",
    "                    probabilities = torch.softmax(outputs, dim=1) # 获取概率\n",
    "                current_val_probs_fold_list.append(probabilities.cpu().numpy())\n",
    "                if y_val_fold_labels_collected is None: # 仅在处理第一个CNN时收集验证标签\n",
    "                    current_val_labels_fold_temp_list.append(targets.cpu().numpy())\n",
    "        \n",
    "        val_meta_features_list_fold.append(np.concatenate(current_val_probs_fold_list, axis=0))\n",
    "        if y_val_fold_labels_collected is None and current_val_labels_fold_temp_list:\n",
    "            y_val_fold_labels_collected = np.concatenate(current_val_labels_fold_temp_list, axis=0)\n",
    "\n",
    "    # 检查标签是否成功收集\n",
    "    if y_train_fold_labels_collected is None or y_val_fold_labels_collected is None:\n",
    "        print(\"错误:未能收集元模型训练/验证的标签。可能是因为训练/验证加载器为空。\")\n",
    "        # 可以选择跳过此折或进行错误处理\n",
    "        continue # 跳到下一个fold\n",
    "\n",
    "    # 拼接所有 CNN 的预测概率作为元特征\n",
    "    X_train_fold_meta = np.concatenate(train_meta_features_list_fold, axis=1)\n",
    "    y_train_fold = y_train_fold_labels_collected # 元模型训练标签\n",
    "\n",
    "    X_val_fold_meta = np.concatenate(val_meta_features_list_fold, axis=1)\n",
    "    y_val_fold = y_val_fold_labels_collected # 元模型验证标签\n",
    "\n",
    "    print(f\"Fold {current_fold_num} 元训练特征形状: {X_train_fold_meta.shape}\")\n",
    "    print(f\"Fold {current_fold_num} 元验证特征形状: {X_val_fold_meta.shape}\")\n",
    "\n",
    "    # --- 4. 训练元模型 ---\n",
    "    print(f\"--- Fold {current_fold_num}: 训练 元模型 (Level-1 Model) ({META_MODEL_TYPE}) ---\")\n",
    "    \n",
    "    start_time_meta_lgbm_train = time.time() # <--- 变量名可以不变，但它现在代表元模型训练时间\n",
    "    # --- 根据 META_MODEL_TYPE 选择并训练元模型 --- # <--- 添加这一段逻辑\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        meta_lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "        eval_set_meta = [(X_val_fold_meta, y_val_fold)] # LightGBM 可以使用验证集进行早停\n",
    "        callbacks_meta = [lgb.early_stopping(stopping_rounds=50, verbose=10)]\n",
    "        meta_lgbm_model.fit(X_train_fold_meta, y_train_fold,\n",
    "                            eval_set=eval_set_meta,\n",
    "                            eval_metric='multi_logloss',\n",
    "                            callbacks=callbacks_meta)\n",
    "        # 对于 LightGBM，检查最佳迭代次数\n",
    "        if hasattr(meta_lgbm_model.booster_, 'best_iteration') and meta_lgbm_model.booster_.best_iteration > 0:\n",
    "            print(f\"LightGBM 元模型在训练集上的最佳迭代次数: {meta_lgbm_model.booster_.best_iteration}\")\n",
    "        else:\n",
    "            print(f\"LightGBM 元模型训练完成 (未使用早停或早停未在50轮内触发).\")\n",
    "\n",
    "    elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "        meta_lgbm_model = LogisticRegression(**logreg_params)\n",
    "        meta_lgbm_model.fit(X_train_fold_meta, y_train_fold)\n",
    "        print(f\"Logistic Regression 元模型训练完成.\")\n",
    "        print(f'Logistic Regression 元模型方程: {meta_lgbm_model.intercept_} + {meta_lgbm_model.coef_} * X')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported META_MODEL_TYPE for training: {META_MODEL_TYPE}\")\n",
    "    end_time_meta_lgbm_train = time.time()\n",
    "    print(f\"元模型训练完成，耗时: {end_time_meta_lgbm_train - start_time_meta_lgbm_train:.2f} 秒\")\n",
    "    if META_MODEL_TYPE == 'LightGBM':\n",
    "        if hasattr(meta_lgbm_model.booster_, 'best_iteration') and meta_lgbm_model.booster_.best_iteration > 0:\n",
    "            print(f\"LightGBM 元模型在训练集上的最佳迭代次数: {meta_lgbm_model.booster_.best_iteration}\")\n",
    "        else:\n",
    "            print(f\"LightGBM 元模型训练完成 (可能未使用早停或早停未在50轮内触发).\")\n",
    "\n",
    "    # --- 5. 评估元模型 (在当前折叠的元验证集上) ---\n",
    "    print(f\"--- Fold {current_fold_num}: 评估 元模型 ---\")\n",
    "    \n",
    "    y_pred_fold_meta = meta_lgbm_model.predict(X_val_fold_meta) # 使用元模型预测\n",
    "    \n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_pred_fold_meta)\n",
    "    fold_macro_precision = precision_score(y_val_fold, y_pred_fold_meta, average='macro', zero_division=0)\n",
    "    fold_macro_f1 = f1_score(y_val_fold, y_pred_fold_meta, average='macro', zero_division=0)\n",
    "    \n",
    "    print(f\"Fold {current_fold_num} 元模型验证准确率: {fold_accuracy:.4f}\")\n",
    "    print(f\"Fold {current_fold_num} 元模型验证Macro Precision: {fold_macro_precision:.4f}\")\n",
    "    print(f\"Fold {current_fold_num} 元模型验证Macro F1: {fold_macro_f1:.4f}\")\n",
    "    \n",
    "    # 存储结果\n",
    "    fold_val_accuracies.append(fold_accuracy)\n",
    "    fold_val_macro_precision_scores.append(fold_macro_precision)\n",
    "    fold_val_macro_f1_scores.append(fold_macro_f1)\n",
    "    \n",
    "    # 清理临时文件\n",
    "    if os.path.exists(fold_train_label_file): os.remove(fold_train_label_file)\n",
    "    if os.path.exists(fold_val_label_file): os.remove(fold_val_label_file)\n",
    "\n",
    "# --- 6. K-Fold 循环结束后，进行分析 ---\n",
    "if K > 0 and fold_val_accuracies: # 确保有结果可分析\n",
    "    print(\"\\n--- K-Fold Cross-Validation (Stacking) 结果分析 ---\")\n",
    "\n",
    "    # 计算平均值和标准差\n",
    "    mean_accuracy = np.mean(fold_val_accuracies)\n",
    "    std_accuracy = np.std(fold_val_accuracies)\n",
    "    mean_precision = np.mean(fold_val_macro_precision_scores)\n",
    "    std_precision = np.std(fold_val_macro_precision_scores)\n",
    "    mean_f1 = np.mean(fold_val_macro_f1_scores)\n",
    "    std_f1 = np.std(fold_val_macro_f1_scores)\n",
    "\n",
    "    print(f\"平均验证准确率 (元模型, across {K} folds): {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    print(f\"平均验证Macro Precision (元模型, across {K} folds): {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "    print(f\"平均验证Macro F1 (元模型, across {K} folds): {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n每折的元模型验证准确率:\")\n",
    "    for i, acc in enumerate(fold_val_accuracies):\n",
    "        print(f\"  Fold {i+1}: {acc:.4f}\")\n",
    "    print(\"\\n每折的元模型验证Macro F1:\")\n",
    "    for i, f1 in enumerate(fold_val_macro_f1_scores):\n",
    "        print(f\"  Fold {i+1}: {f1:.4f}\")\n",
    "        \n",
    "# --- 清理临时文件夹 ---\n",
    "if 'temp_dir_for_folds' in locals() and os.path.exists(temp_dir_for_folds):\n",
    "    print(f\"清理临时文件夹: {temp_dir_for_folds}\")\n",
    "    try:\n",
    "        shutil.rmtree(temp_dir_for_folds)\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 清理临时文件夹失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# 训练最终用于提交的模型\n",
    "使用整个训练集训练 CNN 基础分类器，然后使用它们的预测概率作为元特征，训练最终的元模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 开始训练最终提交的 Stacking 集成模型 ---\")\n",
    "\n",
    "# 使用整个训练集的数据加载器 (即原始的 train_loader)\n",
    "# final_cnn_train_loader 用于训练基础 CNN 模型，应用训练时的数据增强\n",
    "final_cnn_train_loader = train_loader \n",
    "\n",
    "# full_train_loader_eval_transform 用于从训练好的基础CNN模型获取预测概率 (元特征)\n",
    "# 它使用整个训练集，但应用验证集/评估时的变换，以获得更一致的概率输出\n",
    "# (在K-Fold中，这对应于对训练折数据的\"out-of-fold\"预测，这里是对全训练集数据的预测)\n",
    "if 'label_file' in globals() and 'image_dir' in globals() and 'val_transform' in globals():\n",
    "    full_train_dataset_eval_transform = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=val_transform)\n",
    "    full_train_loader_eval_transform = DataLoader(full_train_dataset_eval_transform,\n",
    "                                                batch_size=64, # 根据GPU内存调整\n",
    "                                                shuffle=False, # 提取元特征不需要 shuffle\n",
    "                                                num_workers=num_workers,\n",
    "                                                prefetch_factor=train_loader.prefetch_factor if hasattr(train_loader, 'prefetch_factor') else 2,\n",
    "                                                pin_memory=train_loader.pin_memory if hasattr(train_loader, 'pin_memory') else (platform.system() != \"Windows\"))\n",
    "else:\n",
    "    print(\"错误：label_file, image_dir, 或 val_transform 未定义。无法创建 full_train_loader_eval_transform。\")\n",
    "    # 考虑退出或设置一个标志来跳过后续步骤\n",
    "    # sys.exit(\"关键变量未定义，无法继续最终模型训练。\")\n",
    "\n",
    "\n",
    "# --- 1. 训练 CNN 基础分类器 (在整个训练集上) ---\n",
    "print(\"--- 步骤 1: 训练 CNN 基础分类器 (在整个训练集上) ---\")\n",
    "\n",
    "final_cnn_classifiers = {} # 存储最终训练好的完整 CNN 分类器\n",
    "\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "    print(f\"  训练基础模型: {cnn_name} 在完整数据集上...\")\n",
    "    # 创建一个新的 CNN 模型实例 (带分类头)\n",
    "    cnn_model_for_final_training = globals()[cnn_name](num_classes=3).to(device)\n",
    "\n",
    "    # 配置优化器和调度器\n",
    "    # 可以考虑为最终训练调整 epochs 或学习率，但为简单起见，先用 k-fold 中的参数\n",
    "    final_train_epochs = cnn_micro_train_params.get('num_epochs_final', cnn_micro_train_params['num_epochs']) # 允许覆盖最终训练的epochs\n",
    "    \n",
    "    cnn_optimizer_final = optim.AdamW(cnn_model_for_final_training.parameters(), \n",
    "                                        lr=cnn_micro_train_params['lr'], \n",
    "                                        weight_decay=cnn_micro_train_params['weight_decay'])\n",
    "    cnn_scheduler_final = optim.lr_scheduler.CosineAnnealingLR(cnn_optimizer_final, \n",
    "                                                                T_max=final_train_epochs, \n",
    "                                                                eta_min=1e-6)\n",
    "    cnn_criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "    start_time_cnn_final_train = time.time()\n",
    "    scaler_cnn_final = torch.amp.GradScaler('cuda') \n",
    "    \n",
    "    for cnn_epoch in range(final_train_epochs):\n",
    "        cnn_model_for_final_training.train()\n",
    "        train_loss_cnn_final = 0\n",
    "        train_correct_cnn_final = 0\n",
    "        train_total_cnn_final = 0\n",
    "        \n",
    "        # 使用 final_cnn_train_loader (即原始的 train_loader 带数据增强)\n",
    "        cnn_train_loader_final_tqdm = tqdm(final_cnn_train_loader, desc=f'  {cnn_name} Final Epoch {cnn_epoch+1}/{final_train_epochs}', leave=False)\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(cnn_train_loader_final_tqdm):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            cnn_optimizer_final.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = cnn_model_for_final_training(inputs)\n",
    "                loss = cnn_criterion_final(outputs, targets)\n",
    "            scaler_cnn_final.scale(loss).backward()\n",
    "            scaler_cnn_final.step(cnn_optimizer_final)\n",
    "            scaler_cnn_final.update()\n",
    "            \n",
    "            train_loss_cnn_final += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total_cnn_final += targets.size(0)\n",
    "            train_correct_cnn_final += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            cnn_train_loader_final_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * train_correct_cnn_final / train_total_cnn_final:.2f}%' if train_total_cnn_final > 0 else '0.00%',\n",
    "                'lr': f'{cnn_optimizer_final.param_groups[0][\"lr\"]:.1e}'\n",
    "            })\n",
    "        \n",
    "        current_epoch_avg_loss = train_loss_cnn_final / len(final_cnn_train_loader) if len(final_cnn_train_loader) > 0 else 0\n",
    "        current_epoch_acc = 100. * train_correct_cnn_final / train_total_cnn_final if train_total_cnn_final > 0 else 0\n",
    "        #if cnn_epoch % 5 == 0 or (cnn_epoch + 1) == final_train_epochs: # 打印更频繁或在最后\n",
    "        #    print(f\"    Final Training {cnn_name} Epoch {cnn_epoch+1} Train Acc: {current_epoch_acc:.2f}%, Avg Loss: {current_epoch_avg_loss:.4f}\")\n",
    "        cnn_scheduler_final.step() \n",
    "    \n",
    "    end_time_cnn_final_train = time.time()\n",
    "    print(f\"  训练基础模型 {cnn_name} 在完整数据集上完成，耗时: {end_time_cnn_final_train - start_time_cnn_final_train:.2f} 秒\")\n",
    "\n",
    "    # 存储最终训练好的基础分类器模型\n",
    "    cnn_model_for_final_training.eval() # 设置为评估模式\n",
    "    final_cnn_classifiers[cnn_name] = cnn_model_for_final_training\n",
    "    \n",
    "    # 保存基础分类器的状态字典\n",
    "    base_classifier_save_path = f'./final_{cnn_name}_base_classifier.pth'\n",
    "    save_cnn_state_dict(cnn_model_for_final_training, base_classifier_save_path)\n",
    "    print(f\"  基础分类器 {cnn_name} 已保存到 {base_classifier_save_path}\")\n",
    "\n",
    "\n",
    "# --- 2. 为元模型提取最终训练特征 (从整个训练集，使用训练好的CNN分类器) ---\n",
    "print(\"\\n--- 步骤 2: 为元模型提取整个训练集的预测概率 (元特征) ---\")\n",
    "\n",
    "final_train_meta_features_list = []\n",
    "y_final_train_labels_collected = None # 用于收集标签 (只需一次)\n",
    "\n",
    "if 'full_train_loader_eval_transform' not in globals() or not final_cnn_classifiers:\n",
    "    print(\"错误：full_train_loader_eval_transform 未定义或没有训练好的基础CNN分类器。无法提取元特征。\")\n",
    "    # sys.exit(\"无法继续元特征提取。\")\n",
    "else:\n",
    "    # 对每个训练好的 CNN 分类器提取预测概率\n",
    "    for cnn_name, cnn_classifier_model in final_cnn_classifiers.items():\n",
    "        print(f\"  使用基础模型 {cnn_name} 提取完整训练集预测概率...\")\n",
    "        cnn_classifier_model.eval() # 确保是评估模式\n",
    "        \n",
    "        current_final_train_probs_list = []\n",
    "        current_final_train_labels_temp_list = [] \n",
    "        with torch.no_grad():\n",
    "            # 使用 full_train_loader_eval_transform (无增强的变换)\n",
    "            for inputs, targets in tqdm(full_train_loader_eval_transform, desc=f\"元特征(最终训练) from {cnn_name}\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = cnn_classifier_model(inputs)\n",
    "                    probabilities = torch.softmax(outputs, dim=1)\n",
    "                current_final_train_probs_list.append(probabilities.cpu().numpy())\n",
    "                if y_final_train_labels_collected is None: # 仅在处理第一个CNN时收集标签\n",
    "                    current_final_train_labels_temp_list.append(targets.cpu().numpy())\n",
    "        \n",
    "        final_train_meta_features_list.append(np.concatenate(current_final_train_probs_list, axis=0))\n",
    "        if y_final_train_labels_collected is None and current_final_train_labels_temp_list:\n",
    "            y_final_train_labels_collected = np.concatenate(current_final_train_labels_temp_list, axis=0)\n",
    "\n",
    "    if not final_train_meta_features_list or y_final_train_labels_collected is None:\n",
    "        print(\"错误：未能生成元特征或收集标签。\")\n",
    "        # sys.exit(\"元特征生成失败。\")\n",
    "    else:\n",
    "        X_final_train_meta = np.concatenate(final_train_meta_features_list, axis=1)\n",
    "        y_final_train = y_final_train_labels_collected \n",
    "        print(f\"拼接后完整训练集元特征形状: {X_final_train_meta.shape}\")\n",
    "\n",
    "        # --- 3. 训练最终的元模型 (LightGBM) ---\n",
    "        print(f\"\\n--- 步骤 3: 训练最终 元模型 ({META_MODEL_TYPE}) ---\")\n",
    "\n",
    "        final_meta_lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "\n",
    "        start_time_final_meta_lgbm_train = time.time()\n",
    "        if META_MODEL_TYPE == 'LightGBM':\n",
    "            final_meta_lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "            final_meta_lgbm_model.fit(X_final_train_meta, y_final_train)\n",
    "            print(f\"最终 LightGBM 元模型训练完成.\")\n",
    "        elif META_MODEL_TYPE == 'LogisticRegression':\n",
    "            final_meta_lgbm_model = LogisticRegression(**logreg_params)\n",
    "            final_meta_lgbm_model.fit(X_final_train_meta, y_final_train)\n",
    "            print(f\"最终 Logistic Regression 元模型训练完成.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported META_MODEL_TYPE for final training: {META_MODEL_TYPE}\")\n",
    "        end_time_final_meta_lgbm_train = time.time()\n",
    "        print(f\"最终 LightGBM 元模型训练完成，耗时: {end_time_final_meta_lgbm_train - start_time_final_meta_lgbm_train:.2f} 秒\")\n",
    "\n",
    "        # --- 4. 保存最终的元模型 ---\n",
    "        print(\"\\n--- 步骤 4: 保存最终的元模型 ---\")\n",
    "        final_meta_model_save_path = f\"./final_stacked_meta_classifier_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\" \n",
    "        save_boosting_model(final_meta_lgbm_model, final_meta_model_save_path)\n",
    "        # 注意：对于 Stacking，通常不需要保存 scaler，因为元特征是概率。\n",
    "\n",
    "        print(\"\\n--- 最终提交的 Stacking 集成模型训练完成 ---\")\n",
    "        print(f\"基础CNN分类器已保存 (例如: ./final_{CNN_FEATURE_EXTRACTORS[0]}_base_classifier.pth)\")\n",
    "        print(f\"最终元模型已保存到: {final_meta_model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# 最终 Stacking 集成模型预测\n",
    "加载训练好的 CNN 基础分类器和 LightGBM 元模型，并使用它们对新图像进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最终的元模型\n",
    "final_meta_model_load_path = f\"./final_stacked_meta_classifier_{META_MODEL_TYPE.lower().replace(' ', '_')}.joblib\"\n",
    "if os.path.exists(final_meta_model_load_path):\n",
    "    final_meta_lgbm_model_loaded = load_boosting_model(final_meta_model_load_path)\n",
    "else:\n",
    "    print(f\"错误: 最终元模型文件 {final_meta_model_load_path} 未找到。预测将无法进行。\")\n",
    "    final_meta_lgbm_model_loaded = None # 标记为未加载\n",
    "\n",
    "# 加载最终训练好的 CNN 基础分类器\n",
    "final_cnn_classifiers_loaded = {}\n",
    "print(\"加载微调后的 CNN 基础分类器...\")\n",
    "all_base_classifiers_loaded = True\n",
    "for cnn_name in CNN_FEATURE_EXTRACTORS:\n",
    "    print(f\"  加载 {cnn_name} 基础分类器...\")\n",
    "    # 创建基础分类器模型实例\n",
    "    # globals()[cnn_name] 动态地从字符串获取类名并实例化\n",
    "    # .to(device) 会在 load_cnn_state_dict 中处理\n",
    "    base_classifier_model_instance = globals()[cnn_name](num_classes=3) \n",
    "    \n",
    "    final_cnn_state_dict_path = f'./final_{cnn_name}_base_classifier.pth' # 文件名与训练时对应\n",
    "    if os.path.exists(final_cnn_state_dict_path):\n",
    "        # load_cnn_state_dict 函数应将模型移至 device 并设置为 eval 模式\n",
    "        base_classifier_model_instance = load_cnn_state_dict(base_classifier_model_instance, final_cnn_state_dict_path, device)\n",
    "        base_classifier_model_instance.eval() # 确保是评估模式\n",
    "        final_cnn_classifiers_loaded[cnn_name] = base_classifier_model_instance\n",
    "        print(f\"  基础分类器 {cnn_name} 权重加载成功。\")\n",
    "    else:\n",
    "        print(f\"错误: 未找到基础分类器 {cnn_name} 的权重文件 {final_cnn_state_dict_path}。\")\n",
    "        all_base_classifiers_loaded = False\n",
    "        # 不将未加载的模型添加到字典中，或添加None并在预测时检查\n",
    "\n",
    "if not all_base_classifiers_loaded:\n",
    "    print(\"警告: 一个或多个基础CNN分类器未能加载。预测可能不准确或失败。\")\n",
    "if not final_meta_lgbm_model_loaded:\n",
    "    print(\"警告: 元模型未能加载。预测将失败。\")\n",
    "\n",
    "def predict_single_image_stacked(cnn_base_classifiers_dict, meta_model_instance, image_path, prediction_transform, device_to_use):\n",
    "    \"\"\"\n",
    "    使用 Stacking Ensemble 模型对单张图像进行预测。\n",
    "\n",
    "    参数:\n",
    "        cnn_base_classifiers_dict (dict): 包含已加载和评估模式的基础CNN分类器的字典。\n",
    "        meta_model_instance: 已加载的元模型实例 (例如 LightGBM)。\n",
    "        image_path (str): 待预测图像的路径。\n",
    "        prediction_transform: 应用于预测图像的 torchvision transform。\n",
    "        device_to_use: 'cuda' 或 'cpu'。\n",
    "\n",
    "    返回:\n",
    "        int or None: 预测的类别标签，如果出错则为 None。\n",
    "    \"\"\"\n",
    "    # 1. 检查模型是否都已加载\n",
    "    if not cnn_base_classifiers_dict or not meta_model_instance or not all(cnn_base_classifiers_dict.values()):\n",
    "        print(\"错误: 基础模型或元模型未完全加载。无法进行预测。\")\n",
    "        return None\n",
    "\n",
    "    # 2. 加载和预处理图像\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        # 应用预测时（通常是验证/测试时）的变换\n",
    "        image_tensor = prediction_transform(image).unsqueeze(0).to(device_to_use)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 预测图像文件未找到 {image_path}\")\n",
    "        return None \n",
    "    except Exception as e:\n",
    "        print(f\"错误处理预测图像 {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 3. 使用每个 CNN 基础分类器获取预测概率 (元特征)\n",
    "    meta_features_from_image_list = []\n",
    "    with torch.no_grad(): # 推理时不需要梯度\n",
    "        for cnn_name, cnn_classifier_model in cnn_base_classifiers_dict.items():\n",
    "            if cnn_classifier_model is None: # 如果某个基础模型未加载成功\n",
    "                print(f\"警告：基础模型 {cnn_name} 未加载，无法用于生成元特征。\")\n",
    "                # 根据策略，可以选择返回错误，或尝试用剩余模型预测（不推荐）\n",
    "                return None # 或者抛出异常\n",
    "\n",
    "            cnn_classifier_model.eval() # 确保是评估模式\n",
    "            with torch.amp.autocast('cuda' if device_to_use == 'cuda' else 'cpu', enabled=torch.cuda.is_available()): # AMP 推理\n",
    "                outputs = cnn_classifier_model(image_tensor)\n",
    "                probabilities = torch.softmax(outputs, dim=1) # (batch_size, num_classes)\n",
    "            meta_features_from_image_list.append(probabilities.cpu().numpy()) # 转换为numpy并移至CPU\n",
    "            \n",
    "    # 检查是否成功生成了所有基础模型的概率\n",
    "    if len(meta_features_from_image_list) != len(CNN_FEATURE_EXTRACTORS):\n",
    "        print(\"错误：未能从所有基础模型生成元特征。\")\n",
    "        return None\n",
    "\n",
    "    # 横向拼接来自所有基础模型的概率，形成元模型的输入\n",
    "    # 结果形状应该是 (1, num_base_models * num_classes)\n",
    "    image_meta_features_array = np.concatenate(meta_features_from_image_list, axis=1)\n",
    "\n",
    "    # 4. 使用元模型进行最终预测\n",
    "    try:\n",
    "        # meta_model_instance.predict() 通常返回一个数组，取第一个元素\n",
    "        predicted_class_label = meta_model_instance.predict(image_meta_features_array)[0] \n",
    "    except Exception as e:\n",
    "        print(f\"元模型预测时出错: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return int(predicted_class_label) # 确保返回整数\n",
    "\n",
    "# --- 预测示例: 对验证集目录中的所有图像进行预测 ---\n",
    "def predict_on_image_directory_stacked(\n",
    "    base_classifiers_loaded_dict, \n",
    "    meta_model_loaded_instance, \n",
    "    directory_path, \n",
    "    image_transform_for_prediction, \n",
    "    device_for_prediction,\n",
    "    output_excel_filename=\"Classification_Results_Stacked.xlsx\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    在指定目录中的所有图像上运行 Stacking 模型预测，并将结果保存到 Excel。\n",
    "    \"\"\"\n",
    "    if not base_classifiers_loaded_dict or not meta_model_loaded_instance:\n",
    "        print(\"错误: 基础模型或元模型未提供给预测函数。\")\n",
    "        return\n",
    "\n",
    "    # 查找目录中所有支持的图像文件 (这里假设是 .png)\n",
    "    # 你可以扩展 glob 模式以支持更多格式: os.path.join(directory_path, \"*.[pP][nN][gG]\") 等\n",
    "    image_paths = glob.glob(os.path.join(directory_path, \"*.png\")) \n",
    "    if not image_paths:\n",
    "        print(f\"警告: 在目录 {directory_path} 中未找到任何 .png 图像。\")\n",
    "        return\n",
    "\n",
    "    prediction_results = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Predicting images with Stacking Ensemble\", leave=True):\n",
    "        try:\n",
    "            predicted_label = predict_single_image_stacked(\n",
    "                base_classifiers_loaded_dict, \n",
    "                meta_model_loaded_instance, \n",
    "                img_path, \n",
    "                image_transform_for_prediction, \n",
    "                device_for_prediction\n",
    "            )\n",
    "            \n",
    "            if predicted_label is not None:\n",
    "                # 从文件名提取图像ID (假设文件名是数字，例如 \"0001.png\")\n",
    "                base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                try:\n",
    "                    image_id = int(base_name)\n",
    "                    prediction_results.append({\"Image\": image_id, \"Pterygium\": predicted_label})\n",
    "                except ValueError:\n",
    "                    tqdm.write(f\"警告: 无法从文件名 {base_name} 解析图像ID。跳过此图像。\")\n",
    "            else:\n",
    "                tqdm.write(f\"图像 {img_path} 的预测失败或返回 None。\")\n",
    "\n",
    "        except Exception as e: # 捕获 predict_single_image_stacked 可能未捕获的意外错误\n",
    "            tqdm.write(f\"处理或预测图像 {img_path} 时发生意外错误: {e}\")\n",
    "    \n",
    "    if not prediction_results:\n",
    "        print(\"没有图像被成功预测。未生成结果文件。\")\n",
    "        return\n",
    "\n",
    "    # 按图像ID对结果进行排序\n",
    "    prediction_results.sort(key=lambda x: x[\"Image\"])\n",
    "    \n",
    "    # 将结果转换为 Pandas DataFrame 并保存到 Excel\n",
    "    results_df = pd.DataFrame(prediction_results, columns=[\"Image\", \"Pterygium\"])\n",
    "    \n",
    "    try:\n",
    "        results_df.to_excel(output_excel_filename, index=False)\n",
    "        print(f\"\\n分类结果已保存到 {output_excel_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 保存 Excel 文件失败: {e}\")\n",
    "\n",
    "# --- 调用预测函数 ---\n",
    "# 确保所有模型都已正确加载\n",
    "if all_base_classifiers_loaded and final_meta_lgbm_model_loaded:\n",
    "    print(f\"\\n开始对验证集目录 {val_image_dir} 中的图像进行预测...\")\n",
    "    # 使用验证/测试时的变换 (val_transform)\n",
    "    predict_on_image_directory_stacked(\n",
    "        final_cnn_classifiers_loaded,       # 加载的基础CNN模型字典\n",
    "        final_meta_lgbm_model_loaded,       # 加载的元模型\n",
    "        val_image_dir,                      # 包含待预测图像的目录\n",
    "        val_transform,                      # 图像预处理变换\n",
    "        device,                             # 'cuda' or 'cpu'\n",
    "        output_excel_filename=f\"Classification_Results_Stacking_Ensemble_{META_MODEL_TYPE.replace(' ', '_')}.xlsx\" \n",
    "    )\n",
    "else:\n",
    "    print(\"错误：最终的基础CNN分类器或元模型未能完全加载。跳过在验证目录上的预测。\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7046642,
     "sourceId": 11272397,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 231745112,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 937.871658,
   "end_time": "2025-04-13T02:09:18.610590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T01:53:40.738932",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
