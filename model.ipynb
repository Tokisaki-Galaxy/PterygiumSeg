{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8rV7E66jSoG"
   },
   "source": [
    "# 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-siDBWjjSo6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "%matplotlib inline\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    !wget -O simhei.ttf \"https://www.wfonts.com/download/data/2014/06/01/simhei/chinese.simhei.ttf\"\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "#kaggle_zip_path = \"/kaggle/working/train.zip\"\n",
    "#kaggle_extract_path = \"/kaggle/working/trains/\"\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqZSY8dujSo8"
   },
   "source": [
    "# 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sys\n",
    "\n",
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        # Kaggle 环境下的路径设置\n",
    "        # image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        # label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        # zip_path = kaggle_zip_path\n",
    "        # extract_path = kaggle_extract_path\n",
    "\n",
    "        # if not os.path.exists(zip_path):\n",
    "        #     from kaggle_secrets import UserSecretsClient\n",
    "        #     user_secrets = UserSecretsClient()\n",
    "        #     !gdown --id {user_secrets.get_secret(\"train_zip_downloadurl\")}\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据 Resize\n",
    "这一步骤是将图像调整为224x224的大小，以适应模型输入要求。\n",
    "只在Linux运行时使用，因为windows仅用与测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "target_size = (224, 224) # 目标尺寸\n",
    "output_format = \"PNG\" # 输出格式\n",
    "\n",
    "# --- Transformation Definition ---\n",
    "# We will perform Resize on GPU. ToTensor conversion happens before moving to GPU.\n",
    "# Normalization will be done *online* during training dataloading, not offline.\n",
    "resize_transform = transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True)\n",
    "# BILINEAR is a good default. antialias=True is recommended for downsampling.\n",
    "\n",
    "# --- Processing Function ---\n",
    "def resize_and_save_image(img_info, base_input_dir, base_output_dir, transform, device):\n",
    "    \"\"\"\n",
    "    Reads an image, resizes it (potentially on GPU), and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        input_path = os.path.join(base_input_dir, image_folder, f\"{image_folder}.png\")\n",
    "        \n",
    "        # Create corresponding output subdirectory if it doesn't exist\n",
    "        output_folder_path = os.path.join(base_output_dir, image_folder)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder_path, f\"{image_folder}.{output_format.lower()}\")\n",
    "\n",
    "        # 1. Read image using PIL (CPU)\n",
    "        img_pil = Image.open(input_path).convert(\"RGB\")\n",
    "\n",
    "        # 2. Convert PIL image to Tensor (CPU, scales to [0, 1])\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil) # Output: CxHxW\n",
    "\n",
    "        # 3. Move tensor to GPU (if available)\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)\n",
    "\n",
    "        # 4. Apply Resize transform (GPU)\n",
    "        resized_tensor_gpu = transform(img_tensor_gpu)\n",
    "\n",
    "        # 5. Move resized tensor back to CPU\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()\n",
    "\n",
    "        # 6. Convert tensor back to PIL Image (CPU)\n",
    "        # to_pil_image expects CxHxW tensor in [0, 1] range\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)\n",
    "\n",
    "        # 7. Save the resized PIL image (CPU)\n",
    "        resized_img_pil.save(output_path, format=output_format)\n",
    "        \n",
    "        return True # Indicate success\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {input_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像 {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "if not platform.system() == \"Windows\":\n",
    "    if 'google.colab' in sys.modules:\n",
    "        original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        output_dir = os.path.join(colab_extract_path,\"train_resized\")\n",
    "    elif os.path.exists(\"/kaggle/working\"):\n",
    "        original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        output_dir = os.path.join(kaggle_temp_path,\"train_resized\")\n",
    "    else:\n",
    "        print(\"错误: 无法识别的环境\")\n",
    "        exit(1)\n",
    "    image_dir = output_dir\n",
    "\n",
    "    print(f\"输入目录: {original_image_dir}\")\n",
    "    print(f\"输出目录: {output_dir}\")\n",
    "    print(f\"目标尺寸: {target_size}\")\n",
    "\n",
    "    # Create the main output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read label file to know which images to process\n",
    "    try:\n",
    "        labels_df = pd.read_excel(label_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 标签文件未找到 {label_file}\")\n",
    "        sys.exit(1) # Exit if label file is missing\n",
    "\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # Iterate through images listed in the label file\n",
    "    for index, row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Resizing Images\"):\n",
    "        if resize_and_save_image(row, original_image_dir, output_dir, resize_transform, device):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "\n",
    "    print(f\"\\n处理完成!\")\n",
    "    print(f\"成功处理图像数: {success_count}\")\n",
    "    print(f\"处理失败图像数: {error_count}\")\n",
    "    print(f\"处理后的图像保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okNIq-rfjSo-"
   },
   "source": [
    "# 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11JDwC__jSo-"
   },
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # 先放大一点\n",
    "    transforms.RandomCrop((224, 224)), # 随机裁剪回目标尺寸\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
    "    transforms.RandomRotation(degrees=15), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义验证集/测试集的变换 (无需数据增强)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象 (使用不同的 transform)\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=train_transform) # 使用训练变换\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=val_transform) # 使用验证变换\n",
    "\n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=num_workers, pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=num_workers, pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGn3VBzHjSo_"
   },
   "source": [
    "# 构建 ResNet18 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b"
   },
   "outputs": [],
   "source": [
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "# 定义模型\n",
    "model = ResNet18Classifier(num_classes=3)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 将模型移动到 GPU（如果可用）\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCYYlSWDjSpB"
   },
   "source": [
    "# 定义带正则化项的损失函数\n",
    "实现一个包含正则化项的损失函数，使用交叉熵损失作为基础，并添加特定的正则化项来抑制高光问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tVvDaYLjSpB"
   },
   "outputs": [],
   "source": [
    "# 定义损失函数，包含正则化项以抑制高光问题\n",
    "class HighlightRegularizedLoss(nn.Module):\n",
    "    def __init__(self, base_loss_fn, lambda_reg=0.01):\n",
    "        super(HighlightRegularizedLoss, self).__init__()\n",
    "        self.base_loss_fn = base_loss_fn\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets, inputs):\n",
    "        # 基础损失（交叉熵损失）\n",
    "        base_loss = self.base_loss_fn(outputs, targets)\n",
    "\n",
    "        # 正则化项：抑制高光问题（假设高光区域的像素值接近1）\n",
    "        highlight_penalty = torch.mean(torch.clamp(inputs - 0.9, min=0) ** 2)\n",
    "\n",
    "        # 总损失\n",
    "        total_loss = base_loss #+ self.lambda_reg * highlight_penalty\n",
    "        return total_loss\n",
    "\n",
    "# 定义基础损失函数（交叉熵损失）\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义包含正则化项的损失函数\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjMzFIyejSpC"
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam或SGD优化器，学习率调度器和其他训练参数，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NUONUTJjSpC"
   },
   "outputs": [],
   "source": [
    "# 配置优化器和学习率调度器\n",
    "# 在Adam优化器中添加 weight_decay 参数实现L2正则化\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# 定义学习率调度器，采用余弦退火调度策略\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "# 设置其他训练参数\n",
    "num_epochs = 25  # 训练的总轮数\n",
    "log_interval = 10  # 每隔多少个批次打印一次日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dKuzXaHjSpD"
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播和参数更新，并记录训练过程中的指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义早停类\n",
    "from copy import deepcopy\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta # 允许的最小提升量\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "        # 根据模式确定比较操作\n",
    "        if self.mode == 'min':\n",
    "            self.delta_sign = -1 # 对于最小值模式，分数需要减少 delta\n",
    "        else: # mode == 'max'\n",
    "            self.delta_sign = 1 # 对于最大值模式，分数需要增加 delta\n",
    "            \n",
    "    def __call__(self, val_score, model):\n",
    "        score = val_score # 直接使用验证分数\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            # 第一次调用，初始化最佳分数并保存权重\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            print(f\"EarlyStopping: Initialized best score to {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            # 有足够的提升\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            print(f\"EarlyStopping: Improvement found. Best score updated to {self.best_score:.4f}. Counter reset.\")\n",
    "        else:\n",
    "            # 没有足够的提升\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}. Best score remains {self.best_score:.4f}.')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                print(\"EarlyStopping: Patience reached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wq254XdjSpD"
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 初始化 GradScaler\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "# 初始化早停\n",
    "early_stopping = EarlyStopping(patience=5, mode='max')  # 使用验证准确率\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 使用tqdm创建进度条\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # 将数据移动到 GPU（如果可用）\n",
    "\n",
    "        # 训练循环中修改前向传播和反向传播部分\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "        # 前向传播和损失计算使用混合精度\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, inputs)\n",
    "\n",
    "        # 使用scaler进行反向传播\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # 记录损失和准确率\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # 更新进度条信息\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # 获取当前学习率\n",
    "        train_loader_tqdm.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%',\n",
    "            'lr': f'{current_lr:.1e}'\n",
    "        })\n",
    "        \n",
    "        # 打印训练日志\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, Accuracy: {100. * correct / total:.2f}%\")\n",
    "\n",
    "    # 学习率调度器更新\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # 前向传播和计算损失\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets, inputs)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 记录准确率\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # 打印验证结果\n",
    "    tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {100. * correct / total:.2f}%, Val Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {100. * val_correct / val_total:.2f}%\")\n",
    "    \n",
    "    # 早停检测\n",
    "    val_accuracy = 100. * val_correct / val_total\n",
    "    early_stopping(val_accuracy, model)\n",
    "    \n",
    "    # 判断是否需要早停\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"早停触发！在验证集上的表现不再提升。\")\n",
    "        # 恢复最佳模型权重\n",
    "        model.load_state_dict(early_stopping.best_model_weights)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peWRUqyKjSpE"
   },
   "source": [
    "# 评估模型性能\n",
    "在验证集上评估模型性能，计算准确率、混淆矩阵、F1分数等指标，并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzQdrZkTjSpE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 评估模型性能\n",
    "model.eval()  # 设置模型为评估模式\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测结果\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "print(f\"验证集准确率: {accuracy:.4f}\")\n",
    "print(f\"验证集F1分数: {f1:.4f}\")\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"健康\", \"建议观察\", \"建议手术\"],\n",
    "            yticklabels=[\"健康\", \"建议观察\", \"建议手术\"])\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6VojVHqjSpF"
   },
   "source": [
    "# 模型测试和预测\n",
    "使用训练好的模型对新图像进行预测，并展示几个预测示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3PhSqxEjSpF"
   },
   "outputs": [],
   "source": [
    "# 模型测试和预测\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "# 示例预测\n",
    "test_image_dir = \"./test_images\"  # 测试图像文件夹路径\n",
    "test_images = os.listdir(test_image_dir)[:5]  # 获取测试图像文件夹中的前5张图像\n",
    "\n",
    "# 对每张测试图像进行预测并展示结果\n",
    "for image_name in test_images:\n",
    "    image_path = os.path.join(test_image_dir, image_name)\n",
    "    predicted_class = predict_image(model, image_path, transform, device)\n",
    "    class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "    print(f\"图像: {image_name}, 预测类别: {class_names[predicted_class]}\")\n",
    "\n",
    "    # 可视化图像及其预测结果\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"预测类别: {class_names[predicted_class]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNxGokwmjSpG"
   },
   "source": [
    "# 模型保存和加载\n",
    "保存训练好的模型参数，以便将来使用，并展示如何加载保存的模型进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlrrC6tljSpG"
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    \"\"\"\n",
    "    保存模型参数到指定路径\n",
    "    :param model: 训练好的模型\n",
    "    :param path: 保存路径\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载模型参数\n",
    "def load_model(model, path, device):\n",
    "    \"\"\"\n",
    "    从指定路径加载模型参数\n",
    "    :param model: 模型实例\n",
    "    :param path: 模型参数路径\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 加载参数后的模型\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    print(f\"模型参数已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 示例：保存训练好的模型\n",
    "model_save_path = \"./resnet18_pterygium_classifier.pth\"\n",
    "save_model(model, model_save_path)\n",
    "\n",
    "# 示例：加载保存的模型并进行推理\n",
    "loaded_model = ResNet18Classifier(num_classes=3)\n",
    "loaded_model = load_model(loaded_model, model_save_path, device)\n",
    "\n",
    "# 测试加载的模型是否能够正常推理\n",
    "test_image_path = \"./test_images/sample_image.png\"  # 替换为实际测试图像路径\n",
    "predicted_class = predict_image(loaded_model, test_image_path, transform, device)\n",
    "class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "print(f\"加载模型后预测结果: 图像 {os.path.basename(test_image_path)}, 预测类别: {class_names[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
