{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8rV7E66jSoG"
   },
   "source": [
    "# 导入必要的库\n",
    "导入PyTorch、OpenCV、Pandas等必要的库，为图像分类模型做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-siDBWjjSo6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqZSY8dujSo8"
   },
   "source": [
    "# 读取和准备数据\n",
    "从train_classification_label.xlsx读取标签数据，并组织预处理后的图像数据路径。标签包括：0（健康）、1（建议观察）、2（建议手术）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkqTp50SjSo9",
    "outputId": "94d0a742-5487-4279-f124-ecd67b27bd80"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sys\n",
    "\n",
    "# 如果在 Colab 上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('在 Google Colab 环境中运行')\n",
    "    zip_path = \"/content/drive/My Drive/train.zip\"  # 修改为你的 trains.zip 路径\n",
    "    extract_path = \"/content/trains/\"\n",
    "    image_dir = os.path.join(extract_path,\"train\")\n",
    "    label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    if os.path.exists(label_file):\n",
    "        pass\n",
    "    else:\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "else:\n",
    "    print(f'不在 Google Colab 环境中运行,使用本地数据路径{image_dir}')\n",
    "\n",
    "# 自定义数据集类，用于读取图像和标签\n",
    "class PterygiumDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和标签\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应标签\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "\n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 定义图像变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小以适配ResNet18\n",
    "    transforms.ToTensor(),         # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = PterygiumDataset(label_file=label_file, image_dir=image_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okNIq-rfjSo-"
   },
   "source": [
    "# 创建数据加载器\n",
    "使用PyTorch的Dataset和DataLoader类创建数据集和加载器，包括数据增强和训练/验证集的划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11JDwC__jSo-"
   },
   "outputs": [],
   "source": [
    "# 划分训练集和验证集，并创建对应的数据加载器\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集到临时文件\n",
    "train_label_file = os.path.join(image_dir, \"train_classification_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_classification_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集的数据集对象\n",
    "train_dataset = PterygiumDataset(label_file=train_label_file, image_dir=image_dir, transform=transform)\n",
    "val_dataset = PterygiumDataset(label_file=val_label_file, image_dir=image_dir, transform=transform)\n",
    "\n",
    "# 检测操作系统并设置 num_workers\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上，可以尝试使用多进程\n",
    "    num_workers = 2\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    \n",
    "# 创建训练集和验证集的数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGn3VBzHjSo_"
   },
   "source": [
    "# 构建 ResNet18 模型\n",
    "使用PyTorch的预训练ResNet18模型，修改最后的全连接层以适应3个类别的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wYl9yfzjSpA",
    "outputId": "202683a8-91b6-4ab9-b987-aa1f28aa768b"
   },
   "outputs": [],
   "source": [
    "# 构建 ResNet18 模型\n",
    "from torchvision.models import ResNet18_Weights\n",
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        # 加载预训练的 ResNet18 模型\n",
    "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # 替换最后的全连接层以适应3个类别的分类任务\n",
    "        in_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "# 定义模型\n",
    "model = ResNet18Classifier(num_classes=3)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 将模型移动到 GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCYYlSWDjSpB"
   },
   "source": [
    "# 定义带正则化项的损失函数\n",
    "实现一个包含正则化项的损失函数，使用交叉熵损失作为基础，并添加特定的正则化项来抑制高光问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tVvDaYLjSpB"
   },
   "outputs": [],
   "source": [
    "# 定义损失函数，包含正则化项以抑制高光问题\n",
    "class HighlightRegularizedLoss(nn.Module):\n",
    "    def __init__(self, base_loss_fn, lambda_reg=0.01):\n",
    "        super(HighlightRegularizedLoss, self).__init__()\n",
    "        self.base_loss_fn = base_loss_fn\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets, inputs):\n",
    "        # 基础损失（交叉熵损失）\n",
    "        base_loss = self.base_loss_fn(outputs, targets)\n",
    "\n",
    "        # 正则化项：抑制高光问题（假设高光区域的像素值接近1）\n",
    "        highlight_penalty = torch.mean(torch.clamp(inputs - 0.9, min=0) ** 2)\n",
    "\n",
    "        # 总损失\n",
    "        total_loss = base_loss #+ self.lambda_reg * highlight_penalty\n",
    "        return total_loss\n",
    "\n",
    "# 定义基础损失函数（交叉熵损失）\n",
    "base_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义包含正则化项的损失函数\n",
    "criterion = HighlightRegularizedLoss(base_loss_fn=base_loss_fn, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjMzFIyejSpC"
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam或SGD优化器，学习率调度器和其他训练参数，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NUONUTJjSpC"
   },
   "outputs": [],
   "source": [
    "# 配置优化器和学习率调度器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用 Adam 优化器，初始学习率为 0.001\n",
    "\n",
    "# 定义学习率调度器，采用余弦退火调度策略\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "# 设置其他训练参数\n",
    "num_epochs = 25  # 训练的总轮数\n",
    "log_interval = 10  # 每隔多少个批次打印一次日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dKuzXaHjSpD"
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播和参数更新，并记录训练过程中的指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from copy import deepcopy\n",
    "\n",
    "# 定义早停类\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "    def __call__(self, val_score, model):\n",
    "        score = -val_score if self.mode == 'min' else val_score\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wq254XdjSpD"
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 初始化 GradScaler\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "# 初始化早停\n",
    "early_stopping = EarlyStopping(patience=5, mode='max')  # 使用验证准确率\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 使用tqdm创建进度条\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # 将数据移动到 GPU（如果可用）\n",
    "\n",
    "        # 训练循环中修改前向传播和反向传播部分\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "        # 前向传播和损失计算使用混合精度\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, inputs)\n",
    "\n",
    "        # 使用scaler进行反向传播\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # 记录损失和准确率\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # 更新进度条信息\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # 获取当前学习率\n",
    "        train_loader_tqdm.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%',\n",
    "            'lr': f'{current_lr:.1e}'\n",
    "        })\n",
    "        \n",
    "        # 打印训练日志\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, Accuracy: {100. * correct / total:.2f}%\")\n",
    "\n",
    "    # 学习率调度器更新\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # 前向传播和计算损失\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets, inputs)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 记录准确率\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # 打印验证结果\n",
    "    tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {100. * correct / total:.2f}%, Val Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {100. * val_correct / val_total:.2f}%\")\n",
    "    \n",
    "    # 早停检测\n",
    "    val_accuracy = 100. * val_correct / val_total\n",
    "    early_stopping(val_accuracy, model)\n",
    "    \n",
    "    # 判断是否需要早停\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"早停触发！在验证集上的表现不再提升。\")\n",
    "        # 恢复最佳模型权重\n",
    "        model.load_state_dict(early_stopping.best_model_weights)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peWRUqyKjSpE"
   },
   "source": [
    "# 评估模型性能\n",
    "在验证集上评估模型性能，计算准确率、混淆矩阵、F1分数等指标，并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzQdrZkTjSpE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "# 评估模型性能\n",
    "model.eval()  # 设置模型为评估模式\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 获取预测结果\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "print(f\"验证集准确率: {accuracy:.4f}\")\n",
    "print(f\"验证集F1分数: {f1:.4f}\")\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"健康\", \"建议观察\", \"建议手术\"],\n",
    "            yticklabels=[\"健康\", \"建议观察\", \"建议手术\"])\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6VojVHqjSpF"
   },
   "source": [
    "# 模型测试和预测\n",
    "使用训练好的模型对新图像进行预测，并展示几个预测示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3PhSqxEjSpF"
   },
   "outputs": [],
   "source": [
    "# 模型测试和预测\n",
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    使用训练好的模型对单张图像进行预测\n",
    "    :param model: 训练好的模型\n",
    "    :param image_path: 图像路径\n",
    "    :param transform: 图像预处理变换\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 预测类别\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # 加载图像并转换为RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 应用预处理并添加批次维度\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # 前向传播\n",
    "        _, predicted = outputs.max(1)  # 获取预测类别\n",
    "    return predicted.item()\n",
    "\n",
    "# 示例预测\n",
    "test_image_dir = \"./test_images\"  # 测试图像文件夹路径\n",
    "test_images = os.listdir(test_image_dir)[:5]  # 获取测试图像文件夹中的前5张图像\n",
    "\n",
    "# 对每张测试图像进行预测并展示结果\n",
    "for image_name in test_images:\n",
    "    image_path = os.path.join(test_image_dir, image_name)\n",
    "    predicted_class = predict_image(model, image_path, transform, device)\n",
    "    class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "    print(f\"图像: {image_name}, 预测类别: {class_names[predicted_class]}\")\n",
    "\n",
    "    # 可视化图像及其预测结果\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"预测类别: {class_names[predicted_class]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNxGokwmjSpG"
   },
   "source": [
    "# 模型保存和加载\n",
    "保存训练好的模型参数，以便将来使用，并展示如何加载保存的模型进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlrrC6tljSpG"
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    \"\"\"\n",
    "    保存模型参数到指定路径\n",
    "    :param model: 训练好的模型\n",
    "    :param path: 保存路径\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n",
    "\n",
    "# 加载模型参数\n",
    "def load_model(model, path, device):\n",
    "    \"\"\"\n",
    "    从指定路径加载模型参数\n",
    "    :param model: 模型实例\n",
    "    :param path: 模型参数路径\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :return: 加载参数后的模型\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    print(f\"模型参数已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "# 示例：保存训练好的模型\n",
    "model_save_path = \"./resnet18_pterygium_classifier.pth\"\n",
    "save_model(model, model_save_path)\n",
    "\n",
    "# 示例：加载保存的模型并进行推理\n",
    "loaded_model = ResNet18Classifier(num_classes=3)\n",
    "loaded_model = load_model(loaded_model, model_save_path, device)\n",
    "\n",
    "# 测试加载的模型是否能够正常推理\n",
    "test_image_path = \"./test_images/sample_image.png\"  # 替换为实际测试图像路径\n",
    "predicted_class = predict_image(loaded_model, test_image_path, transform, device)\n",
    "class_names = [\"健康\", \"建议观察\", \"建议手术\"]\n",
    "print(f\"加载模型后预测结果: 图像 {os.path.basename(test_image_path)}, 预测类别: {class_names[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
