{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "90ad95fc",
    "language": "markdown"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tokisaki-Galaxy/PterygiumSeg/blob/master/work2_basemode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "ae9dfa31",
    "language": "markdown"
   },
   "source": [
    "# 翼状胬肉区域分割模型\n",
    "\n",
    "这是项目的第二个任务：实现对眼部裂隙灯检查图片中翼状胬肉区域的精准分割。我们将使用U-Net模型解决这一问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "c8b6c127",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import sys\n",
    "import platform\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "%matplotlib inline\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    num_workers = 0\n",
    "    print(f\"检测到 Windows 系统，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "else:\n",
    "    # 在非 Windows 系统（如 Linux/Colab）上\n",
    "    num_workers = 4\n",
    "    print(f\"检测到非 Windows 系统 ({platform.system()})，将 DataLoader 的 num_workers 设置为 {num_workers}。\")\n",
    "    # 设置中文字体\n",
    "    if not os.path.exists('simhei.ttf'):\n",
    "        !wget -O simhei.ttf \"https://www.wfonts.com/download/data/2014/06/01/simhei/chinese.simhei.ttf\"\n",
    "    matplotlib.font_manager.fontManager.addfont('simhei.ttf')\n",
    "    matplotlib.rc('font', family='SimHei')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ================== 数据集路径 =================\n",
    "# 数据路径\n",
    "image_dir =          r\"f:/train\"\n",
    "# colab路径\n",
    "colab_zip_path = \"/content/drive/My Drive/train.zip\"\n",
    "colab_extract_path = \"/content/trains/\"\n",
    "# Kaggle路径\n",
    "kaggle_extract_path = \"/kaggle/input/pterygium/train/\"\n",
    "kaggle_temp_path = \"/kaggle/working/\"\n",
    "\n",
    "# =================== 验证集路径 =================\n",
    "# 验证集路径\n",
    "val_image_dir =      r\"f:/val\"\n",
    "# colab路径\n",
    "# Kaggle路径\n",
    "kaggle_val_path = \"/kaggle/input/pterygium/val_img/\"\n",
    "\n",
    "# ================== 掩码输出路径 ================\n",
    "output_maskfiles = r\"f:/mask\"\n",
    "# colab路径\n",
    "output_maskfiles_colab = \"/content/mask\"\n",
    "# Kaggle路径\n",
    "output_maskfiles_kaggle = \"/kaggle/working/mask\"\n",
    "\n",
    "# 配置GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "print(f\"使用的设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "7f00c3ad",
    "language": "markdown"
   },
   "source": [
    "# 读取和准备数据\n",
    "我们需要读取原始图像和对应的分割标签（mask）。标签中像素值为128的区域表示翼状胬肉，像素值为0的区域表示背景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "64589f50",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 如果在云端上运行，从 Google Drive 读取数据\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print('在 Google Colab 环境中运行')\n",
    "        image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        zip_path = colab_zip_path\n",
    "        extract_path = colab_extract_path\n",
    "\n",
    "        output_dir_to_zip = output_maskfiles_colab\n",
    "        zip_file_path = f\"{output_dir_to_zip}.zip\"\n",
    "        print(f\"Colab 环境：验证结果将验证压缩 {output_dir_to_zip} 到 {zip_file_path}\")\n",
    "\n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print('在 Kaggle 环境中运行')\n",
    "        image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "        val_image_dir = os.path.join(kaggle_val_path,\"val_img\")\n",
    "        \n",
    "        output_dir_to_zip = output_maskfiles_kaggle\n",
    "        zip_file_path = f\"{output_dir_to_zip}.zip\"\n",
    "        print(f\"Kaggle 环境：验证结果将压缩 {output_dir_to_zip} 到 {zip_file_path}\")\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        # 解压数据\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)    \n",
    "else:\n",
    "    print(f'不在云端环境中运行,使用本地数据路径{image_dir}')\n",
    "label_file = os.path.join(image_dir,\"train_classification_label.xlsx\")\n",
    "\n",
    "# 自定义数据集类，用于读取图像和分割掩码\n",
    "class PterygiumSegmentationDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None, mask_transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param label_file: 包含图像标签的Excel文件路径\n",
    "        :param image_dir: 图像文件夹路径\n",
    "        :param transform: 图像变换操作\n",
    "        :param mask_transform: 掩码变换操作\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        # 只保留翼状胬肉样本（标签1和2）\n",
    "        self.labels_df = self.labels_df[self.labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和分割掩码\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应掩码张量\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        \n",
    "        # 加载图像\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 加载分割掩码\n",
    "        mask_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}_label.png\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # 转换为灰度图\n",
    "        \n",
    "        # 应用图像变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 应用掩码变换\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        else:\n",
    "            # 将掩码转换为张量，并二值化（翼状胬肉区域为1，背景为0）\n",
    "            mask = torch.from_numpy(np.array(mask))\n",
    "            mask = mask.float() / 255.0\n",
    "            mask = (mask > 0.2).float()  # 二值化，阈值设为0.2以捕获可能的淡色区域\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "78ebdf92",
    "language": "markdown"
   },
   "source": [
    "# 数据 Resize\n",
    "将图像和掩码调整为统一的大小，以适应模型输入要求。我们使用256x256的分辨率以提高分割精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "14e01367",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "target_size = (256, 256)  # 目标尺寸\n",
    "output_format = \"PNG\"  # 输出格式\n",
    "\n",
    "# --- Transformation Definition ---\n",
    "# 图像变换\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 掩码变换 - 不进行标准化，仅调整大小\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize(target_size, interpolation=transforms.InterpolationMode.NEAREST),  # 使用最近邻插值避免引入新值\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- 处理函数，调整图像和掩码大小 ---\n",
    "def resize_and_save_image_mask_pair(img_info, base_input_dir, base_output_dir, image_transform, mask_transform, device):\n",
    "    \"\"\"\n",
    "    读取图像和掩码，调整大小并保存。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_name = img_info['Image']\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "        \n",
    "        # 输入路径\n",
    "        image_path = os.path.join(base_input_dir, image_folder, f\"{image_folder}.png\")\n",
    "        mask_path = os.path.join(base_input_dir, image_folder, f\"{image_folder}_label.png\")\n",
    "        \n",
    "        # 确保输出目录存在\n",
    "        output_folder_path = os.path.join(base_output_dir, image_folder)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        \n",
    "        # 输出路径\n",
    "        output_image_path = os.path.join(output_folder_path, f\"{image_folder}.{output_format.lower()}\")\n",
    "        output_mask_path = os.path.join(output_folder_path, f\"{image_folder}_label.{output_format.lower()}\")\n",
    "        \n",
    "        # 1. 处理图像\n",
    "        img_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        img_tensor_cpu = transforms.functional.to_tensor(img_pil)  # 转换为张量\n",
    "        img_tensor_gpu = img_tensor_cpu.to(device)  # 移至GPU\n",
    "        resized_tensor_gpu = image_transform(img_tensor_gpu)  # 应用变换\n",
    "        resized_tensor_cpu = resized_tensor_gpu.cpu()  # 移回CPU\n",
    "        resized_img_pil = to_pil_image(resized_tensor_cpu)  # 转回PIL图像\n",
    "        resized_img_pil.save(output_image_path, format=output_format)  # 保存\n",
    "        \n",
    "        # 2. 处理掩码\n",
    "        mask_pil = Image.open(mask_path).convert(\"L\")  # 读取为灰度图\n",
    "        mask_tensor_cpu = transforms.functional.to_tensor(mask_pil)  # 转换为张量\n",
    "        mask_tensor_gpu = mask_tensor_cpu.to(device)  # 移至GPU\n",
    "        resized_mask_gpu = mask_transform(mask_tensor_gpu)  # 应用变换\n",
    "        resized_mask_cpu = resized_mask_gpu.cpu()  # 移回CPU\n",
    "        resized_mask_pil = to_pil_image(resized_mask_cpu)  # 转回PIL图像\n",
    "        resized_mask_pil.save(output_mask_path, format=output_format)  # 保存\n",
    "        \n",
    "        return True  # 表示成功\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误: 文件未找到 {str(e)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理图像和掩码: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# 只在非Windows环境执行数据预处理\n",
    "if not platform.system() == \"Windows\":\n",
    "    if 'google.colab' in sys.modules:\n",
    "        original_image_dir = os.path.join(colab_extract_path,\"train\")\n",
    "        output_dir = os.path.join(colab_extract_path,\"train_seg_resized\")\n",
    "    elif os.path.exists(\"/kaggle/working\"):\n",
    "        original_image_dir = os.path.join(kaggle_extract_path,\"train\")\n",
    "        output_dir = os.path.join(kaggle_temp_path,\"train_seg_resized\")\n",
    "    else:\n",
    "        print(\"错误: 无法识别的环境\")\n",
    "        exit(1)\n",
    "    image_dir = output_dir\n",
    "\n",
    "    print(f\"输入目录: {original_image_dir}\")\n",
    "    print(f\"输出目录: {output_dir}\")\n",
    "    print(f\"目标尺寸: {target_size}\")\n",
    "\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if os.listdir(output_dir):\n",
    "        print(\"检测到已存在的resize数据，跳过resize步骤\")\n",
    "    else:\n",
    "        # 读取标签文件以知道要处理哪些图像\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file)\n",
    "            # 只保留翼状胬肉样本（标签1和2）用于分割训练\n",
    "            pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"错误: 标签文件未找到 {label_file}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "\n",
    "        # 遍历标签文件中列出的图像\n",
    "        for index, row in tqdm(pterygium_df.iterrows(), total=len(pterygium_df), desc=\"Resizing Images and Masks\"):\n",
    "            if resize_and_save_image_mask_pair(row, original_image_dir, output_dir, image_transform, mask_transform, device):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "        print(f\"\\n处理完成!\")\n",
    "        print(f\"成功处理图像和掩码对的数量: {success_count}\")\n",
    "        print(f\"处理失败的图像和掩码对的数量: {error_count}\")\n",
    "        print(f\"处理后的图像和掩码保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "9d732b67",
    "language": "markdown"
   },
   "source": [
    "# 创建数据加载器\n",
    "设置训练和验证数据加载器，包括数据增强策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "2ba9d65a",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 数据增强变换\n",
    "from torchvision.transforms import functional as F\n",
    "import random\n",
    "\n",
    "class SegmentationTransform:\n",
    "    \"\"\"自定义变换，确保图像和掩码进行相同的随机变换\"\"\"\n",
    "    def __init__(self, base_size=256, crop_size=224, flip_prob=0.5, rotation_degrees=15):\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.flip_prob = flip_prob\n",
    "        self.rotation_degrees = rotation_degrees\n",
    "        \n",
    "    def __call__(self, image, mask):\n",
    "        # 调整大小\n",
    "        image = F.resize(image, (self.base_size, self.base_size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        mask = F.resize(mask, (self.base_size, self.base_size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        \n",
    "        # 随机裁剪\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(self.crop_size, self.crop_size))\n",
    "        image = F.crop(image, i, j, h, w)\n",
    "        mask = F.crop(mask, i, j, h, w)\n",
    "        \n",
    "        # 随机水平翻转\n",
    "        if random.random() < self.flip_prob:\n",
    "            image = F.hflip(image)\n",
    "            mask = F.hflip(mask)\n",
    "        \n",
    "        # 随机旋转\n",
    "        angle = random.uniform(-self.rotation_degrees, self.rotation_degrees)\n",
    "        image = F.rotate(image, angle, interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        mask = F.rotate(mask, angle, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        \n",
    "        # 转换为张量\n",
    "        image = F.to_tensor(image)\n",
    "        # 标准化图像\n",
    "        image = F.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        # 掩码转为张量，不需要标准化\n",
    "        mask = torch.from_numpy(np.array(mask))\n",
    "        mask = mask.float() / 255.0\n",
    "        mask = (mask > 0.2).float().unsqueeze(0)  # 添加通道维度\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# 验证集变换 - 仅调整大小，不进行随机变换\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 掩码验证变换\n",
    "val_mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 修改数据集类，使其支持成对变换\n",
    "class PterygiumSegDataset(Dataset):\n",
    "    def __init__(self, label_file, image_dir, transform=None):\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        # 只保留翼状胬肉样本（标签1和2）\n",
    "        self.labels_df = self.labels_df[self.labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图像和分割掩码\n",
    "        :param idx: 索引\n",
    "        :return: 图像张量和对应掩码张量\n",
    "        \"\"\"\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        image_name = row['Image']\n",
    "        label = row['Pterygium'] # 虽然分割任务不需要label，但保留以兼容数据结构\n",
    "        image_folder = f\"{int(image_name):04d}\"\n",
    "\n",
    "        # 加载图像\n",
    "        image_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}.png\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # 加载分割掩码\n",
    "        mask_path = os.path.join(self.image_dir, image_folder, f\"{image_folder}_label.png\")\n",
    "        # 检查掩码文件是否存在（虽然当前逻辑只处理有翼状胬肉的样本，但增加健壮性）\n",
    "        if os.path.exists(mask_path):\n",
    "            mask_rgb = Image.open(mask_path).convert(\"RGB\")\n",
    "            mask_np = np.array(mask_rgb)\n",
    "            # 提取R通道，像素值为128的区域设为1，其他为0\n",
    "            mask_binary = (mask_np[:, :, 0] == 128).astype(np.uint8)\n",
    "            # 转换回单通道灰度PIL图像 (1 -> 255, 0 -> 0) 以便后续transform处理\n",
    "            mask = Image.fromarray(mask_binary * 255, mode='L')\n",
    "        else:\n",
    "            # 如果没有掩码文件，创建一个全黑的掩码\n",
    "            # 注意：这取决于具体任务需求，这里假设必须有掩码\n",
    "            print(f\"掩码文件未找到 {mask_path}, 将使用全零掩码。\")\n",
    "            # 获取图像尺寸以创建匹配的空掩码\n",
    "            img_width, img_height = image.size\n",
    "            mask = Image.new('L', (img_width, img_height), 0)\n",
    "\n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            # 假设transform接受 image 和 mask 作为输入\n",
    "            image, mask = self.transform(image, mask)\n",
    "        else:\n",
    "            # 如果没有特定transform，应用默认变换\n",
    "            # 图像变换\n",
    "            image = F.to_tensor(image)\n",
    "            image = F.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            # 掩码变换 (转换为Tensor，确保为0或1)\n",
    "            mask = transforms.ToTensor()(mask) # 将 PIL (0/255) 转为 Tensor (0.0/1.0)\n",
    "            mask = (mask > 0.5).float() # 确保是严格的0和1\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# 划分训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取标签文件\n",
    "labels_df = pd.read_excel(label_file)\n",
    "# 只保留翼状胬肉样本\n",
    "pterygium_df = labels_df[labels_df['Pterygium'] > 0].reset_index(drop=True)\n",
    "\n",
    "# 按照8:2的比例划分训练集和验证集\n",
    "train_df, val_df = train_test_split(pterygium_df, test_size=0.2, random_state=42, stratify=pterygium_df['Pterygium'])\n",
    "\n",
    "# 保存划分后的数据集\n",
    "train_label_file = os.path.join(image_dir, \"train_segmentation_label_train.xlsx\")\n",
    "val_label_file = os.path.join(image_dir, \"train_segmentation_label_val.xlsx\")\n",
    "if os.path.exists(\"/kaggle/working\"):\n",
    "    train_label_file = os.path.join(kaggle_temp_path, \"train_segmentation_label_train.xlsx\")\n",
    "    val_label_file = os.path.join(kaggle_temp_path, \"train_segmentation_label_val.xlsx\")\n",
    "train_df.to_excel(train_label_file, index=False)\n",
    "val_df.to_excel(val_label_file, index=False)\n",
    "\n",
    "# 创建训练集和验证集\n",
    "seg_transform = SegmentationTransform(base_size=256, crop_size=224, flip_prob=0.5, rotation_degrees=15)\n",
    "train_dataset = PterygiumSegDataset(train_label_file, image_dir, transform=seg_transform)\n",
    "val_dataset = PterygiumSegDataset(val_label_file, image_dir, transform=None)  # 验证集不使用数据增强\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=num_workers, pin_memory=False if platform.system() == \"Windows\" else True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=num_workers, pin_memory=False if platform.system() == \"Windows\" else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "7700c359",
    "language": "markdown"
   },
   "source": [
    "# 构建U-Net分割模型\n",
    "U-Net是一种经典的图像分割模型，其结构包括下采样路径（编码器）和上采样路径（解码器），以及跳跃连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "b1637cba",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"双卷积块：(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下采样层：MaxPool + DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样层：UpConv + DoubleConv（带跳跃连接）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        # 使用双线性插值或转置卷积进行上采样\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # 输入可能不是整数倍的2，需要进行尺寸调整\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # 连接特征图\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"输出卷积层\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"完整的UNet模型\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        # 加载预训练的ResNet-18\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # 编码器部分 (使用ResNet-18的层)\n",
    "        self.inc = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu\n",
    "        ) # 输出通道: 64\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.down1 = resnet.layer1 # 输出通道: 64\n",
    "        self.down2 = resnet.layer2 # 输出通道: 128\n",
    "        self.down3 = resnet.layer3 # 输出通道: 256\n",
    "        self.down4 = resnet.layer4 # 输出通道: 512\n",
    "\n",
    "        # 解码器部分 (调整通道数以匹配ResNet)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.up1 = Up(512 + 256, 512 // factor, bilinear) # down4(512) + down3(256) -> 256\n",
    "        self.up2 = Up(256 + 128, 256 // factor, bilinear) # up1(256) + down2(128) -> 128\n",
    "        self.up3 = Up(128 + 64, 128 // factor, bilinear)  # up2(128) + down1(64) -> 64\n",
    "        self.up4 = Up(64 + 64, 64, bilinear)             # up3(64) + inc(64) -> 64\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码路径 (ResNet)\n",
    "        x1 = self.inc(x)       # (N, 64, H/2, W/2) after initial conv+bn+relu (stride=2)\n",
    "        x_pool = self.maxpool(x1) # (N, 64, H/4, W/4)\n",
    "        x2 = self.down1(x_pool) # (N, 64, H/4, W/4)\n",
    "        x3 = self.down2(x2)     # (N, 128, H/8, W/8)\n",
    "        x4 = self.down3(x3)     # (N, 256, H/16, W/16)\n",
    "        x5 = self.down4(x4)     # (N, 512, H/32, W/32)\n",
    "\n",
    "        # 解码路径 (带跳跃连接)\n",
    "        x = self.up1(x5, x4) # 输入: x5(512), x4(256) -> 输出: 256\n",
    "        x = self.up2(x, x3)  # 输入: x(256), x3(128) -> 输出: 128\n",
    "        x = self.up3(x, x2)  # 输入: x(128), x2(64) -> 输出: 64\n",
    "        x = self.up4(x, x1)  # 输入: x(64), x1(64) -> 输出: 64\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# 初始化模型\n",
    "model = UNet(n_classes=1, bilinear=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "cefa71b2",
    "language": "markdown"
   },
   "source": [
    "# 定义损失函数和评估指标\n",
    "我们使用组合损失函数：二元交叉熵损失和Dice损失的组合，以更好地处理类别不平衡问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "ff097418",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Dice损失函数\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # 使用sigmoid将logits转换为概率\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # 将维度展平\n",
    "        batch_size = targets.size(0)\n",
    "        probs = probs.view(batch_size, -1)\n",
    "        targets = targets.view(batch_size, -1)\n",
    "        \n",
    "        # 计算交集\n",
    "        intersection = (probs * targets).sum(dim=1)\n",
    "        \n",
    "        # 计算Dice系数\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            probs.sum(dim=1) + targets.sum(dim=1) + self.smooth)\n",
    "        \n",
    "        # 返回Dice损失\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# 组合损失：二元交叉熵 + Dice损失\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        bce = self.bce_loss(logits, targets)\n",
    "        dice = self.dice_loss(logits, targets)\n",
    "        return self.bce_weight * bce + self.dice_weight * dice\n",
    "\n",
    "# 评估指标：Dice系数\n",
    "def dice_coefficient(y_pred, y_true, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"计算预测掩码和真实掩码之间的Dice系数\"\"\"\n",
    "    # 应用阈值将概率转换为二值掩码\n",
    "    y_pred = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    \n",
    "    # 压平张量\n",
    "    y_pred = y_pred.contiguous().view(-1)\n",
    "    y_true = y_true.contiguous().view(-1)\n",
    "    \n",
    "    # 计算交集\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    \n",
    "    # 计算Dice系数\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = CombinedLoss(bce_weight=0.6, dice_weight=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "9ee6f7d9",
    "language": "markdown"
   },
   "source": [
    "# 配置优化器和训练参数\n",
    "设置Adam优化器和学习率调度器，为模型训练做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "9cfd0144",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "num_epochs = 30\n",
    "log_interval = 5\n",
    "\n",
    "# 配置优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# 学习率调度器\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6) # 使用基线超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "d6ea8258",
    "language": "markdown"
   },
   "source": [
    "# 训练模型\n",
    "实现训练循环，包括前向传播、损失计算、反向传播、参数更新，并记录训练过程中的指标。同时实现早停机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "67252228",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 定义早停类\n",
    "from copy import deepcopy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "        # 根据模式确定比较操作\n",
    "        if self.mode == 'min':\n",
    "            self.delta_sign = -1  # 对于最小值模式，分数需要减少delta\n",
    "        else:  # mode == 'max'\n",
    "            self.delta_sign = 1  # 对于最大值模式，分数需要增加delta\n",
    "    \n",
    "    def __call__(self, val_score, model):\n",
    "        score = val_score\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            tqdm.write(f\"EarlyStopping: 初始化最佳分数为 {self.best_score:.4f}\")\n",
    "        # 检查是否有足够的提升\n",
    "        elif (score * self.delta_sign) > (self.best_score * self.delta_sign) + self.min_delta:\n",
    "            # 有足够的提升\n",
    "            self.best_score = score\n",
    "            self.best_model_weights = deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            tqdm.write(f\"EarlyStopping: 发现改进。最佳分数更新为 {self.best_score:.4f}。计数器重置。\")\n",
    "        else:\n",
    "            # 没有足够的提升\n",
    "            self.counter += 1\n",
    "            tqdm.write(f'EarlyStopping计数器: {self.counter} (共 {self.patience})。最佳分数仍为 {self.best_score:.4f}。')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                tqdm.write(\"EarlyStopping: 已达到耐心值。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "8226a404",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_validate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \"\"\"\n",
    "    训练并验证模型一个完整的周期，支持早停。\n",
    "    \n",
    "    返回：\n",
    "        - float: 最佳验证Dice系数\n",
    "        - list: 训练Dice系数历史\n",
    "        - list: 验证Dice系数历史\n",
    "        - dict: 最佳模型的state_dict\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"\\n--- 开始训练 ---\")\n",
    "    \n",
    "    # 初始化状态对象\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max')\n",
    "    scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    train_dice_history = []\n",
    "    val_dice_history = []\n",
    "    best_model_state_dict = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_samples = 0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "        \n",
    "        for images, masks in train_loader_tqdm:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 使用混合精度训练\n",
    "            with torch.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            train_dice += dice_coefficient(outputs, masks) * batch_size\n",
    "            train_samples += batch_size\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            train_loader_tqdm.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{dice_coefficient(outputs, masks):.4f}',\n",
    "                'lr': f'{current_lr:.1e}'\n",
    "            })\n",
    "        \n",
    "        train_loss /= train_samples\n",
    "        train_dice /= train_samples\n",
    "        train_dice_history.append(train_dice)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        val_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                # 推理\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                batch_size = images.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                val_dice += dice_coefficient(outputs, masks) * batch_size\n",
    "                val_samples += batch_size\n",
    "        \n",
    "        val_loss /= val_samples\n",
    "        val_dice /= val_samples\n",
    "        val_dice_history.append(val_dice)\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step(val_dice)\n",
    "        \n",
    "        tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Train Dice: {train_dice:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val Dice: {val_dice:.4f}\")\n",
    "        \n",
    "        # 早停检查\n",
    "        early_stopping(val_dice, model)\n",
    "        if early_stopping.early_stop:\n",
    "            tqdm.write(f\"早停触发于第 {epoch + 1} 轮。\")\n",
    "            best_model_state_dict = early_stopping.best_model_weights\n",
    "            break\n",
    "    \n",
    "    # 如果训练正常完成（未早停），也要保存最后的最佳权重\n",
    "    if not early_stopping.early_stop:\n",
    "        tqdm.write(f\"训练在 {num_epochs} 轮后完成。\")\n",
    "        best_model_state_dict = early_stopping.best_model_weights\n",
    "    \n",
    "    # 使用最佳模型进行最终评估\n",
    "    if best_model_state_dict:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "        model.eval()\n",
    "        final_val_dice = 0.0\n",
    "        val_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                batch_size = images.size(0)\n",
    "                final_val_dice += dice_coefficient(outputs, masks) * batch_size\n",
    "                val_samples += batch_size\n",
    "                \n",
    "        final_val_dice /= val_samples\n",
    "    else:\n",
    "        final_val_dice = 0.0\n",
    "        tqdm.write(\"警告：无法获取最佳模型权重。\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"--- 训练完成 ---\")\n",
    "    print(f\"最终验证Dice系数: {final_val_dice:.4f}\")\n",
    "    print(f\"训练耗时: {end_time - start_time:.2f} 秒\")\n",
    "    \n",
    "    return final_val_dice, train_dice_history, val_dice_history, best_model_state_dict\n",
    "\n",
    "# 开始训练\n",
    "best_dice, train_dice_history, val_dice_history, best_model_weights = train_validate_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "0c161af4",
    "language": "markdown"
   },
   "source": [
    "# 评估模型性能\n",
    "可视化学习曲线和分割结果，计算Dice系数和95% Hausdorff距离等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "958069be",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 可视化学习曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_dice_history) + 1), train_dice_history, label='训练Dice系数')\n",
    "plt.plot(range(1, len(val_dice_history) + 1), val_dice_history, label='验证Dice系数')\n",
    "plt.title('训练和验证Dice系数')\n",
    "plt.xlabel('轮次')\n",
    "plt.ylabel('Dice系数')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 可视化分割结果\n",
    "def visualize_segmentation(model, dataloader, num_samples=5):\n",
    "    \"\"\"可视化分割结果\"\"\"\n",
    "    model.eval()\n",
    "    dataiter = iter(dataloader)\n",
    "    \n",
    "    # 获取一批数据\n",
    "    try:\n",
    "        images, masks = next(dataiter)\n",
    "    except StopIteration:\n",
    "        print(\"数据集太小，无法获取足够的样本。\")\n",
    "        return\n",
    "    \n",
    "    # 限制样本数\n",
    "    num_samples = min(num_samples, images.size(0))\n",
    "    \n",
    "    # 进行预测\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        outputs = model(images)\n",
    "        pred_masks = (torch.sigmoid(outputs) > 0.5).float()\n",
    "    \n",
    "    # 反标准化图像以便可视化\n",
    "    images_np = []\n",
    "    for img in images[:num_samples]:\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)  # 转为HWC格式\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        images_np.append(img)\n",
    "    \n",
    "    # 准备掩码和预测\n",
    "    masks_np = masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    pred_masks_np = pred_masks[:num_samples].cpu().numpy().squeeze(1)  # (N, H, W)\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 4 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 原始图像\n",
    "        axes[i, 0].imshow(images_np[i])\n",
    "        axes[i, 0].set_title('原始图像')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 真实掩码\n",
    "        axes[i, 1].imshow(masks_np[i], cmap='gray')\n",
    "        axes[i, 1].set_title('真实掩码')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 预测掩码\n",
    "        axes[i, 2].imshow(pred_masks_np[i], cmap='gray')\n",
    "        dice = dice_coefficient(outputs[i:i+1], masks[i:i+1])\n",
    "        axes[i, 2].set_title(f'预测掩码 (Dice: {dice:.4f})')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可视化一些样本\n",
    "visualize_segmentation(model, val_loader, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "430f63ad",
    "language": "markdown"
   },
   "source": [
    "# 模型保存和加载\n",
    "保存训练好的模型，以便将来加载并用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "1c3ddb6d",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "def save_model(model, path):\n",
    "    \"\"\"保存模型参数到指定路径\"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"模型参数已保存到 {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# 模型预测与应用\n",
    "\n",
    "现在我们已经训练并保存了最佳模型，可以在新的图像上使用它来进行翼状胬肉区域的分割预测。\n",
    "\n",
    "测试数据的组织方式应与 `work1` 类似，通常包含一个图像文件夹。我们需要遍历测试图像，加载它们，进行预处理，然后使用加载的模型进行预测，最后将预测的掩码保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 加载训练好的模型 ---\n",
    "\n",
    "# 确保模型定义可用 (UNet, DoubleConv, Down, Up, OutConv 类需要已定义)\n",
    "# 初始化模型结构\n",
    "\n",
    "\n",
    "loaded_model = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)\n",
    "\n",
    "# 加载最佳权重 (假设 best_model_weights 变量包含 state_dict)\n",
    "if 'best_model_weights' in locals() and best_model_weights is not None:\n",
    "    loaded_model.load_state_dict(best_model_weights)\n",
    "    print(\"成功加载训练好的模型权重。\")\n",
    "else:\n",
    "    # 如果没有 best_model_weights，尝试从文件加载（需要先保存）\n",
    "    model_save_path = \"pterygium_unet_model_best.pth\" # 假设保存的文件名\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "        print(f\"从 {model_save_path} 加载模型权重。\")\n",
    "    else:\n",
    "        print(\"警告: 未找到训练好的模型权重 (best_model_weights 或文件)。模型将使用随机初始化的权重。\")\n",
    "\n",
    "loaded_model.eval() # 设置为评估模式\n",
    "\n",
    "# --- 2. 定义预测所需的辅助函数 ---\n",
    "\n",
    "# 使用验证集的变换来预处理输入图像\n",
    "predict_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True), # 匹配训练尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    \"\"\"加载并预处理单张图像\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = predict_transform(image)\n",
    "        return image_tensor.unsqueeze(0) # 添加 batch 维度\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 图像文件未找到 {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误: 处理图像时出错 {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_single_mask(model, image_tensor, device, threshold=0.5):\n",
    "    \"\"\"使用模型预测单张图像的掩码\"\"\"\n",
    "    if image_tensor is None:\n",
    "        return None\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        predicted_mask = (probabilities > threshold).float()\n",
    "    return predicted_mask.squeeze(0).cpu().numpy() # 移除 batch 维度并转为 numpy\n",
    "\n",
    "# --- 3. 对测试图像进行预测 ---\n",
    "\n",
    "# 假设测试图像在 'f:/test_images/' 目录下\n",
    "os.makedirs(output_maskfiles, exist_ok=True)\n",
    "\n",
    "# 查找所有测试图像 (例如 .png 文件)\n",
    "test_image_paths = glob.glob(os.path.join(output_maskfiles, \"*.png\"))\n",
    "\n",
    "print(f\"找到 {len(test_image_paths)} 张测试图像。\")\n",
    "\n",
    "# 遍历测试图像并进行预测\n",
    "for img_path in tqdm(test_image_paths, desc=\"处理测试图像\"):\n",
    "    print(f\"处理图像: {img_path}\")\n",
    "    input_tensor = preprocess_single_image(img_path)\n",
    "\n",
    "    if input_tensor is not None:\n",
    "        predicted_mask_np = predict_single_mask(loaded_model, input_tensor, device)\n",
    "\n",
    "        if predicted_mask_np is not None:\n",
    "            # predicted_mask_np 是 (1, H, W) 的 numpy 数组，值为 0 或 1\n",
    "            # 可以将其保存为图像文件\n",
    "            mask_image = Image.fromarray((predicted_mask_np.squeeze() * 255).astype(np.uint8), mode='L') # 转换为灰度图\n",
    "            base_name = os.path.basename(img_path)\n",
    "            save_path = os.path.join(output_maskfiles, f\"{os.path.splitext(base_name)[0]}.png\")\n",
    "            mask_image.save(save_path)\n",
    "            print(f\"预测掩码已保存到: {save_path}\")\n",
    "\n",
    "            # 可选：可视化原始图像和预测掩码\n",
    "            original_image = Image.open(img_path)\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axes[0].imshow(original_image)\n",
    "            axes[0].set_title(\"原始图像\")\n",
    "            axes[0].axis('off')\n",
    "            axes[1].imshow(mask_image, cmap='gray')\n",
    "            axes[1].set_title(\"预测掩码\")\n",
    "            axes[1].axis('off')\n",
    "            plt.show()\n",
    "\n",
    "# 如果在 Colab 或 Kaggle 环境中，保存预测结果到指定目录\n",
    "if 'google.colab' in sys.modules or os.path.exists(\"/kaggle/working\"):\n",
    "    if output_dir_to_zip and os.path.exists(output_dir_to_zip) and os.listdir(output_dir_to_zip):\n",
    "        print(f\"开始压缩目录: {output_dir_to_zip}\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                files_to_zip = glob.glob(os.path.join(output_dir_to_zip, '*.*')) # 获取目录下所有文件\n",
    "                if not files_to_zip:\n",
    "                    print(f\"警告: 目录 {output_dir_to_zip} 为空，无需压缩。\")\n",
    "                else:\n",
    "                    for file in tqdm(files_to_zip, desc=\"压缩文件\"):\n",
    "                        # arcname确保zip文件中不包含完整路径，只有文件名\n",
    "                        zipf.write(file, arcname=os.path.basename(file))\n",
    "                    print(f\"预测结果已成功压缩到: {zip_file_path}\")\n",
    "\n",
    "                    # 压缩成功后删除原始文件\n",
    "                    print(f\"开始删除原始掩码文件于: {output_dir_to_zip}\")\n",
    "                    delete_count = 0\n",
    "                    for file in tqdm(files_to_zip, desc=\"删除原始文件\"):\n",
    "                        try:\n",
    "                            os.remove(file)\n",
    "                            delete_count += 1\n",
    "                        except OSError as e:\n",
    "                            print(f\"删除文件 {file} 时出错: {e}\")\n",
    "                    print(f\"已成功删除 {delete_count} 个原始掩码文件。\")\n",
    "                    # 删除空目录\n",
    "                    try:\n",
    "                        os.rmdir(output_dir_to_zip)\n",
    "                        print(f\"已删除空目录: {output_dir_to_zip}\")\n",
    "                    except OSError as e:\n",
    "                        print(f\"删除目录 {output_dir_to_zip} 时出错: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"压缩或删除文件时发生错误: {e}\")\n",
    "    elif output_dir_to_zip:\n",
    "        print(f\"目录 {output_dir_to_zip} 不存在或为空，跳过压缩和删除步骤。\")\n",
    "\n",
    "\n",
    "print(\"\\n预测处理完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
